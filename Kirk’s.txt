Let's modify the code to use the Azure OpenAI REST API directly with the DefaultAzureCredential:

```python
import os
import pandas as pd
from azure.identity import DefaultAzureCredential
import requests
import logging
import urllib.parse
import json

# Set up logging
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Configure SSL and proxy settings
proxy_username = "ad_username"
proxy_password = "ad_pwd"
proxy_host = "abc.proxy.com"
proxy_port = "80"

encoded_username = urllib.parse.quote(proxy_username)
encoded_password = urllib.parse.quote(proxy_password)

proxy_url = f"http://{encoded_username}:{encoded_password}@{proxy_host}:{proxy_port}"

# Set proxy and SSL settings
proxies = {
    'http': proxy_url,
    'https': proxy_url
}

try:
    # Get Azure AD token
    credential = DefaultAzureCredential()
    token = credential.get_token("https://cognitiveservices.azure.com/.default")
    
    def get_embeddings(texts, endpoint, deployment_name="text-embedding-ada-002", batch_size=100):
        """
        Generate embeddings using Azure OpenAI REST API directly
        """
        headers = {
            'Authorization': f'Bearer {token.token}',
            'Content-Type': 'application/json'
        }
        
        api_url = f"{endpoint}/openai/deployments/{deployment_name}/embeddings?api-version=2024-02-01"
        
        embeddings = []
        
        # Process in batches
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            try:
                payload = {
                    "input": batch
                }
                
                response = requests.post(
                    api_url,
                    headers=headers,
                    json=payload,
                    proxies=proxies,
                    verify='cacert.pem'
                )
                
                if response.status_code == 200:
                    response_data = response.json()
                    batch_embeddings = [item['embedding'] for item in response_data['data']]
                    embeddings.extend(batch_embeddings)
                    logger.debug(f"Successfully processed batch {i//batch_size + 1}")
                else:
                    logger.error(f"Error in batch {i//batch_size + 1}: {response.text}")
                    embeddings.extend([None] * len(batch))
                    
            except Exception as e:
                logger.error(f"Error processing batch starting at index {i}: {str(e)}")
                embeddings.extend([None] * len(batch))
                
        return embeddings

    # Test function
    def test_connection(endpoint):
        try:
            # Test with a single embedding
            test_texts = ["Hello, world!"]
            embeddings = get_embeddings(test_texts, endpoint)
            
            if embeddings and embeddings[0]:
                print("Successfully generated test embedding!")
                print(f"Embedding dimension: {len(embeddings[0])}")
                return True
            else:
                print("Failed to generate test embedding")
                return False
                
        except Exception as e:
            print(f"Test failed: {str(e)}")
            return False

except Exception as e:
    logger.error(f"Setup error: {str(e)}")
    raise

# Usage example:
if __name__ == "__main__":
    # Replace with your endpoint
    azure_endpoint = "your_endpoint"
    
    # Test the connection
    test_connection(azure_endpoint)
    
    # Process your CSV
    # df = pd.read_csv('your_file.csv')
    # texts = df['text'].tolist()
    # embeddings = get_embeddings(texts, azure_endpoint)
    # df['embeddings'] = embeddings
    # df.to_csv('data_with_embeddings.csv', index=False)
```

Key changes made:
1. Removed OpenAI client dependency and using direct REST API calls
2. Using DefaultAzureCredential for authentication
3. Simplified proxy and SSL configuration using requests
4. Added detailed error logging
5. Maintained batch processing capability

To use this code:
1. Replace "your_endpoint" with your Azure OpenAI endpoint
2. Update the proxy credentials if needed
3. Make sure your deployment_name matches your Azure OpenAI deployment
4. Verify that cacert.pem is in the correct location

You can process your CSV data like this:

```python
# Read and process your CSV
df = pd.read_csv('your_file.csv')
texts = df['text'].tolist()  # Adjust column name as needed

# Generate embeddings
embeddings = get_embeddings(texts, azure_endpoint)

# Add embeddings to dataframe
df['embeddings'] = embeddings

# Save results
df.to_csv('data_with_embeddings.csv', index=False)
```

Let me know if you need any adjustments or encounter any issues!​​​​​​​​​​​​​​​​
