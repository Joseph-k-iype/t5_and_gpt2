import os
import time
import logging
import re
import uuid
import json
import pandas as pd
from pathlib import Path
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv, dotenv_values
import requests
import chromadb
from chromadb.config import Settings
from azure.identity import ClientSecretCredential, get_bearer_token_provider
from langchain.chat_models import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# ------------------------------
# Logging Configuration
# ------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ------------------------------
# Helper Functions
# ------------------------------
def is_file_readable(filepath: str) -> bool:
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str) -> bool:
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean string: {s}")

def stable_chunk_text(text: str, max_chars: int = 1000) -> List[str]:
    """Chunk text into smaller pieces at sentence boundaries."""
    sentences = re.split(r'(?<=[.!?])\s+', text)
    chunks = []
    current_chunk = ""
    for sentence in sentences:
        if len(current_chunk) + len(sentence) + 1 <= max_chars:
            current_chunk = (current_chunk + " " + sentence).strip() if current_chunk else sentence
        else:
            chunks.append(current_chunk)
            current_chunk = sentence
    if current_chunk:
        chunks.append(current_chunk)
    return chunks

# ------------------------------
# OSEnv Class: Environment, Proxy, Certificate, and Token Management
# ------------------------------
class OSEnv:
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.bulk_set(config_file, True)
        logger.info(f"Loaded main configuration from {config_file}")
        self.bulk_set(creds_file, False)
        logger.info(f"Loaded credentials from {creds_file}")
        self.set_certificate_path(certificate_path)
        logger.info("Certificate path configured")
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
            logger.info("Proxy configured")
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            logger.info("Securing endpoints using Azure AD")
            self.token = self.get_azure_token()
        else:
            self.token = None

    def set_certificate_path(self, certificate_path: str) -> None:
        if not os.path.isabs(certificate_path):
            certificate_path = os.path.abspath(certificate_path)
        if not is_file_readable(certificate_path):
            raise Exception("Certificate file missing or not readable")
        self.set("REQUESTS_CA_BUNDLE", certificate_path)
        self.set("SSL_CERT_FILE", certificate_path)
        self.set("CURL_CA_BUNDLE", certificate_path)
        logger.info(f"Certificate path set to: {certificate_path}")

    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        if not os.path.isabs(dotenvfile):
            dotenvfile = os.path.abspath(dotenvfile)
        if is_file_readable(dotenvfile):
            logger.info(f"Loading environment variables from {dotenvfile}")
            temp_dict = dotenv_values(dotenvfile)
            for k, v in temp_dict.items():
                self.set(k, v, print_val)
            del temp_dict

    def set(self, var_name: str, val: str, print_val: bool = True) -> None:
        os.environ[var_name] = val
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if print_val:
            logger.info(f"Set {var_name}={val}")

    def get(self, var_name: str, default: Optional[str] = None) -> Optional[str]:
        return os.environ.get(var_name, default)

    def set_proxy(self) -> None:
        ad_username = self.get("AD_USERNAME")
        ad_password = self.get("AD_USER_PW")
        proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
        if not all([ad_username, ad_password, proxy_domain]):
            raise ValueError("Missing proxy credentials")
        proxy_url = f"http://{ad_username}:{ad_password}@{proxy_domain}"
        self.set("HTTP_PROXY", proxy_url, print_val=False)
        self.set("HTTPS_PROXY", proxy_url, print_val=False)
        no_proxy_domains = ['cognitiveservices.azure.com', 'search.windows.net', 'openai.azure.com', 'core.windows.net', 'azurewebsites.net']
        self.set("NO_PROXY", ",".join(no_proxy_domains))
        logger.info("Proxy configuration completed")

    def get_azure_token(self) -> str:
        credential = ClientSecretCredential(
            tenant_id=self.get("AZURE_TENANT_ID"),
            client_id=self.get("AZURE_CLIENT_ID"),
            client_secret=self.get("AZURE_CLIENT_SECRET")
        )
        token = credential.get_token("https://cognitiveservices.azure.com/.default")
        self.set("AZURE_TOKEN", token.token, print_val=False)
        logger.info("Azure token acquired successfully")
        return token.token

    def list_env_vars(self) -> None:
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [HIDDEN]")
            else:
                logger.info(f"{var}: {self.get(var)}")

# ------------------------------
# AzureChatbot: For validation using Azure OpenAI (LangChain)
# ------------------------------
class AzureChatbot:
    def __init__(self, config_file: str, creds_file: str, cert_file: str):
        logger.info("Initializing chatbot...")
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()

    def _setup_chat_model(self) -> None:
        api_key = self.env.get("AZURE_OPENAI_API_KEY")
        endpoint = self.env.get("AZURE_OPENAI_ENDPOINT")
        api_version = self.env.get("API_VERSION", "2024-02-01")
        model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
        temperature = float(self.env.get("MODEL_TEMPERATURE", "0.7"))
        max_tokens = int(self.env.get("MAX_TOKENS", "800"))
        if api_key:
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                openai_api_version=api_version,
                azure_endpoint=endpoint,
                openai_api_key=api_key
            )
        else:
            if not self.env.token:
                raise ValueError("Missing credentials: please provide AZURE_OPENAI_API_KEY or set SECURED_ENDPOINTS to True")
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                openai_api_version=api_version,
                azure_endpoint=endpoint,
                azure_ad_token=self.env.token
            )
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
        logger.info("Chat model initialized successfully")

    def validate_matches(self, query: str, matches: List[Dict[str, Any]]) -> str:
        prompt = f"""You are an expert validation agent. Given the query:
"{query}"
and the following candidate matches:
"""
        for idx, match in enumerate(matches, start=1):
            prompt += f"\n{idx}. Name: {match.get('name')}\n   Definition: {match.get('definition')}\n"
        prompt += "\nIf these matches are satisfactory, simply reply OK. Otherwise, suggest the best matching candidate from our knowledge base in the format:\nName: <name>\nDefinition: <definition>\nExplanation: <brief explanation>."
        try:
            response = self.conversation.predict(input=prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"Validation agent error: {str(e)}")
            return "Validation failed"

    def chat(self, message: str) -> str:
        if not message.strip():
            return "Please provide a non-empty message."
        try:
            response = self.conversation.predict(input=message)
            return response
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return f"An error occurred: {str(e)}"

# ------------------------------
# AzureEmbeddingClient: For generating embeddings via Azure OpenAI
# ------------------------------
class AzureEmbeddingClient:
    def __init__(self, env: OSEnv):
        self.env = env
        endpoint = self.env.get("AZURE_OPENAI_EMBEDDINGS_ENDPOINT")
        if not endpoint:
            raise ValueError("Missing AZURE_OPENAI_EMBEDDINGS_ENDPOINT in environment")
        if "/openai" not in endpoint:
            endpoint = endpoint.rstrip("/") + "/openai"
        self.endpoint = endpoint
        self.deployment = self.env.get("EMBEDDINGS_DEPLOYMENT", "text-embedding-3-large")
        self.api_version = self.env.get("EMBEDDINGS_API_VERSION", "2023-05-15")
        proxy = self.env.get("HTTP_PROXY")
        self.session = requests.Session()
        self.session.trust_env = False
        self.session.verify = self.env.get("REQUESTS_CA_BUNDLE", "cacert.pem")
        if proxy:
            self.session.proxies = {"http": proxy, "https": proxy}
        logger.info("AzureEmbeddingClient session configured")
        
    def get_embeddings(self, texts: List[str], batch_size: int = 100) -> List[Optional[List[float]]]:
        headers = {
            'Authorization': f'Bearer {self.env.token}',
            'Content-Type': 'application/json'
        }
        api_url = f"{self.endpoint}/deployments/{self.deployment}/embeddings?api-version={self.api_version}"
        logger.info(f"Requesting embeddings from URL: {api_url}")
        all_embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            payload = {"input": batch}
            try:
                response = self.session.post(api_url, headers=headers, json=payload)
                if response.status_code == 200:
                    data = response.json()
                    batch_embeds = [item.get("embedding") for item in data.get("data", [])]
                    all_embeddings.extend(batch_embeds)
                    logger.info(f"Received embeddings for batch {i+1}-{min(i+batch_size, len(texts))}")
                else:
                    logger.error(f"Failed for batch {i+1}-{min(i+batch_size, len(texts))} (status {response.status_code}): {response.text}")
                    all_embeddings.extend([None] * len(batch))
            except Exception as e:
                logger.error(f"Error processing batch {i+1}-{min(i+batch_size, len(texts))}: {str(e)}")
                all_embeddings.extend([None] * len(batch))
        return all_embeddings

# ------------------------------
# VectorStoreManager: Manage local ChromaDB storage
# ------------------------------
class VectorStoreManager:
    def __init__(self, persist_dir: str = "./chroma_db"):
        # Remove the anonymized_telemetry parameter as it is unexpected
        self.client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.client.get_or_create_collection(name="knowledge_base")
        logger.info("ChromaDB collection initialized locally")

    def add_documents(self, documents: List[Dict[str, Any]], embeddings: List[List[float]]):
        if len(documents) != len(embeddings):
            raise ValueError("Documents and embeddings count mismatch")
        ids = [str(uuid.uuid4()) for _ in documents]
        metadatas = [{"name": doc["name"], "definition": doc["definition"]} for doc in documents]
        contents = [doc["name"] + "\n" + doc["definition"] for doc in documents]
        self.collection.add(ids=ids, documents=contents, embeddings=embeddings, metadatas=metadatas)
        logger.info(f"Added {len(documents)} documents to the vector store")

    def query(self, query_embedding: List[float], n_results: int = 4) -> List[Dict[str, Any]]:
        results = self.collection.query(query_embedding, n_results=n_results)
        matches = []
        if results and "metadatas" in results:
            for meta in results["metadatas"]:
                matches.append(meta)
        return matches

# ------------------------------
# CSV Processing Functions
# ------------------------------
def load_csv_as_documents(csv_path: str) -> List[Dict[str, Any]]:
    df = pd.read_csv(csv_path)
    if not {"name", "definition"}.issubset(set(df.columns)):
        raise ValueError("CSV must contain 'name' and 'definition' columns")
    documents = []
    for _, row in df.iterrows():
        combined = f"{row['name']}\n{row['definition']}"
        # Optionally perform chunking if needed (here we assume one chunk per row)
        documents.append({"name": row["name"], "definition": row["definition"], "combined": combined})
    return documents

def save_results_to_csv(results: List[Dict[str, Any]], output_path: str) -> None:
    df = pd.DataFrame(results)
    df.to_csv(output_path, index=False)
    logger.info(f"Results saved to {output_path}")

# ------------------------------
# Main Function: Workflow
# ------------------------------
def main():
    try:
        base_dir = Path(__file__).resolve().parent / "env"
        config_path = str(base_dir / "config.env")
        creds_path = str(base_dir / "credentials.env")
        cert_path = str(base_dir / "cacert.pem")
        for f in [config_path, creds_path, cert_path]:
            if not os.path.exists(f):
                print(f"Missing required file: {f}")
                return
        
        logger.info("Initializing environment...")
        env = OSEnv(config_path, creds_path, cert_path)
        
        logger.info("Initializing chatbot agent (for match validation)...")
        chatbot = AzureChatbot(config_path, creds_path, cert_path)
        
        logger.info("Initializing Azure embedding client...")
        embed_client = AzureEmbeddingClient(env)
        
        logger.info("Initializing local ChromaDB vector store...")
        vector_store = VectorStoreManager(persist_dir="./chroma_db")
        
        # STEP 1: Ingest Knowledge Base from CSV
        kb_csv = input("Enter path to knowledge base CSV: ").strip()
        kb_documents = load_csv_as_documents(kb_csv)
        combined_texts = [doc["combined"] for doc in kb_documents]
        logger.info("Generating embeddings for knowledge base documents...")
        kb_embeddings = embed_client.get_embeddings(combined_texts)
        vector_store.add_documents(kb_documents, kb_embeddings)
        
        # STEP 2: Process Query CSV and perform vector matching
        query_csv = input("Enter path to query CSV: ").strip()
        query_df = pd.read_csv(query_csv)
        if not {"name", "definition"}.issubset(set(query_df.columns)):
            raise ValueError("Query CSV must contain 'name' and 'definition' columns")
        
        results = []
        for index, row in query_df.iterrows():
            query_text = f"{row['name']}\n{row['definition']}"
            logger.info(f"Processing query {index+1}: {row['name']}")
            query_embedding = embed_client.get_embeddings([query_text])[0]
            matches = vector_store.query(query_embedding, n_results=4)
            validation_prompt = f"""You are an expert validation agent. Given the query:
"{query_text}"
and the following candidate matches:
"""
            for idx, match in enumerate(matches, start=1):
                validation_prompt += f"\n{idx}. Name: {match.get('name')}\n   Definition: {match.get('definition')}\n"
            validation_prompt += "\nIf these matches are satisfactory, simply reply OK. Otherwise, suggest the best matching candidate from our knowledge base in the format:\nName: <name>\nDefinition: <definition>\nExplanation: <brief explanation>."
            validation_response = chatbot.validate_matches(query_text, matches)
            
            results.append({
                "query_name": row["name"],
                "query_definition": row["definition"],
                "matches": json.dumps(matches),
                "validation": validation_response
            })
        
        output_csv = input("Enter path for output CSV (e.g., output.csv): ").strip()
        save_results_to_csv(results, output_csv)
        print("Workflow completed successfully.")
        
    except Exception as e:
        logger.exception(f"Unexpected error: {str(e)}")
        print(f"An error occurred: {str(e)}")

if __name__ == "__main__":
    main()
