import os
import json
from azure.identity import ClientSecretCredential
from langchain_openai import AzureOpenAI  # latest non-deprecated class
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# ========= Corporate Proxy & Custom CA Configuration =========
# Set your proxy credentials and host details
AD_USERNAME = "your_ad_username"       # e.g. "john.doe"
AD_USERID   = "your_ad_userid"         # e.g. your proxy password or identifier
PROXY_HOST  = "abc.com"
PROXY_PORT  = "80"

# Build the proxy URL and set environment variables so that underlying HTTP calls use your proxy and custom CA
proxy_url = f"http://{AD_USERNAME}:{AD_USERID}@{PROXY_HOST}:{PROXY_PORT}"
os.environ["HTTP_PROXY"]  = proxy_url
os.environ["HTTPS_PROXY"] = proxy_url
os.environ["REQUESTS_CA_BUNDLE"] = "cacert.pem"  # Path to your custom CA certificate file

# ========= Azure Identity & OpenAI Configuration =========
# Set your Azure AD service principal credentials explicitly
CLIENT_ID = os.getenv("AZURE_CLIENT_ID", "your_azure_client_id")
CLIENT_SECRET = os.getenv("AZURE_CLIENT_SECRET", "your_azure_client_secret")
TENANT_ID = os.getenv("AZURE_TENANT_ID", "your_azure_tenant_id")

# Azure OpenAI instance details (replace with your actual values)
AZURE_OPENAI_INSTANCE = "your_resource_name"  # e.g. "myresource" (without protocol)
API_VERSION = "2023-06-01-preview"            # Adjust as needed
DEPLOYMENT_NAME = "gpt-4o-mini"                 # Your deployment name in Azure OpenAI

# ========= Create Credential and Token Provider =========
# Use ClientSecretCredential to explicitly pass client ID, client secret, and tenant ID
credential = ClientSecretCredential(
    tenant_id=TENANT_ID,
    client_id=CLIENT_ID,
    client_secret=CLIENT_SECRET
)

def azure_ad_token_provider():
    # Return a token for the Cognitive Services scope using the service principal
    return credential.get_token("https://cognitiveservices.azure.com/.default").token

# ========= Instantiate the LangChain LLM =========
# Use the new AzureOpenAI class with azureADTokenProvider
llm = AzureOpenAI(
    azureADTokenProvider=azure_ad_token_provider,  # function that returns a bearer token
    azureOpenAIApiInstanceName=f"{AZURE_OPENAI_INSTANCE}.openai.azure.com",
    azureOpenAIApiDeploymentName=DEPLOYMENT_NAME,
    azureOpenAIApiVersion=API_VERSION,
    temperature=0.7,  # adjust as needed
)

print("Azure AD token acquired and AzureOpenAI LLM configured using ClientSecretCredential.")

# ========= Build a LangChain LLMChain =========
prompt_template = PromptTemplate(
    input_variables=["question"],
    template="Answer the following question concisely:\n\n{question}"
)
chain = LLMChain(llm=llm, prompt=prompt_template)

# ========= Run the Chain with an Example Question =========
question = "What is the capital of France?"
result = chain.run(question)
print("Chain output:")
print(result)

# ========= Visualize the Chain using LangGraph =========
try:
    from langgraph import Graph
    graph = Graph.from_chain(chain)
    graph.render()
except Exception as e:
    print("LangGraph visualization is unavailable or failed:")
    print(e)
