pip install azure-identity langchain-openai langchain langgraph
```)
and replace the placeholder strings (for credentials, instance names, etc.) with your actual values.

```python
import os
import json
from azure.identity import DefaultAzureCredential
from langchain_openai import AzureOpenAI  # latest, non-deprecated class
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# ========= Corporate Proxy & Custom CA Configuration =========
# Set your proxy credentials and host details
AD_USERNAME = "your_ad_username"       # e.g. "john.doe"
AD_USERID   = "your_ad_userid"         # e.g. your proxy password or identifier
PROXY_HOST  = "abc.com"
PROXY_PORT  = "80"

# Build the proxy URL and set environment variables so that underlying HTTP calls use your proxy and custom CA
proxy_url = f"http://{AD_USERNAME}:{AD_USERID}@{PROXY_HOST}:{PROXY_PORT}"
os.environ["HTTP_PROXY"]  = proxy_url
os.environ["HTTPS_PROXY"] = proxy_url
os.environ["REQUESTS_CA_BUNDLE"] = "cacert.pem"  # Path to your custom CA certificate file

# ========= Azure OpenAI Configuration =========
# Set your Azure OpenAI instance details
# (Replace <your-resource-name> with your Azure OpenAI resource name; do not include protocol)
AZURE_OPENAI_INSTANCE = "your_resource_name"  # e.g. "myresource"
API_VERSION = "2023-06-01-preview"            # Adjust as needed
DEPLOYMENT_NAME = "gpt-4o-mini"                 # Your deployment name in Azure OpenAI

# ========= Azure Identity Token Provider =========
# Use DefaultAzureCredential to obtain an Azure AD token
credential = DefaultAzureCredential()

def azure_ad_token_provider():
    # Returns a token for the Cognitive Services scope
    return credential.get_token("https://cognitiveservices.azure.com/.default").token

# ========= Instantiate the LangChain LLM =========
# Note: We no longer use the deprecated AzureChatOpenAI; instead, we use AzureOpenAI.
llm = AzureOpenAI(
    azureADTokenProvider=azure_ad_token_provider,  # This function will be called on each request
    azureOpenAIApiInstanceName=f"{AZURE_OPENAI_INSTANCE}.openai.azure.com",
    azureOpenAIApiDeploymentName=DEPLOYMENT_NAME,
    azureOpenAIApiVersion=API_VERSION,
    temperature=0.7,  # adjust as needed
)

print("Azure AD token acquired and AzureOpenAI LLM configured using Azure Identity.")

# ========= Build a LangChain LLMChain =========
prompt_template = PromptTemplate(
    input_variables=["question"],
    template="Answer the following question concisely:\n\n{question}"
)
chain = LLMChain(llm=llm, prompt=prompt_template)

# ========= Run the Chain with an Example Question =========
question = "What is the capital of France?"
result = chain.run(question)
print("Chain output:")
print(result)

# ========= Visualize the Chain using LangGraph =========
try:
    from langgraph import Graph
    graph = Graph.from_chain(chain)
    graph.render()
except Exception as e:
    print("LangGraph visualization is unavailable or failed:")
    print(e)
