def _init_embeddings(self) -> AzureOpenAIEmbeddings:
    """Initialize Azure OpenAI embeddings with proper connection handling."""
    try:
        # Get fresh token
        token = self.env.get_azure_token(force_refresh=True)
        
        # Validate required environment variables
        azure_endpoint = str(self.env.get("AZURE_OPENAI_ENDPOINT"))
        deployment = str(self.env.get("AZURE_EMBEDDING_DEPLOYMENT"))
        api_version = str(self.env.get("AZURE_API_VERSION"))
        
        if not all([azure_endpoint, deployment, api_version]):
            raise ValueError("Missing required Azure OpenAI configuration")
        
        # Configure embeddings with explicit settings
        embeddings = AzureOpenAIEmbeddings(
            azure_endpoint=azure_endpoint,
            deployment=deployment,
            api_version=api_version,
            azure_ad_token=token,
            chunk_size=16,  # Smaller batch size for reliability
            max_retries=3,  # Add retries for reliability
            timeout=30.0,   # Increase timeout
            http_client=None  # Let the SDK handle HTTP client
        )
        
        # Test connection with a simple embedding
        try:
            logger.info("Testing Azure OpenAI connection...")
            test_result = embeddings.embed_query("test connection")
            if test_result and len(test_result) > 0:
                logger.info(f"Successfully connected to Azure OpenAI. Embedding dimension: {len(test_result)}")
            else:
                raise ValueError("Embedding test returned empty result")
                
        except Exception as e:
            raise ConnectionError(f"Failed to connect to Azure OpenAI: {str(e)}")
        
        return embeddings
        
    except Exception as e:
        logger.error(f"Failed to initialize Azure OpenAI embeddings: {str(e)}")
        raise

def create_collection(self, csv_path: Path, text_columns: List[str], 
                     chunk_size: int = 1000, chunk_overlap: int = 100,
                     separator: str = " | ", batch_size: int = 100) -> None:
    """Create Chroma collection with improved error handling."""
    try:
        logger.info(f"Reading CSV file: {csv_path}")
        df = self._read_csv_safely(csv_path)
        
        missing_cols = [col for col in text_columns if col not in df.columns]
        if missing_cols:
            raise ValueError(f"Columns not found in CSV: {', '.join(missing_cols)}")
        
        logger.info(f"Processing columns: {', '.join(text_columns)}")
        all_documents = []
        total_rows = len(df)
        
        # Process in smaller batches
        for start_idx in range(0, total_rows, batch_size):
            end_idx = min(start_idx + batch_size, total_rows)
            batch_df = df.iloc[start_idx:end_idx]
            
            batch_documents = self._process_csv_multi_column(
                batch_df, text_columns, chunk_size, chunk_overlap, separator
            )
            all_documents.extend(batch_documents)
            
            logger.info(f"Processed rows {start_idx + 1} to {end_idx} of {total_rows}")
        
        self.collection_name = csv_path.stem.lower()
        persist_directory = self.env.get("CHROMA_PERSIST_DIR", "./chroma_db")
        os.makedirs(persist_directory, exist_ok=True)
        
        # Create embeddings with retry logic
        max_retries = 3
        retry_delay = 5  # seconds
        
        for attempt in range(max_retries):
            try:
                logger.info(f"Attempt {attempt + 1} of {max_retries} to create embeddings...")
                
                # Refresh token before creating embeddings
                if attempt > 0:
                    self.embeddings = self._init_embeddings()
                
                self.vector_store = Chroma.from_documents(
                    documents=all_documents,
                    embedding=self.embeddings,
                    collection_name=self.collection_name,
                    persist_directory=persist_directory,
                    client=self.client
                )
                
                logger.info(f"Created collection '{self.collection_name}' with {len(all_documents)} documents")
                self.vector_store.persist()
                logger.info(f"Vectors stored locally in {persist_directory}")
                break
                
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"Attempt {attempt + 1} failed: {str(e)}. Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                else:
                    raise Exception(f"Failed to create embeddings after {max_retries} attempts: {str(e)}")
        
    except Exception as e:
        logger.error(f"Collection creation failed: {str(e)}")
        raise
