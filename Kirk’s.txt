import os
import time
import glob
import logging
from pathlib import Path
from typing import Optional, List

from dotenv import dotenv_values
from azure.identity import ClientSecretCredential

# Import Azure-specific chat model and CSV loader from langchain_openai and langchain
from langchain_openai import AzureChatOpenAI
from langchain.schema import SystemMessage
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.document_loaders import CSVLoader

# --------------------- Logging Configuration ---------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --------------------- Utility Functions ---------------------
def is_file_readable(filepath: str) -> bool:
    """Check if a file exists and is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str) -> bool:
    """Convert a string to a boolean."""
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean string: {s}")

# --------------------- Environment Setup ---------------------
class OSEnv:
    """Environment variable and certificate management."""
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []  # Track variables set via this class
        
        # Load configuration and credentials
        self.bulk_set(config_file, print_val=True)
        logger.info(f"Loaded main configuration from {config_file}")
        self.bulk_set(creds_file, print_val=False)
        logger.info(f"Loaded credentials from {creds_file}")
        
        # Set up certificates
        self.set_certificate_path(certificate_path)
        logger.info("Certificate path configured")
        
        # Configure proxy if enabled
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
            logger.info("Proxy configured")
        
        # Acquire Azure token if secure endpoints are enabled
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            logger.info("Securing endpoints")
            self.token = self.get_azure_token()
        else:
            self.token = None

    def set_certificate_path(self, certificate_path: str) -> None:
        """Set the certificate path for SSL verification."""
        if not os.path.isabs(certificate_path):
            certificate_path = os.path.abspath(certificate_path)
        if not is_file_readable(certificate_path):
            raise Exception("Certificate file missing or not readable")
        self.set("REQUESTS_CA_BUNDLE", certificate_path)
        self.set("SSL_CERT_FILE", certificate_path)
        self.set("CURL_CA_BUNDLE", certificate_path)
        logger.info(f"Certificate path set to: {certificate_path}")

    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        """Load environment variables from a dotenv file."""
        if not os.path.isabs(dotenvfile):
            dotenvfile = os.path.abspath(dotenvfile)
        if is_file_readable(dotenvfile):
            logger.info(f"Loading environment variables from {dotenvfile}")
            temp_dict = dotenv_values(dotenvfile)
            for k, v in temp_dict.items():
                self.set(k, v, print_val)
        else:
            raise FileNotFoundError(f"{dotenvfile} not found.")

    def set(self, var_name: str, val: str, print_val: bool = True) -> None:
        """Set an individual environment variable."""
        os.environ[var_name] = val
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if print_val:
            logger.info(f"Set {var_name}={val}")

    def get(self, var_name: str, default: Optional[str] = None) -> Optional[str]:
        """Retrieve an environment variable value."""
        return os.environ.get(var_name, default)

    def set_proxy(self) -> None:
        """Configure proxy settings."""
        ad_username = self.get("AD_USERNAME")
        ad_password = self.get("AD_USER_PW")
        proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
        if not all([ad_username, ad_password, proxy_domain]):
            raise ValueError("Missing proxy credentials")
        proxy_url = f"http://{ad_username}:{ad_password}@{proxy_domain}"
        self.set("HTTP_PROXY", proxy_url, print_val=False)
        self.set("HTTPS_PROXY", proxy_url, print_val=False)
        no_proxy_domains = [
            'cognitiveservices.azure.com',
            'search.windows.net',
            'openai.azure.com',
            'core.windows.net',
            'azurewebsites.net'
        ]
        self.set("NO_PROXY", ",".join(no_proxy_domains))
        logger.info("Proxy configuration completed")

    def get_azure_token(self) -> str:
        """Acquire an Azure authentication token."""
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token acquired successfully")
            return token.token
        except Exception as e:
            logger.error(f"Failed to get Azure token: {str(e)}")
            raise

    def list_env_vars(self) -> None:
        """Print all environment variables set by this class."""
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [HIDDEN]")
            else:
                logger.info(f"{var}: {self.get(var)}")

# --------------------- Agent-Based Chatbot with CSV-Based RAG ---------------------
class AzureChatbot:
    """
    An agent-based chatbot that uses an Azure OpenAI chat model.
    It loads CSV file(s) from a knowledge folder, splits them into chunks,
    and at query time uses the LLM to select the most relevant chunks.
    The selected context is then injected into the final prompt for answering.
    """
    def __init__(self, config_file: str, creds_file: str, cert_file: str, knowledge_dir: Optional[str] = None):
        logger.info("Initializing agent-based chatbot with CSV RAG...")
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.knowledge_dir = knowledge_dir
        self.csv_chunks = []
        if self.knowledge_dir:
            self.csv_chunks = self.load_csv_chunks(self.knowledge_dir)
        # Initialize the chat model (without pre-injecting all knowledge)
        self.llm = AzureChatOpenAI(
            model_name=self.env.get("MODEL_NAME", "gpt-4"),
            deployment_name=self.env.get("CHAT_MODEL_DEPLOYMENT", self.env.get("MODEL_NAME", "gpt-4")),
            temperature=float(self.env.get("MODEL_TEMPERATURE", "0.7")),
            max_tokens=int(self.env.get("MAX_TOKENS", "800")),
            openai_api_version=self.env.get("API_VERSION", "2024-02-01"),
            azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=self.env.token
        )
        self.memory = ConversationBufferMemory()
        # Use a ConversationChain for multi-turn chat
        self.conversation = ConversationChain(
            llm=self.llm,
            memory=self.memory,
            verbose=True
        )

    def load_csv_chunks(self, directory: str) -> List[str]:
        """
        Load all CSV files from the directory and split their content into smaller chunks.
        This helps avoid exceeding token limits.
        """
        chunks = []
        csv_files = glob.glob(os.path.join(directory, "**/*.csv"), recursive=True)
        if not csv_files:
            logger.info("No CSV files found in the knowledge directory.")
            return chunks
        for csv_file in csv_files:
            logger.info(f"Loading CSV file: {csv_file}")
            try:
                loader = CSVLoader(file_path=csv_file)
                docs = loader.load()
                for doc in docs:
                    text = doc.page_content
                    words = text.split()
                    chunk_size = 200  # adjust as needed
                    for i in range(0, len(words), chunk_size):
                        chunk = " ".join(words[i:i+chunk_size])
                        chunks.append(chunk)
            except Exception as e:
                logger.error(f"Error processing {csv_file}: {str(e)}")
        logger.info(f"Total CSV chunks loaded: {len(chunks)}")
        return chunks

    def get_relevance_score(self, query: str, text_chunk: str) -> float:
        """
        Use the LLM to score how relevant a text chunk is to the given query.
        The prompt asks for a number between 0 (not relevant) and 10 (extremely relevant).
        """
        prompt = (
            f"On a scale of 0 to 10, where 0 is not relevant at all and 10 is extremely relevant, "
            f"how relevant is the following text to answering the question: \"{query}\"?\n\n"
            f"Text:\n{text_chunk}\n\nAnswer with only a number."
        )
        try:
            response = self.llm.predict(prompt)
            score = float(response.strip())
        except Exception as e:
            logger.error(f"Error scoring chunk: {str(e)}")
            score = 0.0
        return score

    def get_relevant_context(self, query: str) -> str:
        """
        Evaluate all CSV chunks and select the top relevant ones.
        Returns a string combining the most relevant chunks.
        """
        scored_chunks = []
        for chunk in self.csv_chunks:
            score = self.get_relevance_score(query, chunk)
            scored_chunks.append((score, chunk))
        # Sort chunks in descending order of relevance
        scored_chunks.sort(key=lambda x: x[0], reverse=True)
        # Pick top 3 chunks that have a score of at least 5 (adjust threshold as needed)
        top_chunks = [chunk for score, chunk in scored_chunks if score >= 5.0][:3]
        logger.info(f"Selected {len(top_chunks)} chunks for context.")
        return "\n\n".join(top_chunks)

    def chat(self, message: str) -> str:
        """
        Process a user message by retrieving relevant CSV context and
        constructing a final prompt that combines conversation history,
        relevant context, and the user query.
        """
        if not message.strip():
            return "Please provide a non-empty message."
        try:
            relevant_context = self.get_relevant_context(message)
            conversation_history = self.memory.buffer  # Retrieve conversation history
            final_prompt = (
                "You are an expert assistant. Use the conversation history and the following CSV-derived context "
                "to help answer the user's question.\n\n"
                "Conversation History:\n" + conversation_history + "\n\n"
                "Relevant CSV Context:\n" + relevant_context + "\n\n"
                "User Question: " + message
            )
            response = self.llm.predict(final_prompt)
            # Update conversation memory for multi-turn interactions.
            self.memory.chat_memory.add_user_message(message)
            self.memory.chat_memory.add_ai_message(response)
            return response
        except Exception as e:
            logger.error(f"Error during chat: {str(e)}")
            return f"An error occurred: {str(e)}"

# --------------------- Main Function ---------------------
def main():
    """Main function to run the CSV-based RAG chatbot without a vector DB."""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        env_dir = os.path.join(base_dir, '..', 'env')
        config_path = os.path.join(env_dir, 'config.env')
        creds_path = os.path.join(env_dir, 'credentials.env')
        cert_path = os.path.join(env_dir, 'cacert.pem')
        # Set the knowledge directory to your folder containing CSV files.
        knowledge_dir = os.path.join(base_dir, '..', 'knowledge')
        
        print("\nInitializing CSV-based RAG chatbot (no vector DB)...")
        chatbot = AzureChatbot(
            config_file=config_path,
            creds_file=creds_path,
            cert_file=cert_path,
            knowledge_dir=knowledge_dir
        )
        print("\nChatbot initialized successfully!")
        print("\nType your message to begin chatting (type 'quit', 'exit', or 'bye' to stop):")
        print("-" * 50)
        
        while True:
            user_input = input("\nYou: ").strip()
            if user_input.lower() in ['quit', 'exit', 'bye']:
                print("Goodbye!")
                break
            if user_input.lower() == 'env':
                chatbot.env.list_env_vars()
                continue
            response = chatbot.chat(user_input)
            print(f"\nBot: {response}")
            
    except FileNotFoundError as e:
        print(f"\nFile Error: {str(e)}")
        print("Please check your configuration files and certificate path.")
    except ValueError as e:
        print(f"\nConfiguration Error: {str(e)}")
        print("Please check your environment variables and settings.")
    except Exception as e:
        print(f"\nUnexpected Error: {str(e)}")
        logger.exception("Unexpected error occurred")

if __name__ == "__main__":
    main()
