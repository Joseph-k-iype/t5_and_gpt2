import os
import glob
import logging
import chromadb
from pathlib import Path
from typing import List, Optional

from dotenv import dotenv_values
from azure.identity import ClientSecretCredential

from langchain_openai import AzureChatOpenAI
from langchain.schema import SystemMessage
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import CSVLoader

from chromadb.utils import embedding_functions

# Import your EmbeddingClient (Replace 'your_module' with actual module path)
from your_module import EmbeddingClient  # <-- Update this

# --------------------- Logging Configuration ---------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --------------------- Environment Setup ---------------------
class OSEnv:
    """Environment variable and certificate management."""
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []  
        self.bulk_set(config_file, print_val=True)
        logger.info(f"Loaded main configuration from {config_file}")
        self.bulk_set(creds_file, print_val=False)
        logger.info(f"Loaded credentials from {creds_file}")
        self.set_certificate_path(certificate_path)
        logger.info("Certificate path configured")
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            logger.info("Securing endpoints")
            self.token = self.get_azure_token()
        else:
            self.token = None

    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        """Load environment variables from a dotenv file."""
        if is_file_readable(dotenvfile):
            temp_dict = dotenv_values(dotenvfile)
            for k, v in temp_dict.items():
                self.set(k, v, print_val)

    def set(self, var_name: str, val: str, print_val: bool = True) -> None:
        """Set an environment variable."""
        os.environ[var_name] = val
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if print_val:
            logger.info(f"Set {var_name}={val}")

    def get(self, var_name: str, default: Optional[str] = None) -> Optional[str]:
        """Retrieve an environment variable value."""
        return os.environ.get(var_name, default)

    def get_azure_token(self) -> str:
        """Acquire an Azure authentication token."""
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token acquired successfully")
            return token.token
        except Exception as e:
            logger.error(f"Failed to get Azure token: {str(e)}")
            raise

# --------------------- Load and Store Embeddings in ChromaDB ---------------------
class KnowledgeBase:
    def __init__(self, env: OSEnv, knowledge_dir: str):
        self.env = env
        self.knowledge_dir = knowledge_dir
        self.embedding_client = EmbeddingClient()
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.collection = self.chroma_client.get_or_create_collection(name="csv_knowledge")

    def load_csv_documents(self) -> List[str]:
        """Load CSV documents and return their contents as a list."""
        csv_files = glob.glob(os.path.join(self.knowledge_dir, "**/*.csv"), recursive=True)
        if not csv_files:
            logger.info("No CSV files found in the knowledge directory.")
            return []
        
        documents = []
        for csv_file in csv_files:
            logger.info(f"Loading CSV file: {csv_file}")
            loader = CSVLoader(file_path=csv_file)
            docs = loader.load()
            for doc in docs:
                documents.append(doc.page_content)
        
        return documents

    def store_embeddings(self):
        """Generate and store embeddings for CSV documents in ChromaDB."""
        documents = self.load_csv_documents()
        for i, text in enumerate(documents):
            doc_obj = {"text": text, "id": f"doc_{i}"}
            embedded_doc = self.embedding_client.generate_embeddings(doc_obj)
            self.collection.add(
                ids=[f"doc_{i}"],
                embeddings=[embedded_doc["embedding"]],
                metadatas=[{"source": "csv"}]
            )
        logger.info("Stored document embeddings in ChromaDB.")

    def retrieve_relevant_documents(self, query: str, top_k: int = 3) -> List[str]:
        """Retrieve the top relevant document texts from ChromaDB for a given query."""
        query_embedding = self.embedding_client.generate_embeddings({"text": query})["embedding"]
        results = self.collection.query(query_embeddings=[query_embedding], n_results=top_k)
        return [res["text"] for res in results["metadatas"]]

# --------------------- Agent-Based Chatbot with ChromaDB RAG ---------------------
class AzureChatbot:
    def __init__(self, config_file: str, creds_file: str, cert_file: str, knowledge_dir: str):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.knowledge_base = KnowledgeBase(self.env, knowledge_dir)
        self.llm = AzureChatOpenAI(
            model_name=self.env.get("MODEL_NAME", "gpt-4"),
            deployment_name=self.env.get("CHAT_MODEL_DEPLOYMENT", self.env.get("MODEL_NAME", "gpt-4")),
            temperature=float(self.env.get("MODEL_TEMPERATURE", "0.7")),
            max_tokens=int(self.env.get("MAX_TOKENS", "800")),
            openai_api_version=self.env.get("API_VERSION", "2024-02-01"),
            azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=self.env.token
        )
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.knowledge_base.retrieve_relevant_documents,
            memory=self.memory,
            return_source_documents=True,
            verbose=True
        )

    def chat(self, message: str) -> str:
        """Process a user message with RAG and return the chatbot's response."""
        relevant_context = self.knowledge_base.retrieve_relevant_documents(message)
        final_prompt = (
            "Use the following retrieved knowledge to assist in answering the query:\n\n"
            + "\n".join(relevant_context) +
            f"\n\nUser Query: {message}"
        )
        response = self.llm.predict(final_prompt)
        self.memory.chat_memory.add_user_message(message)
        self.memory.chat_memory.add_ai_message(response)
        return response

# --------------------- Main Function ---------------------
def main():
    """Main function to run the chatbot with ChromaDB RAG."""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    env_dir = os.path.join(base_dir, '..', 'env')
    knowledge_dir = os.path.join(base_dir, '..', 'knowledge')

    chatbot = AzureChatbot(
        config_file=os.path.join(env_dir, 'config.env'),
        creds_file=os.path.join(env_dir, 'credentials.env'),
        cert_file=os.path.join(env_dir, 'cacert.pem'),
        knowledge_dir=knowledge_dir
    )

    while True:
        user_input = input("\nYou: ").strip()
        if user_input.lower() in ['quit', 'exit', 'bye']:
            print("Goodbye!")
            break
        response = chatbot.chat(user_input)
        print(f"\nBot: {response}")

if __name__ == "__main__":
    main()
