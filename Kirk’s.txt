import os
import sys
import uuid
import json
import logging
import pandas as pd
import numpy as np
from typing import List, Dict, Any, Optional, TypeVar, Generic, Type, Union, Literal
from pathlib import Path
from dotenv import load_dotenv, dotenv_values
from pydantic import BaseModel, Field, ValidationError, field_validator, model_dump
import instructor
from instructor.function_calling import OpenAISchema
from openai import AzureOpenAI
from azure.identity import DefaultAzureCredential, get_bearer_token_provider, ClientSecretCredential
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import AzureChatOpenAI
from langchain.chains import ConversationChain
from collections import namedtuple
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode
from langgraph.graph.state import NodeStateType, StateType
from langgraph.checkpoint import MemorySaver

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Define paths
ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

# Create ENV_DIR if it doesn't exist
os.makedirs(ENV_DIR, exist_ok=True)

# Type variable for generic response model
T = TypeVar('T', bound=BaseModel)

# Utility functions
def is_file_readable(filepath: str) -> bool:
    """Check if a file is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        return False
    return True

def str_to_bool(s: str) -> bool:
    """Convert a string to a boolean."""
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean value: {s}")

class OSEnv:
    """Class to manage environment variables"""
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.bulk_set(config_file, True)
        self.bulk_set(creds_file, False)
        
        if is_file_readable(certificate_path):
            self.set_certificate_path(certificate_path)
        
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self.get_azure_token()
        else:
            self.token = None
        
        self.credential = self._get_credential()
    
    def _get_credential(self):
        if str_to_bool(self.get("USE_MANAGED_IDENTITY", "False")):
            return DefaultAzureCredential()
        else:
            return ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"), 
                client_id=self.get("AZURE_CLIENT_ID"), 
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
    
    def set_certificate_path(self, path: str):
        try:
            if not os.path.isabs(path):
                path = os.path.abspath(path)
            if not is_file_readable(path):
                raise FileNotFoundError(f"The file '{path}' does not exist or is not readable")
            
            self.set("REQUESTS_CA_BUNDLE", path)
            self.set("SSL_CERT_FILE", path)
            self.set("CURL_CA_BUNDLE", path)
        except Exception as e:
            logger.error(f"Error setting certificate path: {e}")
            raise
    
    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        try:
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
            if not is_file_readable(dotenvfile):
                logger.warning(f"Environment file not found or not readable: {dotenvfile}")
                return
                
            temp_dict = dotenv_values(dotenvfile)
            for key, value in temp_dict.items():
                self.set(key, value, print_val)
            del temp_dict
        except Exception as e:
            logger.error(f"Error loading environment variables from {dotenvfile}: {e}")
            raise
    
    def set(self, key: str, value: str, print_val: bool = False) -> None:
        try:
            os.environ[key] = value
            if key not in self.var_list:
                self.var_list.append(key)
            if print_val:
                logger.info(f"{key}: {value}")
        except Exception as e:
            logger.error(f"Error setting environment variable {key}: {e}")
            raise
    
    def get(self, key: str, default: Optional[str] = None) -> str:
        try:
            return os.environ.get(key, default)
        except Exception as e:
            logger.error(f"Error getting environment variable {key}: {e}")
            raise
    
    def set_proxy(self) -> None:
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            if not all([ad_username, ad_password, proxy_domain]):
                raise ValueError("Proxy settings are incomplete")
            proxy_url = f"https://{ad_username}:{ad_password}@{proxy_domain}"
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains), print_val=False)
        except Exception as e:
            logger.error(f"Error setting proxy: {e}")
            raise
    
    def get_azure_token(self) -> str:
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token set")
            return token.token
        except Exception as e:
            logger.error(f"Error retrieving Azure token: {e}")
            return None
    
    def list_env_vars(self) -> None:
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [REDACTED]")
            else:
                logger.info(f"{var}: {os.getenv(var)}")


class AzureChatbot:
    """Azure OpenAI chatbot with Instructor integration"""
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
        self._setup_instructor_client()
    
    def _setup_chat_model(self):
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            temperature = float(self.env.get("TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2023-05-15")
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token_provider=token_provider
            )
        except Exception as e:
            logger.error(f"Error setting up chatbot: {e}")
            raise
    
    def _setup_instructor_client(self):
        try:
            # Create the direct Azure client for instructor
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            api_version = self.env.get("API_VERSION", "2023-05-15")
            
            direct_client = AzureOpenAI(
                azure_endpoint=azure_endpoint,
                api_version=api_version,
                azure_ad_token_provider=get_bearer_token_provider(
                    self.env.credential,
                    "https://cognitiveservices.azure.com/.default"
                )
            )
            
            # Apply instructor to the client
            self.instructor_client = instructor.from_openai(direct_client)
            logger.info("Instructor client set up successfully")
        except Exception as e:
            logger.error(f"Error setting up instructor client: {e}")
            raise
    
    def query(self, user_input: str) -> str:
        """Standard chat query that returns a text response"""
        try:
            return self.conversation.predict(input=user_input)
        except Exception as e:
            logger.error(f"Error in chat query: {e}")
            return f"Error: {str(e)}"
    
    def structured_query(self, user_input: str, response_model: Type[T]) -> T:
        """
        Query that returns a structured response using instructor and Pydantic model
        
        Args:
            user_input: The user's query text
            response_model: A Pydantic model class defining the expected response structure
            
        Returns:
            An instance of the response_model populated with extracted data
        """
        try:
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            
            # Use instructor to get structured output
            result = self.instructor_client.chat.completions.create(
                model=model_name,
                response_model=response_model,
                messages=[
                    {"role": "user", "content": user_input}
                ]
            )
            
            # Add the interaction to memory for context
            self.memory.save_context(
                {"input": user_input}, 
                {"output": f"Extracted structured data: {result.model_dump_json()}"}
            )
            
            return result
        except Exception as e:
            logger.error(f"Error in structured query: {e}")
            raise


# Define Pydantic models for structured outputs as OpenAISchema
class IncidentFeatures(OpenAISchema):
    """Extracted relevant features from an incident"""
    id: str
    summary: str
    description: str
    resolution_name: str
    resolution_details: str
    category: str
    subcategory: str
    
    # Extracted indicators that might suggest a data issue
    contains_data_terms: bool = Field(
        description="Whether the incident contains terms related to data issues (e.g., 'data', 'database', 'query', 'missing records', 'corrupt data')"
    )
    contains_system_terms: bool = Field(
        description="Whether the incident contains terms related to system issues (e.g., 'server', 'network', 'hardware', 'connectivity')"
    )
    is_categorized_as_data: bool = Field(
        description="Whether the incident is explicitly categorized as 'Business Process or Usage' or 'database' in category or subcategory"
    )

class ClassificationReason(OpenAISchema):
    """A single reason supporting the classification with its impact on confidence"""
    reason: str = Field(description="Specific evidence or observation supporting the classification")
    impact: float = Field(description="How much this reason impacts the confidence score (0.0 to 1.0)", ge=0.0, le=1.0)
    
class IncidentClassification(OpenAISchema):
    """The final classification of an incident"""
    incident_id: str
    is_data_issue: bool
    confidence_score: float = Field(description="Confidence score from 0.0 to 1.0", ge=0.0, le=1.0)
    supporting_reasons: List[ClassificationReason] = Field(
        description="List of reasons supporting this classification"
    )
    contrary_reasons: List[ClassificationReason] = Field(
        description="List of reasons that contradict this classification"
    )
    
class AgentMessage(BaseModel):
    """Message passed between agents"""
    content: str
    metadata: Dict[str, Any] = {}

# Define LangGraph state model
class ClassificationState(BaseModel):
    """The state maintained throughout the classification process"""
    incident: Optional[IncidentFeatures] = None
    feature_extraction_complete: bool = False
    preliminary_classification: Optional[IncidentClassification] = None
    final_classification: Optional[IncidentClassification] = None
    
    # Messages between agents
    messages: List[AgentMessage] = Field(default_factory=list)
    current_agent: str = "feature_extractor"
    
    # Additional metadata
    metadata: Dict[str, Any] = Field(default_factory=dict)

# Multi-agent system for incident classification
class IncidentClassifier:
    """Multi-agent system for classifying IT incidents as data issues"""
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        # Initialize the chatbot for agent operations
        try:
            self.chatbot = AzureChatbot(
                config_file=config_file, 
                creds_file=creds_file, 
                cert_file=cert_file
            )
        except Exception as e:
            logger.error(f"Error initializing AzureChatbot: {e}")
            raise
        
        # Create the state graph
        try:
            self.graph = self._build_graph()
        except Exception as e:
            logger.error(f"Error building graph: {e}")
            raise
        
    def _build_graph(self):
        """Build the LangGraph for the multi-agent system"""
        # Initialize the graph with the ClassificationState model
        graph = StateGraph(ClassificationState)
        
        # Add nodes to the graph
        graph.add_node("feature_extractor", self.feature_extractor)
        graph.add_node("classifier", self.classifier)
        graph.add_node("reasoning_agent", self.reasoning_agent)
        graph.add_node("confidence_evaluator", self.confidence_evaluator)
        
        # Add edges to connect the nodes
        graph.add_edge("START", "feature_extractor")
        graph.add_edge("feature_extractor", "classifier")
        graph.add_edge("classifier", "reasoning_agent")
        graph.add_edge("reasoning_agent", "confidence_evaluator")
        graph.add_edge("confidence_evaluator", END)
        
        # Add memory to support state checkpoints
        memory = MemorySaver()
        
        # Return the compiled graph with proper checkpointing
        return graph.compile(checkpointer=memory)
    
    def feature_extractor(self, state: ClassificationState) -> dict:
        """Extract features from the incident text"""
        # If feature extraction is already complete, return empty dict (no changes)
        if state.feature_extraction_complete:
            return {}
        
        try:
            # Using instructor to enforce structured output for feature extraction
            metadata = state.metadata
            features = self.chatbot.structured_query(
                f"""
                Extract key features from this IT incident:
                ID: {metadata.get("id", "Unknown")}
                Summary: {metadata.get("summary", "")}
                Description: {metadata.get("description", "")}
                Resolution Name: {metadata.get("resolution_name", "")}
                Resolution Details: {metadata.get("resolution_details", "")}
                Category: {metadata.get("category", "")}
                Subcategory: {metadata.get("subcategory", "")}
                
                Analyze the text and determine if it contains terms related to data issues,
                system issues, and if it's categorized explicitly as a data-related issue.
                """,
                IncidentFeatures
            )
            
            # Create a new messages list with the success message
            new_message = AgentMessage(
                content="Successfully extracted features from the incident",
                metadata={"agent": "feature_extractor", "success": True}
            )
            messages = state.messages.copy()
            messages.append(new_message)
            
            # Return the updates to the state
            return {
                "incident": features,
                "feature_extraction_complete": True,
                "current_agent": "classifier",
                "messages": messages
            }
        except Exception as e:
            logger.error(f"Error in feature extraction: {e}")
            # Append error message to the messages
            error_message = AgentMessage(
                content=f"Error extracting features: {str(e)}",
                metadata={"agent": "feature_extractor", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            return {"messages": messages}
    
    def classifier(self, state: ClassificationState) -> dict:
        """Perform initial classification of the incident"""
        if state.preliminary_classification:
            return {}
        
        if not state.incident:
            error_message = AgentMessage(
                content="Cannot classify without extracted features",
                metadata={"agent": "classifier", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            return {"messages": messages}
        
        try:
            # Create a simple preliminary classification
            is_data_issue = (
                state.incident.is_categorized_as_data or 
                state.incident.contains_data_terms
            )
            
            # Create an initial classification with a basic confidence score
            classification = IncidentClassification(
                incident_id=state.incident.id,
                is_data_issue=is_data_issue,
                confidence_score=0.7 if is_data_issue else 0.3,
                supporting_reasons=[
                    ClassificationReason(
                        reason=f"Incident {'is' if state.incident.is_categorized_as_data else 'is not'} explicitly categorized as data-related",
                        impact=0.6
                    )
                ],
                contrary_reasons=[]
            )
            
            # Prepare success message
            new_message = AgentMessage(
                content=f"Initial classification: {'Data issue' if is_data_issue else 'Not a data issue'}",
                metadata={"agent": "classifier", "success": True}
            )
            messages = state.messages.copy()
            messages.append(new_message)
            
            return {
                "preliminary_classification": classification,
                "current_agent": "reasoning_agent",
                "messages": messages
            }
        except Exception as e:
            logger.error(f"Error in classification: {e}")
            error_message = AgentMessage(
                content=f"Error in classification: {str(e)}",
                metadata={"agent": "classifier", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            return {"messages": messages}
    
    def reasoning_agent(self, state: ClassificationState) -> dict:
        """Develop reasoning and evidence for the classification"""
        if not state.preliminary_classification or not state.incident:
            error_message = AgentMessage(
                content="Cannot provide reasoning without preliminary classification and incident data",
                metadata={"agent": "reasoning_agent", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            return {"messages": messages}
        
        try:
            # Use instructor for structured output
            improved_classification = self.chatbot.structured_query(
                f"""
                Analyze this IT incident in detail and provide reasoning for why it should or should not
                be classified as a data issue:
                
                ID: {state.incident.id}
                Summary: {state.incident.summary}
                Description: {state.incident.description}
                Resolution Name: {state.incident.resolution_name}
                Resolution Details: {state.incident.resolution_details}
                Category: {state.incident.category}
                Subcategory: {state.incident.subcategory}
                
                Current classification: 
                - Is data issue: {state.preliminary_classification.is_data_issue}
                - Confidence: {state.preliminary_classification.confidence_score}
                
                Provide a detailed list of supporting reasons (evidence that it IS a data issue)
                and contrary reasons (evidence that it is NOT a data issue).
                
                Each reason should have an impact score (0.0 to 1.0) indicating how much this 
                particular reason should influence the final confidence score.
                """,
                IncidentClassification
            )
            
            # Prepare success message
            new_message = AgentMessage(
                content="Developed detailed reasoning for classification",
                metadata={"agent": "reasoning_agent", "success": True}
            )
            messages = state.messages.copy()
            messages.append(new_message)
            
            return {
                "final_classification": improved_classification,
                "current_agent": "confidence_evaluator",
                "messages": messages
            }
        except Exception as e:
            logger.error(f"Error in reasoning: {e}")
            error_message = AgentMessage(
                content=f"Error in reasoning: {str(e)}",
                metadata={"agent": "reasoning_agent", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            # Use preliminary classification as fallback
            return {
                "final_classification": state.preliminary_classification,
                "current_agent": "confidence_evaluator",
                "messages": messages
            }
    
    def confidence_evaluator(self, state: ClassificationState) -> dict:
        """Evaluate and finalize the confidence score"""
        # Ensure we have a final classification to work with
        final_classification = state.final_classification
        if not final_classification:
            if state.preliminary_classification:
                final_classification = state.preliminary_classification
                new_message = AgentMessage(
                    content="Using preliminary classification as final classification",
                    metadata={"agent": "confidence_evaluator", "success": True}
                )
            else:
                # Create a default minimal classification based on metadata
                incident_id = state.metadata.get("id", "Unknown")
                if state.incident:
                    incident_id = state.incident.id
                
                final_classification = IncidentClassification(
                    incident_id=incident_id,
                    is_data_issue=False,
                    confidence_score=0.5,
                    supporting_reasons=[
                        ClassificationReason(
                            reason="Insufficient data for classification",
                            impact=1.0
                        )
                    ],
                    contrary_reasons=[]
                )
                new_message = AgentMessage(
                    content="Created default classification due to missing data",
                    metadata={"agent": "confidence_evaluator", "success": False}
                )
            
            messages = state.messages.copy()
            messages.append(new_message)
            final_classification = final_classification
        
        try:
            supporting_impact = sum(reason.impact for reason in final_classification.supporting_reasons)
            contrary_impact = sum(reason.impact for reason in final_classification.contrary_reasons)
            
            total_impact = supporting_impact + contrary_impact
            if total_impact > 0:
                if supporting_impact > contrary_impact:
                    confidence = 0.5 + (0.5 * (supporting_impact - contrary_impact) / total_impact
                else:
                    confidence = 0.5 - (0.5 * (contrary_impact - supporting_impact) / total_impact
            else:
                confidence = 0.5  # Neutral confidence if no impacts
            
            # Update the confidence score
            final_classification.confidence_score = round(confidence, 2)
            
            # Prepare success message
            new_message = AgentMessage(
                content=f"Final confidence score: {final_classification.confidence_score}",
                metadata={"agent": "confidence_evaluator", "success": True}
            )
            messages = state.messages.copy()
            messages.append(new_message)
            
            return {
                "final_classification": final_classification,
                "messages": messages
            }
        except Exception as e:
            logger.error(f"Error in confidence evaluation: {e}")
            error_message = AgentMessage(
                content=f"Error in confidence evaluation: {str(e)}",
                metadata={"agent": "confidence_evaluator", "success": False}
            )
            messages = state.messages.copy()
            messages.append(error_message)
            return {
                "final_classification": final_classification,
                "messages": messages
            }
    
    def classify_incident(self, incident_data: Dict[str, str]) -> IncidentClassification:
        """Classify a single incident using the multi-agent system"""
        # Create the initial state
        initial_state = ClassificationState(
            metadata={
                "id": incident_data.get("Id", "Unknown"),
                "summary": incident_data.get("IT_INCIDENT_SUMMARY", ""),
                "description": incident_data.get("IT_INCIDENT_DESC", ""),
                "resolution_name": incident_data.get("IT_INCIDENT_RESOLUTION_DETAILS_NAME", ""),
                "resolution_details": incident_data.get("IT_INCIDENT_RESOLUTION_DESC", ""),
                "category": incident_data.get("IT_INCIDENT_AREA_CATEGORY", ""),
                "subcategory": incident_data.get("IT_INCIDENT_AREA_SUBCATEGORY", "")
            }
        )
        
        # Run the graph with proper state handling
        try:
            # Execute the graph with the initial state
            final_state = self.graph.invoke(initial_state)
            
            # Return the final classification
            if final_state.final_classification is not None:
                return final_state.final_classification
            else:
                logger.error("Classification graph did not produce a final classification")
                raise ValueError("Classification process did not produce a final classification")
        
        except Exception as e:
            logger.error(f"Error running classification graph: {e}")
            raise
    
    def process_csv(self, csv_path: str, output_path: str = None) -> List[IncidentClassification]:
        """Process a CSV file containing incident data"""
        try:
            # Load the CSV
            df = pd.read_csv(csv_path)
            logger.info(f"Loaded {len(df)} incidents from {csv_path}")
            
            # Process each incident
            results = []
            for i, row in df.iterrows():
                incident_id = row.get('Id', f"Unknown-{i}")
                logger.info(f"Processing incident {i+1}/{len(df)}: {incident_id}")
                
                try:
                    incident_data = row.to_dict()
                    classification = self.classify_incident(incident_data)
                    
                    # Ensure we got a valid classification
                    if not isinstance(classification, IncidentClassification):
                        logger.error(f"Invalid classification type: {type(classification)}")
                        continue
                        
                    results.append(classification)
                    
                    # Log success
                    logger.info(
                        f"Successfully classified incident {classification.incident_id}: "
                        f"{'Data issue' if classification.is_data_issue else 'Not a data issue'} "
                        f"(Confidence: {classification.confidence_score})"
                    )
                except Exception as e:
                    logger.error(f"Error processing incident {incident_id}: {e}")
                    continue
            
            # Save to JSON if output path provided
            if output_path and results:
                with open(output_path, 'w') as f:
                    json.dump([r.model_dump() for r in results], f, indent=2)
                logger.info(f"Saved {len(results)} results to {output_path}")
            
            return results
        except Exception as e:
            logger.error(f"Error processing CSV: {e}")
            raise


def create_sample_data(csv_path: str):
    """Create a sample CSV with IT incident data for testing"""
    sample_data = [
        {
            "Id": "INC001",
            "IT_INCIDENT_SUMMARY": "Database query timeout affecting customer reports",
            "IT_INCIDENT_DESC": "Users reported that customer reports are taking more than 30 minutes to generate, much longer than the expected 2 minutes. Investigation showed database queries timing out due to inefficient query structure.",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Database Optimization",
            "IT_INCIDENT_RESOLUTION_DESC": "Identified slow running query in the customer database. Optimized the query by adding proper indexing and correcting the join conditions.",
            "IT_INCIDENT_AREA_CATEGORY": "Database",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Query Performance"
        },
        {
            "Id": "INC002",
            "IT_INCIDENT_SUMMARY": "Network connectivity issues in Building B",
            "IT_INCIDENT_DESC": "Employees in Building B have been experiencing intermittent network connectivity issues for the past week. Some devices lose connection for 5-10 minutes at a time, affecting productivity.",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Router Replacement",
            "IT_INCIDENT_RESOLUTION_DESC": "Found faulty router in Building B that was causing intermittent connectivity issues. Replaced the hardware and verified connectivity.",
            "IT_INCIDENT_AREA_CATEGORY": "Network",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Hardware Failure"
        },
        {
            "Id": "INC003",
            "IT_INCIDENT_SUMMARY": "Missing customer records in monthly report",
            "IT_INCIDENT_DESC": "The monthly customer activity report is missing approximately 15% of customer records compared to previous months. Finance department flagged the issue as critical since it affects revenue calculations.",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Data Correction",
            "IT_INCIDENT_RESOLUTION_DESC": "Found data integrity issue where customer records were being filtered out incorrectly. Fixed the data validation rules and regenerated reports.",
            "IT_INCIDENT_AREA_CATEGORY": "Business Process or Usage",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Data Integrity"
        },
        {
            "Id": "INC004",
            "IT_INCIDENT_SUMMARY": "Application crashing during end-of-month processing",
            "IT_INCIDENT_DESC": "The financial reporting application crashes consistently during end-of-month processing when attempting to generate quarterly reports. Error logs show memory exceptions before the crash.",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Memory Allocation",
            "IT_INCIDENT_RESOLUTION_DESC": "Application was running out of memory during large batch processes. Increased memory allocation and optimized the processing algorithm.",
            "IT_INCIDENT_AREA_CATEGORY": "Application",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Performance"
        },
        {
            "Id": "INC005",
            "IT_INCIDENT_SUMMARY": "Duplicate transactions appearing in financial database",
            "IT_INCIDENT_DESC": "Finance team identified multiple duplicate transaction records in the financial database over the past week. Some customer transactions are being recorded twice or three times, causing discrepancies in financial reports.",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Transaction Deduplication",
            "IT_INCIDENT_RESOLUTION_DESC": "Identified issue in the transaction processing where network timeouts were causing retries without proper checking. Implemented proper idempotency checks and cleaned up duplicate data.",
            "IT_INCIDENT_AREA_CATEGORY": "Database",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Data Consistency"
        }
    ]
    
    # Create DataFrame and save to CSV
    df = pd.DataFrame(sample_data)
    df.to_csv(csv_path, index=False)
    logger.info(f"Created sample data with {len(df)} incidents")
    return df


def create_config_files():
    """Create sample configuration files if they don't exist"""
    # Create config.env
    if not os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, 'w') as f:
            f.write("""MODEL_NAME=gpt-4o-mini
TEMPERATURE=0.1
MAX_TOKENS=1000
API_VERSION=2023-05-15
AZURE_ENDPOINT=https://your-azure-endpoint.openai.azure.com/
""")
        logger.info(f"Created sample config file at {CONFIG_PATH}")
    
    # Create credentials.env
    if not os.path.exists(CREDS_PATH):
        with open(CREDS_PATH, 'w') as f:
            f.write("""AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-client-id
AZURE_CLIENT_SECRET=your-client-secret
USE_MANAGED_IDENTITY=False
SECURED_ENDPOINTS=True
""")
        logger.info(f"Created sample credentials file at {CREDS_PATH}")


def print_classification_results(results: List[IncidentClassification]):
    """Print a summary of the classification results"""
    if not results:
        print("No classification results to display")
        return
        
    data_issues = [r for r in results if r.is_data_issue]
    high_confidence = [r for r in results if r.confidence_score >= 0.8]
    
    print("\n===== CLASSIFICATION RESULTS =====")
    print(f"Total incidents analyzed: {len(results)}")
    print(f"Data issues found: {len(data_issues)} ({len(data_issues)/len(results)*100:.1f}%)")
    print(f"High confidence classifications: {len(high_confidence)} ({len(high_confidence)/len(results)*100:.1f}%)")
    
    # Display a few examples
    print("\n===== SAMPLE CLASSIFICATIONS =====")
    for i, result in enumerate(results[:min(3, len(results))]):  # Show first 3 results or fewer
        print(f"\nIncident ID: {result.incident_id}")
        print(f"Classification: {'DATA ISSUE' if result.is_data_issue else 'NOT DATA ISSUE'}")
        print(f"Confidence: {result.confidence_score:.2f}")
        
        print("\nSupporting Reasons:")
        for reason in result.supporting_reasons[:min(2, len(result.supporting_reasons))]:  # Show top 2 reasons
            print(f"- {reason.reason} (Impact: {reason.impact:.2f})")
        
        print("\nContrary Reasons:")
        for reason in result.contrary_reasons[:min(2, len(result.contrary_reasons))]:  # Show top 2 reasons
            print(f"- {reason.reason} (Impact: {reason.impact:.2f})")
        
        if i < min(2, len(results) - 1):  # Don't print separator after last item
            print("\n" + "-" * 50)


def main():
    """Main function to run the IT Incident Classifier"""
    print("IT Incident Data Issue Classifier")
    print("=" * 40)
    
    # Create configuration files if they don't exist
    create_config_files()
    
    # Define paths
    csv_path = "it_incidents.csv"
    output_path = "classification_results.json"
    
    # Create sample data if CSV doesn't exist
    if not os.path.exists(csv_path):
        print(f"Sample CSV not found at {csv_path}, creating a sample dataset...")
        create_sample_data(csv_path)
    
    # Check if configuration is set up properly
    if not os.path.exists(CONFIG_PATH) or not os.path.exists(CREDS_PATH):
        print("Error: Configuration files not found.")
        print(f"Please configure {CONFIG_PATH} and {CREDS_PATH} with your Azure OpenAI credentials.")
        return
    
    # Ask for confirmation before proceeding
    print("\nThis script will:")
    print("1. Connect to Azure OpenAI using your credentials")
    print("2. Process IT incidents from the CSV file")
    print("3. Classify each incident as a data issue or not")
    print("4. Save results to a JSON file")
    
    proceed = input("\nDo you want to proceed? (y/n): ").lower()
    if proceed != 'y':
        print("Exiting...")
        return
    
    try:
        # Initialize the classifier
        print("\nInitializing IT Incident Classifier...")
        classifier = IncidentClassifier()
        
        # Process the CSV
        print(f"Processing incidents from {csv_path}...")
        results = classifier.process_csv(csv_path, output_path)
        
        # Print results
        print_classification_results(results)
        print(f"\nResults saved to {output_path}")
        
    except Exception as e:
        logger.error(f"Error running classifier: {e}")
        print(f"\nError: {str(e)}")
        print("\nTroubleshooting tips:")
        print("1. Check your Azure OpenAI credentials in the env files")
        print("2. Verify that your Azure OpenAI service is set up correctly")
        print("3. Ensure you have the required Python packages installed")
        
        # Provide more detailed error information
        import traceback
        print("\nDetailed error:")
        traceback.print_exc()


if __name__ == "__main__":
    main()
