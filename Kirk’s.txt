import os
import time
import logging
from pathlib import Path
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv, dotenv_values
from azure.identity import ClientSecretCredential
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage, Document
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.embeddings import AzureOpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.document_loaders import DirectoryLoader, TextLoader
from langchain.chains import ConversationalRetrievalChain

# Previous logging setup and utility functions remain the same...

class DocumentProcessor:
    """Handles document loading, splitting, and indexing."""
    
    def __init__(self, env: 'OSEnv'):
        """Initialize with environment configuration."""
        self.env = env
        self.embeddings = AzureOpenAIEmbeddings(
            deployment=env.get("EMBEDDING_DEPLOYMENT", "text-embedding-ada-002"),
            openai_api_version=env.get("API_VERSION", "2024-02-01"),
            azure_endpoint=env.get("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=env.token
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        
    def load_documents(self, directory_path: str) -> List[Document]:
        """Load documents from a directory."""
        try:
            loader = DirectoryLoader(
                directory_path,
                glob="**/*.txt",  # Can be modified to support more file types
                loader_cls=TextLoader
            )
            documents = loader.load()
            logger.info(f"Loaded {len(documents)} documents from {directory_path}")
            return documents
        except Exception as e:
            logger.error(f"Error loading documents: {str(e)}")
            raise

    def process_documents(self, documents: List[Document]) -> FAISS:
        """Process documents and create a vector store."""
        try:
            texts = self.text_splitter.split_documents(documents)
            vectorstore = FAISS.from_documents(texts, self.embeddings)
            logger.info(f"Created vector store with {len(texts)} text chunks")
            return vectorstore
        except Exception as e:
            logger.error(f"Error processing documents: {str(e)}")
            raise

class AzureChatbot:
    """RAG-enabled Azure OpenAI chatbot using LangChain."""
    
    def __init__(self, config_file: str, creds_file: str, cert_file: str, knowledge_dir: str):
        """Initialize the chatbot with configuration and knowledge base."""
        logger.info("Initializing RAG-enabled chatbot...")
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.doc_processor = DocumentProcessor(self.env)
        self._setup_knowledge_base(knowledge_dir)
        self._setup_chat_model()

    def _setup_knowledge_base(self, knowledge_dir: str) -> None:
        """Set up the knowledge base from documents."""
        try:
            documents = self.doc_processor.load_documents(knowledge_dir)
            self.vectorstore = self.doc_processor.process_documents(documents)
            logger.info("Knowledge base initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize knowledge base: {str(e)}")
            raise

    def _setup_chat_model(self) -> None:
        """Set up the RAG-enabled conversation chain."""
        try:
            self.llm = AzureChatOpenAI(
                model_name=self.env.get("MODEL_NAME", "gpt-4"),
                temperature=float(self.env.get("MODEL_TEMPERATURE", "0.7")),
                max_tokens=int(self.env.get("MAX_TOKENS", "800")),
                openai_api_version=self.env.get("API_VERSION", "2024-02-01"),
                azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
                azure_ad_token=self.env.token
            )
            
            self.memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True
            )
            
            self.conversation = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.vectorstore.as_retriever(
                    search_kwargs={"k": 3}
                ),
                memory=self.memory,
                return_source_documents=True,
                verbose=True
            )
            
            logger.info("RAG conversation chain initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize chat model: {str(e)}")
            raise

    def chat(self, message: str) -> Dict[str, Any]:
        """Process a message and return the response with source documents."""
        if not message.strip():
            return {"response": "Please provide a non-empty message.", "sources": []}
        
        try:
            result = self.conversation({"question": message})
            response = {
                "response": result["answer"],
                "sources": [doc.metadata for doc in result["source_documents"]]
            }
            return response
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return {"response": f"An error occurred: {str(e)}", "sources": []}

def main():
    """Main function to run the RAG-enabled chatbot."""
    try:
        # Define paths
        base_dir = os.path.dirname(os.path.abspath(__file__))
        env_dir = os.path.join(base_dir, '..', 'env')
        knowledge_dir = os.path.join(base_dir, '..', 'knowledge')
        
        config_path = os.path.join(env_dir, 'config.env')
        creds_path = os.path.join(env_dir, 'credentials.env')
        cert_path = os.path.join(env_dir, 'cacert.pem')
        
        # Check if directories exist
        os.makedirs(knowledge_dir, exist_ok=True)
        
        # Initialize chatbot
        print("\nInitializing RAG-enabled chatbot...")
        chatbot = AzureChatbot(
            config_file=config_path,
            creds_file=creds_path,
            cert_file=cert_path,
            knowledge_dir=knowledge_dir
        )
        
        print("\nChatbot initialized successfully!")
        print("\nAvailable commands:")
        print("- 'quit', 'exit', or 'bye': End the conversation")
        print("- 'env': Show current environment variables")
        print("\nType your message to begin chatting...")
        print("-" * 50)
        
        while True:
            user_input = input("\nYou: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'bye']:
                print("Goodbye!")
                break
            
            if user_input.lower() == 'env':
                chatbot.env.list_env_vars()
                continue
            
            result = chatbot.chat(user_input)
            print(f"\nBot: {result['response']}")
            
            if result['sources']:
                print("\nSources:")
                for source in result['sources']:
                    print(f"- {source.get('source', 'Unknown source')}")
            
    except Exception as e:
        print(f"\nUnexpected Error: {str(e)}")
        print("Please check the logs for more details.")
        logger.exception("Unexpected error occurred")

if __name__ == "__main__":
    main()
