import sys
import os
import logging
import chromadb
from langchain_openai import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import CSVLoader
from typing import List

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../oaai_client_sdk_core')))
from azoi_embedding_client import EmbeddingClient

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class KnowledgeBase:
    def __init__(self, base_dir: str, knowledge_dir: str):
        self.embedding_client = EmbeddingClient(base_dir)
        self.knowledge_dir = knowledge_dir
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.collection = self.chroma_client.get_or_create_collection(name="csv_knowledge")

    def load_csv_documents(self) -> List[str]:
        """Load CSV documents and return their contents as a list."""
        return [f for f in os.listdir(self.knowledge_dir) if f.endswith(".csv")]

    def store_embeddings(self):
        """Generate and store embeddings for CSV documents in ChromaDB."""
        for file in self.load_csv_documents():
            loader = CSVLoader(file_path=os.path.join(self.knowledge_dir, file))
            docs = loader.load()
            for i, doc in enumerate(docs):
                embedding = self.embedding_client.generate_embeddings(doc.page_content)
                self.collection.add(ids=[f"doc_{i}"], embeddings=[embedding], metadatas=[{"source": "csv"}])

class AzureChatbot:
    def __init__(self, base_dir: str, knowledge_dir: str):
        """Initialize the chatbot with environment variables from env/."""
        self.knowledge_base = KnowledgeBase(base_dir, knowledge_dir)
        self.llm = AzureChatOpenAI(
            model_name=os.getenv("MODEL_NAME", "gpt-4"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=os.getenv("AZURE_TOKEN")
        )
        self.memory = ConversationBufferMemory()

    def chat(self, message: str) -> str:
        """Process a user message with RAG."""
        return self.llm.predict(message)

def main():
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    knowledge_dir = os.path.join(base_dir, "knowledge")

    chatbot = AzureChatbot(base_dir, knowledge_dir)

    while True:
        user_input = input("You: ").strip()
        if user_input.lower() in ['quit', 'exit', 'bye']:
            break
        print(f"\nBot: {chatbot.chat(user_input)}")

if __name__ == "__main__":
    main()
