import sys
import os
import logging
import chromadb
from dotenv import dotenv_values
from langchain_openai import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import CSVLoader
from typing import List

# --------------------- Import EmbeddingClient from Parallel Directory ---------------------
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../oaai_client_sdk_core')))
from azoi_embedding_client import EmbeddingClient

# --------------------- Logging Configuration ---------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# --------------------- Load and Store Embeddings in ChromaDB ---------------------
class KnowledgeBase:
    def __init__(self, config_file: str, creds_file: str, cert_file: str, knowledge_dir: str):
        """Initialize the knowledge base and store embeddings in ChromaDB."""
        self.env = dotenv_values(config_file)
        self.embedding_client = EmbeddingClient(config_file, creds_file, cert_file)
        self.knowledge_dir = knowledge_dir
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        self.collection = self.chroma_client.get_or_create_collection(name="csv_knowledge")

    def load_csv_documents(self) -> List[str]:
        """Load CSV documents and return their contents as a list."""
        csv_files = [f for f in os.listdir(self.knowledge_dir) if f.endswith(".csv")]
        if not csv_files:
            logger.info("No CSV files found in the knowledge directory.")
            return []
        
        documents = []
        for file in csv_files:
            logger.info(f"Loading CSV file: {file}")
            loader = CSVLoader(file_path=os.path.join(self.knowledge_dir, file))
            docs = loader.load()
            for doc in docs:
                documents.append(doc.page_content)
        
        return documents

    def store_embeddings(self):
        """Generate and store embeddings for CSV documents in ChromaDB."""
        documents = self.load_csv_documents()
        for i, text in enumerate(documents):
            embedding = self.embedding_client.generate_embeddings(text)
            self.collection.add(
                ids=[f"doc_{i}"],
                embeddings=[embedding],
                metadatas=[{"source": "csv"}]
            )
        logger.info("Stored document embeddings in ChromaDB.")

    def retrieve_relevant_documents(self, query: str, top_k: int = 3) -> List[str]:
        """Retrieve the top relevant document texts from ChromaDB for a given query."""
        query_embedding = self.embedding_client.generate_embeddings(query)
        results = self.collection.query(query_embeddings=[query_embedding], n_results=top_k)
        return [res["source"] for res in results["metadatas"]]

# --------------------- Agent-Based Chatbot with ChromaDB RAG ---------------------
class AzureChatbot:
    def __init__(self, config_file: str, creds_file: str, cert_file: str, knowledge_dir: str):
        """Initialize the chatbot with configuration files and knowledge base."""
        self.env = dotenv_values(config_file)
        self.knowledge_base = KnowledgeBase(config_file, creds_file, cert_file, knowledge_dir)
        
        # Ensure Azure OpenAI endpoint is set correctly
        azure_endpoint = self.env.get("AZURE_OPENAI_ENDPOINT")
        if not azure_endpoint:
            raise ValueError("AZURE_OPENAI_ENDPOINT is missing! Please check your .env files.")

        self.llm = AzureChatOpenAI(
            model_name=self.env.get("MODEL_NAME", "gpt-4"),
            deployment_name=self.env.get("CHAT_MODEL_DEPLOYMENT", self.env.get("MODEL_NAME", "gpt-4")),
            temperature=float(self.env.get("MODEL_TEMPERATURE", "0.7")),
            max_tokens=int(self.env.get("MAX_TOKENS", "800")),
            openai_api_version=self.env.get("API_VERSION", "2024-02-01"),
            azure_endpoint=azure_endpoint,
            azure_ad_token=self.env.get("AZURE_TOKEN")
        )
        
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.knowledge_base.retrieve_relevant_documents,
            memory=self.memory,
            return_source_documents=True,
            verbose=True
        )

    def chat(self, message: str) -> str:
        """Process a user message with RAG and return the chatbot's response."""
        relevant_context = self.knowledge_base.retrieve_relevant_documents(message)
        final_prompt = (
            "Use the following retrieved knowledge to assist in answering the query:\n\n"
            + "\n".join(relevant_context) +
            f"\n\nUser Query: {message}"
        )
        response = self.llm.predict(final_prompt)
        self.memory.chat_memory.add_user_message(message)
        self.memory.chat_memory.add_ai_message(response)
        return response

# --------------------- Main Function ---------------------
def main():
    """Main function to run the chatbot with ChromaDB RAG."""
    base_dir = os.path.dirname(os.path.abspath(__file__))
    env_dir = os.path.abspath(os.path.join(base_dir, '..', 'env'))
    knowledge_dir = os.path.abspath(os.path.join(base_dir, '..', 'knowledge'))

    chatbot = AzureChatbot(
        config_file=os.path.join(env_dir, 'config.env'),
        creds_file=os.path.join(env_dir, 'credentials.env'),
        cert_file=os.path.join(env_dir, 'cacert.pem'),
        knowledge_dir=knowledge_dir
    )

    print("\nChatbot initialized. Type 'quit' to exit.")
    while True:
        user_input = input("\nYou: ").strip()
        if user_input.lower() in ['quit', 'exit', 'bye']:
            print("Goodbye!")
            break
        response = chatbot.chat(user_input)
        print(f"\nBot: {response}")

if __name__ == "__main__":
    main()
