import pandas as pd
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
import rdflib
from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore
import os
import sys

# Set up the RDF SPARQL endpoint and data fetching
endpoint = "abc.com"
st = SPARQLUpdateStore(endpoint)
rdf = rdflib.ConjunctiveGraph(store=st)

# Function to query data from RDF using a dynamic report URL
def generate_data(report_value):
    results = []
    query = f"""
        SELECT ?reportName ?processName ?prodbdeName ?conbdeName ?conrmName ?prodrmName ?gucid ?type
        WHERE {{
            <{report_value}> a abc:Report .
            <{report_value}> abc:hasProcess ?process .
            <{report_value}> abc:reportName ?reportName .
            ?process abc:hasProcessName ?processName .
            ?process abc:hasProducedBDE ?prodbde .
            ?prodbde abc:hasBDEName ?prodbdeName .
            OPTIONAL {{?process abc:hasConsumedBDE ?conbde .
            ?conbde abc:hasBDEName ?conbdeName .}}
            OPTIONAL {{?process abc:hasConsumedMetric ?conrm .
            ?conrm abc:hasMetricName ?conrmName .}}
            OPTIONAL {{?process abc:hasProducedMetric ?prodrm .
            ?prodrm abc:hasMetricName ?prodrmName .}}
            OPTIONAL {{?process abc:hasMonitored ?guc .
            ?guc abc:hasGUCID ?gucid .}}
            OPTIONAL {{?process abc:hasFlowType ?type .}}
        }}
    """
    for (a, b, c, d, e, f, g, h) in rdf.query(query):
        results.append({
            'Report Name': str(a),
            'Process': str(b),
            'Produced BDE': str(c),
            'Consumed BDE': str(d),
            'Consumed Metric': str(e),
            'Produced Metric': str(f),
            'Monitored': str(g),
            'Flow Type': str(h)
        })
    df_data = pd.DataFrame(results)
    return df_data.replace(['None', 'NA', 'N/A'], '').fillna('')

# Function to replace the Report Name on Slide 1
def replace_report_name(slide, report_name):
    for shape in slide.shapes:
        if shape.has_text_frame:
            if "Report Name Analysis" in shape.text:
                shape.text = report_name
                for paragraph in shape.text_frame.paragraphs:
                    for run in paragraph.runs:
                        run.font.size = Pt(54)
                        run.font.name = 'Arial'
                        run.font.bold = True
                        run.font.color.rgb = RGBColor(255, 255, 255)  # White font color

# Function to delete all tables from a slide
def delete_existing_tables(slide):
    shapes_to_delete = [shape for shape in slide.shapes if shape.has_table]
    for shape in shapes_to_delete:
        sp = shape._element
        sp.getparent().remove(sp)

# Function to create a new table on a slide with dynamic font size
def create_table(slide, headers, num_rows, top_position):
    cols = len(headers)
    table = slide.shapes.add_table(num_rows, cols, Inches(0.5), top_position, Inches(11), Inches(0.5)).table

    # Set header row with green background and white font
    for col_idx, header in enumerate(headers):
        cell = table.cell(0, col_idx)
        cell.text = header
        cell.fill.solid()
        cell.fill.fore_color.rgb = RGBColor(0x48, 0x8F, 0x29)  # Green header background
        for paragraph in cell.text_frame.paragraphs:
            for run in paragraph.runs:
                run.font.size = Pt(10)
                run.font.bold = True
                run.font.color.rgb = RGBColor(255, 255, 255)  # White text

    # Determine font size dynamically based on the number of rows, capped at 10
    font_size = max(10 - ((num_rows - 1) // 5), 6)  # Reduces by 1 pt for every 5 extra rows but won't go below 6
    font_size = min(font_size, 10)  # Cap font size at 10

    # Apply font size to all cells
    for row in table.rows:
        for cell in row.cells:
            for paragraph in cell.text_frame.paragraphs:
                for run in paragraph.runs:
                    run.font.size = Pt(font_size)

    return table

# Function to populate a table with data
def populate_table(table, data, start_row=1):
    for row_idx, row_data in enumerate(data, start=start_row):
        for col_idx, cell_data in enumerate(row_data):
            cell = table.cell(row_idx, col_idx)
            cell.text = str(cell_data)
            cell.fill.solid()
            cell.fill.fore_color.rgb = RGBColor(255, 255, 255)  # White background for data rows
            for paragraph in cell.text_frame.paragraphs:
                for run in paragraph.runs:
                    run.font.color.rgb = RGBColor(0, 0, 0)  # Black text

# Function to save data to a CSV file
def save_csv(csv_data, folder_path, file_name="SPARQL_Results.csv"):
    column_names = [
        "Hop Count", "Process", "Consumed or Produced", "Total BDEs", "Total BDEs Agreed to Monitor",
        "% BDE Monitored", "BDEs at Boundary Level", "Boundary BDEs Agreed to Monitor",
        "% Boundary BDE Monitored", "Intra Process BDEs", "Intra Process BDE Agreed to Monitor",
        "% Intra Process BDE Monitored", "Total Metrics", "Total Metrics Agreed to Monitor", "% Metrics Monitored"
    ]
    df = pd.DataFrame(csv_data, columns=column_names)
    df.to_csv(os.path.join(folder_path, file_name), index=False)
    print(f"CSV data saved to {os.path.join(folder_path, file_name)}")

# Populate Slide 6 with two tables
def populate_slide_6(slide, df):
    delete_existing_tables(slide)
    
    # Position for the first table
    top_position_1 = Inches(1)
    headers_1 = ["Process", "Consumed or Produced", "Total BDEs/Metrics"]
    table_1 = create_table(slide, headers_1, num_rows=1 + 2 * df['Process'].nunique(), top_position=top_position_1)
    row_data_1 = []
    for process in df['Process'].unique():
        process_data = df[df['Process'] == process]
        consumed_total = process_data['Consumed BDE'].loc[process_data['Consumed BDE'] != ''].nunique() + process_data['Consumed Metric'].loc[process_data['Consumed Metric'] != ''].nunique()
        produced_total = process_data['Produced BDE'].loc[process_data['Produced BDE'] != ''].nunique() + process_data['Produced Metric'].loc[process_data['Produced Metric'] != ''].nunique()
        row_data_1.append([process, 'Consumed', consumed_total])
        row_data_1.append([process, 'Produced', produced_total])
    populate_table(table_1, row_data_1)

    # Position for the second table
    top_position_2 = Inches(3)  # Adjusted to prevent overlap
    headers_2 = ["Hop", "Process", "Consumed or Produced", "Total Metrics", "Total BDEs", "BDEs at Boundary Level", "Intra Process BDEs"]
    table_2 = create_table(slide, headers_2, num_rows=1 + 2 * df['Process'].nunique(), top_position=top_position_2)
    row_data_2 = []
    for hop_count, process in enumerate(df['Process'].unique(), start=1):
        process_data = df[df['Process'] == process]
        consumed_metrics = process_data['Consumed Metric'].loc[process_data['Consumed Metric'] != ''].nunique()
        produced_metrics = process_data['Produced Metric'].loc[process_data['Produced Metric'] != ''].nunique()
        total_bdes_consumed = process_data['Consumed BDE'].loc[process_data['Consumed BDE'] != ''].nunique()
        total_bdes_produced = process_data['Produced BDE'].loc[process_data['Produced BDE'] != ''].nunique()
        boundary_bdes_consumed = process_data[(process_data['Flow Type'].str.contains("Inbound", case=False, na=False)) & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        boundary_bdes_produced = process_data[(process_data['Flow Type'].str.contains("Process Output", case=False, na=False)) & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        intra_process_bdes_consumed = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        intra_process_bdes_produced = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        
        row_data_2.append([hop_count, process, 'Consumed', consumed_metrics, total_bdes_consumed, boundary_bdes_consumed, intra_process_bdes_consumed])
        row_data_2.append([hop_count, process, 'Produced', produced_metrics, total_bdes_produced, boundary_bdes_produced, intra_process_bdes_produced])
    populate_table(table_2, row_data_2)

# Populate Slide 8 table
def populate_slide_8(slide, df, csv_data):
    delete_existing_tables(slide)
    headers_8 = [
        "Hop Count", "Process", "Consumed or Produced", "Total BDEs", "Total BDEs Agreed to Monitor", "% BDE Monitored",
        "BDEs at Boundary Level", "Boundary BDEs Agreed to Monitor", "% Boundary BDE Monitored",
        "Intra Process BDEs", "Intra Process BDE Agreed to Monitor", "% Intra Process BDE Monitored",
        "Total Metrics", "Total Metrics Agreed to Monitor", "% Metrics Monitored"
    ]
    table_8 = create_table(slide, headers_8, num_rows=1 + 2 * df['Process'].nunique(), top_position=Inches(1))
    row_data_8 = []
    
    for hop_count, process in enumerate(df['Process'].unique(), start=1):
        process_data = df[df['Process'] == process]
        
        # Consumed data calculations
        consumed_bdes = process_data['Consumed BDE'].loc[process_data['Consumed BDE'] != ''].nunique()
        consumed_monitored = process_data[(process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        boundary_consumed_bdes = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        boundary_consumed_monitored = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        intra_process_bdes = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        intra_process_monitored = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        total_metrics = process_data['Consumed Metric'].loc[process_data['Consumed Metric'] != ''].nunique()
        monitored_metrics = process_data[(process_data['Consumed Metric'] != '') & (process_data['Monitored'] != '')]['Consumed Metric'].nunique()

        row_data_8.append([
            hop_count, process, 'Consumed', consumed_bdes, consumed_monitored,
            f"{(consumed_monitored / consumed_bdes * 100) if consumed_bdes > 0 else 0:.2f}%",
            boundary_consumed_bdes, boundary_consumed_monitored,
            f"{(boundary_consumed_monitored / boundary_consumed_bdes * 100) if boundary_consumed_bdes > 0 else 0:.2f}%",
            intra_process_bdes, intra_process_monitored,
            f"{(intra_process_monitored / intra_process_bdes * 100) if intra_process_bdes > 0 else 0:.2f}%",
            total_metrics, monitored_metrics,
            f"{(monitored_metrics / total_metrics * 100) if total_metrics > 0 else 0:.2f}%"
        ])
        
        # Produced data calculations
        produced_bdes = process_data['Produced BDE'].loc[process_data['Produced BDE'] != ''].nunique()
        produced_monitored = process_data[(process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        boundary_produced_bdes = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        boundary_produced_monitored = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        intra_process_produced_bdes = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        intra_process_produced_monitored = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        total_produced_metrics = process_data['Produced Metric'].loc[process_data['Produced Metric'] != ''].nunique()
        monitored_produced_metrics = process_data[(process_data['Produced Metric'] != '') & (process_data['Monitored'] != '')]['Produced Metric'].nunique()

        row_data_8.append([
            hop_count, process, 'Produced', produced_bdes, produced_monitored,
            f"{(produced_monitored / produced_bdes * 100) if produced_bdes > 0 else 0:.2f}%",
            boundary_produced_bdes, boundary_produced_monitored,
            f"{(boundary_produced_monitored / boundary_produced_bdes * 100) if boundary_produced_bdes > 0 else 0:.2f}%",
            intra_process_produced_bdes, intra_process_produced_monitored,
            f"{(intra_process_produced_monitored / intra_process_produced_bdes * 100) if intra_process_produced_bdes > 0 else 0:.2f}%",
            total_produced_metrics, monitored_produced_metrics,
            f"{(monitored_produced_metrics / total_produced_metrics * 100) if total_produced_metrics > 0 else 0:.2f}%"
        ])
    populate_table(table_8, row_data_8)
    csv_data.extend(row_data_8)

# Function to create individual report
def create_report(template_path, output_folder, report_value):
    prs = Presentation(template_path)
    df = generate_data(report_value)
    report_name = df['Report Name'].iloc[0] if 'Report Name' in df.columns and not df['Report Name'].empty else "Unknown Report"

    # Create a folder for each report
    report_folder = os.path.join(output_folder, report_name)
    os.makedirs(report_folder, exist_ok=True)

    # Update Slide 1 with the report name
    if len(prs.slides) > 0:
        replace_report_name(prs.slides[0], report_name)

    # Populate Slide 6 tables
    if len(prs.slides) > 5:
        populate_slide_6(prs.slides[5], df)

    # Populate Slide 8 table
    if len(prs.slides) > 7:
        csv_data = []
        populate_slide_8(prs.slides[7], df, csv_data)
        save_csv(csv_data, report_folder)

    # Save the PowerPoint
    pptx_path = os.path.join(report_folder, f"{report_name}.pptx")
    prs.save(pptx_path)
    print(f"PowerPoint saved as {pptx_path}")

# Main function to handle single and bulk reports
def main():
    template_path = "Report Name Analysis.pptx"

    if len(sys.argv) > 1:
        # Bulk processing using command line argument
        csv_path = sys.argv[1]
        bulk_process = True
    else:
        # Ask user for single or bulk processing
        option = input("Generate single report or bulk reports? Enter 'single' or 'bulk': ").strip().lower()
        bulk_process = option == 'bulk'

        if bulk_process:
            csv_path = input("Enter the path to the CSV file with report URLs: ").strip()
        else:
            report_url = input("Enter the report URL: ").strip()

    output_folder = "results"
    os.makedirs(output_folder, exist_ok=True)

    if bulk_process:
        # Process each report URL from the CSV
        urls_df = pd.read_csv(csv_path, header=None)  # Read without considering headers
        for report_value in urls_df.iloc[:, 0]:  # Take the first column with URLs
            create_report(template_path, output_folder, report_value)
    else:
        # Single report processing
        create_report(template_path, output_folder, report_url)

if __name__ == "__main__":
    main()
