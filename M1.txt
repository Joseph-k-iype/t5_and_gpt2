import pandas as pd
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
import rdflib
from rdflib.plugins.stores.sparqlstore import SPARQLUpdateStore
import os
import sys

# Set up the RDF SPARQL endpoint and data fetching
endpoint = "abc.com"
st = SPARQLUpdateStore(endpoint)
rdf = rdflib.ConjunctiveGraph(store=st)

# Function to query data from RDF for the main report data
def generate_main_data(report_value):
    results = []
    query = f"""
        SELECT ?reportName ?processName ?prodbdeName ?conbdeName ?conrmName ?prodrmName ?gucid ?type
        WHERE {{
            <{report_value}> a abc:Report .
            <{report_value}> abc:hasProcess ?process .
            <{report_value}> abc:reportName ?reportName .
            ?process abc:hasProcessName ?processName .
            ?process abc:hasProducedBDE ?prodbde .
            ?prodbde abc:hasBDEName ?prodbdeName .
            OPTIONAL {{?process abc:hasConsumedBDE ?conbde .
            ?conbde abc:hasBDEName ?conbdeName .}}
            OPTIONAL {{?process abc:hasConsumedMetric ?conrm .
            ?conrm abc:hasMetricName ?conrmName .}}
            OPTIONAL {{?process abc:hasProducedMetric ?prodrm .
            ?prodrm abc:hasMetricName ?prodrmName .}}
            OPTIONAL {{?process abc:hasMonitored ?guc .
            ?guc abc:hasGUCID ?gucid .}}
            OPTIONAL {{?process abc:hasFlowType ?type .}}
        }}
    """
    for (a, b, c, d, e, f, g, h) in rdf.query(query):
        results.append({
            'Report Name': str(a),
            'Process': str(b),
            'Produced BDE': str(c),
            'Consumed BDE': str(d),
            'Consumed Metric': str(e),
            'Produced Metric': str(f),
            'Monitored': str(g),
            'Flow Type': str(h)
        })
    return pd.DataFrame(results).replace(['None', 'NA', 'N/A'], '').fillna('')

# Function to query data specifically for Slide 9 (Business, Upstream, Downstream)
def generate_slide9_data(report_value):
    results = []
    query = f"""
        SELECT ?business ?upstream ?downstream
        WHERE {{
            <{report_value}> abc:hasBusiness ?business .
            ?business abc:hasUpstream ?upstream .
            ?business abc:hasDownstream ?downstream .
        }}
    """
    for (a, b, c) in rdf.query(query):
        results.append({
            'Business': str(a),
            'Upstream': str(b),
            'Downstream': str(c)
        })
    return pd.DataFrame(results).replace(['None', 'NA', 'N/A'], '').fillna('')

# Function to query data specifically for Slide 10 (Issue, Summary)
def generate_slide10_data(report_value):
    results = []
    query = f"""
        SELECT ?issue ?summary
        WHERE {{
            <{report_value}> abc:hasIssue ?issue .
            ?issue abc:hasSummary ?summary .
        }}
    """
    for (a, b) in rdf.query(query):
        results.append({
            'Issue': str(a),
            'Summary': str(b)
        })
    return pd.DataFrame(results).replace(['None', 'NA', 'N/A'], '').fillna('')

# Function to replace the Report Name on Slide 1
def replace_report_name(slide, report_name):
    for shape in slide.shapes:
        if shape.has_text_frame and "Report Name Analysis" in shape.text:
            shape.text = report_name
            for paragraph in shape.text_frame.paragraphs:
                for run in paragraph.runs:
                    run.font.size = Pt(54)
                    run.font.name = 'Arial'
                    run.font.bold = True
                    run.font.color.rgb = RGBColor(255, 255, 255)

# Function to delete all tables from a slide
def delete_existing_tables(slide):
    shapes_to_delete = [shape for shape in slide.shapes if shape.has_table]
    for shape in shapes_to_delete:
        sp = shape._element
        sp.getparent().remove(sp)

# Function to create a new table on a slide with dynamic font size
def create_table(slide, headers, num_rows, top_position):
    cols = len(headers)
    table = slide.shapes.add_table(num_rows, cols, Inches(0.5), top_position, Inches(11), Inches(0.5)).table

    # Set header row with green background and white font
    for col_idx, header in enumerate(headers):
        cell = table.cell(0, col_idx)
        cell.text = header
        cell.fill.solid()
        cell.fill.fore_color.rgb = RGBColor(0x48, 0x8F, 0x29)  # Green header background
        for paragraph in cell.text_frame.paragraphs:
            for run in paragraph.runs:
                run.font.size = Pt(10)
                run.font.bold = True
                run.font.color.rgb = RGBColor(255, 255, 255)

    return table

# Function to populate a table with data
def populate_table(table, data, start_row=1):
    for row_idx, row_data in enumerate(data, start=start_row):
        for col_idx, cell_data in enumerate(row_data):
            cell = table.cell(row_idx, col_idx)
            cell.text = str(cell_data)
            cell.fill.solid()
            cell.fill.fore_color.rgb = RGBColor(255, 255, 255)
            for paragraph in cell.text_frame.paragraphs:
                for run in paragraph.runs:
                    run.font.color.rgb = RGBColor(0, 0, 0)

# Populate Slide 6 with two tables
def populate_slide_6(slide, df):
    delete_existing_tables(slide)
    
    headers_1 = ["Process", "Consumed or Produced", "Total BDEs/Metrics"]
    top_position_1 = Inches(1)
    table_1 = create_table(slide, headers_1, num_rows=1 + 2 * df['Process'].nunique(), top_position=top_position_1)
    row_data_1 = [
        [process, 'Consumed', df[df['Process'] == process]['Consumed BDE'].nunique() + df[df['Process'] == process]['Consumed Metric'].nunique()]
        for process in df['Process'].unique()
    ] + [
        [process, 'Produced', df[df['Process'] == process]['Produced BDE'].nunique() + df[df['Process'] == process]['Produced Metric'].nunique()]
        for process in df['Process'].unique()
    ]
    populate_table(table_1, row_data_1)

# Populate Slide 8 table with full calculation logic
def populate_slide_8(slide, df, csv_data):
    delete_existing_tables(slide)
    headers = [
        "Hop Count", "Process", "Consumed or Produced", "Total BDEs", "Total BDEs Agreed to Monitor", "% BDE Monitored",
        "BDEs at Boundary Level", "Boundary BDEs Agreed to Monitor", "% Boundary BDE Monitored",
        "Intra Process BDEs", "Intra Process BDE Agreed to Monitor", "% Intra Process BDE Monitored",
        "Total Metrics", "Total Metrics Agreed to Monitor", "% Metrics Monitored"
    ]
    table = create_table(slide, headers, num_rows=1 + 2 * df['Process'].nunique(), top_position=Inches(1))

    row_data = []
    for hop_count, process in enumerate(df['Process'].unique(), start=1):
        process_data = df[df['Process'] == process]

        # Consumed Data Calculations
        consumed_bdes = process_data['Consumed BDE'].loc[process_data['Consumed BDE'] != ''].nunique()
        consumed_monitored = process_data[(process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        boundary_consumed_bdes = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        boundary_consumed_monitored = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        intra_process_bdes = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Consumed BDE'] != '')]['Consumed BDE'].nunique()
        intra_process_monitored = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Consumed BDE'] != '') & (process_data['Monitored'] != '')]['Consumed BDE'].nunique()
        total_metrics = process_data['Consumed Metric'].loc[process_data['Consumed Metric'] != ''].nunique()
        monitored_metrics = process_data[(process_data['Consumed Metric'] != '') & (process_data['Monitored'] != '')]['Consumed Metric'].nunique()

        row_data.append([
            hop_count, process, 'Consumed', consumed_bdes, consumed_monitored,
            f"{(consumed_monitored / consumed_bdes * 100) if consumed_bdes else 0:.2f}%",
            boundary_consumed_bdes, boundary_consumed_monitored,
            f"{(boundary_consumed_monitored / boundary_consumed_bdes * 100) if boundary_consumed_bdes else 0:.2f}%",
            intra_process_bdes, intra_process_monitored,
            f"{(intra_process_monitored / intra_process_bdes * 100) if intra_process_bdes else 0:.2f}%",
            total_metrics, monitored_metrics,
            f"{(monitored_metrics / total_metrics * 100) if total_metrics else 0:.2f}%"
        ])

        # Produced Data Calculations
        produced_bdes = process_data['Produced BDE'].loc[process_data['Produced BDE'] != ''].nunique()
        produced_monitored = process_data[(process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        boundary_produced_bdes = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        boundary_produced_monitored = process_data[(process_data['Flow Type'] != 'Intra Process') & (process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        intra_process_produced_bdes = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Produced BDE'] != '')]['Produced BDE'].nunique()
        intra_process_produced_monitored = process_data[(process_data['Flow Type'].str.contains("Intra[- ]?Process", case=False, na=False)) & (process_data['Produced BDE'] != '') & (process_data['Monitored'] != '')]['Produced BDE'].nunique()
        total_produced_metrics = process_data['Produced Metric'].loc[process_data['Produced Metric'] != ''].nunique()
        monitored_produced_metrics = process_data[(process_data['Produced Metric'] != '') & (process_data['Monitored'] != '')]['Produced Metric'].nunique()

        row_data.append([
            hop_count, process, 'Produced', produced_bdes, produced_monitored,
            f"{(produced_monitored / produced_bdes * 100) if produced_bdes else 0:.2f}%",
            boundary_produced_bdes, boundary_produced_monitored,
            f"{(boundary_produced_monitored / boundary_produced_bdes * 100) if boundary_produced_bdes else 0:.2f}%",
            intra_process_produced_bdes, intra_process_produced_monitored,
            f"{(intra_process_produced_monitored / intra_process_produced_bdes * 100) if intra_process_produced_bdes else 0:.2f}%",
            total_produced_metrics, monitored_produced_metrics,
            f"{(monitored_produced_metrics / total_produced_metrics * 100) if total_produced_metrics else 0:.2f}%"
        ])

    populate_table(table, row_data)
    csv_data.extend(row_data)

# Populate Slide 9 table (Business, Upstream, Downstream)
def populate_slide_9(slide, df_slide9):
    delete_existing_tables(slide)
    headers = ["Business", "Upstream", "Downstream"]
    table = create_table(slide, headers, num_rows=1 + len(df_slide9), top_position=Inches(1))
    row_data = df_slide9[["Business", "Upstream", "Downstream"]].values.tolist()
    populate_table(table, row_data)

# Populate Slide 10 table (Issue, Summary)
def populate_slide_10(slide, df_slide10):
    delete_existing_tables(slide)
    headers = ["Issue", "Summary"]
    table = create_table(slide, headers, num_rows=1 + len(df_slide10), top_position=Inches(1))
    row_data = df_slide10[["Issue", "Summary"]].values.tolist()
    populate_table(table, row_data)

# Function to save data to a CSV file
def save_csv(csv_data, folder_path, file_name="SPARQL_Results.csv"):
    df = pd.DataFrame(csv_data)
    df.to_csv(os.path.join(folder_path, file_name), index=False)

# Function to create individual report
def create_report(template_path, output_folder, report_value):
    try:
        prs = Presentation(template_path)
        df = generate_main_data(report_value)
        df_slide9 = generate_slide9_data(report_value)
        df_slide10 = generate_slide10_data(report_value)
        
        if df.empty:
            print(f"No data returned for report URL: {report_value}. Skipping...")
            return

        report_name = df['Report Name'].iloc[0] if 'Report Name' in df.columns else "Unknown Report"
        report_folder = os.path.join(output_folder, report_name)
        os.makedirs(report_folder, exist_ok=True)

        replace_report_name(prs.slides[0], report_name)

        if len(prs.slides) > 5:
            populate_slide_6(prs.slides[5], df)
        if len(prs.slides) > 7:
            csv_data = []
            populate_slide_8(prs.slides[7], df, csv_data)
            save_csv(csv_data, report_folder)
        if len(prs.slides) > 8:
            populate_slide_9(prs.slides[8], df_slide9)
        if len(prs.slides) > 9:
            populate_slide_10(prs.slides[9], df_slide10)

        pptx_path = os.path.join(report_folder, f"{report_name}.pptx")
        prs.save(pptx_path)
        print(f"PowerPoint saved as {pptx_path}")

    except Exception as e:
        print(f"Error processing report URL {report_value}: {e}")

# Main function to handle single and bulk reports
def main():
    template_path = "Report Name Analysis.pptx"
    output_folder = "results"
    os.makedirs(output_folder, exist_ok=True)

    if len(sys.argv) > 1:
        csv_path = sys.argv[1]
        urls_df = pd.read_csv(csv_path, header=None)
        for report_value in urls_df.iloc[:, 0]:
            create_report(template_path, output_folder, report_value)
    else:
        option = input("Generate single report or bulk reports? Enter 'single' or 'bulk': ").strip().lower()
        if option == 'bulk':
            csv_path = input("Enter the path to the CSV file with report URLs: ").strip()
            urls_df = pd.read_csv(csv_path, header=None)
            for report_value in urls_df.iloc[:, 0]:
                create_report(template_path, output_folder, report_value)
        else:
            report_url = input("Enter the report URL: ").strip()
            create_report(template_path, output_folder, report_url)

if __name__ == "__main__":
    main()
