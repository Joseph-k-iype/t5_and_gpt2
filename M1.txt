import os
import sys
import uuid
import json
import logging
import pandas as pd
import networkx as nx
import numpy as np
from typing import Optional, Any, Dict, List, Union, Tuple, Callable
from pathlib import Path
from dotenv import dotenv_values
from azure.identity import DefaultAzureCredential, get_bearer_token_provider, ClientSecretCredential
from openai import AzureOpenAI
from pydantic import BaseModel
from langchain.chat_models import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain.docstore import Document as LC_DOCUMENT
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from collections import namedtuple
import re
from pydantic import BaseModel, ValidationError, field_validator
import traceback

# Import necessary RDF libraries
import rdflib
from rdflib import Graph as RDFGraph, URIRef, Literal, BNode, ConjunctiveGraph
from rdflib.namespace import RDF, RDFS, OWL
from rdflib.plugins.stores.sparqlstore import SPARQLStore, SPARQLUpdateStore

# Import LangGraph for agent orchestration
from langgraph.graph import StateGraph, END

# Additional LangChain components for structured output
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser
from langchain_core.pydantic_v1 import BaseModel as LCBaseModel, Field
from langchain_core.messages import AIMessage, HumanMessage, SystemMessage

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

Triple = namedtuple("Triple", ["subject", "predicate", "object"])

## utility functions
def is_file_readable(filepath: str)->bool:
    """Check if a file is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        logger.warning(f"The file '{filepath}' does not exist or is not readable")
        return False
    return True

def str_to_bool(s: str)->bool:
    """Convert a string to a boolean."""
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean value: {s}")

## OSEnv class
class OSEnv:
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.credential = None
        
        try:
            self.bulk_set(config_file, True)
        except Exception as e:
            logger.warning(f"Error loading config file: {e}")
            
        try:
            self.bulk_set(creds_file, False)
        except Exception as e:
            logger.warning(f"Error loading creds file: {e}")
            
        try:
            self.set_certificate_path(certificate_path)
        except Exception as e:
            logger.warning(f"Error setting certificate path: {e}")
            
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            try:
                self.set_proxy()
            except Exception as e:
                logger.warning(f"Error setting proxy: {e}")
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            try:
                self.token = self.get_azure_token()
            except Exception as e:
                logger.warning(f"Error getting Azure token: {e}")
                self.token = None
        else:
            self.token = None
        
        # Initialize credential
        self.credential = self._get_credential()
    
    def _get_credential(self):
        """Get the appropriate Azure credential"""
        try:
            if str_to_bool(self.get("USE_MANAGED_IDENTITY", "False")):
                return DefaultAzureCredential()
            else:
                tenant_id = self.get("AZURE_TENANT_ID")
                client_id = self.get("AZURE_CLIENT_ID")
                client_secret = self.get("AZURE_CLIENT_SECRET")
                
                # Check if required values are present
                if not all([tenant_id, client_id, client_secret]):
                    logger.warning("Missing Azure credentials, returning DefaultAzureCredential")
                    return DefaultAzureCredential()
                    
                return ClientSecretCredential(
                    tenant_id=tenant_id, 
                    client_id=client_id, 
                    client_secret=client_secret
                )
        except Exception as e:
            logger.warning(f"Error creating credential: {e}")
            # Return default credential as fallback
            return DefaultAzureCredential()
    
    def set_certificate_path(self, path: str):
        """Set the certificate path for SSL connections"""
        try:
            if not path:
                logger.warning("Certificate path is empty")
                return
                
            if not os.path.isabs(path):
                path = os.path.abspath(path)
            
            if not is_file_readable(path):
                logger.warning(f"Certificate file not readable: {path}")
                return
            
            self.set("REQUESTS_CA_BUNDLE", path)
            self.set("SSL_CERT_FILE", path)
            self.set("CURL_CA_BUNDLE", path)
            logger.info(f"Set certificate path: {path}")
        except Exception as e:
            logger.error(f"Error setting certificate path: {e}")
    
    def bulk_set(self, dotenvfile: str, print_val: bool = False)->None:
        """Load and set environment variables from a .env file"""
        try:
            if not dotenvfile:
                logger.warning("Dotenv file path is empty")
                return
                
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
            
            if not is_file_readable(dotenvfile):
                logger.warning(f"Dotenv file not readable: {dotenvfile}")
                return
            
            temp_dict = dotenv_values(dotenvfile)
            for key, value in temp_dict.items():
                self.set(key, value, print_val)
            
            logger.info(f"Loaded {len(temp_dict)} environment variables from {dotenvfile}")
            del temp_dict
        except Exception as e:
            logger.error(f"Error loading environment variables from {dotenvfile}: {e}")
    
    def set(self, key: str, value: str, print_val: bool = False)->None:
        """Set an environment variable"""
        try:
            if key and value is not None:  # Allow empty string values but not None
                os.environ[key] = value
                if key not in self.var_list:
                    self.var_list.append(key)
                if print_val:
                    logger.info(f"Set env var: {key}: {value}")
        except Exception as e:
            logger.error(f"Error setting environment variable {key}: {e}")
    
    def get(self, key: str, default: Optional[str] = None)->str:
        """Get an environment variable with optional default"""
        try:
            return os.environ.get(key, default)
        except Exception as e:
            logger.error(f"Error getting environment variable {key}: {e}")
            return default
    
    def set_proxy(self) -> None:
        """Configure proxy settings from environment variables"""
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            
            if not all([ad_username, ad_password, proxy_domain]):
                logger.warning("Proxy settings are incomplete")
                return
                
            proxy_url = f"https://{ad_username}:{ad_password}@{proxy_domain}"
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains), print_val=False)
            logger.info("Proxy settings configured")
        except Exception as e:
            logger.error(f"Error setting proxy: {e}")
    
    def get_azure_token(self) -> str:
        """Get an Azure authentication token"""
        try:
            tenant_id = self.get("AZURE_TENANT_ID")
            client_id = self.get("AZURE_CLIENT_ID")
            client_secret = self.get("AZURE_CLIENT_SECRET")
            
            if not all([tenant_id, client_id, client_secret]):
                logger.warning("Missing Azure credentials for token")
                return None
                
            credential = ClientSecretCredential(
                tenant_id=tenant_id,
                client_id=client_id,
                client_secret=client_secret
            )
            
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token acquired")
            return token.token
        except Exception as e:
            logger.error(f"Error retrieving Azure token: {e}")
            return None
    
    def list_env_vars(self)->None:
        """List all environment variables that have been set"""
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [REDACTED]")
            else:
                logger.info(f"{var}: {os.getenv(var)}")


## embedding class + Document class
class MyDocument(BaseModel):
    """Document model for embeddings"""
    id: str = ""
    text: str = ""
    embedding: List[float] = []
    metadata: Dict[str, Any] = {}


class EmbeddingClient:
    """Client for generating embeddings using Azure OpenAI"""
    def __init__(self, azure_api_version: str = "2023-05-15", embeddings_model: str = "text-embedding-3-large"):
        self.azure_api_version = azure_api_version
        self.embeddings_model = embeddings_model
        self.direct_azure_client = None
        
        try:
            self.direct_azure_client = self._get_direct_azure_client()
        except Exception as e:
            logger.error(f"Error initializing Azure client: {e}")
    
    def _get_direct_azure_client(self):
        """Get an Azure OpenAI client for embeddings"""
        try:
            token_provider = get_bearer_token_provider(
                DefaultAzureCredential(),
                "https://cognitiveservices.azure.com/.default"
            )
            return AzureOpenAI(token_provider, self.azure_api_version)
        except Exception as e:
            logger.error(f"Error getting Azure client: {e}")
            return None
    
    def generate_embeddings(self, doc: MyDocument)->MyDocument:
        """Generate embeddings for the given document"""
        try:
            if not self.direct_azure_client:
                logger.error("Azure client not initialized")
                return doc
                
            response = self.direct_azure_client.embeddings.create(
                model=self.embeddings_model,
                input=doc.text
            ).data[0].embedding
            
            doc.embedding = response
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            return doc


## AzureChatbot components
class AzureChatbot:
    """Base chatbot using Azure OpenAI"""
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.llm = None
        
        try:
            self._setup_chat_model()
            self.memory = ConversationBufferMemory()
            self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
        except Exception as e:
            logger.error(f"Error initializing AzureChatbot: {e}")
    
    def _setup_chat_model(self):
        """Set up the Azure OpenAI chat model"""
        try:
            if not self.env.credential:
                logger.error("No Azure credential available")
                return
                
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            temperature = float(self.env.get("TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2023-05-15")
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            if not azure_endpoint:
                logger.error("Azure endpoint not specified")
                return
                
            azure_ad_token_provider = token_provider
            
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token_provider=azure_ad_token_provider
            )
            
            logger.info(f"Chat model initialized: {model_name} on {azure_endpoint}")
        except Exception as e:
            logger.error(f"Error setting up chat model: {e}")
            raise


# Define models for the GraphRAG components
class QueryUnderstanding(LCBaseModel):
    """Model for understanding the user's query"""
    intent: str = Field(description="The main intent of the user's query")
    entities: List[Dict[str, str]] = Field(description="Key entities mentioned in the query")
    filters: Optional[List[Dict[str, Any]]] = Field(default=None, description="Any filters or constraints specified")
    question_type: str = Field(description="The type of question (e.g., 'factual', 'analytical', 'comparative')")


class SparqlQuery(LCBaseModel):
    """Model for a SPARQL query"""
    query_id: str
    original_query: str
    sparql_query: str
    is_valid: bool = False
    error_message: Optional[str] = None


class QueryResult(LCBaseModel):
    """Model for query results"""
    query_id: str
    original_query: str
    sparql_query: str
    results: List[Dict[str, Any]]
    result_count: int


class BusinessReport(LCBaseModel):
    """Model for the final business report"""
    query_id: str
    original_query: str
    report_text: str
    insights: Optional[List[str]] = None
    recommendations: Optional[List[str]] = None


class QueryValidation(LCBaseModel):
    """Model for query validation results"""
    is_valid: bool = Field(description="Whether the query is valid")
    corrected_query: Optional[str] = Field(default=None, description="The corrected query if the original was invalid")
    explanation: str = Field(description="Explanation of the errors found or why the query is valid")


class WorkflowState(BaseModel):
    """State object for the agent workflow with reasoning traces"""
    query_id: str
    original_query: str
    query_understanding: Optional[Dict[str, Any]] = None
    understanding_reasoning: Optional[str] = None
    sparql_query: Optional[str] = None
    sparql_generation_reasoning: Optional[str] = None
    validation_result: Optional[Dict[str, Any]] = None
    validation_reasoning: Optional[str] = None
    query_results: Optional[List[Dict[str, Any]]] = None
    reporting_reasoning: Optional[str] = None
    final_report: Optional[str] = None
    
    def __getitem__(self, key):
        """Allow dict-like access to state properties"""
        return getattr(self, key)
    
    def __setitem__(self, key, value):
        """Allow dict-like setting of state properties"""
        setattr(self, key, value)


# Main GraphRAG chatbot class
class GraphRAGChatbot:
    """GraphRAG chatbot for querying knowledge graphs using natural language"""
    def __init__(self, 
                 config_file=CONFIG_PATH, 
                 creds_file=CREDS_PATH, 
                 cert_file=CERT_PATH, 
                 ontology_path=None):
        """
        Initialize the GraphRAG chatbot
        
        Args:
            config_file (str): Path to the config file
            creds_file (str): Path to the credentials file
            cert_file (str): Path to the certificate file
            ontology_path (str, optional): Path to the ontology file. If None, will use the value from
                                           ONTOLOGY_PATH environment variable or default to "ontology.owl"
        """
        try:
            # Initialize the base chatbot for Azure OpenAI integration
            self.base_chatbot = AzureChatbot(config_file, creds_file, cert_file)
            self.env = self.base_chatbot.env
            self.llm = self.base_chatbot.llm
            
            if not self.llm:
                logger.error("LLM not initialized - check Azure configuration")
                raise ValueError("LLM not initialized")
            
            # Initialize RDF components
            # Determine the ontology path from parameters or environment variables
            self.ontology_path = ontology_path or self.env.get("ONTOLOGY_PATH", "ontology.owl")
            logger.info(f"Using ontology file: {self.ontology_path}")
            
            # Load ontology and setup SPARQL endpoint
            self.ontology_graph = self._load_ontology()
            self.sparql_store, self.sparql_graph = self._setup_sparql_endpoint()
            
            # Initialize conversation memory
            self.memory = ConversationBufferMemory()
            
            # Initialize the agents
            self.query_understanding_agent = None
            self.ontology_agent = None
            self.validation_agent = None
            self.reporting_agent = None
            
            # Setup the agent workflow
            self.agent_workflow = self._setup_agent_workflow()
            
            logger.info("GraphRAG chatbot initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing GraphRAG chatbot: {e}")
            logger.error(traceback.format_exc())
            raise
    
    def _load_ontology(self) -> RDFGraph:
        """Load the ontology from the file (supports OWL/XML, TTL, N3, etc.)"""
        try:
            # Check if the ontology file exists
            if not is_file_readable(self.ontology_path):
                logger.warning(f"Ontology file not found or not readable: {self.ontology_path}")
                # Return an empty graph instead of raising an exception
                return RDFGraph()
            
            ontology = RDFGraph()
            
            # Determine file format based on extension
            file_ext = os.path.splitext(self.ontology_path)[1].lower()
            
            if file_ext == '.ttl':
                format_name = 'turtle'
            elif file_ext == '.n3':
                format_name = 'n3'
            elif file_ext == '.nt':
                format_name = 'nt'
            elif file_ext == '.jsonld':
                format_name = 'json-ld'
            elif file_ext in ['.owl', '.rdf', '.xml']:
                format_name = 'xml'
            else:
                # If extension is not recognized, let rdflib try to guess
                format_name = None
            
            try:
                # Parse the ontology file
                ontology.parse(self.ontology_path, format=format_name)
                logger.info(f"Loaded ontology from {self.ontology_path} with {len(ontology)} triples (format: {format_name or 'auto-detected'})")
            except Exception as format_error:
                # If parsing fails with the detected format, try without specifying a format
                logger.warning(f"Error parsing ontology with format {format_name}: {format_error}")
                logger.info(f"Trying to parse ontology without specifying format")
                ontology = RDFGraph()
                ontology.parse(self.ontology_path)
                logger.info(f"Loaded ontology with {len(ontology)} triples using auto-detection")
            
            return ontology
        except Exception as e:
            logger.error(f"Error loading ontology: {e}")
            logger.error(traceback.format_exc())
            # Return an empty graph instead of raising an exception
            return RDFGraph()
    
    def _setup_sparql_endpoint(self):
        """Setup connection to the SPARQL endpoint with SPARQLUpdateStore and ConjunctiveGraph"""
        try:
            endpoint_url = self.env.get("SPARQL_ENDPOINT_URL")
            if not endpoint_url:
                logger.warning("SPARQL endpoint URL not configured in environment variables")
                # Create a default in-memory store and graph
                default_store = rdflib.plugin.get('Memory', rdflib.store.Store)()
                default_graph = rdflib.ConjunctiveGraph(store=default_store)
                return default_store, default_graph
            
            # Hard-coded Basic auth credentials
            username = "abc"
            password = "124"
            
            logger.info(f"Connecting to SPARQL endpoint: {endpoint_url}")
            
            try:
                # Use default SPARQLUpdateStore
                store = rdflib.plugins.stores.sparqlstore.SPARQLUpdateStore()
                
                # Open the store with the endpoint URL and credentials
                store.open((endpoint_url, endpoint_url))
                
                # Set authentication directly
                store.setCredentials(username, password)
                
                # Create a ConjunctiveGraph using this store
                graph = rdflib.ConjunctiveGraph(store=store)
                
                # Test connection with a simple query
                try:
                    test_query = "SELECT ?s ?p ?o WHERE { ?s ?p ?o } LIMIT 1"
                    logger.info(f"Testing connection with query: {test_query}")
                    results = list(graph.query(test_query))
                    logger.info(f"Successfully connected to SPARQL endpoint: {endpoint_url}")
                    logger.info(f"Test query returned {len(results)} results")
                except Exception as e:
                    logger.warning(f"Test query failed but continuing: {str(e)}")
                
                return store, graph
            except Exception as e:
                logger.error(f"Error with SPARQLUpdateStore: {e}")
                
                # Try alternative connection method with SPARQLStore
                logger.info("Trying alternative connection method with SPARQLStore")
                alt_store = SPARQLStore(endpoint_url, auth=(username, password))
                alt_graph = ConjunctiveGraph(store=alt_store)
                return alt_store, alt_graph
                
        except Exception as e:
            logger.error(f"Error connecting to SPARQL endpoint: {e}")
            logger.error(traceback.format_exc())
            
            # Return a default in-memory store and graph
            default_store = rdflib.plugin.get('Memory', rdflib.store.Store)()
            default_graph = rdflib.ConjunctiveGraph(store=default_store)
            return default_store, default_graph
    
    def _setup_query_understanding_agent(self):
        """Create an agent for understanding the user query with chain-of-thought reasoning"""
        try:
            # Define the system prompt with chain-of-thought instructions
            system_prompt = """You are an expert in understanding user queries about data from knowledge graphs.
            Your task is to analyze the user's question and break down your understanding using chain-of-thought reasoning.
            
            Follow these steps in your analysis:
            1. First, identify the core question type (e.g., factual lookup, comparative analysis, relationship exploration)
            2. Next, identify all entities mentioned in the question and their types
            3. Determine any specific attributes or properties being requested
            4. Identify any filters, constraints, or conditions (temporal, numerical, categorical)
            5. Recognize any sorting, grouping, or aggregation requests
            6. Determine the overall intent of the query
            
            For each step, explicitly state your reasoning before drawing conclusions.
            
            After your reasoning, provide a structured understanding of the query with the following fields:
            - intent: The main intent of the user's query
            - entities: Key entities mentioned in the query
            - filters: Any filters or constraints specified
            - question_type: The type of question being asked
            
            Your structured output should capture the essence of the query in a way that can be translated to a SPARQL query.
            """
            
            # Create the prompt template
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", "{query}")
            ])
            
            # Create the output parser
            parser = PydanticOutputParser(pydantic_object=QueryUnderstanding)
            
            # Create the chain
            understanding_chain = prompt | self.llm | parser
            
            return understanding_chain
        except Exception as e:
            logger.error(f"Error setting up query understanding agent: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _setup_ontology_agent(self):
        """Create an agent for converting natural language to SPARQL based on the ontology"""
        try:
            if not self.ontology_graph:
                logger.warning("Ontology graph not loaded")
                
            # Extract ontology information
            ontology_classes = []
            ontology_properties = []
            ontology_relationships = []
            
            try:
                # Extract classes with descriptions and labels
                for cls in self.ontology_graph.subjects(RDF.type, OWL.Class):
                    if isinstance(cls, URIRef):
                        label = self.ontology_graph.value(cls, RDFS.label)
                        description = self.ontology_graph.value(cls, RDFS.comment)
                        
                        label_str = str(label) if label else cls.split('#')[-1] if '#' in str(cls) else str(cls)
                        desc_str = f" - {str(description)}" if description else ""
                        
                        ontology_classes.append(f"Class: {label_str} ({cls}){desc_str}")
                
                # Extract datatype properties with domains, ranges, and descriptions
                for prop in self.ontology_graph.subjects(RDF.type, OWL.DatatypeProperty):
                    if isinstance(prop, URIRef):
                        label = self.ontology_graph.value(prop, RDFS.label)
                        description = self.ontology_graph.value(prop, RDFS.comment)
                        domain = self.ontology_graph.value(prop, RDFS.domain)
                        range_val = self.ontology_graph.value(prop, RDFS.range)
                        
                        label_str = str(label) if label else prop.split('#')[-1] if '#' in str(prop) else str(prop)
                        domain_str = domain.split('#')[-1] if domain and '#' in str(domain) else "Unspecified"
                        range_str = range_val.split('#')[-1] if range_val and '#' in str(range_val) else "Unspecified"
                        desc_str = f" - {str(description)}" if description else ""
                        
                        ontology_properties.append(f"DatatypeProperty: {label_str} ({prop}) - Domain: {domain_str}, Range: {range_str}{desc_str}")
                
                # Extract object properties with domains, ranges, and descriptions
                for prop in self.ontology_graph.subjects(RDF.type, OWL.ObjectProperty):
                    if isinstance(prop, URIRef):
                        label = self.ontology_graph.value(prop, RDFS.label)
                        description = self.ontology_graph.value(prop, RDFS.comment)
                        domain = self.ontology_graph.value(prop, RDFS.domain)
                        range_val = self.ontology_graph.value(prop, RDFS.range)
                        
                        label_str = str(label) if label else prop.split('#')[-1] if '#' in str(prop) else str(prop)
                        domain_str = domain.split('#')[-1] if domain and '#' in str(domain) else "Unspecified"
                        range_str = range_val.split('#')[-1] if range_val and '#' in str(range_val) else "Unspecified"
                        desc_str = f" - {str(description)}" if description else ""
                        
                        relationship = f"ObjectProperty: {label_str} ({prop}) - Domain: {domain_str}, Range: {range_str}{desc_str}"
                        ontology_properties.append(relationship)
                        ontology_relationships.append(relationship)
            except Exception as extraction_err:
                logger.warning(f"Error extracting ontology information: {extraction_err}")
                
            # If no classes or properties were found, create some example data
            if not ontology_classes:
                ontology_classes = ["Class: Example (http://example.org/ontology#Example)"]
            
            if not ontology_properties:
                ontology_properties = ["Property: exampleProperty (http://example.org/ontology#exampleProperty) - Domain: Example, Range: xsd:string"]
            
            if not ontology_relationships:
                ontology_relationships = ["ObjectProperty: relatedTo (http://example.org/ontology#relatedTo) - Domain: Example, Range: Example"]
            
            # Define the system prompt with ontology information and chain of thought instructions
            system_prompt = f"""You are an expert in Semantic Web technologies, RDF, OWL ontologies, and SPARQL query generation.
            Your task is to convert a natural language query into a precise, valid SPARQL query by reasoning step-by-step through the mapping process.
            
            Here's the ontology structure:
            
            CLASSES:
            {chr(10).join(ontology_classes[:20])}
            ... {len(ontology_classes) - 20 if len(ontology_classes) > 20 else 0} more classes
            
            PROPERTIES:
            {chr(10).join(ontology_properties[:20])}
            ... {len(ontology_properties) - 20 if len(ontology_properties) > 20 else 0} more properties
            
            KEY RELATIONSHIPS:
            {chr(10).join(ontology_relationships[:15])}
            ... {len(ontology_relationships) - 15 if len(ontology_relationships) > 15 else 0} more relationships
            
            Follow these chain-of-thought reasoning steps when converting the query understanding to SPARQL:
            
            1. IDENTIFY CORE ENTITIES:
               - Determine the main classes from the ontology that correspond to entities in the query
               - Map each entity to its corresponding class URI
            
            2. IDENTIFY PROPERTIES:
               - For each attribute or relationship mentioned in the query, identify the corresponding properties
               - Determine if they are datatype properties or object properties
               - Map property names to their corresponding property URIs
            
            3. CONSTRUCT TRIPLE PATTERNS:
               - Create the basic triple patterns needed to represent the query
               - Consider subject-predicate-object patterns for each relationship
            
            4. ADD CONSTRAINTS:
               - Translate filters, conditions, or constraints into SPARQL FILTER clauses
               - Handle any comparison operators (equals, greater than, less than, etc.)
            
            5. DETERMINE QUERY TYPE:
               - Decide if this should be a SELECT, ASK, CONSTRUCT, or DESCRIBE query
               - For SELECT queries, identify the specific variables to include in the result
            
            6. ADD MODIFIERS:
               - Add any ORDER BY, GROUP BY, LIMIT, or OFFSET clauses needed
               - Consider aggregation functions (COUNT, SUM, AVG, etc.) if needed
            
            7. FINALIZE PREFIXES:
               - Add all necessary namespace prefixes based on the URIs used

            8. CHECK FOR COMMON ISSUES:
               - Verify no typos in property or class URIs
               - Ensure all variables are properly defined
               - Confirm proper syntax for FILTER expressions
            
            After completing your step-by-step reasoning, provide the full, executable SPARQL query.
            
            Use standard prefixes and ensure the query is syntactically correct according to SPARQL 1.1.
            """
            
            # Create the prompt template that shows the query understanding
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", "Query Understanding: {query_understanding}\n\nGenerate a SPARQL query to answer this question, showing your chain-of-thought reasoning process.")
            ])
            
            # Create the chain
            sparql_generation_chain = prompt | self.llm | StrOutputParser()
            
            return sparql_generation_chain
        except Exception as e:
            logger.error(f"Error setting up ontology agent: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _setup_query_validation_agent(self):
        """Create an agent for validating and fixing SPARQL queries with chain-of-thought reasoning"""
        try:
            # Enhanced system prompt with chain-of-thought instructions
            system_prompt = """You are an expert in SPARQL query syntax, validation, and optimization with deep knowledge of the SPARQL 1.1 specification.
            Your task is to validate the provided SPARQL query using chain-of-thought reasoning to identify and fix any issues.

            Follow these reasoning steps when validating the query:

            1. ANALYZE PREFIXES:
               - Check if all required namespace prefixes are declared
               - Verify that prefixes are correctly formatted
               - Ensure each prefix used in the query body is defined
            
            2. VALIDATE TRIPLE PATTERNS:
               - Examine each triple pattern for correct subject-predicate-object structure
               - Check variable naming conventions (should start with ? or $)
               - Verify URI formatting (should be enclosed in <> or use defined prefixes)
               - Ensure literals have appropriate datatype or language tags if needed
            
            3. REVIEW QUERY STRUCTURE:
               - Validate the query structure for the specific query form (SELECT, ASK, CONSTRUCT, DESCRIBE)
               - Check for required components (e.g., WHERE clause)
               - Ensure proper nesting of OPTIONAL, UNION, FILTER clauses
               - Verify matching of opening and closing braces and parentheses
            
            4. EXAMINE FILTER EXPRESSIONS:
               - Validate the syntax of FILTER expressions
               - Check for correct use of operators (=, !=, <, >, etc.)
               - Verify proper escaping in strings
               - Ensure type compatibility in comparisons
            
            5. VALIDATE SOLUTION MODIFIERS:
               - Check syntax of any ORDER BY, GROUP BY, HAVING, LIMIT, or OFFSET clauses
               - Verify that variables used in these clauses are defined in the query
               - Ensure aggregation functions have proper syntax
            
            6. IDENTIFY SEMANTIC ISSUES:
               - Check for common logical errors that might produce empty results
               - Look for redundant patterns
               - Identify overly complex constructions that could be simplified
            
            7. OPTIMIZE IF NEEDED:
               - Suggest optimizations for better performance
               - Identify any inefficient patterns that could be rewritten
            
            After completing your analysis, provide:
            
            1. A determination of whether the query is valid (is_valid: true/false)
            2. If not valid, a corrected version of the query (corrected_query)
            3. A clear explanation of any issues found or why the query is valid (explanation)
            
            Always consider both syntactic correctness and semantic meaningfulness in your validation.
            """
            
            # Enhanced prompt template that shows the query in formatted code block
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", "SPARQL Query to validate:\n\n```sparql\n{sparql_query}\n```\n\nPlease analyze this query thoroughly using the chain-of-thought process.")
            ])
            
            # Create the output parser
            parser = PydanticOutputParser(pydantic_object=QueryValidation)
            
            # Create the chain
            validation_chain = prompt | self.llm | parser
            
            return validation_chain
        except Exception as e:
            logger.error(f"Error setting up query validation agent: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _setup_reporting_agent(self):
        """Create an agent for generating business-friendly reports from query results with chain-of-thought reasoning"""
        try:
            system_prompt = """You are an expert in data analysis, knowledge graph interpretation, and business communication.
            Your task is to create a clear, concise, and business-friendly report based on the results of a SPARQL query through careful chain-of-thought reasoning.
            
            Follow these analytical steps when generating your report:
            
            1. UNDERSTAND THE QUESTION CONTEXT:
               - Review the original question to understand what the user was seeking
               - Identify the key business metrics or relationships they wanted to know about
               - Consider any implicit needs or context not directly stated in the question
            
            2. ANALYZE THE QUERY RESULTS:
               - Examine all returned data systematically
               - Identify patterns, trends, outliers, or anomalies
               - Note the completeness of results (any missing data or null values?)
               - Verify the data makes logical sense based on domain knowledge
            
            3. EXTRACT KEY INSIGHTS:
               - Determine the most important findings that directly answer the question
               - Identify secondary insights that provide additional value
               - Note any unexpected findings that might be of interest
               - Consider the business implications of these insights
            
            4. STRUCTURE YOUR REPORT:
               - Start with a clear, direct answer to the original question
               - Present key findings in order of importance
               - Group related information logically
               - Use appropriate formatting (lists, sections) for readability
            
            5. TRANSLATE TECHNICAL DETAILS:
               - Convert technical terminology into business language
               - Explain complex relationships in simple terms
               - Provide context for any metrics or measurements
               - Use analogies or comparisons when helpful
            
            6. FORMULATE RECOMMENDATIONS (IF APPROPRIATE):
               - Consider what actions could be taken based on these insights
               - Suggest potential next steps or further analyses
               - Frame recommendations in terms of business impact
            
            The final report should be:
            - Accessible to non-technical stakeholders
            - Free of query language or technical jargon
            - Precise and accurate regarding the data
            - Well-structured with clear sections
            - Concise yet comprehensive
            - Action-oriented where appropriate
            
            After completing your analysis, provide a polished business report that someone could present to executives or include in a business document.
            """
            
            # Create the prompt template with added query details for context
            prompt = ChatPromptTemplate.from_messages([
                ("system", system_prompt),
                ("human", """
                Original Question: {original_query}
                
                Query Results:
                {query_results}
                
                SPARQL Query Used:
                {sparql_query}
                
                Please generate a business-friendly report that answers the original question based on these results. 
                Show your analytical thinking as you interpret the data and formulate your response.
                """)
            ])
            
            # Create the chain
            reporting_chain = prompt | self.llm | StrOutputParser()
            
            return reporting_chain
        except Exception as e:
            logger.error(f"Error setting up reporting agent: {e}")
            logger.error(traceback.format_exc())
            return None
    
    def _extract_sparql_from_reasoning(self, text: str) -> str:
        """Helper method to extract the SPARQL query from a reasoning text"""
        try:
            # Try to find a SPARQL query enclosed in triple backticks with sparql language marker
            sparql_blocks = re.findall(r"```sparql\n(.*?)\n```", text, re.DOTALL)
            if sparql_blocks:
                return sparql_blocks[0].strip()
            
            # Try to find any code block that might contain SPARQL
            code_blocks = re.findall(r"```(.*?)```", text, re.DOTALL)
            if code_blocks:
                for block in code_blocks:
                    # Check if block looks like SPARQL (contains SELECT/ASK/CONSTRUCT/DESCRIBE and WHERE)
                    if re.search(r"(SELECT|ASK|CONSTRUCT|DESCRIBE).*?WHERE", block, re.DOTALL | re.IGNORECASE):
                        return block.strip()
            
            # If no clear SPARQL blocks found, look for patterns that suggest a SPARQL query
            potential_query = re.search(r"(PREFIX.*?|SELECT.*?WHERE.*?\{.*?\})", text, re.DOTALL | re.IGNORECASE)
            if potential_query:
                return potential_query.group(0).strip()
            
            # If all else fails, return the original text but log a warning
            logger.warning("Could not extract clean SPARQL query from reasoning text")
            return text
        except Exception as e:
            logger.error(f"Error extracting SPARQL query: {e}")
            return text
    
    def _execute_sparql_query(self, query: str) -> List[Dict[str, Any]]:
        """Execute a SPARQL query against the endpoint and return results"""
        try:
            if not query or not query.strip():
                logger.error("Empty query provided")
                return [{"error": "Empty query provided"}]
            
            # Log the query
            logger.info(f"Executing SPARQL query: {query}")
            
            # Execute the query using the graph with the connected store
            results = self.sparql_graph.query(query)
            
            # Process results into a dictionary format
            processed_results = []
            
            # Handle empty results
            if not results or len(results) == 0:
                logger.info("Query returned no results")
                return []
            
            # Process each result row
            for row in results:
                row_dict = {}
                
                # Handle different result formats
                if hasattr(results, 'vars') and results.vars:
                    # Standard query results with variables
                    for var_name, var_value in zip(results.vars, row):
                        if var_value is None:
                            row_dict[str(var_name)] = {"value": None}
                            continue
                            
                        if isinstance(var_value, URIRef):
                            # Get label if available
                            label = self.ontology_graph.value(var_value, RDFS.label)
                            if label:
                                row_dict[str(var_name)] = {"uri": str(var_value), "label": str(label)}
                            else:
                                row_dict[str(var_name)] = {"uri": str(var_value)}
                        elif isinstance(var_value, Literal):
                            datatype = var_value.datatype.n3() if var_value.datatype else None
                            row_dict[str(var_name)] = {"value": str(var_value), "datatype": datatype}
                        else:
                            row_dict[str(var_name)] = {"value": str(var_value)}
                else:
                    # Handle boolean results (ASK queries)
                    if isinstance(row, bool):
                        row_dict["result"] = {"value": row}
                    else:
                        # Handle other result formats
                        row_dict["result"] = {"value": str(row)}
                
                processed_results.append(row_dict)
            
            logger.info(f"Query returned {len(processed_results)} results")
            return processed_results
            
        except Exception as e:
            logger.error(f"Error executing SPARQL query: {e}")
            logger.error(traceback.format_exc())
            return [{"error": str(e)}]
    
    def _setup_agent_workflow(self):
        """Create the multi-agent workflow using LangGraph"""
        try:
            # Initialize the agents
            self.query_understanding_agent = self._setup_query_understanding_agent()
            self.ontology_agent = self._setup_ontology_agent()
            self.validation_agent = self._setup_query_validation_agent()
            self.reporting_agent = self._setup_reporting_agent()
            
            # Check if all agents were initialized
            if not all([self.query_understanding_agent, self.ontology_agent, self.validation_agent, self.reporting_agent]):
                logger.error("One or more agents failed to initialize")
            
            # Define workflow nodes as functions with reasoning capture
            def understand_query(state):
                """Node for understanding the user query with chain-of-thought reasoning"""
                try:
                    # Get the structured output and reasoning
                    query_understanding_input = {"query": state.original_query}
                    
                    # Capture the full response for the reasoning trace
                    understanding_response = self.llm.invoke(
                        f"User query: {state.original_query}\n\nAnalyze this query step by step, identifying the intent, entities, filters, and question type."
                    )
                    understanding_reasoning = understanding_response.content
                    
                    # Get the structured output
                    query_understanding = self.query_understanding_agent.invoke(query_understanding_input)
                    
                    return {
                        "query_understanding": query_understanding,
                        "understanding_reasoning": understanding_reasoning
                    }
                except Exception as e:
                    logger.error(f"Error in understand_query node: {e}")
                    logger.error(traceback.format_exc())
                    # Return a default understanding to allow the workflow to continue
                    return {
                        "query_understanding": {
                            "intent": "general_query",
                            "entities": [],
                            "filters": [],
                            "question_type": "factual"
                        },
                        "understanding_reasoning": f"Error analyzing query: {str(e)}"
                    }
            
            def generate_sparql(state):
                """Node for generating a SPARQL query with chain-of-thought reasoning"""
                try:
                    # Get both the SPARQL query and the reasoning behind it
                    sparql_generation_input = {
                        "query_understanding": json.dumps(state.query_understanding)
                    }
                    
                    # Capture the full reasoning process
                    sparql_generation_response = self.llm.invoke(
                        f"Query Understanding: {json.dumps(state.query_understanding)}\n\n" +
                        "Based on this understanding and the ontology, generate a SPARQL query step by step."
                    )
                    sparql_generation_reasoning = sparql_generation_response.content
                    
                    # Get the actual SPARQL query
                    sparql_query = self.ontology_agent.invoke(sparql_generation_input)
                    
                    # Extract just the SPARQL query from the reasoning if needed
                    cleaned_sparql = self._extract_sparql_from_reasoning(sparql_query)
                    
                    return {
                        "sparql_query": cleaned_sparql,
                        "sparql_generation_reasoning": sparql_generation_reasoning
                    }
                except Exception as e:
                    logger.error(f"Error in generate_sparql node: {e}")
                    logger.error(traceback.format_exc())
                    # Generate a simple fallback query
                    fallback_query = "SELECT * WHERE { ?s ?p ?o } LIMIT 10"
                    return {
                        "sparql_query": fallback_query,
                        "sparql_generation_reasoning": f"Error generating SPARQL: {str(e)}. Using fallback query."
                    }
            
            def validate_query(state):
                """Node for validating the SPARQL query with chain-of-thought reasoning"""
                try:
                    # Capture the validation reasoning process
                    validation_response = self.llm.invoke(
                        f"SPARQL Query to validate:\n\n```sparql\n{state.sparql_query}\n```\n\n" +
                        "Validate this SPARQL query step by step, checking for syntax errors, logical issues, and potential optimizations."
                    )
                    validation_reasoning = validation_response.content
                    
                    # Get the structured validation result
                    validation_result = self.validation_agent.invoke({
                        "sparql_query": state.sparql_query
                    })
                    
                    return {
                        "validation_result": validation_result,
                        "validation_reasoning": validation_reasoning
                    }
                except Exception as e:
                    logger.error(f"Error in validate_query node: {e}")
                    logger.error(traceback.format_exc())
                    # Return a default validation result
                    return {
                        "validation_result": {
                            "is_valid": True,  # Assume valid to allow execution
                            "explanation": f"Error validating query: {str(e)}. Assuming query is valid."
                        },
                        "validation_reasoning": f"Error validating query: {str(e)}"
                    }
            
            def fix_query(state):
                """Node for fixing an invalid SPARQL query"""
                try:
                    # Use the corrected query from validation if available
                    if state.validation_result and "corrected_query" in state.validation_result and state.validation_result["corrected_query"]:
                        return {"sparql_query": state.validation_result["corrected_query"]}
                    
                    # If no corrected query is available, generate a simple query
                    logger.warning("No corrected query provided, using fallback query")
                    return {"sparql_query": "SELECT * WHERE { ?s ?p ?o } LIMIT 10"}
                except Exception as e:
                    logger.error(f"Error in fix_query node: {e}")
                    logger.error(traceback.format_exc())
                    # Return a simple fallback query
                    return {"sparql_query": "SELECT * WHERE { ?s ?p ?o } LIMIT 10"}
            
            def execute_query(state):
                """Node for executing the SPARQL query"""
                try:
                    # Log the query execution
                    logger.info(f"Executing SPARQL query: {state.sparql_query}")
                    
                    # Execute the query and get results
                    query_results = self._execute_sparql_query(state.sparql_query)
                    
                    # Log the number of results
                    logger.info(f"Query returned {len(query_results)} results")
                    
                    return {"query_results": query_results}
                except Exception as e:
                    logger.error(f"Error in execute_query node: {e}")
                    logger.error(traceback.format_exc())
                    # Return an error result
                    return {"query_results": [{"error": f"Query execution failed: {str(e)}"}]}
            
            def generate_report(state):
                """Node for generating the final report with chain-of-thought reasoning"""
                try:
                    # Ensure query_results exists
                    if not hasattr(state, 'query_results') or not state.query_results:
                        logger.warning("No query results available for report generation")
                        state.query_results = [{"error": "No results available"}]
                    
                    # Handle string conversion for JSON serialization
                    query_results_str = json.dumps(state.query_results)
                    
                    # Capture the reporting reasoning process
                    reporting_response = self.llm.invoke(
                        f"Original Question: {state.original_query}\n\n" +
                        f"Query Results: {query_results_str}\n\n" +
                        "Analyze these results step by step and create a business-friendly report."
                    )
                    reporting_reasoning = reporting_response.content
                    
                    # Generate the actual report
                    final_report = self.reporting_agent.invoke({
                        "original_query": state.original_query,
                        "query_results": query_results_str,
                        "sparql_query": state.sparql_query
                    })
                    
                    return {
                        "final_report": final_report,
                        "reporting_reasoning": reporting_reasoning
                    }
                except Exception as e:
                    logger.error(f"Error in generate_report node: {e}")
                    logger.error(traceback.format_exc())
                    # Generate a simple error report
                    error_report = f"I apologize, but I encountered an error while analyzing the query results: {str(e)}. " \
                                  f"The original query was: '{state.original_query}'. " \
                                  f"Please try rephrasing your question or contact support if this issue persists."
                    return {
                        "final_report": error_report,
                        "reporting_reasoning": f"Error generating report: {str(e)}"
                    }
            
            # Define the router for conditional branching
            def validation_router(state):
                """Route based on query validation results"""
                try:
                    if state.validation_result and state.validation_result.get("is_valid", False):
                        return "execute_query"
                    else:
                        return "fix_query"
                except Exception as e:
                    logger.error(f"Error in validation_router: {e}")
                    # Default to fix_query on error
                    return "fix_query"
            
            # Create the graph
            workflow = StateGraph(WorkflowState)
            
            # Add nodes to the graph
            workflow.add_node("understand_query", understand_query)
            workflow.add_node("generate_sparql", generate_sparql)
            workflow.add_node("validate_query", validate_query)
            workflow.add_node("fix_query", fix_query)
            workflow.add_node("execute_query", execute_query)
            workflow.add_node("generate_report", generate_report)
            
            # Add edges to create the workflow
            workflow.add_edge("understand_query", "generate_sparql")
            workflow.add_edge("generate_sparql", "validate_query")
            workflow.add_conditional_edges(
                "validate_query",
                validation_router,
                {
                    "execute_query": "execute_query",
                    "fix_query": "fix_query"
                }
            )
            workflow.add_edge("fix_query", "validate_query")  # Loop back for revalidation
            workflow.add_edge("execute_query", "generate_report")
            workflow.add_edge("generate_report", END)
            
            # Set the entry point
            workflow.set_entry_point("understand_query")
            
            # Compile the workflow
            return workflow.compile()
        except Exception as e:
            logger.error(f"Error setting up agent workflow: {e}")
            logger.error(traceback.format_exc())
            raise
    
    def ask(self, query: str) -> str:
        """Process a user query through the entire workflow and return the final report"""
        query_id = str(uuid.uuid4())
        
        # Initialize the workflow state
        initial_state = WorkflowState(
            query_id=query_id,
            original_query=query
        )
        
        # Execute the workflow
        try:
            logger.info(f"Processing query: {query}")
            
            # For debugging - force using a simple workflow
            if os.environ.get("DEBUG_SIMPLE_RESPONSE", "False").lower() == "true":
                logger.info("Using simple response mode for debugging")
                return f"DEBUG MODE: Your query was: {query}"
            
            # Check if we have a valid workflow
            if not self.agent_workflow:
                logger.error("Agent workflow not initialized")
                return "I'm sorry, the chatbot system has not been properly initialized. Please try again later."
            
            final_state = self.agent_workflow.invoke(initial_state)
            
            # Store the conversation in memory
            try:
                self.memory.save_context(
                    {"input": query},
                    {"output": final_state.final_report}
                )
            except Exception as mem_error:
                logger.warning(f"Error saving to memory: {mem_error}")
            
            return final_state.final_report or "No report was generated. There may have been an error processing your query."
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            logger.error(traceback.format_exc())
            return f"Sorry, I encountered an error while processing your query: {str(e)}"


# FastAPI implementation for API access
from fastapi import FastAPI, HTTPException, Depends, Security, status
from fastapi.security import APIKeyHeader
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel as FastAPIBaseModel
import uvicorn

# Request and response models
class ChatRequest(FastAPIBaseModel):
    query: str
    conversation_id: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None

class ChatResponse(FastAPIBaseModel):
    query_id: str
    original_query: str
    response: str
    metadata: Optional[Dict[str, Any]] = None

class HealthResponse(FastAPIBaseModel):
    status: str
    version: str

# Global chatbot instance
_chatbot_instance = None

def get_chatbot():
    """Singleton pattern to get or create the chatbot instance"""
    global _chatbot_instance
    if _chatbot_instance is None:
        try:
            _chatbot_instance = GraphRAGChatbot()
        except Exception as e:
            logger.error(f"Error creating chatbot instance: {e}")
            logger.error(traceback.format_exc())
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error initializing chatbot: {str(e)}"
            )
    return _chatbot_instance

# API Key security
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

async def get_api_key(api_key: str = Security(api_key_header)):
    """Validate API key if enabled"""
    # Get from environment if API key security is enabled
    if os.environ.get("API_KEY_ENABLED", "False").lower() == "true":
        correct_api_key = os.environ.get("API_KEY", "")
        if not correct_api_key or api_key != correct_api_key:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Invalid API Key",
            )
    return api_key

# Create FastAPI app
app = FastAPI(
    title="GraphRAG Chatbot API",
    description="API for querying knowledge graphs using natural language",
    version="1.0.0"
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Modify this in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    return {"status": "ok", "version": "1.0.0"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest, api_key: str = Depends(get_api_key)):
    """Process a chat request"""
    try:
        chatbot = get_chatbot()
        response = chatbot.ask(request.query)
        
        # Get query_id from memory or generate a new one
        query_id = str(uuid.uuid4())
        
        return {
            "query_id": query_id,
            "original_query": request.query,
            "response": response,
            "metadata": request.metadata
        }
    except Exception as e:
        logger.error(f"Error processing chat request: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {str(e)}"
        )

@app.post("/query_with_details", response_model=Dict[str, Any])
async def query_with_details(request: ChatRequest, api_key: str = Depends(get_api_key)):
    """Process a query and return detailed workflow information with reasoning traces"""
    try:
        chatbot = get_chatbot()
        
        # Initialize the workflow with tracking enabled
        query_id = str(uuid.uuid4())
        
        # Initialize the workflow state
        initial_state = WorkflowState(
            query_id=query_id,
            original_query=request.query
        )
        
        # Execute the workflow and capture intermediate states with reasoning
        final_state = chatbot.agent_workflow.invoke(initial_state)
        
        # Return the full workflow details including all reasoning traces
        return {
            "query_id": query_id,
            "original_query": request.query,
            # Query understanding with reasoning
            "query_understanding": final_state.query_understanding,
            "understanding_reasoning": final_state.understanding_reasoning,
            # SPARQL generation with reasoning
            "sparql_query": final_state.sparql_query,
            "sparql_generation_reasoning": final_state.sparql_generation_reasoning,
            # Query validation with reasoning
            "validation_result": final_state.validation_result,
            "validation_reasoning": final_state.validation_reasoning,
            # Query results
            "query_results": final_state.query_results,
            # Report generation with reasoning
            "reporting_reasoning": final_state.reporting_reasoning,
            "final_report": final_state.final_report,
            # Additional metadata
            "metadata": request.metadata
        }
    except Exception as e:
        logger.error(f"Error processing detailed query: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {str(e)}"
        )

@app.post("/reasoning_only", response_model=Dict[str, Any])
async def get_reasoning_only(request: ChatRequest, api_key: str = Depends(get_api_key)):
    """Process a query and return only the chain-of-thought reasoning for each step"""
    try:
        chatbot = get_chatbot()
        
        # Initialize the workflow
        query_id = str(uuid.uuid4())
        initial_state = WorkflowState(
            query_id=query_id,
            original_query=request.query
        )
        
        # Execute the workflow
        final_state = chatbot.agent_workflow.invoke(initial_state)
        
        # Return only the reasoning traces
        return {
            "query_id": query_id,
            "original_query": request.query,
            "understanding_reasoning": final_state.understanding_reasoning,
            "sparql_generation_reasoning": final_state.sparql_generation_reasoning,
            "validation_reasoning": final_state.validation_reasoning,
            "reporting_reasoning": final_state.reporting_reasoning,
            "metadata": request.metadata
        }
    except Exception as e:
        logger.error(f"Error processing reasoning query: {e}")
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {str(e)}"
        )

# Command-line interface function
def cli():
    """Command-line interface for the GraphRAG chatbot"""
    try:
        # Initialize the chatbot
        chatbot = get_chatbot()
        
        # Interactive loop
        print("GraphRAG Chatbot initialized. Type 'exit' to quit.")
        while True:
            try:
                user_query = input("\nEnter your question: ")
                if user_query.lower() in ["exit", "quit", "bye"]:
                    print("Goodbye!")
                    break
                    
                # Process query
                response = chatbot.ask(user_query)
                print("\nResponse:")
                print(response)
            except KeyboardInterrupt:
                print("\nInterrupted by user. Goodbye!")
                break
            except Exception as e:
                print(f"\nError: {str(e)}")
                print("Please try again or type 'exit' to quit.")
            
    except Exception as e:
        logger.error(f"Error in CLI function: {e}")
        logger.error(traceback.format_exc())
        print(f"Fatal error: {str(e)}")
        sys.exit(1)

# API server function
def serve_api(host="0.0.0.0", port=8000):
    """Start the API server"""
    try:
        uvicorn.run(app, host=host, port=port)
    except Exception as e:
        logger.error(f"Error starting API server: {e}")
        logger.error(traceback.format_exc())
        sys.exit(1)

# Main function that can start either the CLI or API server
def main():
    """Main function to start either the CLI or API server based on arguments"""
    import argparse
    
    parser = argparse.ArgumentParser(description="GraphRAG Chatbot")
    parser.add_argument("--api", action="store_true", help="Start the API server")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="API server host")
    parser.add_argument("--port", type=int, default=8000, help="API server port")
    parser.add_argument("--ontology", type=str, help="Path to the ontology file (OWL, TTL, N3, etc.)")
    parser.add_argument("--config", type=str, help="Path to the config file")
    parser.add_argument("--creds", type=str, help="Path to the credentials file")
    parser.add_argument("--cert", type=str, help="Path to the certificate file")
    parser.add_argument("--sparql-endpoint", type=str, help="URL of the SPARQL endpoint")
    parser.add_argument("--sparql-username", type=str, help="Username for SPARQL endpoint Basic auth")
    parser.add_argument("--sparql-password", type=str, help="Password for SPARQL endpoint Basic auth")
    parser.add_argument("--debug", action="store_true", help="Enable debug mode for simple responses")
    
    args = parser.parse_args()
    
    # Set environment variables from command line arguments if provided
    if args.sparql_endpoint:
        os.environ["SPARQL_ENDPOINT_URL"] = args.sparql_endpoint
    
    # Handle authentication
    if args.sparql_username and args.sparql_password:
        os.environ["SPARQL_AUTH_ENABLED"] = "True"
        os.environ["SPARQL_AUTH_TYPE"] = "basic"
        os.environ["SPARQL_USERNAME"] = args.sparql_username
        os.environ["SPARQL_PASSWORD"] = args.sparql_password
    
    if args.ontology:
        os.environ["ONTOLOGY_PATH"] = args.ontology
        
    if args.debug:
        os.environ["DEBUG_SIMPLE_RESPONSE"] = "True"
    
    # Determine file paths
    config_path = args.config or CONFIG_PATH
    creds_path = args.creds or CREDS_PATH
    cert_path = args.cert or CERT_PATH
    ontology_path = args.ontology
    
    try:
        # Initialize the global chatbot instance with the provided paths
        global _chatbot_instance
        _chatbot_instance = GraphRAGChatbot(
            config_file=config_path,
            creds_file=creds_path,
            cert_file=cert_path,
            ontology_path=ontology_path
        )
        
        if args.api:
            print(f"Starting API server on {args.host}:{args.port}")
            serve_api(host=args.host, port=args.port)
        else:
            cli()
    except Exception as e:
        logger.error(f"Error in main function: {e}")
        logger.error(traceback.format_exc())
        print(f"Fatal error: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()
