import os
import re
import json
import logging
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple, Union
from langgraph.graph import StateGraph, END
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pydantic import BaseModel, ValidationError, Field, field_validator
import traceback

# Import base code classes
# Note: These classes are in the first document and should not be changed
from dotenv import dotenv_values

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Environment paths (from the base code)
ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

class RegexGeneratorConfig(BaseModel):
    """Configuration for the regex generator"""
    max_iterations: int = 3
    min_coverage: float = 0.85
    complexity_level: str = "high"
    allowed_charset: str = r"\w\s\-$%().,;:@#&*+!?'[]{}^|<>=/\"\\~`"

class TestCase(BaseModel):
    """Test case for regex validation"""
    text: str
    should_match: bool
    reason: str = ""

class PatternResult(BaseModel):
    """Results for a pattern's validation"""
    pattern: str
    tests: Dict[str, List[Dict[str, Any]]] = {"positive": [], "negative": []}
    score: float = 0.0
    failures: Dict[str, List[str]] = {"false_positives": [], "false_negatives": []}

class TermData(BaseModel):
    """Data for a technical term"""
    name: str
    definition: str
    related_terms: List[Dict[str, str]] = []
    iteration: int = 0
    candidates: List[str] = []
    validation_results: List[PatternResult] = []
    best_pattern: Optional[str] = None

class RegexPattern(BaseModel):
    """Final regex pattern output"""
    name: str
    pattern: str
    status: str = "GREEN"
    reasons: List[str] = []
    coverage: str = "N/A"
    examples: Dict[str, List[str]] = {"valid": [], "invalid": []}

    @field_validator('pattern')
    def validate_pattern(cls, v):
        try:
            re.compile(v)
            return v
        except re.error as e:
            raise ValueError(f"Invalid regex: {e}")

class WorkflowState(BaseModel):
    """State for the regex generation workflow"""
    terms: List[TermData] = []
    current_term_index: int = 0
    final_patterns: List[RegexPattern] = []
    config: RegexGeneratorConfig = RegexGeneratorConfig()

class RegexGenerationWorkflow:
    """Workflow for generating robust regex patterns for technical terms"""
    
    def __init__(self, csv_path: str, config: RegexGeneratorConfig = RegexGeneratorConfig()):
        """Initialize the workflow with a CSV file containing technical terms"""
        self.csv_path = csv_path
        self.config = config
        self.chatbot = AzureChatbot(CONFIG_PATH, CREDS_PATH, CERT_PATH)
        self.workflow = self._build_workflow()
    
    def _load_csv(self) -> pd.DataFrame:
        """Load and validate the CSV file"""
        try:
            df = pd.read_csv(self.csv_path)
            required_columns = ["name", "definition"]
            
            # Check for required columns
            missing = [col for col in required_columns if col not in df.columns]
            if missing:
                raise ValueError(f"CSV is missing required columns: {', '.join(missing)}")
            
            return df
        except Exception as e:
            logger.error(f"Error loading CSV: {e}")
            raise
    
    def _get_related_terms(self, term_name: str, df: pd.DataFrame) -> List[Dict[str, str]]:
        """Extract related terms for a given term name"""
        related_terms = []
        
        # Filter rows for the current term
        term_rows = df[df["name"] == term_name]
        
        # Extract related terms if available
        for _, row in term_rows.iterrows():
            if "related_term_name" in df.columns and "related_term_definition" in df.columns:
                if pd.notna(row["related_term_name"]) and pd.notna(row["related_term_definition"]):
                    example = row.get("related_term_example", "") if "related_term_example" in df.columns else ""
                    related_terms.append({
                        "name": row["related_term_name"],
                        "definition": row["related_term_definition"],
                        "example": example if pd.notna(example) else ""
                    })
        
        return related_terms
    
    def _build_workflow(self) -> Any:
        """Build the LangGraph workflow for regex generation"""
        # Create workflow
        workflow = StateGraph(WorkflowState)
        
        # Add nodes
        workflow.add_node("analyze_terms", self.analyze_terms)
        workflow.add_node("generate_candidates", self.generate_candidates)
        workflow.add_node("validate_patterns", self.validate_patterns)
        workflow.add_node("refine_patterns", self.refine_patterns)
        workflow.add_node("select_best_pattern", self.select_best_pattern)
        workflow.add_node("finalize_pattern", self.finalize_pattern)
        
        # Set entry point
        workflow.set_entry_point("analyze_terms")
        
        # Add edges
        workflow.add_edge("analyze_terms", "generate_candidates")
        workflow.add_edge("generate_candidates", "validate_patterns")
        workflow.add_edge("validate_patterns", "refine_patterns")
        
        # Add conditional edges
        workflow.add_conditional_edges(
            "refine_patterns",
            self.should_continue_refining,
            {
                "continue": "validate_patterns",
                "select": "select_best_pattern",
                "next_term": "analyze_terms"
            }
        )
        
        workflow.add_edge("select_best_pattern", "finalize_pattern")
        
        workflow.add_conditional_edges(
            "finalize_pattern",
            self.check_completion,
            {
                "complete": END,
                "next_term": "analyze_terms"
            }
        )
        
        return workflow.compile()
    
    def analyze_terms(self, state: WorkflowState) -> WorkflowState:
        """Analyze terms from the CSV file"""
        # Load CSV if this is the first run
        if not state.terms:
            df = self._load_csv()
            unique_terms = df["name"].unique()
            
            for term_name in unique_terms:
                term_rows = df[df["name"] == term_name]
                definition = term_rows["definition"].iloc[0] if not term_rows.empty else ""
                
                related_terms = self._get_related_terms(term_name, df)
                
                state.terms.append(TermData(
                    name=term_name,
                    definition=definition,
                    related_terms=related_terms
                ))
            
            logger.info(f"Loaded {len(state.terms)} unique terms from CSV")
        
        # Check if we've processed all terms
        if state.current_term_index >= len(state.terms):
            return state
        
        # Reset current term's data for a new iteration
        current_term = state.terms[state.current_term_index]
        current_term.iteration = 0
        current_term.candidates = []
        current_term.validation_results = []
        current_term.best_pattern = None
        
        logger.info(f"Analyzing term: {current_term.name}")
        return state
    
    def generate_candidates(self, state: WorkflowState) -> WorkflowState:
        """Generate regex pattern candidates for the current term"""
        if state.current_term_index >= len(state.terms):
            return state
        
        current_term = state.terms[state.current_term_index]
        
        # Construct prompt for pattern generation
        related_terms_formatted = "\n".join([
            f"- {rt['name']}: {rt['definition']} (Example: {rt['example']})"
            for rt in current_term.related_terms
        ])
        
        prompt = ChatPromptTemplate.from_template("""
        As an expert regex pattern designer, create 3 robust patterns to identify and match values related to: "{name}"
        
        Definition: {definition}
        
        Related Terms:
        {related_terms}
        
        Patterns must:
        1. Be highly generic to match many variations
        2. Handle different cases (uppercase, lowercase, mixed)
        3. Support partial matches (with word boundaries)
        4. Handle abbreviations, symbols, and alternative representations
        5. Support Unicode characters if relevant
        6. Account for language variations
        7. Include exact AND conceptually-related values
        
        For example, if generating patterns for "Currency Code":
        - Should match codes like "USD", "EUR", "GBP", "Â¥", etc.
        - Should match words like "dollar", "euro", "yen", etc.
        - Should match related terms like "forex", "exchange rate", etc.
        - Should match variations like "foreign currency", "monetary unit", etc.
        
        Return ONLY a JSON array with 3 regex patterns (no explanation):
        ["pattern1", "pattern2", "pattern3"]
        """)
        
        chain = prompt | self.chatbot.llm | StrOutputParser()
        
        try:
            # Invoke LLM to generate patterns
            response = chain.invoke({
                "name": current_term.name,
                "definition": current_term.definition,
                "related_terms": related_terms_formatted if related_terms_formatted else "No related terms available."
            })
            
            # Parse and validate the patterns
            patterns = json.loads(response.strip())
            valid_patterns = []
            
            for pattern in patterns:
                try:
                    re.compile(pattern)
                    valid_patterns.append(pattern)
                except re.error:
                    logger.warning(f"Invalid regex pattern generated: {pattern}")
            
            if valid_patterns:
                current_term.candidates = valid_patterns
                logger.info(f"Generated {len(valid_patterns)} valid regex candidates for {current_term.name}")
            else:
                # Create a fallback pattern if all generated are invalid
                fallback = rf"(?i)\b{re.escape(current_term.name)}\b"
                current_term.candidates = [fallback]
                logger.warning(f"All generated patterns invalid, using fallback: {fallback}")
            
        except Exception as e:
            logger.error(f"Error generating patterns: {str(e)}")
            # Create a basic fallback pattern
            fallback = rf"(?i)\b{re.escape(current_term.name)}\b"
            current_term.candidates = [fallback]
            logger.warning(f"Using fallback pattern: {fallback}")
        
        return state
    
    def validate_patterns(self, state: WorkflowState) -> WorkflowState:
        """Validate the regex patterns against test cases"""
        if state.current_term_index >= len(state.terms):
            return state
        
        current_term = state.terms[state.current_term_index]
        
        if not current_term.candidates:
            return state
        
        # Construct prompt for test case generation
        related_terms_formatted = "\n".join([
            f"- {rt['name']}: {rt['definition']} (Example: {rt['example']})"
            for rt in current_term.related_terms
        ])
        
        prompt = ChatPromptTemplate.from_template("""
        Generate comprehensive test cases to validate regex patterns for the term: "{name}"
        
        Definition: {definition}
        
        Related Terms:
        {related_terms}
        
        Please generate:
        1. 10 POSITIVE examples (should match)
        2. 10 NEGATIVE examples (should NOT match)
        
        Include a diverse range:
        - Different formats and representations
        - Various capitalizations
        - Common abbreviations
        - Related concepts
        - Edge cases
        - Alternative phrasings
        - With/without special characters
        
        For each test case, provide:
        - The text string
        - Whether it should match (true/false)
        - Brief explanation of why
        
        Return only in this JSON format:
        {{
          "positive": [
            {{"text": "example string", "should_match": true, "reason": "explanation"}}
          ],
          "negative": [
            {{"text": "example string", "should_match": false, "reason": "explanation"}}
          ]
        }}
        """)
        
        chain = prompt | self.chatbot.llm | StrOutputParser()
        
        try:
            # Generate test cases
            response = chain.invoke({
                "name": current_term.name,
                "definition": current_term.definition,
                "related_terms": related_terms_formatted if related_terms_formatted else "No related terms available."
            })
            
            # Parse test cases
            test_cases = json.loads(response.strip())
            
            # Validate each pattern against the test cases
            validation_results = []
            
            for pattern in current_term.candidates:
                result = PatternResult(pattern=pattern)
                result.tests = test_cases
                
                # Validate positives
                for test in test_cases["positive"]:
                    matches = bool(re.search(pattern, test["text"], re.IGNORECASE | re.UNICODE))
                    if not matches:
                        result.failures["false_negatives"].append(test["text"])
                
                # Validate negatives
                for test in test_cases["negative"]:
                    matches = bool(re.search(pattern, test["text"], re.IGNORECASE | re.UNICODE))
                    if matches:
                        result.failures["false_positives"].append(test["text"])
                
                # Calculate score
                total_tests = len(test_cases["positive"]) + len(test_cases["negative"])
                passed = total_tests - len(result.failures["false_negatives"]) - len(result.failures["false_positives"])
                result.score = passed / total_tests if total_tests > 0 else 0
                
                validation_results.append(result)
            
            # Sort results by score (highest first)
            validation_results.sort(key=lambda x: x.score, reverse=True)
            current_term.validation_results = validation_results
            
            # Log results
            logger.info(f"Validated {len(current_term.candidates)} patterns for {current_term.name}")
            for i, result in enumerate(validation_results):
                logger.info(f"Pattern {i+1}: {result.pattern} (Score: {result.score:.2f})")
        
        except Exception as e:
            logger.error(f"Error validating patterns: {str(e)}")
            # Create minimal validation results
            for pattern in current_term.candidates:
                current_term.validation_results.append(PatternResult(
                    pattern=pattern, 
                    score=0.5  # Default score
                ))
        
        return state
    
    def refine_patterns(self, state: WorkflowState) -> WorkflowState:
        """Refine regex patterns based on validation results"""
        if state.current_term_index >= len(state.terms):
            return state
        
        current_term = state.terms[state.current_term_index]
        current_term.iteration += 1
        
        if not current_term.validation_results:
            return state
        
        # Skip refinement if max iterations reached or we have good patterns
        if current_term.iteration >= state.config.max_iterations:
            logger.info(f"Max iterations ({state.config.max_iterations}) reached for {current_term.name}")
            return state
        
        best_score = max([r.score for r in current_term.validation_results], default=0)
        if best_score >= state.config.min_coverage:
            logger.info(f"Achieved minimum coverage for {current_term.name} (Score: {best_score:.2f})")
            return state
        
        # Identify patterns needing improvement
        patterns_to_refine = [r for r in current_term.validation_results if r.score < state.config.min_coverage]
        
        if not patterns_to_refine:
            return state
        
        # Construct prompt for pattern refinement
        prompt = ChatPromptTemplate.from_template("""
        Refine this regex pattern to improve its accuracy:
        
        Original Pattern: {pattern}
        
        Testing Results:
        - Score: {score}
        - False Negatives (should match but didn't): {false_negatives}
        - False Positives (shouldn't match but did): {false_positives}
        
        Requirements:
        1. Fix the pattern to correctly handle failed cases
        2. Maintain existing valid matches
        3. Make the pattern more robust and generic
        4. Ensure correct word boundaries and partial matching
        5. Keep pattern complexity reasonable
        
        Return ONLY the improved regex pattern (no explanation):
        """)
        
        chain = prompt | self.chatbot.llm | StrOutputParser()
        
        refined_candidates = []
        
        for result in patterns_to_refine:
            try:
                # Invoke LLM to refine the pattern
                response = chain.invoke({
                    "pattern": result.pattern,
                    "score": f"{result.score:.2f}",
                    "false_negatives": result.failures["false_negatives"],
                    "false_positives": result.failures["false_positives"]
                })
                
                # Validate the refined pattern
                refined = response.strip()
                try:
                    re.compile(refined)
                    refined_candidates.append(refined)
                    logger.info(f"Refined pattern: {refined}")
                except re.error:
                    logger.warning(f"Invalid refined pattern: {refined}")
            except Exception as e:
                logger.error(f"Error refining pattern: {str(e)}")
        
        # Add new candidates
        if refined_candidates:
            current_term.candidates = refined_candidates
            logger.info(f"Generated {len(refined_candidates)} refined patterns for {current_term.name}")
        
        return state
    
    def should_continue_refining(self, state: WorkflowState) -> str:
        """Determine next step based on refinement results"""
        if state.current_term_index >= len(state.terms):
            return "next_term"
        
        current_term = state.terms[state.current_term_index]
        
        # Check if max iterations reached
        if current_term.iteration >= state.config.max_iterations:
            return "select"
        
        # Check if we have a good score
        best_score = max([r.score for r in current_term.validation_results], default=0)
        if best_score >= state.config.min_coverage:
            return "select"
        
        # Continue refining
        return "continue"
    
    def select_best_pattern(self, state: WorkflowState) -> WorkflowState:
        """Select the best regex pattern from candidates"""
        if state.current_term_index >= len(state.terms):
            return state
        
        current_term = state.terms[state.current_term_index]
        
        if not current_term.validation_results:
            # Use a default pattern if no validation results
            current_term.best_pattern = rf"(?i)\b{re.escape(current_term.name)}\b"
            return state
        
        # Select pattern with highest score
        best_result = max(current_term.validation_results, key=lambda x: x.score)
        current_term.best_pattern = best_result.pattern
        
        logger.info(f"Selected best pattern for {current_term.name}: {current_term.best_pattern} (Score: {best_result.score:.2f})")
        return state
    
    def finalize_pattern(self, state: WorkflowState) -> WorkflowState:
        """Create the final regex pattern and prepare for next term"""
        if state.current_term_index >= len(state.terms):
            return state
        
        current_term = state.terms[state.current_term_index]
        
        if not current_term.best_pattern:
            # Skip this term
            state.current_term_index += 1
            return state
        
        try:
            # Generate examples for the pattern
            prompt = ChatPromptTemplate.from_template("""
            Generate 5 valid and 5 invalid examples for the regex pattern: {pattern}
            
            Term: {name}
            Definition: {definition}
            
            Valid examples should match the pattern.
            Invalid examples should NOT match the pattern.
            
            Return only in this JSON format:
            {{"valid": ["example1", "example2", ...], "invalid": ["example1", "example2", ...]}}
            """)
            
            chain = prompt | self.chatbot.llm | StrOutputParser()
            
            response = chain.invoke({
                "pattern": current_term.best_pattern,
                "name": current_term.name,
                "definition": current_term.definition
            })
            
            examples = json.loads(response.strip())
            
            # Find the validation result for the best pattern
            best_result = next(
                (r for r in current_term.validation_results if r.pattern == current_term.best_pattern), 
                None
            )
            
            # Create the final pattern
            final_pattern = RegexPattern(
                name=current_term.name,
                pattern=current_term.best_pattern,
                status="GREEN" if best_result and best_result.score >= state.config.min_coverage else "YELLOW",
                reasons=[f"Generated after {current_term.iteration} iterations"],
                coverage=f"{best_result.score:.2f}" if best_result else "N/A",
                examples=examples
            )
            
            # Add to final patterns
            state.final_patterns.append(final_pattern)
            logger.info(f"Finalized pattern for {current_term.name}")
            
        except Exception as e:
            logger.error(f"Error finalizing pattern: {str(e)}")
            # Create a minimal pattern
            state.final_patterns.append(RegexPattern(
                name=current_term.name,
                pattern=current_term.best_pattern or rf"(?i)\b{re.escape(current_term.name)}\b",
                status="YELLOW",
                reasons=["Error during finalization"],
                coverage="N/A"
            ))
        
        # Move to next term
        state.current_term_index += 1
        logger.info(f"Moving to next term ({state.current_term_index}/{len(state.terms)})")
        
        return state
    
    def check_completion(self, state: WorkflowState) -> str:
        """Check if all terms are processed"""
        return "complete" if state.current_term_index >= len(state.terms) else "next_term"
    
    def run(self) -> List[RegexPattern]:
        """Run the workflow and return the generated patterns"""
        # Initialize state
        state = WorkflowState(config=self.config)
        
        try:
            # Execute workflow
            final_state = self.workflow.invoke(state)
            
            # Return patterns
            return final_state.final_patterns
        except Exception as e:
            logger.error(f"Error executing workflow: {str(e)}")
            logger.error(traceback.format_exc())
            raise

def save_patterns(patterns: List[RegexPattern], output_path: str = "regex_patterns.json") -> None:
    """Save patterns to a JSON file"""
    try:
        with open(output_path, "w") as f:
            # Convert to dict before serializing
            patterns_dict = [p.model_dump() for p in patterns]
            json.dump(patterns_dict, f, indent=2)
        logger.info(f"Saved {len(patterns)} patterns to {output_path}")
    except Exception as e:
        logger.error(f"Error saving patterns: {str(e)}")

# Main execution function
def generate_regex_patterns(csv_path: str, output_path: str = "regex_patterns.json") -> None:
    """Generate regex patterns from a CSV file of technical terms"""
    try:
        # Configure regex generator
        config = RegexGeneratorConfig(
            max_iterations=3,
            min_coverage=0.85,
            complexity_level="high"
        )
        
        # Create and run workflow
        workflow = RegexGenerationWorkflow(csv_path, config)
        patterns = workflow.run()
        
        # Save results
        save_patterns(patterns, output_path)
        
        # Print summary
        print(f"\nGenerated {len(patterns)} regex patterns:")
        for pattern in patterns:
            print(f"- {pattern.name}: {pattern.pattern}")
            print(f"  Coverage: {pattern.coverage}")
            print(f"  Status: {pattern.status}")
            print()
            
    except Exception as e:
        logger.error(f"Error generating patterns: {str(e)}")
        logger.error(traceback.format_exc())

# Command-line execution
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate robust regex patterns for technical terms")
    parser.add_argument("csv_path", help="Path to the CSV file with technical terms")
    parser.add_argument("--output", "-o", default="regex_patterns.json", help="Path to output JSON file")
    
    args = parser.parse_args()
    
    generate_regex_patterns(args.csv_path, args.output)
