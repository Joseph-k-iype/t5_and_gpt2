"""
Enterprise FalkorDB Graph RAG Search Engine
Leverages LangChain's built-in FalkorDB integration with multi-agent intelligence.
No external web connectivity - enterprise security focused.

Author: Assistant
Date: 2025
Dependencies: falkordb, langchain, langchain-community, langgraph, openai
"""

import os
import json
import asyncio
import argparse
import logging
from typing import Dict, List, Any, Optional, TypedDict, Annotated
from datetime import datetime

# Core LangChain imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool, BaseTool
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

# FalkorDB-specific LangChain imports
from langchain_community.chains.graph_qa.falkordb import FalkorDBQAChain
from langchain_community.graphs import FalkorDBGraph

# LangGraph imports
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command

# Pydantic for data validation
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class GraphSearchState(TypedDict):
    """State for the enterprise graph search system."""
    messages: Annotated[List[BaseMessage], "The conversation messages"]
    user_query: str
    graph_schema: Optional[str]
    cypher_queries: Optional[List[str]]
    graph_results: Optional[List[Dict[str, Any]]]
    analysis_insights: Optional[List[str]]
    final_answer: Optional[str]
    current_agent: Optional[str]
    metadata: Dict[str, Any]


class EnterpriseGraphRAGEngine:
    """Enterprise Graph RAG Engine using LangChain's FalkorDB integration."""
    
    def __init__(self, 
                 openai_api_key: str,
                 openai_base_url: Optional[str] = None,
                 falkordb_host: str = 'localhost',
                 falkordb_port: int = 6379,
                 graph_name: str = 'test_cor'):
        
        self.graph_name = graph_name
        
        # Initialize OpenAI LLM
        self.llm = ChatOpenAI(
            model="o3-mini",
            api_key=openai_api_key,
            base_url=openai_base_url,
            temperature=0.1
        )
        
        # Initialize FalkorDB Graph wrapper
        self.graph = FalkorDBGraph(
            database=graph_name,
            host=falkordb_host,
            port=falkordb_port
        )
        
        # Initialize FalkorDB QA Chain
        self.qa_chain = FalkorDBQAChain.from_llm(
            llm=self.llm,
            graph=self.graph,
            verbose=True,
            allow_dangerous_requests=True,  # Enterprise controlled environment
            return_intermediate_steps=True
        )
        
        # Create the multi-agent workflow
        self.workflow = self._create_workflow()
        logger.info(f"Enterprise Graph RAG Engine initialized for graph: {graph_name}")
        
    def _create_tools(self) -> List[BaseTool]:
        """Create enterprise-safe tools using LangChain's FalkorDB integration."""
        
        @tool
        def get_graph_schema() -> str:
            """Get comprehensive schema information from the FalkorDB graph."""
            try:
                schema_info = {
                    'database': self.graph.database,
                    'schema': self.graph.get_schema,
                    'structured_schema': self.graph.get_structured_schema
                }
                return json.dumps(schema_info, indent=2, default=str)
            except Exception as e:
                return f"Schema retrieval error: {str(e)}"
        
        @tool
        def execute_graph_qa(question: str) -> str:
            """Execute a question against the graph using LangChain's FalkorDBQAChain."""
            try:
                logger.info(f"Executing graph QA: {question[:100]}...")
                result = self.qa_chain.invoke({"query": question})
                
                # Extract both result and intermediate steps
                response = {
                    'answer': result.get('result', ''),
                    'cypher_query': result.get('intermediate_steps', [{}])[0].get('query', '') if result.get('intermediate_steps') else '',
                    'context': result.get('intermediate_steps', [{}])[0].get('context', '') if result.get('intermediate_steps') else ''
                }
                
                return json.dumps(response, indent=2)
            except Exception as e:
                logger.error(f"Graph QA execution failed: {e}")
                return json.dumps({'error': f"Graph QA failed: {str(e)}"}, indent=2)
        
        @tool
        def analyze_graph_structure() -> str:
            """Analyze the overall structure and topology of the graph."""
            try:
                # Get basic statistics using direct graph queries
                stats_queries = [
                    "MATCH (n) RETURN count(n) as total_nodes",
                    "MATCH ()-[r]->() RETURN count(r) as total_relationships",
                    "MATCH (n) RETURN labels(n) as node_labels, count(n) as count ORDER BY count DESC",
                    "MATCH ()-[r]->() RETURN type(r) as relationship_type, count(r) as count ORDER BY count DESC"
                ]
                
                results = {}
                for i, query in enumerate(stats_queries):
                    try:
                        result = self.graph.query(query)
                        results[f"query_{i+1}"] = {
                            'cypher': query,
                            'result': result
                        }
                    except Exception as e:
                        results[f"query_{i+1}"] = {
                            'cypher': query,
                            'error': str(e)
                        }
                
                return json.dumps({
                    'analysis_type': 'graph_structure',
                    'statistics': results
                }, indent=2)
            except Exception as e:
                return json.dumps({'error': f"Structure analysis failed: {str(e)}"}, indent=2)
        
        @tool
        def find_key_entities(entity_type: Optional[str] = None, limit: int = 10) -> str:
            """Find key entities in the graph based on connectivity (degree centrality)."""
            try:
                if entity_type:
                    question = f"Find the top {limit} most connected {entity_type} entities and their relationships"
                else:
                    question = f"Find the top {limit} most connected entities in the graph and analyze their importance"
                
                result = self.qa_chain.invoke({"query": question})
                
                return json.dumps({
                    'analysis_type': 'key_entities',
                    'entity_type': entity_type or 'all',
                    'limit': limit,
                    'result': result.get('result', ''),
                    'cypher_used': result.get('intermediate_steps', [{}])[0].get('query', '') if result.get('intermediate_steps') else ''
                }, indent=2)
            except Exception as e:
                return json.dumps({'error': f"Key entities analysis failed: {str(e)}"}, indent=2)
        
        @tool
        def explore_relationships(source_entity: str, max_depth: int = 2) -> str:
            """Explore relationships around a specific entity up to a certain depth."""
            try:
                question = f"Show all relationships connected to '{source_entity}' within {max_depth} degrees of separation"
                result = self.qa_chain.invoke({"query": question})
                
                return json.dumps({
                    'analysis_type': 'relationship_exploration',
                    'source_entity': source_entity,
                    'max_depth': max_depth,
                    'result': result.get('result', ''),
                    'cypher_used': result.get('intermediate_steps', [{}])[0].get('query', '') if result.get('intermediate_steps') else ''
                }, indent=2)
            except Exception as e:
                return json.dumps({'error': f"Relationship exploration failed: {str(e)}"}, indent=2)
        
        return [get_graph_schema, execute_graph_qa, analyze_graph_structure, 
                find_key_entities, explore_relationships]
    
    def _create_agents(self) -> Dict[str, Any]:
        """Create specialized agents using LangChain tools."""
        
        tools = self._create_tools()
        
        # Schema Analysis Agent
        schema_agent = create_react_agent(
            self.llm,
            tools=[tools[0], tools[2]],  # get_graph_schema, analyze_graph_structure
            state_modifier="""You are an enterprise graph schema analyst. Your expertise includes:
            
            ğŸ” RESPONSIBILITIES:
            â€¢ Analyze graph database schemas and structures
            â€¢ Identify entity types, relationships, and data patterns
            â€¢ Assess data quality and completeness
            â€¢ Provide recommendations for graph optimization
            
            ğŸ“Š APPROACH:
            â€¢ Use get_graph_schema() to understand the data model
            â€¢ Use analyze_graph_structure() for topology insights
            â€¢ Focus on business-relevant patterns and anomalies
            â€¢ Provide actionable recommendations for enterprise users
            
            Always provide clear, structured analysis that helps business stakeholders understand their data landscape."""
        )
        
        # Query Planning Agent
        query_planning_agent = create_react_agent(
            self.llm,
            tools=[tools[0], tools[3], tools[4]],  # schema, find_key_entities, explore_relationships
            state_modifier="""You are an enterprise query planning specialist. Your expertise includes:
            
            ğŸ¯ RESPONSIBILITIES:
            â€¢ Understand complex business questions and break them down
            â€¢ Identify relevant entities and relationships for analysis
            â€¢ Plan efficient query strategies
            â€¢ Focus on business value and actionable insights
            
            ğŸ” APPROACH:
            â€¢ Use get_graph_schema() to understand available data
            â€¢ Use find_key_entities() to identify important nodes
            â€¢ Use explore_relationships() for targeted analysis
            â€¢ Plan queries that deliver maximum business value
            
            Always think strategically about what information would be most valuable to enterprise decision-makers."""
        )
        
        # Graph Execution Agent
        graph_execution_agent = create_react_agent(
            self.llm,
            tools=[tools[1], tools[3], tools[4]],  # execute_graph_qa, find_key_entities, explore_relationships
            state_modifier="""You are a graph query execution specialist. Your expertise includes:
            
            âš¡ RESPONSIBILITIES:
            â€¢ Execute complex graph queries efficiently
            â€¢ Extract meaningful data from graph structures
            â€¢ Analyze query results for patterns and insights
            â€¢ Ensure data accuracy and completeness
            
            ğŸ”§ APPROACH:
            â€¢ Use execute_graph_qa() for natural language questions
            â€¢ Use find_key_entities() for centrality analysis
            â€¢ Use explore_relationships() for connectivity analysis
            â€¢ Focus on extracting actionable data points
            
            Always ensure queries are executed safely and results are comprehensive and accurate."""
        )
        
        # Business Intelligence Agent
        business_intelligence_agent = create_react_agent(
            self.llm,
            tools=tools,  # All tools available for comprehensive analysis
            state_modifier="""You are an enterprise business intelligence analyst. Your expertise includes:
            
            ğŸ“Š RESPONSIBILITIES:
            â€¢ Transform graph data into business insights
            â€¢ Identify strategic opportunities and risks
            â€¢ Create executive-ready summaries and recommendations
            â€¢ Provide actionable intelligence for decision-making
            
            ğŸ’¼ APPROACH:
            â€¢ Synthesize data from multiple graph analyses
            â€¢ Focus on business impact and strategic value
            â€¢ Identify trends, patterns, and anomalies
            â€¢ Provide clear recommendations with supporting evidence
            
            ğŸ¯ OUTPUT FOCUS:
            â€¢ Executive summaries with key findings
            â€¢ Strategic recommendations
            â€¢ Risk assessments and opportunity identification
            â€¢ Clear, jargon-free business language
            
            Always deliver insights that directly support enterprise decision-making and strategic planning."""
        )
        
        return {
            'schema_agent': schema_agent,
            'query_planning_agent': query_planning_agent,
            'graph_execution_agent': graph_execution_agent,
            'business_intelligence_agent': business_intelligence_agent
        }
    
    def _create_supervisor_agent(self) -> Any:
        """Create the supervisor agent for workflow orchestration."""
        
        supervisor_prompt = ChatPromptTemplate.from_template("""
        You are supervising an enterprise graph analysis team with the following specialists:
        
        ğŸ” Schema Agent: Analyzes graph structure and data models
        ğŸ“‹ Query Planning Agent: Plans efficient analysis strategies  
        âš¡ Graph Execution Agent: Executes queries and extracts data
        ğŸ“Š Business Intelligence Agent: Creates business insights and recommendations
        
        Current business question: "{user_query}"
        
        Conversation progress: {messages}
        
        DECISION FRAMEWORK:
        
        For new queries, typically follow this enterprise workflow:
        1. Schema Agent: If understanding the data model is needed
        2. Query Planning Agent: To develop analysis strategy
        3. Graph Execution Agent: To extract relevant data
        4. Business Intelligence Agent: To create executive insights
        5. FINISH: When comprehensive business analysis is complete
        
        For follow-up questions:
        - Route directly to the most relevant specialist
        - Skip redundant schema analysis if already done
        - Focus on delivering incremental value
        
        ROUTING RULES:
        - Complex new questions â†’ Start with schema_agent
        - Specific data requests â†’ graph_execution_agent
        - Strategic analysis requests â†’ business_intelligence_agent
        - Technical questions â†’ query_planning_agent
        - Ready for business summary â†’ business_intelligence_agent
        
        Options: schema_agent, query_planning_agent, graph_execution_agent, business_intelligence_agent, FINISH
        
        Respond with just the agent name or FINISH.
        """)
        
        supervisor = supervisor_prompt | self.llm
        return supervisor
    
    def _create_workflow(self) -> StateGraph:
        """Create the LangGraph workflow using LangChain components."""
        
        # Create agents
        agents = self._create_agents()
        supervisor = self._create_supervisor_agent()
        
        # Define workflow
        workflow = StateGraph(GraphSearchState)
        
        # Add agent nodes
        for agent_name, agent in agents.items():
            workflow.add_node(agent_name, agent)
        
        # Add supervisor node
        def supervisor_node(state: GraphSearchState) -> GraphSearchState:
            """Supervisor decision node."""
            result = supervisor.invoke({
                "user_query": state["user_query"],
                "messages": state["messages"]
            })
            
            next_agent = result.content.strip().lower()
            
            if next_agent == "finish":
                state["current_agent"] = "FINISH"
            else:
                state["current_agent"] = next_agent
                
            return state
        
        workflow.add_node("supervisor", supervisor_node)
        
        # Add edges
        workflow.add_edge(START, "supervisor")
        
        # Conditional edges from supervisor to agents
        def route_supervisor(state: GraphSearchState) -> str:
            current_agent = state.get("current_agent", "").lower()
            if current_agent == "finish":
                return END
            elif current_agent in agents:
                return current_agent
            else:
                return "query_planning_agent"  # Default fallback
        
        workflow.add_conditional_edges(
            "supervisor",
            route_supervisor,
            {
                "schema_agent": "schema_agent",
                "query_planning_agent": "query_planning_agent", 
                "graph_execution_agent": "graph_execution_agent",
                "business_intelligence_agent": "business_intelligence_agent",
                END: END
            }
        )
        
        # Add edges back to supervisor from each agent
        for agent_name in agents.keys():
            workflow.add_edge(agent_name, "supervisor")
        
        # Compile workflow
        memory = MemorySaver()
        return workflow.compile(checkpointer=memory)
    
    async def search(self, user_query: str, thread_id: str = "default") -> str:
        """Execute a graph analysis query using the multi-agent system."""
        
        initial_state = GraphSearchState(
            messages=[HumanMessage(content=user_query)],
            user_query=user_query,
            graph_schema=None,
            cypher_queries=None,
            graph_results=None,
            analysis_insights=None,
            final_answer=None,
            current_agent=None,
            metadata={
                "timestamp": datetime.now().isoformat(),
                "thread_id": thread_id,
                "graph_database": self.graph_name,
                "analysis_type": "enterprise_graph_intelligence"
            }
        )
        
        config = {"configurable": {"thread_id": thread_id}}
        
        try:
            logger.info(f"Processing enterprise query: {user_query}")
            
            # Run the workflow
            final_state = await self.workflow.ainvoke(initial_state, config=config)
            
            # Extract final answer from the last AI message
            for message in reversed(final_state["messages"]):
                if isinstance(message, AIMessage):
                    logger.info("Enterprise analysis completed successfully")
                    return message.content
                    
            return "I apologize, but I couldn't generate a comprehensive analysis for your query."
            
        except Exception as e:
            error_msg = f"Enterprise analysis failed: {str(e)}"
            logger.error(error_msg)
            return error_msg
    
    def search_sync(self, user_query: str, thread_id: str = "default") -> str:
        """Synchronous version of search method."""
        return asyncio.run(self.search(user_query, thread_id))
    
    def get_graph_info(self) -> Dict[str, Any]:
        """Get comprehensive graph information using LangChain integration."""
        try:
            return {
                'database_name': self.graph.database,
                'schema': self.graph.get_schema,
                'structured_schema': self.graph.get_structured_schema,
                'connection_info': {
                    'host': getattr(self.graph, '_host', 'localhost'),
                    'port': getattr(self.graph, '_port', 6379),
                    'connected': True
                },
                'generated_at': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Failed to get graph info: {e}")
            return {'error': str(e), 'connected': False}
    
    def test_connection(self) -> Dict[str, Any]:
        """Test the FalkorDB connection using LangChain integration."""
        try:
            # Simple test query
            test_result = self.graph.query("RETURN 'connection_test' as status")
            return {
                'status': 'connected',
                'database': self.graph.database,
                'test_result': test_result,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }


class EnterpriseConfig:
    """Enterprise configuration management."""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = os.getenv("OPENAI_BASE_URL")
        self.falkordb_host = os.getenv("FALKORDB_HOST", "localhost")
        self.falkordb_port = int(os.getenv("FALKORDB_PORT", "6379"))
        self.graph_name = os.getenv("GRAPH_NAME", "test_cor")
    
    def validate(self) -> bool:
        """Validate enterprise configuration."""
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY is required for enterprise deployment")
        return True
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert config to dictionary."""
        return {
            'openai_base_url': self.openai_base_url,
            'falkordb_host': self.falkordb_host,
            'falkordb_port': self.falkordb_port,
            'graph_name': self.graph_name,
            'has_openai_key': bool(self.openai_api_key)
        }


def main():
    """Command-line interface for enterprise graph analysis."""
    parser = argparse.ArgumentParser(
        description="Enterprise FalkorDB Graph RAG Search Engine with LangChain Integration",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python graph_rag_search.py --query "What are the key business relationships in our network?"
  python graph_rag_search.py --query "Find the most influential entities and analyze risks" --thread-id "analysis_001"
  python graph_rag_search.py --interactive
  python graph_rag_search.py --test-connection
        """
    )
    
    parser.add_argument("--query", "-q", help="Business analysis query")
    parser.add_argument("--thread-id", "-t", default="default", help="Analysis session ID")
    parser.add_argument("--config-file", "-c", help="Path to configuration file")
    parser.add_argument("--interactive", "-i", action="store_true", help="Start interactive analysis mode")
    parser.add_argument("--test-connection", action="store_true", help="Test FalkorDB connection")
    parser.add_argument("--graph-info", action="store_true", help="Show graph information")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Load configuration
    config = EnterpriseConfig()
    
    if args.config_file:
        with open(args.config_file, 'r') as f:
            config_data = json.load(f)
            for key, value in config_data.items():
                setattr(config, key, value)
    
    try:
        config.validate()
    except ValueError as e:
        print(f"âŒ Configuration Error: {e}")
        return 1
    
    # Print banner
    print("ğŸ¢ Enterprise FalkorDB Graph RAG Search Engine")
    print("=" * 55)
    print(f"ğŸ“Š Graph Database: {config.graph_name}")
    print(f"ğŸ”— FalkorDB: {config.falkordb_host}:{config.falkordb_port}")
    print(f"ğŸ¤– AI Model: OpenAI o3-mini")
    print(f"ğŸ”§ Integration: LangChain FalkorDBQAChain")
    print(f"ğŸ”’ Security: No external connectivity")
    print("=" * 55)
    
    try:
        engine = EnterpriseGraphRAGEngine(
            openai_api_key=config.openai_api_key,
            openai_base_url=config.openai_base_url,
            falkordb_host=config.falkordb_host,
            falkordb_port=config.falkordb_port,
            graph_name=config.graph_name
        )
        
        print("âœ… Enterprise engine initialized successfully")
        
    except Exception as e:
        print(f"âŒ Failed to initialize engine: {e}")
        return 1
    
    # Handle different modes
    if args.test_connection:
        print("\nğŸ” Testing FalkorDB Connection...")
        result = engine.test_connection()
        if result['status'] == 'connected':
            print(f"âœ… Connection successful to database: {result['database']}")
        else:
            print(f"âŒ Connection failed: {result['error']}")
        return 0
    
    if args.graph_info:
        print("\nğŸ“Š Graph Information:")
        print("-" * 30)
        info = engine.get_graph_info()
        if 'error' not in info:
            print(f"Database: {info['database_name']}")
            print(f"Schema: {json.dumps(info.get('schema', {}), indent=2)}")
        else:
            print(f"âŒ Error: {info['error']}")
        return 0
    
    if args.interactive:
        print("\nğŸ¯ Enterprise Interactive Analysis Mode")
        print("ğŸ’¡ Example Business Queries:")
        print("  â€¢ What are the key business entities and their strategic relationships?")
        print("  â€¢ Find the most influential nodes and analyze potential risks")
        print("  â€¢ Analyze our organizational network for optimization opportunities")
        print("  â€¢ Identify critical dependencies and single points of failure")
        print("-" * 55)
        
        while True:
            try:
                query = input(f"\n[{args.thread_id}] ğŸ” Business Query: ").strip()
                if query.lower() in ['exit', 'quit', 'q']:
                    print("ğŸ‘‹ Ending analysis session...")
                    break
                
                if not query:
                    continue
                
                print("\nğŸ¤– Analyzing with multi-agent intelligence system...")
                result = engine.search_sync(query, args.thread_id)
                print(f"\nğŸ“Š ENTERPRISE ANALYSIS:\n{'-' * 50}\n{result}\n{'-' * 50}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ Analysis session terminated by user")
                break
            except Exception as e:
                print(f"âŒ Analysis error: {e}")
        
        return 0
    
    if args.query:
        print(f"\nğŸ” Business Query: {args.query}")
        print("-" * 55)
        
        try:
            result = engine.search_sync(args.query, args.thread_id)
            print(f"\nğŸ“Š ENTERPRISE ANALYSIS:\n{result}")
        except Exception as e:
            print(f"âŒ Analysis failed: {e}")
            return 1
    else:
        print("\nâš ï¸  No query provided. Use --query, --interactive, or --test-connection")
        parser.print_help()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
