#!/usr/bin/env python3
"""
Complete TTL File Processing System - Standalone Version
No external imports needed, everything included in one file
"""

import os
import json
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import logging
from pathlib import Path
import hashlib
import uuid
import re
from collections import defaultdict, Counter
import argparse
import sys

# Graph analysis and RDF processing
import networkx as nx
from rdflib import Graph, Namespace, URIRef, Literal, BNode
from rdflib.namespace import RDF, RDFS, OWL, XSD
from rdflib.plugins.sparql import prepareQuery
import rdflib.plugins.sparql as sparql

# Pydantic v2 with enhanced validation
from pydantic import BaseModel, Field, ValidationError, field_validator
from typing_extensions import Annotated

# LangGraph with advanced patterns
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ReasoningType(Enum):
    """Types of reasoning patterns available"""
    CHAIN_OF_THOUGHT = "cot"
    TREE_OF_THOUGHTS = "tot"
    REFLEXION = "reflexion"
    LATS = "lats"
    REACT = "react"
    TEMPORAL = "temporal"
    FORMAL_VERIFICATION = "formal_verification"
    PATTERN_DISCOVERY = "pattern_discovery"

class ConfidenceLevel(Enum):
    """Confidence levels for reasoning outputs"""
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNCERTAIN = "uncertain"

# ===============================
# CORE REASONING SYSTEM CLASSES
# ===============================

@dataclass
class TTLContent:
    """Complete preservation of original TTL content with enhancements"""
    original_ttl: str
    enhanced_ttl: str
    preservation_map: Dict[str, str]
    lost_information: List[str]
    enhancement_log: List[str]
    graph: Graph
    metadata: Dict[str, Any]

@dataclass
class ThoughtNode:
    """Domain-agnostic thought node for reasoning"""
    thought_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    content: str = ""
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    reasoning_depth: int = 0
    discovered_concepts: List[str] = field(default_factory=list)
    temporal_context: Optional[Dict[str, Any]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class ContentPreservingAnalyzer:
    """Analyzes TTL content while preserving every piece of information"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.discovered_patterns: Dict[str, Any] = {}
        self.concept_taxonomy: Dict[str, Set[str]] = defaultdict(set)
        
    async def analyze_ttl_comprehensively(self, ttl_content: str) -> TTLContent:
        """Comprehensive analysis that preserves all original content"""
        
        # Parse original content
        original_graph = Graph()
        try:
            original_graph.parse(data=ttl_content, format='turtle')
        except Exception as e:
            logger.error(f"Failed to parse original TTL: {e}")
            return TTLContent(
                original_ttl=ttl_content,
                enhanced_ttl=ttl_content,
                preservation_map={},
                lost_information=[f"Parsing error: {e}"],
                enhancement_log=["Original content preserved despite parsing issues"],
                graph=Graph(),
                metadata={"parse_error": str(e)}
            )
        
        # Extract all structural elements
        structural_analysis = self._extract_all_structural_elements(original_graph)
        
        # Discover domain-specific patterns
        discovered_patterns = await self._discover_domain_patterns(structural_analysis, ttl_content)
        
        # Generate enhanced version while preserving everything
        enhanced_content = await self._generate_enhanced_preserving_ttl(
            ttl_content, structural_analysis, discovered_patterns
        )
        
        # Verify no information was lost
        preservation_verification = self._verify_information_preservation(
            ttl_content, enhanced_content["enhanced_ttl"]
        )
        
        return TTLContent(
            original_ttl=ttl_content,
            enhanced_ttl=enhanced_content["enhanced_ttl"],
            preservation_map=enhanced_content["preservation_map"],
            lost_information=preservation_verification["lost_information"],
            enhancement_log=enhanced_content["enhancement_log"],
            graph=enhanced_content["enhanced_graph"],
            metadata={
                "original_size": len(ttl_content),
                "enhanced_size": len(enhanced_content["enhanced_ttl"]),
                "original_triples": len(original_graph),
                "enhanced_triples": len(enhanced_content["enhanced_graph"]),
                "structural_analysis": structural_analysis,
                "discovered_patterns": discovered_patterns,
                "preservation_verification": preservation_verification
            }
        )
    
    def _extract_all_structural_elements(self, graph: Graph) -> Dict[str, Any]:
        """Extract every structural element from the graph"""
        
        analysis = {
            "namespaces": dict(graph.namespaces()),
            "classes": set(),
            "properties": {"object": set(), "data": set(), "annotation": set()},
            "individuals": set(),
            "literals": {"values": set(), "datatypes": set(), "languages": set()},
            "blank_nodes": set(),
            "predicates": set(),
            "subjects": set(),
            "objects": set(),
            "triple_patterns": [],
            "hierarchical_relationships": [],
            "domain_range_relationships": [],
            "temporal_elements": [],
        }
        
        # Extract all triples and categorize elements
        for subj, pred, obj in graph:
            # Record the triple pattern
            analysis["triple_patterns"].append({
                "subject": str(subj),
                "predicate": str(pred),
                "object": str(obj),
                "subject_type": type(subj).__name__,
                "object_type": type(obj).__name__
            })
            
            # Categorize subjects, predicates, objects
            analysis["subjects"].add(str(subj))
            analysis["predicates"].add(str(pred))
            analysis["objects"].add(str(obj))
            
            # Identify classes
            if pred == RDF.type and obj == OWL.Class:
                analysis["classes"].add(str(subj))
            elif pred == RDF.type and obj == RDFS.Class:
                analysis["classes"].add(str(subj))
            
            # Identify properties
            if pred == RDF.type:
                if obj == OWL.ObjectProperty:
                    analysis["properties"]["object"].add(str(subj))
                elif obj == OWL.DatatypeProperty:
                    analysis["properties"]["data"].add(str(subj))
                elif obj == OWL.AnnotationProperty:
                    analysis["properties"]["annotation"].add(str(subj))
            
            # Identify individuals
            if pred == RDF.type and str(obj) not in [str(OWL.Class), str(RDFS.Class), 
                                                   str(OWL.ObjectProperty), str(OWL.DatatypeProperty)]:
                analysis["individuals"].add(str(subj))
            
            # Handle literals
            if isinstance(obj, Literal):
                analysis["literals"]["values"].add(str(obj))
                if obj.datatype:
                    analysis["literals"]["datatypes"].add(str(obj.datatype))
                if obj.language:
                    analysis["literals"]["languages"].add(obj.language)
            
            # Handle blank nodes
            if isinstance(subj, BNode):
                analysis["blank_nodes"].add(str(subj))
            if isinstance(obj, BNode):
                analysis["blank_nodes"].add(str(obj))
            
            # Identify hierarchical relationships
            if pred == RDFS.subClassOf:
                analysis["hierarchical_relationships"].append({
                    "child": str(subj),
                    "parent": str(obj),
                    "relationship_type": "subclass"
                })
            elif pred == RDFS.subPropertyOf:
                analysis["hierarchical_relationships"].append({
                    "child": str(subj),
                    "parent": str(obj),
                    "relationship_type": "subproperty"
                })
            
            # Identify domain/range relationships
            if pred == RDFS.domain:
                analysis["domain_range_relationships"].append({
                    "property": str(subj),
                    "domain": str(obj),
                    "type": "domain"
                })
            elif pred == RDFS.range:
                analysis["domain_range_relationships"].append({
                    "property": str(subj),
                    "range": str(obj),
                    "type": "range"
                })
            
            # Identify temporal elements
            temporal_indicators = [
                "time", "date", "temporal", "valid", "effective", "expires",
                "created", "modified", "established", "enacted", "repealed"
            ]
            if any(indicator in str(pred).lower() or indicator in str(obj).lower() 
                   for indicator in temporal_indicators):
                analysis["temporal_elements"].append({
                    "subject": str(subj),
                    "predicate": str(pred),
                    "object": str(obj),
                    "temporal_type": "discovered"
                })
        
        # Convert sets to lists for JSON serialization
        for key, value in analysis.items():
            if isinstance(value, set):
                analysis[key] = list(value)
        
        return analysis
    
    async def _discover_domain_patterns(self, structural_analysis: Dict[str, Any], ttl_content: str) -> Dict[str, Any]:
        """Discover domain-specific patterns from the content itself"""
        
        discovery_prompt = f"""
        Analyze this RDF/TTL content to discover domain-specific patterns and concepts.
        DO NOT assume any specific domain (like GDPR, SOX, etc.).
        
        Structural Analysis Summary:
        - Classes found: {len(structural_analysis['classes'])}
        - Properties found: {len(structural_analysis['properties']['object']) + len(structural_analysis['properties']['data'])}
        - Individuals found: {len(structural_analysis['individuals'])}
        - Hierarchical relationships: {len(structural_analysis['hierarchical_relationships'])}
        - Temporal elements: {len(structural_analysis['temporal_elements'])}
        
        Sample classes: {structural_analysis['classes'][:10]}
        Sample properties: {list(structural_analysis['properties']['object'])[:5] + list(structural_analysis['properties']['data'])[:5]}
        
        Discover and return:
        1. **Domain classification**: What domain does this appear to be?
        2. **Conceptual patterns**: What types of concepts are being modeled?
        3. **Relationship patterns**: What relationship types exist between concepts?
        4. **Constraint patterns**: What constraints or rules are implied?
        5. **Temporal patterns**: How is time/validity represented?
        6. **Hierarchical patterns**: What hierarchies exist?
        7. **Naming conventions**: What naming patterns are used?
        8. **Custom semantics**: Any domain-specific semantic patterns?
        
        Base your analysis ONLY on what's actually present in the data.
        Return as JSON:
        {{
            "domain_classification": {{
                "primary_domain": "detected domain",
                "confidence": 0.0-1.0,
                "evidence": ["evidence1", "evidence2"]
            }},
            "conceptual_patterns": [
                {{
                    "pattern_type": "type of concept pattern",
                    "examples": ["example1", "example2"],
                    "frequency": "number of occurrences"
                }}
            ],
            "relationship_patterns": [
                {{
                    "pattern_name": "relationship pattern name",
                    "pattern_description": "what this relationship represents",
                    "examples": ["subj pred obj examples"]
                }}
            ],
            "constraint_patterns": [
                {{
                    "constraint_type": "type of constraint discovered",
                    "description": "what constraint is implied",
                    "evidence": ["evidence from data"]
                }}
            ],
            "temporal_patterns": {{
                "has_temporal_data": false,
                "temporal_representations": [],
                "temporal_concepts": []
            }},
            "hierarchical_patterns": [
                {{
                    "hierarchy_type": "type of hierarchy",
                    "root_concepts": ["top-level concepts"],
                    "depth": "estimated depth"
                }}
            ],
            "naming_conventions": {{
                "uri_patterns": ["URI naming patterns"],
                "prefix_usage": {{}},
                "identifier_patterns": ["identifier patterns"]
            }},
            "custom_semantics": []
        }}
        
        RESPOND ONLY WITH VALID JSON. Base analysis on actual data content.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=discovery_prompt)])
            # Clean the response to extract JSON
            response_text = response.content.strip()
            
            # Remove markdown code blocks if present
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            response_text = response_text.strip()
            
            patterns = json.loads(response_text)
            self.discovered_patterns = patterns
            return patterns
            
        except Exception as e:
            logger.error(f"Error discovering domain patterns: {e}")
            return {
                "domain_classification": {"primary_domain": "unknown", "confidence": 0.0, "evidence": []},
                "conceptual_patterns": [],
                "relationship_patterns": [],
                "constraint_patterns": [],
                "temporal_patterns": {"has_temporal_data": False, "temporal_representations": [], "temporal_concepts": []},
                "hierarchical_patterns": [],
                "naming_conventions": {"uri_patterns": [], "prefix_usage": {}, "identifier_patterns": []},
                "custom_semantics": []
            }
    
    async def _generate_enhanced_preserving_ttl(self, 
                                              original_ttl: str, 
                                              structural_analysis: Dict[str, Any],
                                              discovered_patterns: Dict[str, Any]) -> Dict[str, Any]:
        """Generate enhanced TTL while preserving every piece of original information"""
        
        enhancement_prompt = f"""
        Enhance this TTL content while PRESERVING EVERY SINGLE piece of original information.
        You must NOT lose any triples, namespaces, comments, or data.
        
        Original TTL Content:
        {original_ttl}
        
        Discovered Domain Patterns:
        {json.dumps(discovered_patterns, indent=2)}
        
        Enhancement Guidelines:
        1. **PRESERVE EVERYTHING**: All original triples, namespaces, prefixes, comments must remain
        2. **ADD COMPLEMENTARY CONTENT**: Only add content that enhances understanding
        3. **Semantic Enrichment**: Add inferred relationships based on discovered patterns
        4. **Documentation**: Add rdfs:label and rdfs:comment for better understanding
        5. **Type Inference**: Add missing rdf:type statements where clearly implied
        6. **Constraint Formalization**: Add OWL restrictions based on discovered constraints
        7. **Temporal Formalization**: Formalize temporal patterns discovered
        8. **Hierarchical Completion**: Complete implied hierarchical relationships
        
        Enhanced content should include:
        - ALL original content exactly as provided
        - Additional rdfs:label for human readability
        - Additional rdfs:comment for documentation
        - Inferred rdf:type statements where obvious
        - OWL property characteristics where applicable
        - Additional ontological structure that makes implicit knowledge explicit
        
        RESPOND ONLY WITH VALID TTL CONTENT.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=enhancement_prompt)])
            enhanced_ttl = response.content.strip()
            
            # Remove markdown code blocks if present
            if enhanced_ttl.startswith('```turtle') or enhanced_ttl.startswith('```ttl'):
                lines = enhanced_ttl.split('\n')
                enhanced_ttl = '\n'.join(lines[1:])
            if enhanced_ttl.endswith('```'):
                enhanced_ttl = enhanced_ttl[:-3].strip()
            
            # Parse enhanced content to verify it's valid
            enhanced_graph = Graph()
            enhanced_graph.parse(data=enhanced_ttl, format='turtle')
            
            # Create preservation map
            preservation_map = self._create_preservation_map(original_ttl, enhanced_ttl)
            
            # Create enhancement log
            enhancement_log = [
                f"Enhanced TTL from {len(original_ttl)} to {len(enhanced_ttl)} characters",
                f"Expanded from {len(structural_analysis['triple_patterns'])} to {len(enhanced_graph)} triples",
                "Added semantic annotations and documentation",
                "Formalized discovered patterns into explicit ontological structures",
                "Enhanced machine readability while preserving human readability"
            ]
            
            return {
                "enhanced_ttl": enhanced_ttl,
                "enhanced_graph": enhanced_graph,
                "preservation_map": preservation_map,
                "enhancement_log": enhancement_log
            }
            
        except Exception as e:
            logger.error(f"Error generating enhanced TTL: {e}")
            # If enhancement fails, return original content
            original_graph = Graph()
            original_graph.parse(data=original_ttl, format='turtle')
            
            return {
                "enhanced_ttl": original_ttl,
                "enhanced_graph": original_graph,
                "preservation_map": {"preservation_status": "original_preserved_due_to_enhancement_error"},
                "enhancement_log": [f"Enhancement failed: {e}", "Original content preserved"]
            }
    
    def _create_preservation_map(self, original: str, enhanced: str) -> Dict[str, str]:
        """Create a mapping showing how original content is preserved in enhanced version"""
        
        original_lines = original.strip().split('\n')
        enhanced_lines = enhanced.strip().split('\n')
        
        preservation_map = {}
        
        for i, original_line in enumerate(original_lines):
            original_line = original_line.strip()
            if original_line and not original_line.startswith('#'):
                found_in_enhanced = []
                for j, enhanced_line in enumerate(enhanced_lines):
                    if original_line in enhanced_line or enhanced_line in original_line:
                        found_in_enhanced.append(j)
                
                preservation_map[f"original_line_{i}"] = {
                    "content": original_line,
                    "found_in_enhanced_lines": found_in_enhanced,
                    "preserved": len(found_in_enhanced) > 0
                }
        
        return preservation_map
    
    def _verify_information_preservation(self, original: str, enhanced: str) -> Dict[str, Any]:
        """Verify that no information was lost during enhancement"""
        
        try:
            original_graph = Graph()
            enhanced_graph = Graph()
            
            original_graph.parse(data=original, format='turtle')
            enhanced_graph.parse(data=enhanced, format='turtle')
            
            # Check if all original triples are present in enhanced version
            original_triples = set((str(s), str(p), str(o)) for s, p, o in original_graph)
            enhanced_triples = set((str(s), str(p), str(o)) for s, p, o in enhanced_graph)
            
            missing_triples = original_triples - enhanced_triples
            added_triples = enhanced_triples - original_triples
            
            # Check namespaces
            original_namespaces = dict(original_graph.namespaces())
            enhanced_namespaces = dict(enhanced_graph.namespaces())
            
            missing_namespaces = set(original_namespaces.items()) - set(enhanced_namespaces.items())
            
            lost_information = []
            
            if missing_triples:
                lost_information.extend([f"Missing triple: {t}" for t in missing_triples])
            
            if missing_namespaces:
                lost_information.extend([f"Missing namespace: {ns}" for ns in missing_namespaces])
            
            return {
                "lost_information": lost_information,
                "preservation_successful": len(lost_information) == 0,
                "original_triple_count": len(original_triples),
                "enhanced_triple_count": len(enhanced_triples),
                "added_triple_count": len(added_triples),
                "missing_triple_count": len(missing_triples),
                "preservation_ratio": len(original_triples & enhanced_triples) / max(len(original_triples), 1)
            }
            
        except Exception as e:
            return {
                "lost_information": [f"Verification error: {e}"],
                "preservation_successful": False,
                "preservation_ratio": 0.0
            }

class AdaptiveTreeOfThoughts:
    """Tree of Thoughts that adapts to any domain based on input content"""
    
    def __init__(self, llm: ChatOpenAI, max_depth: int = 3, breadth: int = 2):
        self.llm = llm
        self.max_depth = max_depth
        self.breadth = breadth
        self.thoughts: Dict[str, ThoughtNode] = {}
        self.root_id: Optional[str] = None
        self.domain_context: Dict[str, Any] = {}
        
    async def reasoning_with_domain_adaptation(self, 
                                             problem: str,
                                             discovered_patterns: Dict[str, Any],
                                             ttl_content: TTLContent) -> Dict[str, Any]:
        """Perform reasoning adapted to the discovered domain patterns"""
        
        self.domain_context = discovered_patterns
        
        # Initialize root with domain-aware context
        root = ThoughtNode(
            content=f"Domain Analysis: {discovered_patterns.get('domain_classification', {}).get('primary_domain', 'unknown')} - Problem: {problem}",
            reasoning_depth=0,
            discovered_concepts=list(ttl_content.metadata.get('structural_analysis', {}).get('classes', []))[:10]
        )
        self.thoughts[root.thought_id] = root
        self.root_id = root.thought_id
        
        # Generate domain-adapted reasoning tree
        await self._generate_domain_adapted_thoughts(problem, ttl_content)
        
        # Evaluate thoughts with domain context
        evaluations = await self._evaluate_domain_thoughts()
        
        # Find best reasoning path
        best_path = self._find_optimal_path()
        
        return {
            "reasoning_type": "adaptive_tree_of_thoughts",
            "domain_adapted": True,
            "domain_context": self.domain_context,
            "total_thoughts_generated": len(self.thoughts),
            "reasoning_depth_achieved": max(node.reasoning_depth for node in self.thoughts.values()),
            "best_reasoning_path": [
                {
                    "thought_content": node.content,
                    "confidence_score": node.confidence_score,
                    "discovered_concepts": node.discovered_concepts,
                    "reasoning_depth": node.reasoning_depth
                }
                for node in best_path
            ],
            "domain_insights": self._extract_domain_insights(),
            "adaptive_confidence": self._calculate_adaptive_confidence(evaluations)
        }
    
    async def _generate_domain_adapted_thoughts(self, problem: str, ttl_content: TTLContent):
        """Generate thoughts adapted to the discovered domain"""
        
        for depth in range(self.max_depth):
            current_nodes = [node for node in self.thoughts.values() 
                           if node.reasoning_depth == depth]
            
            for node in current_nodes:
                await self._expand_node_with_domain_context(node, problem, ttl_content)
    
    async def _expand_node_with_domain_context(self, node: ThoughtNode, problem: str, ttl_content: TTLContent):
        """Expand a node considering domain-specific context"""
        
        domain_info = self.domain_context.get('domain_classification', {})
        conceptual_patterns = self.domain_context.get('conceptual_patterns', [])
        
        expansion_prompt = f"""
        Continue reasoning about this problem using domain-specific knowledge discovered from the data.
        
        Current reasoning: {node.content}
        Problem: {problem}
        
        Domain Context:
        - Primary domain: {domain_info.get('primary_domain', 'unknown')}
        - Conceptual patterns found: {[p.get('pattern_type', '') for p in conceptual_patterns]}
        - Available concepts: {node.discovered_concepts}
        
        Generate {self.breadth} different reasoning approaches that:
        1. Build on current reasoning
        2. Use domain-specific patterns discovered in the data
        3. Consider different interpretations within this domain
        
        Base reasoning ONLY on patterns found in the actual data.
        
        Return as JSON array:
        [
            {{
                "thought": "detailed reasoning step using discovered patterns",
                "discovered_concepts": ["concepts from data used in this reasoning"],
                "confidence": 0.5,
                "domain_evidence": ["evidence from data supporting this reasoning"]
            }}
        ]
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=expansion_prompt)])
            response_text = response.content.strip()
            
            # Clean JSON response
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            response_text = response_text.strip()
            
            thoughts_data = json.loads(response_text)
            
            for thought_data in thoughts_data:
                new_thought = ThoughtNode(
                    content=thought_data.get("thought", ""),
                    parent_id=node.thought_id,
                    confidence_score=thought_data.get("confidence", 0.5),
                    reasoning_depth=node.reasoning_depth + 1,
                    discovered_concepts=thought_data.get("discovered_concepts", []),
                    metadata={
                        "domain_evidence": thought_data.get("domain_evidence", []),
                        "generated_at": datetime.now().isoformat()
                    }
                )
                
                self.thoughts[new_thought.thought_id] = new_thought
                node.children_ids.append(new_thought.thought_id)
                
        except Exception as e:
            logger.error(f"Error expanding node: {e}")
    
    async def _evaluate_domain_thoughts(self) -> Dict[str, float]:
        """Evaluate thoughts considering domain-specific criteria"""
        
        evaluations = {}
        
        for thought_id, thought in self.thoughts.items():
            eval_prompt = f"""
            Evaluate this reasoning step for quality within the discovered domain context.
            
            Reasoning: {thought.content}
            Domain: {self.domain_context.get('domain_classification', {}).get('primary_domain', 'unknown')}
            Concepts used: {thought.discovered_concepts}
            
            Rate overall quality from 0.0 to 1.0 based on:
            1. Accuracy within the domain
            2. Logical consistency
            3. Use of discovered concepts
            4. Evidence support from data
            
            Return JSON: {{"overall_score": 0.7}}
            
            RESPOND ONLY WITH VALID JSON.
            """
            
            try:
                response = await self.llm.ainvoke([HumanMessage(content=eval_prompt)])
                response_text = response.content.strip()
                
                # Clean JSON response
                if response_text.startswith('```json'):
                    response_text = response_text[7:]
                if response_text.endswith('```'):
                    response_text = response_text[:-3]
                response_text = response_text.strip()
                
                eval_data = json.loads(response_text)
                score = eval_data.get("overall_score", 0.5)
                evaluations[thought_id] = score
                thought.confidence_score = score
                
            except Exception as e:
                logger.error(f"Error evaluating thought {thought_id}: {e}")
                evaluations[thought_id] = 0.5
                thought.confidence_score = 0.5
        
        return evaluations
    
    def _find_optimal_path(self) -> List[ThoughtNode]:
        """Find the optimal reasoning path through the tree"""
        if not self.root_id:
            return []
        
        def find_best_path(node_id: str, path: List[ThoughtNode]) -> List[ThoughtNode]:
            node = self.thoughts[node_id]
            current_path = path + [node]
            
            if not node.children_ids:
                return current_path
            
            best_child_id = max(
                node.children_ids,
                key=lambda cid: self.thoughts[cid].confidence_score
            )
            
            return find_best_path(best_child_id, current_path)
        
        return find_best_path(self.root_id, [])
    
    def _extract_domain_insights(self) -> Dict[str, Any]:
        """Extract insights specific to the discovered domain"""
        
        all_concepts = []
        all_evidence = []
        confidence_scores = []
        
        for thought in self.thoughts.values():
            all_concepts.extend(thought.discovered_concepts)
            all_evidence.extend(thought.metadata.get("domain_evidence", []))
            confidence_scores.append(thought.confidence_score)
        
        return {
            "most_used_concepts": [item for item, count in Counter(all_concepts).most_common(5)],
            "strongest_evidence": [item for item, count in Counter(all_evidence).most_common(3)],
            "average_confidence": sum(confidence_scores) / max(len(confidence_scores), 1),
            "domain_coverage": len(set(all_concepts)) / max(len(all_concepts), 1) if all_concepts else 0
        }
    
    def _calculate_adaptive_confidence(self, evaluations: Dict[str, float]) -> float:
        """Calculate confidence adapted to domain context"""
        
        if not evaluations:
            return 0.0
        
        base_confidence = sum(evaluations.values()) / len(evaluations)
        domain_confidence = self.domain_context.get('domain_classification', {}).get('confidence', 0.5)
        
        adaptive_confidence = (base_confidence * 0.7) + (domain_confidence * 0.3)
        return adaptive_confidence

class GeneralPurposeLegalReasoningSystem:
    """General-purpose reasoning system that adapts to any domain"""
    
    def __init__(self, base_url: str, api_key: str, model: str = "o3-mini"):
        self.llm = ChatOpenAI(base_url=base_url, api_key=api_key, model=model)
        
        # Initialize adaptive components
        self.content_analyzer = ContentPreservingAnalyzer(self.llm)
        self.adaptive_tot = AdaptiveTreeOfThoughts(self.llm)
        
    async def comprehensive_analysis(self, ttl_content: str) -> Dict[str, Any]:
        """Perform comprehensive analysis preserving all information"""
        
        analysis_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        logger.info(f"Starting comprehensive analysis {analysis_id}")
        
        # Step 1: Content-preserving analysis
        logger.info("Step 1: Analyzing content while preserving all information")
        preserved_content = await self.content_analyzer.analyze_ttl_comprehensively(ttl_content)
        
        # Step 2: Domain-adaptive reasoning
        logger.info("Step 2: Performing domain-adaptive reasoning")
        reasoning_problem = f"Analyze the semantics, constraints, and relationships in this {preserved_content.metadata.get('discovered_patterns', {}).get('domain_classification', {}).get('primary_domain', 'unknown')} knowledge graph"
        
        reasoning_result = await self.adaptive_tot.reasoning_with_domain_adaptation(
            problem=reasoning_problem,
            discovered_patterns=preserved_content.metadata.get('discovered_patterns', {}),
            ttl_content=preserved_content
        )
        
        # Step 3: Consolidate insights
        logger.info("Step 3: Consolidating insights")
        consolidated_insights = await self._consolidate_insights(
            preserved_content, reasoning_result
        )
        
        end_time = datetime.now()
        processing_duration = (end_time - start_time).total_seconds()
        
        return {
            "analysis_id": analysis_id,
            "analysis_timestamp": start_time.isoformat(),
            "processing_duration_seconds": processing_duration,
            "input_preservation": {
                "original_size": len(ttl_content),
                "enhanced_size": len(preserved_content.enhanced_ttl),
                "information_preserved": len(preserved_content.lost_information) == 0,
                "lost_information": preserved_content.lost_information,
                "preservation_ratio": preserved_content.metadata.get("preservation_verification", {}).get("preservation_ratio", 0.0)
            },
            "domain_discovery": preserved_content.metadata.get('discovered_patterns', {}),
            "content_analysis": {
                "original_content": preserved_content.original_ttl,
                "enhanced_content": preserved_content.enhanced_ttl,
                "preservation_map": preserved_content.preservation_map,
                "enhancement_log": preserved_content.enhancement_log,
                "structural_analysis": preserved_content.metadata.get('structural_analysis', {})
            },
            "reasoning_analysis": reasoning_result,
            "consolidated_insights": consolidated_insights,
            "system_metadata": {
                "reasoning_patterns_used": ["adaptive_tree_of_thoughts"],
                "domain_agnostic": True,
                "information_preserving": True,
                "adaptive_to_input": True
            }
        }
    
    async def _consolidate_insights(self, 
                                  preserved_content: TTLContent,
                                  reasoning_result: Dict[str, Any]) -> Dict[str, Any]:
        """Consolidate insights from all analysis phases"""
        
        consolidation_prompt = f"""
        Consolidate insights from comprehensive analysis of this knowledge graph.
        
        Domain Discovery:
        {json.dumps(preserved_content.metadata.get('discovered_patterns', {}), indent=2)}
        
        Reasoning Analysis Summary:
        - Reasoning type: {reasoning_result.get('reasoning_type', 'unknown')}
        - Thoughts generated: {reasoning_result.get('total_thoughts_generated', 0)}
        - Best path confidence: {reasoning_result.get('adaptive_confidence', 0.0)}
        - Domain insights: {reasoning_result.get('domain_insights', {})}
        
        Provide consolidated insights:
        1. **Overall Assessment**: Quality and consistency of the knowledge graph
        2. **Key Findings**: Most important discoveries about the domain and data
        3. **Strengths**: What is well-represented and consistent
        4. **Issues Identified**: Problems, inconsistencies, or gaps found
        5. **Recommendations**: Actionable improvements based on discovered patterns
        6. **Confidence Assessment**: Overall confidence in the analysis
        
        Return as JSON:
        {{
            "overall_assessment": {{
                "quality_score": 0.8,
                "consistency_score": 0.7,
                "completeness_score": 0.9,
                "summary": "executive summary"
            }},
            "key_findings": [
                {{
                    "finding": "important discovery",
                    "evidence": ["supporting evidence"],
                    "implications": ["what this means"]
                }}
            ],
            "strengths": ["identified strengths"],
            "issues_identified": [
                {{
                    "issue_type": "type of issue",
                    "description": "specific issue found",
                    "severity": "medium",
                    "recommendation": "how to address"
                }}
            ],
            "actionable_recommendations": [
                {{
                    "recommendation": "what to do",
                    "rationale": "why this is recommended",
                    "priority": "medium"
                }}
            ],
            "confidence_assessment": {{
                "overall_confidence": 0.8,
                "confidence_factors": ["factors affecting confidence"],
                "uncertainty_areas": ["areas of uncertainty"]
            }}
        }}
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=consolidation_prompt)])
            response_text = response.content.strip()
            
            # Clean JSON response
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            response_text = response_text.strip()
            
            return json.loads(response_text)
        except Exception as e:
            logger.error(f"Error consolidating insights: {e}")
            return {
                "overall_assessment": {"quality_score": 0.0, "summary": f"Consolidation failed: {e}"},
                "key_findings": [],
                "strengths": [],
                "issues_identified": [],
                "actionable_recommendations": [],
                "confidence_assessment": {"overall_confidence": 0.0, "uncertainty_areas": ["consolidation_error"]}
            }

# ===============================
# FILE PROCESSING SYSTEM
# ===============================

@dataclass
class ProcessingConfig:
    """Configuration for TTL file processing"""
    input_path: str
    output_path: str
    api_key: str
    base_url: str = "https://api.openai.com/v1"
    model: str = "o3-mini"
    batch_processing: bool = True
    create_subdirs: bool = True
    preserve_structure: bool = True
    max_concurrent: int = 3

class TTLFileProcessor:
    """Main processor for TTL files with flexible path configuration"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.reasoning_system = GeneralPurposeLegalReasoningSystem(
            base_url=config.base_url,
            api_key=config.api_key,
            model=config.model
        )
        self.setup_paths()
    
    def setup_paths(self):
        """Setup input and output paths"""
        self.input_path = Path(self.config.input_path).resolve()
        self.output_path = Path(self.config.output_path).resolve()
        
        # Validate input path exists
        if not self.input_path.exists():
            raise FileNotFoundError(f"Input path does not exist: {self.input_path}")
        
        # Create output directory if it doesn't exist
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        print(f"✅ Input path: {self.input_path}")
        print(f"✅ Output path: {self.output_path}")
    
    async def process_single_file(self, ttl_file_path: str, output_dir: Optional[str] = None) -> Dict[str, Any]:
        """Process a single TTL file"""
        
        file_path = Path(ttl_file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"TTL file not found: {file_path}")
        
        print(f"\n🔄 Processing: {file_path.name}")
        
        # Read the TTL content
        with open(file_path, 'r', encoding='utf-8') as f:
            ttl_content = f.read()
        
        # Process with reasoning system
        analysis_result = await self.reasoning_system.comprehensive_analysis(ttl_content)
        
        # Determine output directory
        if output_dir:
            output_directory = Path(output_dir)
        else:
            output_directory = self.output_path
            
        output_directory.mkdir(parents=True, exist_ok=True)
        
        # Generate output file names
        base_name = file_path.stem
        
        # Save enhanced TTL
        enhanced_ttl_file = output_directory / f"{base_name}_enhanced.ttl"
        with open(enhanced_ttl_file, 'w', encoding='utf-8') as f:
            f.write(analysis_result['content_analysis']['enhanced_content'])
        
        # Save original TTL (for reference)
        original_ttl_file = output_directory / f"{base_name}_original.ttl"
        with open(original_ttl_file, 'w', encoding='utf-8') as f:
            f.write(analysis_result['content_analysis']['original_content'])
        
        # Save comprehensive analysis report
        analysis_report_file = output_directory / f"{base_name}_analysis.json"
        with open(analysis_report_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_result, f, indent=2, default=str)
        
        # Save preservation map
        preservation_file = output_directory / f"{base_name}_preservation.json"
        with open(preservation_file, 'w', encoding='utf-8') as f:
            json.dump({
                'preservation_map': analysis_result['content_analysis']['preservation_map'],
                'enhancement_log': analysis_result['content_analysis']['enhancement_log'],
                'information_preserved': analysis_result['input_preservation']['information_preserved'],
                'preservation_ratio': analysis_result['input_preservation']['preservation_ratio']
            }, f, indent=2)
        
        # Save executive summary
        summary_file = output_directory / f"{base_name}_summary.txt"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(self._generate_summary_report(analysis_result, file_path.name))
        
        print(f"✅ Completed: {file_path.name}")
        print(f"   📁 Output directory: {output_directory}")
        print(f"   📄 Enhanced TTL: {enhanced_ttl_file.name}")
        print(f"   📄 Analysis: {analysis_report_file.name}")
        print(f"   📄 Summary: {summary_file.name}")
        
        return {
            'input_file': str(file_path),
            'output_directory': str(output_directory),
            'files_created': [
                str(enhanced_ttl_file),
                str(original_ttl_file),
                str(analysis_report_file),
                str(preservation_file),
                str(summary_file)
            ],
            'analysis_result': analysis_result
        }
    
    async def process_directory(self, preserve_directory_structure: bool = True) -> Dict[str, Any]:
        """Process all TTL files in the input directory"""
        
        if not self.input_path.is_dir():
            raise ValueError(f"Input path is not a directory: {self.input_path}")
        
        # Find all TTL files
        ttl_files = list(self.input_path.rglob("*.ttl"))
        
        if not ttl_files:
            raise ValueError(f"No TTL files found in: {self.input_path}")
        
        print(f"\n🔍 Found {len(ttl_files)} TTL files to process")
        
        results = {}
        processing_stats = {
            'total_files': len(ttl_files),
            'successful': 0,
            'failed': 0,
            'start_time': datetime.now(),
            'end_time': None
        }
        
        for ttl_file in ttl_files:
            try:
                # Determine output subdirectory
                if preserve_directory_structure:
                    relative_path = ttl_file.relative_to(self.input_path)
                    output_subdir = self.output_path / relative_path.parent
                else:
                    output_subdir = self.output_path
                
                # Process the file
                result = await self.process_single_file(str(ttl_file), str(output_subdir))
                results[str(ttl_file)] = result
                processing_stats['successful'] += 1
                
            except Exception as e:
                print(f"❌ Error processing {ttl_file.name}: {e}")
                results[str(ttl_file)] = {'error': str(e)}
                processing_stats['failed'] += 1
        
        processing_stats['end_time'] = datetime.now()
        processing_stats['total_duration'] = (processing_stats['end_time'] - processing_stats['start_time']).total_seconds()
        
        # Save batch processing summary
        batch_summary_file = self.output_path / "batch_processing_summary.json"
        with open(batch_summary_file, 'w', encoding='utf-8') as f:
            json.dump({
                'processing_stats': processing_stats,
                'config': {
                    'input_path': str(self.input_path),
                    'output_path': str(self.output_path),
                    'preserve_structure': preserve_directory_structure
                }
            }, f, indent=2, default=str)
        
        print(f"\n📊 Batch Processing Complete!")
        print(f"   ✅ Successful: {processing_stats['successful']}")
        print(f"   ❌ Failed: {processing_stats['failed']}")
        print(f"   ⏱️  Duration: {processing_stats['total_duration']:.2f} seconds")
        print(f"   📁 Summary saved: {batch_summary_file}")
        
        return {
            'processing_stats': processing_stats,
            'results': results,
            'batch_summary_file': str(batch_summary_file)
        }
    
    def _generate_summary_report(self, analysis_result: Dict[str, Any], filename: str) -> str:
        """Generate a human-readable summary report"""
        
        domain_info = analysis_result.get('domain_discovery', {}).get('domain_classification', {})
        overall_assessment = analysis_result.get('consolidated_insights', {}).get('overall_assessment', {})
        preservation_info = analysis_result.get('input_preservation', {})
        
        summary = f"""
TTL FILE ANALYSIS SUMMARY
========================

File: {filename}
Analysis ID: {analysis_result.get('analysis_id', 'N/A')}
Processing Date: {analysis_result.get('analysis_timestamp', 'N/A')}
Duration: {analysis_result.get('processing_duration_seconds', 0):.2f} seconds

INFORMATION PRESERVATION
-----------------------
✓ Information Preserved: {preservation_info.get('information_preserved', False)}
✓ Preservation Ratio: {preservation_info.get('preservation_ratio', 0.0):.1%}
✓ Original Size: {preservation_info.get('original_size', 0):,} characters
✓ Enhanced Size: {preservation_info.get('enhanced_size', 0):,} characters

DOMAIN DISCOVERY
---------------
✓ Detected Domain: {domain_info.get('primary_domain', 'Unknown')}
✓ Confidence: {domain_info.get('confidence', 0.0):.1%}
✓ Evidence: {', '.join(domain_info.get('evidence', [])[:3])}

QUALITY ASSESSMENT
-----------------
✓ Overall Quality: {overall_assessment.get('quality_score', 0.0):.1%}
✓ Consistency: {overall_assessment.get('consistency_score', 0.0):.1%}
✓ Completeness: {overall_assessment.get('completeness_score', 0.0):.1%}

KEY FINDINGS
-----------
"""
        
        for i, finding in enumerate(analysis_result.get('consolidated_insights', {}).get('key_findings', [])[:5], 1):
            summary += f"{i}. {finding.get('finding', 'N/A')}\n"
        
        summary += f"""
RECOMMENDATIONS
--------------
"""
        
        for i, rec in enumerate(analysis_result.get('consolidated_insights', {}).get('actionable_recommendations', [])[:5], 1):
            summary += f"{i}. {rec.get('recommendation', 'N/A')} (Priority: {rec.get('priority', 'N/A')})\n"
        
        summary += f"""
TECHNICAL DETAILS
----------------
✓ Original Triples: {len(analysis_result.get('content_analysis', {}).get('structural_analysis', {}).get('triple_patterns', []))}
✓ Reasoning Confidence: {analysis_result.get('consolidated_insights', {}).get('confidence_assessment', {}).get('overall_confidence', 0.0):.1%}

For detailed technical analysis, see the corresponding JSON files.
"""
        
        return summary

# ===============================
# CONFIGURATION AND MAIN FUNCTIONS
# ===============================

def load_config_from_file(config_file: str) -> ProcessingConfig:
    """Load configuration from JSON file"""
    with open(config_file, 'r') as f:
        config_data = json.load(f)
    
    return ProcessingConfig(**config_data)

def create_sample_config(config_file: str = "ttl_config.json"):
    """Create a sample configuration file"""
    sample_config = {
        "input_path": "./input_ttl_files",
        "output_path": "./output_analysis",
        "api_key": "your-openai-api-key-here",
        "base_url": "https://api.openai.com/v1",
        "model": "o3-mini",
        "batch_processing": True,
        "create_subdirs": True,
        "preserve_structure": True,
        "max_concurrent": 3
    }
    
    with open(config_file, 'w') as f:
        json.dump(sample_config, f, indent=2)
    
    print(f"✅ Sample configuration created: {config_file}")
    print("📝 Please edit this file with your specific paths and API key.")

def main():
    """Main function with command line interface"""
    parser = argparse.ArgumentParser(description="Process TTL files with advanced reasoning")
    parser.add_argument('--input', '-i', type=str, help='Input TTL file or directory path')
    parser.add_argument('--output', '-o', type=str, help='Output directory path')
    parser.add_argument('--config', '-c', type=str, help='Configuration file path')
    parser.add_argument('--api-key', type=str, help='OpenAI API key')
    parser.add_argument('--model', type=str, default='o3-mini', help='Model to use (default: o3-mini)')
    parser.add_argument('--single', action='store_true', help='Process single file instead of directory')
    parser.add_argument('--create-config', action='store_true', help='Create sample configuration file')
    
    args = parser.parse_args()
    
    # Create sample configuration if requested
    if args.create_config:
        create_sample_config()
        return
    
    # Load configuration
    if args.config:
        config = load_config_from_file(args.config)
    else:
        # Create config from command line arguments
        if not args.input or not args.output or not args.api_key:
            print("❌ Error: Either provide --config file or --input, --output, and --api-key")
            print("💡 Use --create-config to generate a sample configuration file")
            sys.exit(1)
        
        config = ProcessingConfig(
            input_path=args.input,
            output_path=args.output,
            api_key=args.api_key,
            model=args.model
        )
    
    # Run the processor
    async def run_processor():
        try:
            processor = TTLFileProcessor(config)
            
            if args.single or Path(config.input_path).is_file():
                # Process single file
                result = await processor.process_single_file(config.input_path)
                print(f"\n🎉 Single file processing complete!")
            else:
                # Process directory
                result = await processor.process_directory(config.preserve_structure)
                print(f"\n🎉 Batch processing complete!")
                
        except Exception as e:
            print(f"❌ Processing failed: {e}")
            sys.exit(1)
    
    # Run the async function
    asyncio.run(run_processor())

# Example usage functions for demonstration
async def example_usage():
    """Example of how to use the system programmatically"""
    
    # Example 1: Process a single file
    config = ProcessingConfig(
        input_path="./my_legal_document.ttl",
        output_path="./analysis_results",
        api_key="your-api-key-here"
    )
    
    processor = TTLFileProcessor(config)
    # result = await processor.process_single_file(config.input_path)
    
    # Example 2: Process entire directory
    config = ProcessingConfig(
        input_path="./legal_documents_folder",
        output_path="./batch_analysis_results",
        api_key="your-api-key-here",
        preserve_structure=True
    )
    
    processor = TTLFileProcessor(config)
    # result = await processor.process_directory()
    
    print("Example configuration complete!")

if __name__ == "__main__":
    # Command line interface
    main()
    
    # Or run examples:
    # asyncio.run(example_usage())
