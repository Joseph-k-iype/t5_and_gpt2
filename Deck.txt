import os
import json
import asyncio
import argparse
import logging
import re
from typing import Dict, List, Any, Optional, TypedDict, Annotated, Tuple
from datetime import datetime

# Core LangChain imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

# FalkorDB-specific LangChain imports
from langchain_community.chains.graph_qa.falkordb import FalkorDBQAChain
from langchain_community.graphs import FalkorDBGraph

# Try to import vector store - it's optional
try:
    from langchain_community.vectorstores import FalkorDBVector
    VECTOR_SEARCH_AVAILABLE = True
except ImportError:
    VECTOR_SEARCH_AVAILABLE = False
    FalkorDBVector = None

# Pydantic for data validation
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class BusinessInsight(BaseModel):
    """Structured business insight model"""
    executive_summary: str = Field(description="High-level executive summary in 2-3 sentences")
    key_findings: List[str] = Field(description="List of key findings as bullet points")
    strategic_implications: List[str] = Field(description="Strategic business implications")
    risks_and_opportunities: List[str] = Field(description="Identified risks and opportunities")
    recommended_actions: List[str] = Field(description="Specific recommended next steps")
    technical_details: Optional[str] = Field(description="Technical analysis details", default=None)


class FalkorDBQueryValidator:
    """Simple query validator for basic FalkorDB compatibility"""
    
    @staticmethod
    def is_safe_query(query: str) -> bool:
        """Check if query is safe and likely to work with FalkorDB"""
        if not query or not query.strip():
            return False
        
        query_upper = query.upper()
        
        # Check for dangerous operations
        dangerous_keywords = ['DELETE', 'DROP', 'CREATE INDEX', 'CREATE CONSTRAINT']
        for keyword in dangerous_keywords:
            if keyword in query_upper and not query_upper.startswith('CREATE ('):
                return False
        
        # Avoid overly complex patterns that often fail
        if query.count('-[*') > 1:  # Multiple variable length paths
            return False
        
        if re.search(r'-\[\*\d+\.\.\d+\]', query):  # Complex range patterns
            # Allow simple ranges like [*1..3] but be cautious
            if query.count('[*') > 1:
                return False
        
        return True


class EnhancedGraphRAGEngine:
    """Enhanced Enterprise Graph RAG Engine with business intelligence focus."""
    
    def __init__(self, 
                 openai_api_key: str,
                 openai_base_url: Optional[str] = None,
                 falkordb_host: str = 'localhost',
                 falkordb_port: int = 6379,
                 graph_name: str = 'test_cor'):
        
        self.graph_name = graph_name
        self.validator = FalkorDBQueryValidator()
        
        # Initialize OpenAI LLM with o3-mini optimized settings
        self.llm = ChatOpenAI(
            model="o3-mini",
            api_key=openai_api_key,
            base_url=openai_base_url,
            temperature=0.1,
            model_kwargs={
                "reasoning_effort": "medium"  # Use o3-mini's built-in reasoning
            }
        )
        
        # Initialize embeddings for vector search (optional)
        self.embeddings = None
        if VECTOR_SEARCH_AVAILABLE:
            try:
                self.embeddings = OpenAIEmbeddings(
                    api_key=openai_api_key,
                    base_url=openai_base_url
                )
            except Exception as e:
                logger.warning(f"Embeddings initialization failed: {e}")
        
        # Initialize FalkorDB Graph wrapper
        self.graph = FalkorDBGraph(
            database=graph_name,
            host=falkordb_host,
            port=falkordb_port
        )
        
        # Initialize vector store for semantic search (optional)
        self.vector_store = None
        if VECTOR_SEARCH_AVAILABLE and self.embeddings:
            try:
                self.vector_store = FalkorDBVector(
                    host=falkordb_host,
                    port=falkordb_port,
                    embedding=self.embeddings,
                    database=graph_name
                )
            except Exception as e:
                logger.warning(f"Vector store initialization failed: {e}")
        
        # Create enhanced QA chain with business-focused prompts
        self.qa_chain = self._create_enhanced_qa_chain()
        
        # Get schema information for context
        self.schema_info = self._get_enhanced_schema_info()
        
        logger.info(f"Enhanced FalkorDB Graph RAG Engine initialized for graph: {graph_name}")
        logger.info(f"Vector search available: {self.vector_store is not None}")
        
    def _create_enhanced_qa_chain(self) -> FalkorDBQAChain:
        """Create enhanced QA chain with business-focused prompts."""
        
        business_cypher_prompt = """
You are a FalkorDB business analyst expert. Generate precise, business-focused openCypher queries.

CRITICAL QUERY GUIDELINES:
- Use SIMPLE, DIRECT queries that work reliably with FalkorDB
- Prefer basic MATCH patterns: MATCH (n:Label)-[r:RELATIONSHIP]->(m:Label)
- Use standard aggregations: count(), sum(), avg(), max(), min()
- Use proper WHERE clauses for filtering
- Use ORDER BY and LIMIT for meaningful results
- Avoid complex path traversals unless absolutely necessary
- NO GDS functions (gds.*) - they are NOT supported
- NO APOC procedures (apoc.*) - they are NOT supported
- Use standard openCypher functions: labels(), keys(), type(), size()

Schema Context: {schema}

Business Question: {question}

Generate a clear, business-focused openCypher query that:
1. Uses simple MATCH patterns with specific node labels when possible
2. Includes business-relevant aggregations (count, sum, avg) when appropriate
3. Uses proper property filtering for meaningful results
4. Returns data that directly answers the business question
5. Is reliable and won't cause syntax errors

Focus on generating queries that provide business insights, not technical complexity.

Query:
"""
        
        cypher_prompt = PromptTemplate(
            input_variables=["schema", "question"],
            template=business_cypher_prompt
        )
        
        return FalkorDBQAChain.from_llm(
            llm=self.llm,
            graph=self.graph,
            verbose=True,
            allow_dangerous_requests=True,
            return_intermediate_steps=True,
            cypher_prompt=cypher_prompt
        )
    
    def _get_enhanced_schema_info(self) -> Dict[str, Any]:
        """Get comprehensive schema information for better context."""
        try:
            schema_info = {
                'raw_schema': self.graph.get_schema,
                'structured_schema': self.graph.get_structured_schema
            }
            
            # Get business context with simple, reliable queries
            business_queries = [
                "MATCH (n) RETURN DISTINCT labels(n) as node_types, count(n) as count ORDER BY count DESC LIMIT 10",
                "MATCH ()-[r]->() RETURN DISTINCT type(r) as relationship_types, count(r) as count ORDER BY count DESC LIMIT 10"
            ]
            
            for i, query in enumerate(business_queries):
                try:
                    result = self.graph.query(query)
                    schema_info[f'business_context_{i}'] = result
                except Exception as e:
                    logger.debug(f"Business context query {i} failed: {e}")
            
            return schema_info
        except Exception as e:
            logger.error(f"Failed to get schema info: {e}")
            return {}
    
    def _format_business_response(self, 
                                query: str, 
                                raw_result: str, 
                                cypher_query: str = "",
                                query_results: List = None) -> str:
        """Format response as a business-friendly report using o3-mini's reasoning."""
        
        # Use o3-mini's built-in reasoning for business analysis
        business_prompt = f"""
Transform this graph analysis into a professional business intelligence report.

ORIGINAL QUESTION: "{query}"

ANALYSIS RESULTS: {raw_result}

TECHNICAL QUERY USED: {cypher_query}

DATA SAMPLE: {str(query_results[:3]) if query_results else "No specific data"}

Create a structured business report with the following sections:

## Executive Summary
[Provide a 2-3 sentence high-level summary of the key findings and their business significance]

## Key Findings
• [Finding 1 - specific, data-driven insight]
• [Finding 2 - specific, data-driven insight]  
• [Finding 3 - specific, data-driven insight]

## Strategic Implications
• [Implication 1 - what this means for business strategy]
• [Implication 2 - what this means for business strategy]

## Risks & Opportunities
• [Risk/Opportunity 1 - specific business concern or chance]
• [Risk/Opportunity 2 - specific business concern or chance]

## Recommended Actions
• [Action 1 - specific, actionable next step]
• [Action 2 - specific, actionable next step]

## Technical Notes
[Brief summary of the analysis method and data sources]

Format with proper markdown. Focus on business value and actionable insights, not technical jargon. Be specific and data-driven where possible.
"""
        
        try:
            business_analysis = self.llm.invoke(business_prompt)
            return business_analysis.content
        except Exception as e:
            logger.error(f"Business formatting failed: {e}")
            # Fallback formatting
            return f"""## Analysis Results

### Executive Summary
{raw_result}

### Technical Details
**Query Used:** `{cypher_query}`

**Data Sample:** {str(query_results[:3]) if query_results else "No specific data available"}

### Recommended Actions
• Review the findings with relevant stakeholders
• Consider additional analysis based on these initial results
• Implement data-driven decision making based on these insights
"""
    
    def _semantic_search_enhancement(self, query: str) -> str:
        """Use vector search to enhance query context if available."""
        if not self.vector_store:
            return ""
        
        try:
            # Get semantic context from vector search
            similar_docs = self.vector_store.similarity_search(query, k=3)
            if similar_docs:
                context = "\n".join([doc.page_content[:200] for doc in similar_docs])
                return f"\n\nSemantic Context from Vector Search:\n{context}"
        except Exception as e:
            logger.debug(f"Vector search failed: {e}")
        
        return ""
    
    def _try_vector_search_query(self, query: str) -> Optional[str]:
        """Try to use FalkorDB's native vector search if applicable."""
        if not self.vector_store:
            return None
        
        try:
            # Check if query seems like it would benefit from vector search
            vector_keywords = ['similar', 'like', 'related', 'find', 'search', 'recommendations']
            if any(keyword in query.lower() for keyword in vector_keywords):
                # Try to extract entity or concept for vector search
                # This is a simple heuristic - you can make it more sophisticated
                similar_docs = self.vector_store.similarity_search(query, k=5)
                if similar_docs:
                    context = "Based on vector similarity search:\n"
                    for i, doc in enumerate(similar_docs, 1):
                        context += f"{i}. {doc.page_content[:150]}...\n"
                    return context
        except Exception as e:
            logger.debug(f"Vector search query failed: {e}")
        
        return None
    
    def search_with_business_intelligence(self, user_query: str) -> Tuple[str, List[str]]:
        """Execute search with business intelligence formatting and follow-ups."""
        
        logger.info(f"Processing business intelligence query: {user_query}")
        
        try:
            # Try vector search enhancement first
            vector_context = self._try_vector_search_query(user_query)
            
            # Add semantic context if available
            semantic_context = self._semantic_search_enhancement(user_query)
            enhanced_query = user_query + semantic_context
            
            # If we have vector search results, include them
            if vector_context:
                enhanced_query = f"{user_query}\n\nAdditional Context:\n{vector_context}"
            
            # Execute main query using QA chain
            result = self.qa_chain.invoke({"query": enhanced_query})
            
            raw_result = result.get('result', '')
            cypher_query = ""
            query_results = []
            
            # Extract technical details
            if result.get('intermediate_steps'):
                step = result['intermediate_steps'][0]
                cypher_query = step.get('query', '')
                query_results = step.get('context', [])
            
            # Validate the generated query
            if cypher_query and not self.validator.is_safe_query(cypher_query):
                logger.warning(f"Generated query may have issues: {cypher_query}")
            
            # Format as business report using o3-mini's reasoning
            business_report = self._format_business_response(
                user_query, raw_result, cypher_query, query_results
            )
            
            # Generate follow-up questions using o3-mini's reasoning
            followup_questions = self._generate_intelligent_followups(
                user_query, business_report
            )
            
            return business_report, followup_questions
            
        except Exception as e:
            logger.error(f"Business intelligence search failed: {e}")
            error_report = f"""## Analysis Error

**Query:** {user_query}

**Issue:** Technical error occurred during analysis: {str(e)}

## Recommended Actions
• Verify FalkorDB connection and data availability
• Try a simpler, more specific query
• Check if the requested data exists in the graph
• Review the query for potential syntax issues

## Alternative Approaches
• Use basic graph exploration queries first
• Break down complex questions into simpler parts
• Focus on specific node types or relationships
"""
            return error_report, [
                "What node types are available in the graph?",
                "What are the main relationships in the data?",
                "Can you show me a simple overview of the graph structure?",
                "What properties are available for analysis?"
            ]
    
    def _generate_intelligent_followups(self, original_query: str, analysis_result: str) -> List[str]:
        """Generate intelligent follow-up questions using o3-mini's reasoning."""
        
        followup_prompt = f"""
Based on this business analysis, generate 6-8 intelligent follow-up questions that would provide additional business value.

Original Question: "{original_query}"

Analysis Result: {analysis_result[:1000]}...

Generate follow-up questions that:
1. Dig deeper into the specific findings mentioned
2. Explore related business opportunities  
3. Address potential risks or concerns
4. Suggest operational improvements
5. Investigate root causes or drivers
6. Explore competitive or market implications
7. Focus on actionable next steps

Requirements:
- Each question should be specific and actionable
- Focus on business insights, not technical details
- Questions should build on the findings in the analysis
- Avoid generic questions - be specific to the results
- Format as simple questions (one per line, no numbering)
- Each question should end with a question mark

Format as a simple list of questions.
"""
        
        try:
            followup_result = self.llm.invoke(followup_prompt)
            questions = []
            for line in followup_result.content.split('\n'):
                line = line.strip()
                # Clean up the line and check if it's a valid question
                line = re.sub(r'^\d+\.\s*', '', line)  # Remove numbering
                line = line.strip('•-*').strip()  # Remove bullet points
                if line and '?' in line and len(line) > 10:
                    questions.append(line)
            
            return questions[:8]  # Limit to 8 questions
        except Exception as e:
            logger.error(f"Follow-up generation failed: {e}")
            return [
                "What are the root causes behind these patterns?",
                "How can we optimize our operations based on these findings?", 
                "What risks should we monitor related to these insights?",
                "What opportunities can we pursue from this analysis?",
                "How do these findings compare to industry benchmarks?",
                "What would be the business impact of addressing these issues?"
            ]
    
    def simple_business_query(self, query: str) -> str:
        """Simple business query without follow-ups."""
        result, _ = self.search_with_business_intelligence(query)
        return result
    
    # Backward compatibility methods
    def search_sync(self, user_query: str, thread_id: str = "default") -> str:
        """Synchronous search for backward compatibility."""
        return self.simple_business_query(user_query)
    
    def search_with_followups_sync(self, user_query: str, thread_id: str = "default") -> Tuple[str, List[str]]:
        """Synchronous search with follow-ups for backward compatibility."""
        return self.search_with_business_intelligence(user_query)
    
    async def search(self, user_query: str, thread_id: str = "default") -> str:
        """Async search method."""
        return self.simple_business_query(user_query)
    
    async def search_with_followups(self, user_query: str, thread_id: str = "default") -> Tuple[str, List[str]]:
        """Async search with follow-ups."""
        return self.search_with_business_intelligence(user_query)
    
    def get_graph_info(self) -> Dict[str, Any]:
        """Get comprehensive graph information."""
        try:
            return {
                'database_name': self.graph.database,
                'database_type': 'FalkorDB',
                'query_language': 'openCypher',
                'schema': self.graph.get_schema,
                'structured_schema': self.graph.get_structured_schema,
                'schema_info': self.schema_info,
                'connection_info': {
                    'host': getattr(self.graph, '_host', 'localhost'),
                    'port': getattr(self.graph, '_port', 6379),
                    'connected': True
                },
                'enhanced_features': {
                    'business_intelligence': True,
                    'vector_search': self.vector_store is not None,
                    'semantic_enhancement': self.vector_store is not None,
                    'o3_mini_reasoning': True,
                    'schema_aware_queries': True,
                    'business_report_formatting': True,
                    'query_validation': True
                },
                'ai_model': {
                    'name': 'o3-mini',
                    'reasoning_effort': 'medium',
                    'built_in_reasoning': True
                },
                'generated_at': datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Failed to get graph info: {e}")
            return {'error': str(e), 'connected': False}
    
    def test_connection(self) -> Dict[str, Any]:
        """Test connection with enhanced capabilities."""
        try:
            # Test basic connection
            test_result = self.graph.query("RETURN 'connection_test' as status")
            
            # Test vector store if available
            vector_status = False
            if self.vector_store:
                try:
                    # Simple vector test
                    vector_status = True
                except:
                    vector_status = False
            
            return {
                'status': 'connected',
                'database': self.graph.database,
                'database_type': 'FalkorDB',
                'query_language': 'openCypher',
                'test_result': test_result,
                'vector_search_available': vector_status,
                'business_intelligence': True,
                'o3_mini_reasoning': True,
                'enhanced_features': True,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'status': 'failed',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }


class EnterpriseConfig:
    """Enterprise configuration management."""
    
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.openai_base_url = os.getenv("OPENAI_BASE_URL")
        self.falkordb_host = os.getenv("FALKORDB_HOST", "localhost")
        self.falkordb_port = int(os.getenv("FALKORDB_PORT", "6379"))
        self.graph_name = os.getenv("GRAPH_NAME", "test_cor")
    
    def validate(self) -> bool:
        """Validate enterprise configuration."""
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY is required for enterprise deployment")
        return True


def main():
    """Enhanced command-line interface with business intelligence focus."""
    parser = argparse.ArgumentParser(
        description="Enhanced FalkorDB Business Intelligence Graph RAG Engine",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python falkordb_graphrag_searchengine.py --query "What are our key business relationships?" 
  python falkordb_graphrag_searchengine.py --interactive
  python falkordb_graphrag_searchengine.py --test-connection
        """
    )
    
    parser.add_argument("--query", "-q", help="Business intelligence query")
    parser.add_argument("--thread-id", "-t", default="default", help="Session ID")
    parser.add_argument("--interactive", "-i", action="store_true", help="Interactive mode")
    parser.add_argument("--follow-ups", "-f", action="store_true", help="Generate follow-up questions")
    parser.add_argument("--test-connection", action="store_true", help="Test connection")
    parser.add_argument("--graph-info", action="store_true", help="Show graph information")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    
    args = parser.parse_args()
    
    # Set logging level
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Load configuration
    config = EnterpriseConfig()
    
    try:
        config.validate()
    except ValueError as e:
        print(f"❌ Configuration Error: {e}")
        return 1
    
    # Print enhanced banner
    print("🔧 Enhanced FalkorDB Business Intelligence Engine")
    print("=" * 60)
    print(f"📊 Graph Database: {config.graph_name} (FalkorDB)")
    print(f"🔗 Connection: {config.falkordb_host}:{config.falkordb_port}")
    print(f"🤖 AI Model: OpenAI o3-mini (Built-in Reasoning)")
    print(f"💼 Focus: Business Intelligence & Strategic Analysis")
    print(f"🔍 Features: Vector Search, Schema-Aware Queries, Business Reports")
    print("=" * 60)
    
    try:
        engine = EnhancedGraphRAGEngine(
            openai_api_key=config.openai_api_key,
            openai_base_url=config.openai_base_url,
            falkordb_host=config.falkordb_host,
            falkordb_port=config.falkordb_port,
            graph_name=config.graph_name
        )
        
        print("✅ Enhanced business intelligence engine initialized successfully")
        
    except Exception as e:
        print(f"❌ Failed to initialize engine: {e}")
        return 1
    
    # Handle different modes
    if args.test_connection:
        print("\n🔍 Testing Enhanced Connection...")
        result = engine.test_connection()
        if result['status'] == 'connected':
            print(f"✅ Successfully connected to {result['database_type']}: {result['database']}")
            print(f"🔍 Vector Search: {'✅' if result.get('vector_search_available') else '❌'}")
            print(f"💼 Business Intelligence: {'✅' if result.get('business_intelligence') else '❌'}")
            print(f"🤖 o3-mini Reasoning: {'✅' if result.get('o3_mini_reasoning') else '❌'}")
        else:
            print(f"❌ Connection failed: {result['error']}")
        return 0
    
    if args.graph_info:
        print("\n📊 Enhanced Graph Information:")
        print("-" * 50)
        info = engine.get_graph_info()
        if 'error' not in info:
            print(f"Database Type: {info['database_type']}")
            print(f"Enhanced Features:")
            for feature, enabled in info.get('enhanced_features', {}).items():
                print(f"  • {feature.replace('_', ' ').title()}: {'✅' if enabled else '❌'}")
        else:
            print(f"❌ Error: {info['error']}")
        return 0
    
    if args.interactive:
        print("\n💼 Enhanced Business Intelligence Mode")
        print("💡 Ask business questions to get strategic analysis")
        print("-" * 60)
        
        while True:
            try:
                query = input(f"\n[{args.thread_id}] 🔍 Business Question: ").strip()
                if query.lower() in ['exit', 'quit', 'q']:
                    print("👋 Ending session...")
                    break
                
                if not query:
                    continue
                
                print("\n💼 Analyzing with business intelligence...")
                
                if args.follow_ups:
                    result, follow_ups = engine.search_with_business_intelligence(query)
                    print(f"\n{result}")
                    
                    if follow_ups:
                        print(f"\n🤔 INTELLIGENT FOLLOW-UP QUESTIONS:")
                        print("-" * 40)
                        for i, follow_up in enumerate(follow_ups, 1):
                            print(f"{i}. {follow_up}")
                else:
                    result = engine.simple_business_query(query)
                    print(f"\n{result}")
                
                print("\n" + "=" * 60)
                
            except KeyboardInterrupt:
                print("\n👋 Session terminated by user")
                break
            except Exception as e:
                print(f"❌ Analysis error: {e}")
        
        return 0
    
    if args.query:
        print(f"\n🔍 Business Query: {args.query}")
        print("-" * 60)
        
        try:
            if args.follow_ups:
                result, follow_ups = engine.search_with_business_intelligence(args.query)
                print(f"\n{result}")
                
                if follow_ups:
                    print(f"\n🤔 STRATEGIC FOLLOW-UPS:")
                    print("-" * 30)
                    for i, follow_up in enumerate(follow_ups, 1):
                        print(f"{i}. {follow_up}")
            else:
                result = engine.simple_business_query(args.query)
                print(f"\n{result}")
                
        except Exception as e:
            print(f"❌ Analysis failed: {e}")
            return 1
    else:
        print("\n⚠️  No query provided. Use --query, --interactive, or --test-connection")
        parser.print_help()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
