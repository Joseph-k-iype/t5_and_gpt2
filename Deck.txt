#!/usr/bin/env python3
"""
General-Purpose Legal Knowledge Graph Reasoning System
Domain-agnostic, learns from input TTL, preserves all original information
Enhanced with file path support for reading TTL files
"""

import os
import json
import asyncio
from typing import Dict, List, Any, Optional, Union, Tuple, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import logging
from pathlib import Path
import hashlib
import uuid
import re
from collections import defaultdict, Counter
import glob

# Graph analysis and RDF processing
import networkx as nx
from rdflib import Graph, Namespace, URIRef, Literal, BNode
from rdflib.namespace import RDF, RDFS, OWL, XSD
from rdflib.plugins.sparql import prepareQuery
import rdflib.plugins.sparql as sparql

# Pydantic v2 with enhanced validation
from pydantic import BaseModel, Field, ValidationError, field_validator
from typing_extensions import Annotated

# LangGraph with advanced patterns
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===============================
# GLOBAL CONFIGURATION
# ===============================

# API Configuration
OPENAI_BASE_URL = "https://api.openai.com/v1"  # Change this to your API base URL
OPENAI_API_KEY = "your-api-key-here"           # Replace with your actual API key
DEFAULT_MODEL = "o3-mini"                      # Default model to use

# File Paths Configuration
DEFAULT_TTL_DIRECTORY = "./ttl_files/"         # Default directory for TTL files
DEFAULT_OUTPUT_DIRECTORY = "./analysis_output/" # Default directory for analysis outputs
DEFAULT_PATTERN = "**/*.ttl"                  # Default glob pattern for TTL files

# Analysis Configuration
MAX_REASONING_DEPTH = 5                        # Maximum reasoning depth for ToT
REASONING_BREADTH = 3                          # Number of reasoning branches to explore
ENABLE_TEMPORAL_REASONING = True               # Whether to enable temporal reasoning
ENABLE_FORMAL_VERIFICATION = True             # Whether to enable formal verification

# Logging Configuration
LOG_LEVEL = logging.INFO                       # Logging level
LOG_FILE = "./reasoning_system.log"           # Log file path (None for console only)

class SystemConfig:
    """System configuration class for easy parameter management"""
    
    def __init__(self):
        self.openai_base_url = OPENAI_BASE_URL
        self.openai_api_key = OPENAI_API_KEY
        self.default_model = DEFAULT_MODEL
        self.default_ttl_directory = DEFAULT_TTL_DIRECTORY
        self.default_output_directory = DEFAULT_OUTPUT_DIRECTORY
        self.default_pattern = DEFAULT_PATTERN
        self.max_reasoning_depth = MAX_REASONING_DEPTH
        self.reasoning_breadth = REASONING_BREADTH
        self.enable_temporal_reasoning = ENABLE_TEMPORAL_REASONING
        self.enable_formal_verification = ENABLE_FORMAL_VERIFICATION
        self.log_level = LOG_LEVEL
        self.log_file = LOG_FILE
    
    def update_from_env(self):
        """Update configuration from environment variables"""
        import os
        self.openai_api_key = os.getenv('OPENAI_API_KEY', self.openai_api_key)
        self.openai_base_url = os.getenv('OPENAI_BASE_URL', self.openai_base_url)
        self.default_model = os.getenv('DEFAULT_MODEL', self.default_model)
        self.default_ttl_directory = os.getenv('DEFAULT_TTL_DIRECTORY', self.default_ttl_directory)
        self.default_output_directory = os.getenv('DEFAULT_OUTPUT_DIRECTORY', self.default_output_directory)
    
    def validate(self):
        """Validate configuration settings"""
        if self.openai_api_key == "your-api-key-here":
            logger.warning("API key not set! Please update OPENAI_API_KEY")
        
        # Create directories if they don't exist
        Path(self.default_ttl_directory).mkdir(parents=True, exist_ok=True)
        Path(self.default_output_directory).mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Configuration validated. Using model: {self.default_model}")
    
    def save_to_file(self, config_path: str = "./config.json"):
        """Save configuration to a JSON file"""
        config_dict = {
            'openai_base_url': self.openai_base_url,
            'openai_api_key': self.openai_api_key,
            'default_model': self.default_model,
            'default_ttl_directory': self.default_ttl_directory,
            'default_output_directory': self.default_output_directory,
            'default_pattern': self.default_pattern,
            'max_reasoning_depth': self.max_reasoning_depth,
            'reasoning_breadth': self.reasoning_breadth,
            'enable_temporal_reasoning': self.enable_temporal_reasoning,
            'enable_formal_verification': self.enable_formal_verification,
            'log_level': self.log_level,
            'log_file': self.log_file
        }
        
        with open(config_path, 'w') as f:
            json.dump(config_dict, f, indent=2)
        
        logger.info(f"Configuration saved to {config_path}")
    
    def load_from_file(self, config_path: str = "./config.json"):
        """Load configuration from a JSON file"""
        try:
            with open(config_path, 'r') as f:
                config_dict = json.load(f)
            
            for key, value in config_dict.items():
                if hasattr(self, key):
                    setattr(self, key, value)
            
            logger.info(f"Configuration loaded from {config_path}")
        except FileNotFoundError:
            logger.warning(f"Configuration file {config_path} not found, using defaults")
        except Exception as e:
            logger.error(f"Error loading configuration: {e}")
    
    def __str__(self):
        """String representation of configuration"""
        masked_key = '*' * 20 + self.openai_api_key[-8:] if len(self.openai_api_key) > 8 else 'NOT_SET'
        return f"""SystemConfig:
  API Base URL: {self.openai_base_url}
  API Key: {masked_key}
  Model: {self.default_model}
  TTL Directory: {self.default_ttl_directory}
  Output Directory: {self.default_output_directory}
  Pattern: {self.default_pattern}
  Max Depth: {self.max_reasoning_depth}
  Breadth: {self.reasoning_breadth}
  Temporal Reasoning: {self.enable_temporal_reasoning}
  Formal Verification: {self.enable_formal_verification}"""

# Global configuration instance
CONFIG = SystemConfig()
CONFIG.load_from_file()  # Try to load from config.json if it exists
CONFIG.update_from_env()  # Load from environment variables if available

class ReasoningType(Enum):
    """Types of reasoning patterns available"""
    CHAIN_OF_THOUGHT = "cot"
    TREE_OF_THOUGHTS = "tot"
    REFLEXION = "reflexion"
    LATS = "lats"
    REACT = "react"
    TEMPORAL = "temporal"
    FORMAL_VERIFICATION = "formal_verification"
    PATTERN_DISCOVERY = "pattern_discovery"

class ConfidenceLevel(Enum):
    """Confidence levels for reasoning outputs"""
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNCERTAIN = "uncertain"

# ===============================
# 0. TTL FILE MANAGEMENT SYSTEM
# ===============================

@dataclass
class TTLFileInfo:
    """Information about a TTL file"""
    file_path: str
    file_name: str
    file_size: int
    modification_time: datetime
    content: str
    is_valid_ttl: bool
    parse_errors: List[str] = field(default_factory=list)

class TTLFileManager:
    """Manages reading and processing TTL files from various sources"""
    
    def __init__(self):
        self.supported_extensions = ['.ttl', '.turtle', '.n3', '.nt']
        
    def read_ttl_from_path(self, path: Union[str, Path]) -> List[TTLFileInfo]:
        """Read TTL files from a given path (file or directory)"""
        
        path = Path(path)
        ttl_files = []
        
        if not path.exists():
            logger.error(f"Path does not exist: {path}")
            return []
        
        if path.is_file():
            # Single file
            if self._is_ttl_file(path):
                file_info = self._read_single_ttl_file(path)
                if file_info:
                    ttl_files.append(file_info)
            else:
                logger.warning(f"File {path} is not a recognized TTL file")
        
        elif path.is_dir():
            # Directory - find all TTL files
            ttl_files = self._read_ttl_files_from_directory(path)
        
        else:
            logger.error(f"Path is neither file nor directory: {path}")
        
        logger.info(f"Found {len(ttl_files)} TTL files in path: {path}")
        return ttl_files
    
    def read_ttl_from_pattern(self, pattern: str) -> List[TTLFileInfo]:
        """Read TTL files matching a glob pattern"""
        
        ttl_files = []
        matching_files = glob.glob(pattern, recursive=True)
        
        for file_path in matching_files:
            path = Path(file_path)
            if path.is_file() and self._is_ttl_file(path):
                file_info = self._read_single_ttl_file(path)
                if file_info:
                    ttl_files.append(file_info)
        
        logger.info(f"Found {len(ttl_files)} TTL files matching pattern: {pattern}")
        return ttl_files
    
    def combine_ttl_files(self, ttl_files: List[TTLFileInfo]) -> str:
        """Combine multiple TTL files into a single content string"""
        
        if not ttl_files:
            return ""
        
        if len(ttl_files) == 1:
            return ttl_files[0].content
        
        combined_content = []
        
        # Add header comment
        combined_content.append(f"# Combined TTL content from {len(ttl_files)} files")
        combined_content.append(f"# Generated at: {datetime.now().isoformat()}")
        combined_content.append("")
        
        # Collect all prefixes first
        all_prefixes = set()
        for file_info in ttl_files:
            prefixes = self._extract_prefixes(file_info.content)
            all_prefixes.update(prefixes)
        
        # Add all unique prefixes
        for prefix in sorted(all_prefixes):
            combined_content.append(prefix)
        
        combined_content.append("")
        
        # Add content from each file
        for i, file_info in enumerate(ttl_files):
            combined_content.append(f"# === Content from: {file_info.file_name} ===")
            
            # Remove prefixes from individual file content to avoid duplication
            content_without_prefixes = self._remove_prefixes(file_info.content)
            combined_content.append(content_without_prefixes)
            
            if i < len(ttl_files) - 1:  # Add separator between files
                combined_content.append("")
                combined_content.append(f"# === End of {file_info.file_name} ===")
                combined_content.append("")
        
        return "\n".join(combined_content)
    
    def _read_ttl_files_from_directory(self, directory: Path) -> List[TTLFileInfo]:
        """Read all TTL files from a directory"""
        
        ttl_files = []
        
        # Search recursively for TTL files
        for ext in self.supported_extensions:
            pattern = f"**/*{ext}"
            for file_path in directory.glob(pattern):
                if file_path.is_file():
                    file_info = self._read_single_ttl_file(file_path)
                    if file_info:
                        ttl_files.append(file_info)
        
        return sorted(ttl_files, key=lambda x: x.file_name)
    
    def _read_single_ttl_file(self, file_path: Path) -> Optional[TTLFileInfo]:
        """Read a single TTL file and return file info"""
        
        try:
            # Get file metadata
            stat_info = file_path.stat()
            modification_time = datetime.fromtimestamp(stat_info.st_mtime)
            
            # Read file content
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Validate TTL content
            is_valid, parse_errors = self._validate_ttl_content(content)
            
            return TTLFileInfo(
                file_path=str(file_path),
                file_name=file_path.name,
                file_size=stat_info.st_size,
                modification_time=modification_time,
                content=content,
                is_valid_ttl=is_valid,
                parse_errors=parse_errors
            )
            
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {e}")
            return None
    
    def _is_ttl_file(self, file_path: Path) -> bool:
        """Check if a file is a TTL file based on extension"""
        return file_path.suffix.lower() in self.supported_extensions
    
    def _validate_ttl_content(self, content: str) -> Tuple[bool, List[str]]:
        """Validate TTL content by attempting to parse it"""
        
        try:
            test_graph = Graph()
            test_graph.parse(data=content, format='turtle')
            return True, []
        except Exception as e:
            return False, [str(e)]
    
    def _extract_prefixes(self, content: str) -> List[str]:
        """Extract prefix declarations from TTL content"""
        
        prefixes = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('@prefix') or line.startswith('PREFIX'):
                prefixes.append(line)
        
        return prefixes
    
    def _remove_prefixes(self, content: str) -> str:
        """Remove prefix declarations from TTL content"""
        
        lines = content.split('\n')
        content_lines = []
        
        for line in lines:
            stripped_line = line.strip()
            if not (stripped_line.startswith('@prefix') or stripped_line.startswith('PREFIX')):
                content_lines.append(line)
        
        return '\n'.join(content_lines)

# ===============================
# 1. CONTENT-PRESERVING TTL ANALYZER
# ===============================

@dataclass
class TTLContent:
    """Complete preservation of original TTL content with enhancements"""
    original_ttl: str
    enhanced_ttl: str
    preservation_map: Dict[str, str]  # Maps original to enhanced elements
    lost_information: List[str]  # Should always be empty
    enhancement_log: List[str]
    graph: Graph
    metadata: Dict[str, Any]

class ContentPreservingAnalyzer:
    """Analyzes TTL content while preserving every piece of information"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.discovered_patterns: Dict[str, Any] = {}
        self.concept_taxonomy: Dict[str, Set[str]] = defaultdict(set)
        
    async def analyze_ttl_comprehensively(self, ttl_content: str) -> TTLContent:
        """Comprehensive analysis that preserves all original content"""
        
        # Parse original content
        original_graph = Graph()
        try:
            original_graph.parse(data=ttl_content, format='turtle')
        except Exception as e:
            logger.error(f"Failed to parse original TTL: {e}")
            # Still preserve the content even if unparseable
            return TTLContent(
                original_ttl=ttl_content,
                enhanced_ttl=ttl_content,
                preservation_map={},
                lost_information=[f"Parsing error: {e}"],
                enhancement_log=["Original content preserved despite parsing issues"],
                graph=Graph(),
                metadata={"parse_error": str(e)}
            )
        
        # Extract all structural elements
        structural_analysis = self._extract_all_structural_elements(original_graph)
        
        # Discover domain-specific patterns
        discovered_patterns = await self._discover_domain_patterns(structural_analysis, ttl_content)
        
        # Generate enhanced version while preserving everything
        enhanced_content = await self._generate_enhanced_preserving_ttl(
            ttl_content, structural_analysis, discovered_patterns
        )
        
        # Verify no information was lost
        preservation_verification = self._verify_information_preservation(
            ttl_content, enhanced_content["enhanced_ttl"]
        )
        
        return TTLContent(
            original_ttl=ttl_content,
            enhanced_ttl=enhanced_content["enhanced_ttl"],
            preservation_map=enhanced_content["preservation_map"],
            lost_information=preservation_verification["lost_information"],
            enhancement_log=enhanced_content["enhancement_log"],
            graph=enhanced_content["enhanced_graph"],
            metadata={
                "original_size": len(ttl_content),
                "enhanced_size": len(enhanced_content["enhanced_ttl"]),
                "original_triples": len(original_graph),
                "enhanced_triples": len(enhanced_content["enhanced_graph"]),
                "structural_analysis": structural_analysis,
                "discovered_patterns": discovered_patterns,
                "preservation_verification": preservation_verification
            }
        )
    
    def _extract_all_structural_elements(self, graph: Graph) -> Dict[str, Any]:
        """Extract every structural element from the graph"""
        
        analysis = {
            "namespaces": dict(graph.namespaces()),
            "classes": set(),
            "properties": {"object": set(), "data": set(), "annotation": set()},
            "individuals": set(),
            "literals": {"values": set(), "datatypes": set(), "languages": set()},
            "blank_nodes": set(),
            "predicates": set(),
            "subjects": set(),
            "objects": set(),
            "triple_patterns": [],
            "hierarchical_relationships": [],
            "domain_range_relationships": [],
            "cardinality_constraints": [],
            "value_restrictions": [],
            "temporal_elements": [],
            "custom_annotations": []
        }
        
        # Extract all triples and categorize elements
        for subj, pred, obj in graph:
            # Record the triple pattern
            analysis["triple_patterns"].append({
                "subject": str(subj),
                "predicate": str(pred),
                "object": str(obj),
                "subject_type": type(subj).__name__,
                "object_type": type(obj).__name__
            })
            
            # Categorize subjects, predicates, objects
            analysis["subjects"].add(str(subj))
            analysis["predicates"].add(str(pred))
            analysis["objects"].add(str(obj))
            
            # Identify classes
            if pred == RDF.type and obj == OWL.Class:
                analysis["classes"].add(str(subj))
            elif pred == RDF.type and obj == RDFS.Class:
                analysis["classes"].add(str(subj))
            
            # Identify properties
            if pred == RDF.type:
                if obj == OWL.ObjectProperty:
                    analysis["properties"]["object"].add(str(subj))
                elif obj == OWL.DatatypeProperty:
                    analysis["properties"]["data"].add(str(subj))
                elif obj == OWL.AnnotationProperty:
                    analysis["properties"]["annotation"].add(str(subj))
            
            # Identify individuals
            if pred == RDF.type and str(obj) not in [str(OWL.Class), str(RDFS.Class), 
                                                   str(OWL.ObjectProperty), str(OWL.DatatypeProperty)]:
                analysis["individuals"].add(str(subj))
            
            # Handle literals
            if isinstance(obj, Literal):
                analysis["literals"]["values"].add(str(obj))
                if obj.datatype:
                    analysis["literals"]["datatypes"].add(str(obj.datatype))
                if obj.language:
                    analysis["literals"]["languages"].add(obj.language)
            
            # Handle blank nodes
            if isinstance(subj, BNode):
                analysis["blank_nodes"].add(str(subj))
            if isinstance(obj, BNode):
                analysis["blank_nodes"].add(str(obj))
            
            # Identify hierarchical relationships
            if pred == RDFS.subClassOf:
                analysis["hierarchical_relationships"].append({
                    "child": str(subj),
                    "parent": str(obj),
                    "relationship_type": "subclass"
                })
            elif pred == RDFS.subPropertyOf:
                analysis["hierarchical_relationships"].append({
                    "child": str(subj),
                    "parent": str(obj),
                    "relationship_type": "subproperty"
                })
            
            # Identify domain/range relationships
            if pred == RDFS.domain:
                analysis["domain_range_relationships"].append({
                    "property": str(subj),
                    "domain": str(obj),
                    "type": "domain"
                })
            elif pred == RDFS.range:
                analysis["domain_range_relationships"].append({
                    "property": str(subj),
                    "range": str(obj),
                    "type": "range"
                })
            
            # Identify temporal elements (any predicate/object suggesting time)
            temporal_indicators = [
                "time", "date", "temporal", "valid", "effective", "expires",
                "created", "modified", "established", "enacted", "repealed"
            ]
            if any(indicator in str(pred).lower() or indicator in str(obj).lower() 
                   for indicator in temporal_indicators):
                analysis["temporal_elements"].append({
                    "subject": str(subj),
                    "predicate": str(pred),
                    "object": str(obj),
                    "temporal_type": "discovered"
                })
        
        # Convert sets to lists for JSON serialization
        for key, value in analysis.items():
            if isinstance(value, set):
                analysis[key] = list(value)
        
        return analysis
    
    async def _discover_domain_patterns(self, structural_analysis: Dict[str, Any], ttl_content: str) -> Dict[str, Any]:
        """Discover domain-specific patterns from the content itself"""
        
        discovery_prompt = f"""
        Analyze this RDF/TTL content to discover domain-specific patterns and concepts.
        DO NOT assume any specific legal domain (like GDPR, SOX, etc.).
        
        Structural Analysis Summary:
        - Classes found: {len(structural_analysis['classes'])}
        - Properties found: {len(structural_analysis['properties']['object']) + len(structural_analysis['properties']['data'])}
        - Individuals found: {len(structural_analysis['individuals'])}
        - Hierarchical relationships: {len(structural_analysis['hierarchical_relationships'])}
        - Temporal elements: {len(structural_analysis['temporal_elements'])}
        
        Sample classes: {structural_analysis['classes'][:10]}
        Sample properties: {list(structural_analysis['properties']['object'])[:5] + list(structural_analysis['properties']['data'])[:5]}
        Sample temporal elements: {structural_analysis['temporal_elements'][:5]}
        
        Discover and return:
        1. **Domain classification**: What domain does this appear to be (legal, medical, financial, etc.)?
        2. **Conceptual patterns**: What types of concepts are being modeled?
        3. **Relationship patterns**: What relationship types exist between concepts?
        4. **Constraint patterns**: What constraints or rules are implied?
        5. **Temporal patterns**: How is time/validity represented?
        6. **Hierarchical patterns**: What hierarchies exist?
        7. **Naming conventions**: What naming patterns are used?
        8. **Custom semantics**: Any domain-specific semantic patterns?
        
        Base your analysis ONLY on what's actually present in the data.
        Return as JSON:
        {{
            "domain_classification": {{
                "primary_domain": "detected domain",
                "confidence": 0.0-1.0,
                "evidence": ["evidence1", "evidence2"]
            }},
            "conceptual_patterns": [
                {{
                    "pattern_type": "type of concept pattern",
                    "examples": ["example1", "example2"],
                    "frequency": "number of occurrences"
                }}
            ],
            "relationship_patterns": [
                {{
                    "pattern_name": "relationship pattern name",
                    "pattern_description": "what this relationship represents",
                    "examples": ["subj pred obj examples"]
                }}
            ],
            "constraint_patterns": [
                {{
                    "constraint_type": "type of constraint discovered",
                    "description": "what constraint is implied",
                    "evidence": ["evidence from data"]
                }}
            ],
            "temporal_patterns": {{
                "has_temporal_data": boolean,
                "temporal_representations": ["how time is represented"],
                "temporal_concepts": ["time-related concepts found"]
            }},
            "hierarchical_patterns": [
                {{
                    "hierarchy_type": "type of hierarchy",
                    "root_concepts": ["top-level concepts"],
                    "depth": "estimated depth"
                }}
            ],
            "naming_conventions": {{
                "uri_patterns": ["URI naming patterns"],
                "prefix_usage": {{"prefix": "namespace"}},
                "identifier_patterns": ["identifier patterns"]
            }},
            "custom_semantics": [
                {{
                    "semantic_pattern": "custom semantic meaning",
                    "evidence": ["supporting evidence"],
                    "implications": ["what this means for reasoning"]
                }}
            ]
        }}
        
        RESPOND ONLY WITH VALID JSON. Base analysis on actual data content.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=discovery_prompt)])
            patterns = json.loads(response.content)
            
            # Store discovered patterns for future use
            self.discovered_patterns = patterns
            
            return patterns
            
        except Exception as e:
            logger.error(f"Error discovering domain patterns: {e}")
            return {
                "domain_classification": {"primary_domain": "unknown", "confidence": 0.0},
                "conceptual_patterns": [],
                "relationship_patterns": [],
                "constraint_patterns": [],
                "temporal_patterns": {"has_temporal_data": False},
                "hierarchical_patterns": [],
                "naming_conventions": {},
                "custom_semantics": []
            }
    
    async def _generate_enhanced_preserving_ttl(self, 
                                              original_ttl: str, 
                                              structural_analysis: Dict[str, Any],
                                              discovered_patterns: Dict[str, Any]) -> Dict[str, Any]:
        """Generate enhanced TTL while preserving every piece of original information"""
        
        enhancement_prompt = f"""
        Enhance this TTL content while PRESERVING EVERY SINGLE piece of original information.
        You must NOT lose any triples, namespaces, comments, or data.
        
        Original TTL Content:
        {original_ttl}
        
        Discovered Domain Patterns:
        {json.dumps(discovered_patterns, indent=2)}
        
        Enhancement Guidelines:
        1. **PRESERVE EVERYTHING**: All original triples, namespaces, prefixes, comments must remain
        2. **ADD COMPLEMENTARY CONTENT**: Only add content that enhances understanding
        3. **Semantic Enrichment**: Add inferred relationships based on discovered patterns
        4. **Documentation**: Add rdfs:label and rdfs:comment for better understanding
        5. **Type Inference**: Add missing rdf:type statements where clearly implied
        6. **Constraint Formalization**: Add OWL restrictions based on discovered constraints
        7. **Temporal Formalization**: Formalize temporal patterns discovered
        8. **Hierarchical Completion**: Complete implied hierarchical relationships
        
        Enhanced content should include:
        - ALL original content exactly as provided
        - Additional rdfs:label for human readability
        - Additional rdfs:comment for documentation
        - Inferred rdf:type statements where obvious
        - OWL property characteristics (functional, transitive, etc.) where applicable
        - SHACL shapes for validation (based on discovered patterns)
        - Additional ontological structure that makes implicit knowledge explicit
        
        Return the enhanced TTL content that:
        1. Contains ALL original information
        2. Adds semantic richness
        3. Improves machine processability
        4. Maintains parsability
        
        RESPOND ONLY WITH VALID TTL CONTENT.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=enhancement_prompt)])
            enhanced_ttl = response.content
            
            # Parse enhanced content to verify it's valid
            enhanced_graph = Graph()
            enhanced_graph.parse(data=enhanced_ttl, format='turtle')
            
            # Create preservation map
            preservation_map = self._create_preservation_map(original_ttl, enhanced_ttl)
            
            # Create enhancement log
            enhancement_log = [
                f"Enhanced TTL from {len(original_ttl)} to {len(enhanced_ttl)} characters",
                f"Expanded from {len(structural_analysis['triple_patterns'])} to {len(enhanced_graph)} triples",
                "Added semantic annotations and documentation",
                "Formalized discovered patterns into explicit ontological structures",
                "Enhanced machine readability while preserving human readability"
            ]
            
            return {
                "enhanced_ttl": enhanced_ttl,
                "enhanced_graph": enhanced_graph,
                "preservation_map": preservation_map,
                "enhancement_log": enhancement_log
            }
            
        except Exception as e:
            logger.error(f"Error generating enhanced TTL: {e}")
            # If enhancement fails, return original content
            original_graph = Graph()
            original_graph.parse(data=original_ttl, format='turtle')
            
            return {
                "enhanced_ttl": original_ttl,
                "enhanced_graph": original_graph,
                "preservation_map": {"preservation_status": "original_preserved_due_to_enhancement_error"},
                "enhancement_log": [f"Enhancement failed: {e}", "Original content preserved"]
            }
    
    def _create_preservation_map(self, original: str, enhanced: str) -> Dict[str, str]:
        """Create a mapping showing how original content is preserved in enhanced version"""
        
        # Split into lines for analysis
        original_lines = original.strip().split('\n')
        enhanced_lines = enhanced.strip().split('\n')
        
        preservation_map = {}
        
        # Map original lines to enhanced content
        for i, original_line in enumerate(original_lines):
            original_line = original_line.strip()
            if original_line and not original_line.startswith('#'):
                # Find this line or similar in enhanced content
                found_in_enhanced = []
                for j, enhanced_line in enumerate(enhanced_lines):
                    if original_line in enhanced_line or enhanced_line in original_line:
                        found_in_enhanced.append(j)
                
                preservation_map[f"original_line_{i}"] = {
                    "content": original_line,
                    "found_in_enhanced_lines": found_in_enhanced,
                    "preserved": len(found_in_enhanced) > 0
                }
        
        return preservation_map
    
    def _verify_information_preservation(self, original: str, enhanced: str) -> Dict[str, Any]:
        """Verify that no information was lost during enhancement"""
        
        try:
            # Parse both versions
            original_graph = Graph()
            enhanced_graph = Graph()
            
            original_graph.parse(data=original, format='turtle')
            enhanced_graph.parse(data=enhanced, format='turtle')
            
            # Check if all original triples are present in enhanced version
            original_triples = set((str(s), str(p), str(o)) for s, p, o in original_graph)
            enhanced_triples = set((str(s), str(p), str(o)) for s, p, o in enhanced_graph)
            
            missing_triples = original_triples - enhanced_triples
            added_triples = enhanced_triples - original_triples
            
            # Check namespaces
            original_namespaces = dict(original_graph.namespaces())
            enhanced_namespaces = dict(enhanced_graph.namespaces())
            
            missing_namespaces = set(original_namespaces.items()) - set(enhanced_namespaces.items())
            
            lost_information = []
            
            if missing_triples:
                lost_information.extend([f"Missing triple: {t}" for t in missing_triples])
            
            if missing_namespaces:
                lost_information.extend([f"Missing namespace: {ns}" for ns in missing_namespaces])
            
            return {
                "lost_information": lost_information,
                "preservation_successful": len(lost_information) == 0,
                "original_triple_count": len(original_triples),
                "enhanced_triple_count": len(enhanced_triples),
                "added_triple_count": len(added_triples),
                "missing_triple_count": len(missing_triples),
                "preservation_ratio": len(original_triples & enhanced_triples) / max(len(original_triples), 1)
            }
            
        except Exception as e:
            return {
                "lost_information": [f"Verification error: {e}"],
                "preservation_successful": False,
                "preservation_ratio": 0.0
            }

# ===============================
# 2. ADAPTIVE REASONING ENGINE
# ===============================

@dataclass
class ThoughtNode:
    """Domain-agnostic thought node for reasoning"""
    thought_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    content: str = ""
    parent_id: Optional[str] = None
    children_ids: List[str] = field(default_factory=list)
    confidence_score: float = 0.0
    reasoning_depth: int = 0
    discovered_concepts: List[str] = field(default_factory=list)
    temporal_context: Optional[Dict[str, Any]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class AdaptiveTreeOfThoughts:
    """Tree of Thoughts that adapts to any domain based on input content"""
    
    def __init__(self, llm: ChatOpenAI, max_depth: int = None, breadth: int = None):
        self.llm = llm
        self.max_depth = max_depth or CONFIG.max_reasoning_depth
        self.breadth = breadth or CONFIG.reasoning_breadth
        self.thoughts: Dict[str, ThoughtNode] = {}
        self.root_id: Optional[str] = None
        self.domain_context: Dict[str, Any] = {}
        
    async def reasoning_with_domain_adaptation(self, 
                                             problem: str,
                                             discovered_patterns: Dict[str, Any],
                                             ttl_content: TTLContent) -> Dict[str, Any]:
        """Perform reasoning adapted to the discovered domain patterns"""
        
        # Set domain context
        self.domain_context = discovered_patterns
        
        # Initialize root with domain-aware context
        root = ThoughtNode(
            content=f"Domain Analysis: {discovered_patterns.get('domain_classification', {}).get('primary_domain', 'unknown')} - Problem: {problem}",
            reasoning_depth=0,
            discovered_concepts=list(ttl_content.metadata.get('structural_analysis', {}).get('classes', []))[:10]
        )
        self.thoughts[root.thought_id] = root
        self.root_id = root.thought_id
        
        # Generate domain-adapted reasoning tree
        await self._generate_domain_adapted_thoughts(problem, ttl_content)
        
        # Evaluate thoughts with domain context
        evaluations = await self._evaluate_domain_thoughts()
        
        # Find best reasoning path
        best_path = self._find_optimal_path()
        
        return {
            "reasoning_type": "adaptive_tree_of_thoughts",
            "domain_adapted": True,
            "domain_context": self.domain_context,
            "total_thoughts_generated": len(self.thoughts),
            "reasoning_depth_achieved": max(node.reasoning_depth for node in self.thoughts.values()),
            "best_reasoning_path": [
                {
                    "thought_content": node.content,
                    "confidence_score": node.confidence_score,
                    "discovered_concepts": node.discovered_concepts,
                    "reasoning_depth": node.reasoning_depth,
                    "temporal_context": node.temporal_context
                }
                for node in best_path
            ],
            "domain_insights": self._extract_domain_insights(),
            "adaptive_confidence": self._calculate_adaptive_confidence(evaluations)
        }
    
    async def _generate_domain_adapted_thoughts(self, problem: str, ttl_content: TTLContent):
        """Generate thoughts adapted to the discovered domain"""
        
        for depth in range(self.max_depth):
            current_nodes = [node for node in self.thoughts.values() 
                           if node.reasoning_depth == depth]
            
            for node in current_nodes:
                await self._expand_node_with_domain_context(node, problem, ttl_content)
    
    async def _expand_node_with_domain_context(self, node: ThoughtNode, problem: str, ttl_content: TTLContent):
        """Expand a node considering domain-specific context"""
        
        domain_info = self.domain_context.get('domain_classification', {})
        conceptual_patterns = self.domain_context.get('conceptual_patterns', [])
        relationship_patterns = self.domain_context.get('relationship_patterns', [])
        
        expansion_prompt = f"""
        Continue reasoning about this problem using domain-specific knowledge discovered from the data.
        
        Current reasoning: {node.content}
        Problem: {problem}
        
        Domain Context:
        - Primary domain: {domain_info.get('primary_domain', 'unknown')}
        - Conceptual patterns found: {[p.get('pattern_type', '') for p in conceptual_patterns]}
        - Relationship patterns: {[p.get('pattern_name', '') for p in relationship_patterns]}
        - Available concepts: {node.discovered_concepts}
        
        Generate {self.breadth} different reasoning approaches that:
        1. Build on current reasoning
        2. Use domain-specific patterns discovered in the data
        3. Consider the conceptual relationships found
        4. Explore different interpretations within this domain
        5. Consider temporal aspects if present in the data
        
        Base reasoning ONLY on patterns and concepts found in the actual data.
        Do NOT assume knowledge not present in the input.
        
        Return as JSON array:
        [
            {{
                "thought": "detailed reasoning step using discovered patterns",
                "discovered_concepts": ["concepts from data used in this reasoning"],
                "confidence": 0.0-1.0,
                "domain_evidence": ["evidence from data supporting this reasoning"],
                "temporal_context": {{"temporal_info": "if applicable"}}
            }}
        ]
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=expansion_prompt)])
            thoughts_data = json.loads(response.content)
            
            for thought_data in thoughts_data:
                new_thought = ThoughtNode(
                    content=thought_data["thought"],
                    parent_id=node.thought_id,
                    confidence_score=thought_data.get("confidence", 0.5),
                    reasoning_depth=node.reasoning_depth + 1,
                    discovered_concepts=thought_data.get("discovered_concepts", []),
                    temporal_context=thought_data.get("temporal_context"),
                    metadata={
                        "domain_evidence": thought_data.get("domain_evidence", []),
                        "generated_at": datetime.now().isoformat()
                    }
                )
                
                self.thoughts[new_thought.thought_id] = new_thought
                node.children_ids.append(new_thought.thought_id)
                
        except Exception as e:
            logger.error(f"Error expanding node: {e}")
    
    async def _evaluate_domain_thoughts(self) -> Dict[str, float]:
        """Evaluate thoughts considering domain-specific criteria"""
        
        evaluations = {}
        
        for thought_id, thought in self.thoughts.items():
            eval_prompt = f"""
            Evaluate this reasoning step for quality within the discovered domain context.
            
            Reasoning: {thought.content}
            Domain: {self.domain_context.get('domain_classification', {}).get('primary_domain', 'unknown')}
            Concepts used: {thought.discovered_concepts}
            Domain evidence: {thought.metadata.get('domain_evidence', [])}
            
            Evaluate based on:
            1. Accuracy within the domain (based on discovered patterns)
            2. Logical consistency with domain constraints
            3. Effective use of discovered concepts
            4. Evidence support from actual data
            5. Reasoning completeness for the domain
            
            Rate each criterion 0.0-1.0 and provide overall score.
            
            Return JSON: {{"overall_score": 0.0-1.0, "criteria_scores": {{}}, "evaluation_rationale": ""}}
            
            RESPOND ONLY WITH VALID JSON.
            """
            
            try:
                response = await self.llm.ainvoke([HumanMessage(content=eval_prompt)])
                eval_data = json.loads(response.content)
                
                score = eval_data.get("overall_score", 0.5)
                evaluations[thought_id] = score
                thought.confidence_score = score
                thought.metadata["evaluation"] = eval_data
                
            except Exception as e:
                logger.error(f"Error evaluating thought {thought_id}: {e}")
                evaluations[thought_id] = 0.5
        
        return evaluations
    
    def _find_optimal_path(self) -> List[ThoughtNode]:
        """Find the optimal reasoning path through the tree"""
        if not self.root_id:
            return []
        
        def find_best_path(node_id: str, path: List[ThoughtNode]) -> List[ThoughtNode]:
            node = self.thoughts[node_id]
            current_path = path + [node]
            
            if not node.children_ids:
                return current_path
            
            # Find child with highest confidence considering domain relevance
            best_child_id = max(
                node.children_ids,
                key=lambda cid: self.thoughts[cid].confidence_score
            )
            
            return find_best_path(best_child_id, current_path)
        
        return find_best_path(self.root_id, [])
    
    def _extract_domain_insights(self) -> Dict[str, Any]:
        """Extract insights specific to the discovered domain"""
        
        all_concepts = []
        all_evidence = []
        confidence_scores = []
        
        for thought in self.thoughts.values():
            all_concepts.extend(thought.discovered_concepts)
            all_evidence.extend(thought.metadata.get("domain_evidence", []))
            confidence_scores.append(thought.confidence_score)
        
        return {
            "most_used_concepts": [item for item, count in Counter(all_concepts).most_common(10)],
            "strongest_evidence": [item for item, count in Counter(all_evidence).most_common(5)],
            "average_confidence": sum(confidence_scores) / max(len(confidence_scores), 1),
            "domain_coverage": len(set(all_concepts)) / max(len(all_concepts), 1)
        }
    
    def _calculate_adaptive_confidence(self, evaluations: Dict[str, float]) -> float:
        """Calculate confidence adapted to domain context"""
        
        if not evaluations:
            return 0.0
        
        base_confidence = sum(evaluations.values()) / len(evaluations)
        
        # Adjust based on domain discovery confidence
        domain_confidence = self.domain_context.get('domain_classification', {}).get('confidence', 0.5)
        
        # Weight the confidence by domain understanding
        adaptive_confidence = (base_confidence * 0.7) + (domain_confidence * 0.3)
        
        return adaptive_confidence

# ===============================
# 3. GENERAL-PURPOSE FORMAL VERIFICATION
# ===============================

class GeneralPurposeFormalVerifier:
    """Domain-agnostic formal verification system"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.discovered_constraints: List[str] = []
        self.logical_patterns: Dict[str, Any] = {}
        
    async def discover_and_verify_constraints(self, ttl_content: TTLContent) -> Dict[str, Any]:
        """Discover constraints from data and verify consistency"""
        
        # Discover constraints from the actual data
        discovered_constraints = await self._discover_constraints_from_data(ttl_content)
        
        # Generate formal logical expressions
        formal_constraints = await self._formalize_discovered_constraints(discovered_constraints)
        
        # Verify consistency
        verification_result = await self._verify_against_discovered_constraints(
            ttl_content.graph, formal_constraints
        )
        
        return {
            "verification_type": "general_purpose_formal",
            "discovered_constraints": discovered_constraints,
            "formal_constraints": formal_constraints,
            "verification_result": verification_result,
            "constraint_coverage": self._calculate_constraint_coverage(ttl_content, discovered_constraints)
        }
    
    async def _discover_constraints_from_data(self, ttl_content: TTLContent) -> List[Dict[str, Any]]:
        """Discover logical constraints present in the data"""
        
        structural_analysis = ttl_content.metadata.get('structural_analysis', {})
        
        discovery_prompt = f"""
        Discover logical constraints and rules from this RDF data structure.
        
        Data Analysis:
        - Hierarchical relationships: {structural_analysis.get('hierarchical_relationships', [])}
        - Domain/Range relationships: {structural_analysis.get('domain_range_relationships', [])}
        - Classes: {structural_analysis.get('classes', [])}
        - Properties: {structural_analysis.get('properties', {})}
        - Triple patterns: {len(structural_analysis.get('triple_patterns', []))} total
        
        Sample triple patterns: {structural_analysis.get('triple_patterns', [])[:20]}
        
        Discover constraints that are IMPLIED by the data structure:
        1. **Mutual exclusivity**: concepts that cannot coexist
        2. **Dependency relationships**: A requires B
        3. **Cardinality constraints**: how many relationships are allowed
        4. **Type constraints**: what types are valid in what contexts
        5. **Temporal constraints**: time-based rules if temporal data exists
        6. **Hierarchical constraints**: rules about class/property hierarchies
        7. **Domain-specific rules**: rules specific to this domain
        
        Base discoveries ONLY on patterns visible in the actual data.
        Do NOT assume external knowledge.
        
        Return as JSON:
        [
            {{
                "constraint_type": "type of constraint discovered",
                "description": "what the constraint states",
                "evidence": ["data patterns supporting this constraint"],
                "entities_involved": ["entities this constraint applies to"],
                "logical_form": "informal logical expression",
                "confidence": 0.0-1.0
            }}
        ]
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=discovery_prompt)])
            constraints = json.loads(response.content)
            return constraints
        except Exception as e:
            logger.error(f"Error discovering constraints: {e}")
            return []
    
    async def _formalize_discovered_constraints(self, discovered_constraints: List[Dict[str, Any]]) -> List[str]:
        """Convert discovered constraints into formal logical expressions"""
        
        formalization_prompt = f"""
        Convert these discovered constraints into formal logical expressions.
        
        Discovered Constraints:
        {json.dumps(discovered_constraints, indent=2)}
        
        Convert each constraint into:
        1. **First-order logic** format where possible
        2. **SHACL constraint** format for validation
        3. **OWL axiom** format where applicable
        
        Use standard logical notation:
        - ∀ (for all), ∃ (exists)
        - ∧ (and), ∨ (or), ¬ (not)
        - → (implies), ↔ (if and only if)
        
        Example formats:
        - FOL: ∀x (ClassA(x) → ¬ClassB(x))
        - SHACL: sh:property [ sh:path :hasProperty ; sh:maxCount 1 ]
        - OWL: ClassA owl:disjointWith ClassB
        
        Return as JSON:
        [
            {{
                "original_constraint_id": "reference to original",
                "formal_expressions": {{
                    "first_order_logic": "FOL expression",
                    "shacl": "SHACL constraint",
                    "owl": "OWL axiom"
                }},
                "applicability": "when this constraint applies"
            }}
        ]
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=formalization_prompt)])
            formal_constraints = json.loads(response.content)
            
            # Extract just the logical expressions
            expressions = []
            for constraint in formal_constraints:
                formal_exprs = constraint.get("formal_expressions", {})
                if formal_exprs.get("first_order_logic"):
                    expressions.append(formal_exprs["first_order_logic"])
            
            return expressions
            
        except Exception as e:
            logger.error(f"Error formalizing constraints: {e}")
            return []
    
    async def _verify_against_discovered_constraints(self, 
                                                   graph: Graph, 
                                                   formal_constraints: List[str]) -> Dict[str, Any]:
        """Verify the graph against discovered constraints"""
        
        # Convert graph to triple list for analysis
        triples = [(str(s), str(p), str(o)) for s, p, o in graph]
        
        verification_prompt = f"""
        Verify this RDF graph against the discovered logical constraints.
        
        Graph Data:
        - Total triples: {len(triples)}
        - Sample triples: {triples[:30]}
        
        Formal Constraints to Check:
        {json.dumps(formal_constraints, indent=2)}
        
        For each constraint, verify:
        1. Does the data satisfy the constraint?
        2. Are there any violations?
        3. What evidence supports compliance/violation?
        4. What is the confidence in this verification?
        
        Return verification results as JSON:
        {{
            "overall_consistency": boolean,
            "constraint_results": [
                {{
                    "constraint": "the constraint being checked",
                    "satisfied": boolean,
                    "violations": [
                        {{
                            "violation_type": "what kind of violation",
                            "description": "specific violation found",
                            "affected_triples": ["relevant triples"],
                            "severity": "high|medium|low"
                        }}
                    ],
                    "evidence": ["supporting evidence"],
                    "confidence": 0.0-1.0
                }}
            ],
            "consistency_score": 0.0-1.0,
            "verification_summary": "overall assessment"
        }}
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=verification_prompt)])
            return json.loads(response.content)
        except Exception as e:
            logger.error(f"Error in verification: {e}")
            return {
                "overall_consistency": False,
                "constraint_results": [],
                "consistency_score": 0.0,
                "verification_summary": f"Verification failed: {e}"
            }
    
    def _calculate_constraint_coverage(self, ttl_content: TTLContent, constraints: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Calculate how well constraints cover the data"""
        
        total_entities = len(ttl_content.metadata.get('structural_analysis', {}).get('classes', []))
        entities_with_constraints = len(set(
            entity for constraint in constraints 
            for entity in constraint.get('entities_involved', [])
        ))
        
        coverage_ratio = entities_with_constraints / max(total_entities, 1)
        
        return {
            "constraint_count": len(constraints),
            "entities_covered": entities_with_constraints,
            "total_entities": total_entities,
            "coverage_ratio": coverage_ratio,
            "coverage_assessment": (
                "comprehensive" if coverage_ratio >= 0.8 else
                "good" if coverage_ratio >= 0.6 else
                "partial" if coverage_ratio >= 0.4 else
                "minimal"
            )
        }

# ===============================
# 4. ADAPTIVE TEMPORAL REASONING
# ===============================

class AdaptiveTemporalReasoner:
    """Discovers and reasons about temporal patterns from data"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        
    async def discover_temporal_semantics(self, ttl_content: TTLContent) -> Dict[str, Any]:
        """Discover how time is represented in this specific dataset"""
        
        temporal_elements = ttl_content.metadata.get('structural_analysis', {}).get('temporal_elements', [])
        
        if not temporal_elements:
            return {
                "has_temporal_data": False,
                "temporal_reasoning_applicable": False,
                "message": "No temporal indicators found in the data"
            }
        
        discovery_prompt = f"""
        Analyze how time and temporal relationships are represented in this data.
        
        Temporal Elements Found:
        {json.dumps(temporal_elements, indent=2)}
        
        Discover:
        1. **Temporal representation patterns**: How is time encoded?
        2. **Temporal relationships**: What temporal relationships exist?
        3. **Validity patterns**: How is validity/applicability over time represented?
        4. **Temporal constraints**: What time-based rules are implied?
        5. **Temporal hierarchy**: Are there temporal precedence rules?
        6. **Change patterns**: How are changes over time represented?
        
        Base analysis ONLY on the temporal patterns visible in the data.
        
        Return as JSON:
        {{
            "has_temporal_data": true,
            "temporal_representations": [
                {{
                    "pattern_type": "how time is represented",
                    "examples": ["examples from data"],
                    "semantic_meaning": "what this represents"
                }}
            ],
            "temporal_relationships": [
                {{
                    "relationship_type": "type of temporal relationship",
                    "description": "what this relationship means",
                    "examples": ["examples from data"]
                }}
            ],
            "temporal_constraints": [
                {{
                    "constraint_type": "temporal constraint discovered",
                    "description": "what the constraint implies",
                    "evidence": ["supporting evidence from data"]
                }}
            ],
            "temporal_reasoning_rules": [
                {{
                    "rule_type": "temporal reasoning rule",
                    "rule_description": "how to reason about time in this domain",
                    "applicability": "when this rule applies"
                }}
            ]
        }}
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=discovery_prompt)])
            temporal_semantics = json.loads(response.content)
            
            # Apply discovered temporal reasoning
            temporal_analysis = await self._apply_discovered_temporal_reasoning(
                ttl_content, temporal_semantics
            )
            
            return {
                **temporal_semantics,
                "temporal_analysis": temporal_analysis,
                "temporal_reasoning_applicable": True
            }
            
        except Exception as e:
            logger.error(f"Error discovering temporal semantics: {e}")
            return {
                "has_temporal_data": len(temporal_elements) > 0,
                "temporal_reasoning_applicable": False,
                "error": str(e)
            }
    
    async def _apply_discovered_temporal_reasoning(self, 
                                                 ttl_content: TTLContent,
                                                 temporal_semantics: Dict[str, Any]) -> Dict[str, Any]:
        """Apply temporal reasoning based on discovered patterns"""
        
        reasoning_prompt = f"""
        Apply temporal reasoning to this data using the discovered temporal patterns.
        
        Discovered Temporal Semantics:
        {json.dumps(temporal_semantics, indent=2)}
        
        Graph size: {len(ttl_content.graph)} triples
        
        Apply temporal reasoning to determine:
        1. **Current validity**: What is currently valid/active?
        2. **Temporal conflicts**: Any conflicting temporal assertions?
        3. **Succession patterns**: What supersedes what over time?
        4. **Temporal gaps**: Missing temporal information?
        5. **Temporal consistency**: Are temporal assertions consistent?
        6. **Future implications**: What temporal changes are implied?
        
        Use ONLY the temporal reasoning rules discovered from this specific data.
        
        Return analysis as JSON:
        {{
            "temporal_consistency": boolean,
            "current_validity_status": [
                {{
                    "entity": "entity identifier",
                    "status": "active|expired|superseded|pending",
                    "evidence": "temporal evidence from data"
                }}
            ],
            "temporal_conflicts": [
                {{
                    "conflict_type": "type of temporal conflict",
                    "entities_involved": ["conflicting entities"],
                    "description": "nature of the conflict",
                    "resolution_suggestion": "how to resolve based on discovered patterns"
                }}
            ],
            "succession_chains": [
                {{
                    "predecessor": "earlier entity",
                    "successor": "later entity", 
                    "transition_evidence": "evidence for succession"
                }}
            ],
            "temporal_reasoning_confidence": 0.0-1.0
        }}
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=reasoning_prompt)])
            return json.loads(response.content)
        except Exception as e:
            logger.error(f"Error in temporal reasoning: {e}")
            return {
                "temporal_consistency": False,
                "error": str(e),
                "temporal_reasoning_confidence": 0.0
            }

# ===============================
# 5. MASTER COORDINATION SYSTEM
# ===============================

class GeneralPurposeLegalReasoningSystem:
    """General-purpose reasoning system that adapts to any domain"""
    
    def __init__(self, base_url: str = None, api_key: str = None, model: str = None):
        # Use global configuration as defaults
        base_url = base_url or CONFIG.openai_base_url
        api_key = api_key or CONFIG.openai_api_key
        model = model or CONFIG.default_model
        
        # Validate configuration
        CONFIG.validate()
        
        self.llm = ChatOpenAI(base_url=base_url, api_key=api_key, model=model)
        
        # Initialize adaptive components
        self.content_analyzer = ContentPreservingAnalyzer(self.llm)
        self.adaptive_tot = AdaptiveTreeOfThoughts(self.llm)
        self.formal_verifier = GeneralPurposeFormalVerifier(self.llm)
        self.temporal_reasoner = AdaptiveTemporalReasoner(self.llm)
        
        # Initialize file management
        self.file_manager = TTLFileManager()
        
        logger.info(f"Initialized system with model: {model}, base_url: {base_url}")
    
    async def analyze_default_directory(self) -> Dict[str, Any]:
        """Analyze TTL files from the default configured directory"""
        return await self.analyze_from_path(CONFIG.default_ttl_directory)
    
    async def analyze_default_pattern(self) -> Dict[str, Any]:
        """Analyze TTL files using the default configured pattern"""
        return await self.analyze_from_pattern(CONFIG.default_pattern)
        
    async def analyze_from_path(self, path: Union[str, Path]) -> Dict[str, Any]:
        """Analyze TTL files from a given path (file or directory)"""
        
        analysis_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        logger.info(f"Starting path-based analysis {analysis_id} for path: {path}")
        
        # Step 1: Read TTL files from path
        logger.info(f"Step 1: Reading TTL files from path: {path}")
        ttl_files = self.file_manager.read_ttl_from_path(path)
        
        if not ttl_files:
            return {
                "analysis_id": analysis_id,
                "error": f"No valid TTL files found at path: {path}",
                "files_found": [],
                "analysis_timestamp": start_time.isoformat()
            }
        
        # Step 2: Combine TTL files if multiple
        logger.info(f"Step 2: Processing {len(ttl_files)} TTL file(s)")
        combined_ttl_content = self.file_manager.combine_ttl_files(ttl_files)
        
        # Step 3: Perform comprehensive analysis
        logger.info("Step 3: Performing comprehensive analysis on combined content")
        analysis_result = await self.comprehensive_analysis(combined_ttl_content)
        
        # Step 4: Add file metadata
        file_metadata = {
            "source_path": str(path),
            "files_processed": [
                {
                    "file_name": f.file_name,
                    "file_path": f.file_path,
                    "file_size": f.file_size,
                    "modification_time": f.modification_time.isoformat(),
                    "is_valid_ttl": f.is_valid_ttl,
                    "parse_errors": f.parse_errors
                }
                for f in ttl_files
            ],
            "total_files": len(ttl_files),
            "combined_content_size": len(combined_ttl_content),
            "files_with_errors": len([f for f in ttl_files if not f.is_valid_ttl])
        }
        
        # Merge with comprehensive analysis result
        analysis_result["file_source_metadata"] = file_metadata
        analysis_result["analysis_source"] = "file_path"
        
        return analysis_result
    
    async def analyze_from_pattern(self, pattern: str) -> Dict[str, Any]:
        """Analyze TTL files matching a glob pattern"""
        
        analysis_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        logger.info(f"Starting pattern-based analysis {analysis_id} for pattern: {pattern}")
        
        # Step 1: Read TTL files matching pattern
        logger.info(f"Step 1: Finding TTL files matching pattern: {pattern}")
        ttl_files = self.file_manager.read_ttl_from_pattern(pattern)
        
        if not ttl_files:
            return {
                "analysis_id": analysis_id,
                "error": f"No valid TTL files found matching pattern: {pattern}",
                "pattern_used": pattern,
                "files_found": [],
                "analysis_timestamp": start_time.isoformat()
            }
        
        # Step 2: Combine TTL files
        logger.info(f"Step 2: Processing {len(ttl_files)} TTL file(s) from pattern")
        combined_ttl_content = self.file_manager.combine_ttl_files(ttl_files)
        
        # Step 3: Perform comprehensive analysis
        logger.info("Step 3: Performing comprehensive analysis on combined content")
        analysis_result = await self.comprehensive_analysis(combined_ttl_content)
        
        # Step 4: Add pattern metadata
        pattern_metadata = {
            "search_pattern": pattern,
            "files_processed": [
                {
                    "file_name": f.file_name,
                    "file_path": f.file_path,
                    "file_size": f.file_size,
                    "modification_time": f.modification_time.isoformat(),
                    "is_valid_ttl": f.is_valid_ttl,
                    "parse_errors": f.parse_errors
                }
                for f in ttl_files
            ],
            "total_files": len(ttl_files),
            "combined_content_size": len(combined_ttl_content),
            "files_with_errors": len([f for f in ttl_files if not f.is_valid_ttl])
        }
        
        # Merge with comprehensive analysis result
        analysis_result["file_source_metadata"] = pattern_metadata
        analysis_result["analysis_source"] = "glob_pattern"
        
        return analysis_result
    
    async def comprehensive_analysis(self, ttl_content: str) -> Dict[str, Any]:
        """Perform comprehensive analysis preserving all information"""
        
        analysis_id = str(uuid.uuid4())
        start_time = datetime.now()
        
        logger.info(f"Starting comprehensive analysis {analysis_id}")
        
        # Step 1: Content-preserving analysis
        logger.info("Step 1: Analyzing content while preserving all information")
        preserved_content = await self.content_analyzer.analyze_ttl_comprehensively(ttl_content)
        
        # Verify no information was lost
        if preserved_content.lost_information:
            logger.warning(f"Information loss detected: {preserved_content.lost_information}")
        
        # Step 2: Domain-adaptive reasoning
        logger.info("Step 2: Performing domain-adaptive reasoning")
        reasoning_problem = f"Analyze the semantics, constraints, and relationships in this {preserved_content.metadata.get('discovered_patterns', {}).get('domain_classification', {}).get('primary_domain', 'unknown')} knowledge graph"
        
        reasoning_result = await self.adaptive_tot.reasoning_with_domain_adaptation(
            problem=reasoning_problem,
            discovered_patterns=preserved_content.metadata.get('discovered_patterns', {}),
            ttl_content=preserved_content
        )
        
        # Step 3: Formal verification
        logger.info("Step 3: Performing formal verification")
        verification_result = await self.formal_verifier.discover_and_verify_constraints(preserved_content)
        
        # Step 4: Temporal reasoning (if applicable)
        logger.info("Step 4: Analyzing temporal aspects")
        temporal_result = await self.temporal_reasoner.discover_temporal_semantics(preserved_content)
        
        # Step 5: Consolidate insights
        logger.info("Step 5: Consolidating insights")
        consolidated_insights = await self._consolidate_all_insights(
            preserved_content, reasoning_result, verification_result, temporal_result
        )
        
        end_time = datetime.now()
        processing_duration = (end_time - start_time).total_seconds()
        
        return {
            "analysis_id": analysis_id,
            "analysis_timestamp": start_time.isoformat(),
            "processing_duration_seconds": processing_duration,
            "input_preservation": {
                "original_size": len(ttl_content),
                "enhanced_size": len(preserved_content.enhanced_ttl),
                "information_preserved": len(preserved_content.lost_information) == 0,
                "lost_information": preserved_content.lost_information,
                "preservation_ratio": preserved_content.metadata.get("preservation_verification", {}).get("preservation_ratio", 0.0)
            },
            "domain_discovery": preserved_content.metadata.get('discovered_patterns', {}),
            "content_analysis": {
                "original_content": preserved_content.original_ttl,
                "enhanced_content": preserved_content.enhanced_ttl,
                "preservation_map": preserved_content.preservation_map,
                "enhancement_log": preserved_content.enhancement_log,
                "structural_analysis": preserved_content.metadata.get('structural_analysis', {})
            },
            "reasoning_analysis": reasoning_result,
            "formal_verification": verification_result,
            "temporal_analysis": temporal_result,
            "consolidated_insights": consolidated_insights,
            "system_metadata": {
                "reasoning_patterns_used": ["adaptive_tree_of_thoughts", "formal_verification", "temporal_reasoning"],
                "domain_agnostic": True,
                "information_preserving": True,
                "adaptive_to_input": True
            }
        }
    
    async def _consolidate_all_insights(self, 
                                      preserved_content: TTLContent,
                                      reasoning_result: Dict[str, Any],
                                      verification_result: Dict[str, Any],
                                      temporal_result: Dict[str, Any]) -> Dict[str, Any]:
        """Consolidate insights from all analysis phases"""
        
        consolidation_prompt = f"""
        Consolidate insights from comprehensive analysis of this knowledge graph.
        
        Domain Discovery:
        {json.dumps(preserved_content.metadata.get('discovered_patterns', {}), indent=2)}
        
        Reasoning Analysis:
        {json.dumps(reasoning_result, indent=2)[:2000]}...
        
        Formal Verification:
        {json.dumps(verification_result, indent=2)[:2000]}...
        
        Temporal Analysis:
        {json.dumps(temporal_result, indent=2)[:1000]}...
        
        Provide consolidated insights:
        1. **Overall Assessment**: Quality and consistency of the knowledge graph
        2. **Key Findings**: Most important discoveries about the domain and data
        3. **Strengths**: What is well-represented and consistent
        4. **Issues Identified**: Problems, inconsistencies, or gaps found
        5. **Recommendations**: Actionable improvements based on discovered patterns
        6. **Domain-Specific Insights**: Insights specific to the discovered domain
        7. **Confidence Assessment**: Overall confidence in the analysis
        
        Base recommendations on actual patterns found in the data.
        
        Return as JSON:
        {{
            "overall_assessment": {{
                "quality_score": 0.0-1.0,
                "consistency_score": 0.0-1.0,
                "completeness_score": 0.0-1.0,
                "summary": "executive summary"
            }},
            "key_findings": [
                {{
                    "finding": "important discovery",
                    "evidence": ["supporting evidence"],
                    "implications": ["what this means"]
                }}
            ],
            "strengths": ["identified strengths"],
            "issues_identified": [
                {{
                    "issue_type": "type of issue",
                    "description": "specific issue found",
                    "severity": "high|medium|low",
                    "recommendation": "how to address"
                }}
            ],
            "domain_specific_insights": [
                {{
                    "insight": "domain-specific insight",
                    "relevance": "why this matters for this domain"
                }}
            ],
            "actionable_recommendations": [
                {{
                    "recommendation": "what to do",
                    "rationale": "why this is recommended",
                    "priority": "high|medium|low"
                }}
            ],
            "confidence_assessment": {{
                "overall_confidence": 0.0-1.0,
                "confidence_factors": ["factors affecting confidence"],
                "uncertainty_areas": ["areas of uncertainty"]
            }}
        }}
        
        RESPOND ONLY WITH VALID JSON.
        """
        
        try:
            response = await self.llm.ainvoke([HumanMessage(content=consolidation_prompt)])
            return json.loads(response.content)
        except Exception as e:
            logger.error(f"Error consolidating insights: {e}")
            return {
                "overall_assessment": {"quality_score": 0.0, "summary": f"Consolidation failed: {e}"},
                "key_findings": [],
                "strengths": [],
                "issues_identified": [],
                "domain_specific_insights": [],
                "actionable_recommendations": [],
                "confidence_assessment": {"overall_confidence": 0.0, "uncertainty_areas": ["consolidation_error"]}
            }


# ===============================
# 6. DEMONSTRATION FUNCTIONS
# ===============================

async def demonstrate_general_purpose_reasoning():
    """Demonstrate the general-purpose reasoning system"""
    
    # Initialize system using global configuration
    reasoning_system = GeneralPurposeLegalReasoningSystem()
    
    # Example TTL content (could be from any domain)
    sample_ttl = """
    @prefix ex: <http://example.org/> .
    @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
    @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
    
    # This could be any domain - legal, medical, financial, etc.
    ex:Document_123 a ex:RegulatoryDocument ;
        ex:title "Data Processing Guidelines" ;
        ex:effectiveDate "2023-01-01"^^xsd:date ;
        ex:hasRequirement ex:Requirement_1 .
    
    ex:Requirement_1 a ex:ComplianceRequirement ;
        ex:description "Organizations must obtain consent" ;
        ex:appliesTo ex:PersonalDataProcessing ;
        ex:mandatoryFrom "2023-06-01"^^xsd:date .
    
    ex:PersonalDataProcessing a ex:ProcessingActivity ;
        ex:requiresLegalBasis ex:ConsentBasis ;
        ex:subjectTo ex:Requirement_1 .
    
    ex:ConsentBasis a ex:LegalBasis ;
        rdfs:label "Consent" ;
        ex:validityDuration "P2Y"^^xsd:duration .
    """
    
    # Perform comprehensive analysis
    print("Starting general-purpose analysis...")
    print(f"Using configuration: {CONFIG.default_model} @ {CONFIG.openai_base_url}")
    analysis = await reasoning_system.comprehensive_analysis(sample_ttl)
    
    print("\n=== ANALYSIS COMPLETE ===")
    print(f"Analysis ID: {analysis['analysis_id']}")
    print(f"Processing Duration: {analysis['processing_duration_seconds']:.2f} seconds")
    
    print(f"\n=== INFORMATION PRESERVATION ===")
    print(f"Information Preserved: {analysis['input_preservation']['information_preserved']}")
    print(f"Original Size: {analysis['input_preservation']['original_size']} chars")
    print(f"Enhanced Size: {analysis['input_preservation']['enhanced_size']} chars")
    print(f"Preservation Ratio: {analysis['input_preservation']['preservation_ratio']:.2%}")
    
    print(f"\n=== DOMAIN DISCOVERY ===")
    domain_info = analysis['domain_discovery'].get('domain_classification', {})
    print(f"Detected Domain: {domain_info.get('primary_domain', 'unknown')}")
    print(f"Confidence: {domain_info.get('confidence', 0.0):.2%}")
    
    print(f"\n=== OVERALL ASSESSMENT ===")
    overall = analysis['consolidated_insights'].get('overall_assessment', {})
    print(f"Quality Score: {overall.get('quality_score', 0.0):.2%}")
    print(f"Consistency Score: {overall.get('consistency_score', 0.0):.2%}")
    print(f"Summary: {overall.get('summary', 'N/A')}")
    
    print(f"\n=== KEY FINDINGS ===")
    for finding in analysis['consolidated_insights'].get('key_findings', [])[:3]:
        print(f"- {finding.get('finding', 'N/A')}")
    
    print(f"\n=== RECOMMENDATIONS ===")
    for rec in analysis['consolidated_insights'].get('actionable_recommendations', [])[:3]:
        print(f"- {rec.get('recommendation', 'N/A')} (Priority: {rec.get('priority', 'N/A')})")
    
    print("\nGeneral-purpose analysis completed successfully!")
    print("The system adapted to the input without hardcoded assumptions.")

async def demonstrate_file_path_analysis():
    """Demonstrate analysis from file paths"""
    
    # Initialize system using global configuration
    reasoning_system = GeneralPurposeLegalReasoningSystem()
    
    print("=== DEMONSTRATING FILE PATH ANALYSIS ===")
    print(f"Global Configuration:")
    print(f"  Default TTL Directory: {CONFIG.default_ttl_directory}")
    print(f"  Default Output Directory: {CONFIG.default_output_directory}")
    print(f"  Default Pattern: {CONFIG.default_pattern}")
    print(f"  Model: {CONFIG.default_model}")
    
    # Example 1: Analyze single file
    print("\n1. Analyzing single TTL file:")
    print("Usage: analysis = await reasoning_system.analyze_from_path('/path/to/file.ttl')")
    
    # Example 2: Analyze directory
    print("\n2. Analyzing all TTL files in directory:")
    print("Usage: analysis = await reasoning_system.analyze_from_path('/path/to/ttl_directory/')")
    
    # Example 3: Analyze with glob pattern
    print("\n3. Analyzing files matching pattern:")
    print("Usage: analysis = await reasoning_system.analyze_from_pattern('/path/**/*.ttl')")
    print("       analysis = await reasoning_system.analyze_from_pattern('./data/legal_*.ttl')")
    
    # Example 4: Use default configurations
    print("\n4. Using default configurations:")
    print("Usage: analysis = await reasoning_system.analyze_default_directory()")
    print("       analysis = await reasoning_system.analyze_default_pattern()")
    
    # Show sample file structure handling
    print("\n=== FILE STRUCTURE EXAMPLE ===")
    print("Directory structure:")
    print("  /ontologies/")
    print("    ├── legal/")
    print("    │   ├── gdpr.ttl")
    print("    │   ├── sox.ttl")
    print("    │   └── contracts.ttl")
    print("    ├── medical/")
    print("    │   ├── hipaa.ttl")
    print("    │   └── clinical.ttl")
    print("    └── financial/")
    print("        ├── basel.ttl")
    print("        └── mifid.ttl")
    
    print("\nAnalysis commands:")
    print("# Analyze all legal ontologies:")
    print("await reasoning_system.analyze_from_path('/ontologies/legal/')")
    
    print("\n# Analyze specific pattern:")
    print("await reasoning_system.analyze_from_pattern('/ontologies/**/g*.ttl')")
    
    print("\n# Analyze single file:")
    print("await reasoning_system.analyze_from_path('/ontologies/legal/gdpr.ttl')")
    
    print("\n# Use default directory:")
    print("await reasoning_system.analyze_default_directory()")
    
    print("\n=== FILE FEATURES ===")
    print("✓ Automatic TTL file discovery")
    print("✓ Recursive directory scanning")
    print("✓ Multiple file combination")
    print("✓ Prefix deduplication")
    print("✓ File validation and error handling")
    print("✓ Metadata preservation (file size, modification time, etc.)")
    print("✓ Support for .ttl, .turtle, .n3, .nt files")
    print("✓ Glob pattern matching")
    print("✓ Global configuration management")

async def demonstrate_complete_workflow():
    """Demonstrate complete workflow with file analysis"""
    
    # Initialize system using global configuration
    reasoning_system = GeneralPurposeLegalReasoningSystem()
    
    print("=== COMPLETE WORKFLOW DEMONSTRATION ===")
    print(f"Using global configuration:")
    print(f"  Model: {CONFIG.default_model}")
    print(f"  Base URL: {CONFIG.openai_base_url}")
    print(f"  Max Depth: {CONFIG.max_reasoning_depth}")
    print(f"  Breadth: {CONFIG.reasoning_breadth}")
    
    # Create sample TTL files (in practice, these would exist on disk)
    sample_files = {
        "gdpr_basic.ttl": """
        @prefix gdpr: <http://example.org/gdpr/> .
        @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
        @prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
        
        gdpr:Article6 a gdpr:LegalBasis ;
            rdfs:label "Lawfulness of processing" ;
            gdpr:effectiveDate "2018-05-25"^^xsd:date .
        
        gdpr:Consent a gdpr:LegalBasisType ;
            rdfs:label "Consent" ;
            gdpr:definedIn gdpr:Article6 .
        """,
        
        "gdpr_extended.ttl": """
        @prefix gdpr: <http://example.org/gdpr/> .
        @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
        
        gdpr:DataProcessor a gdpr:Role ;
            rdfs:label "Data Processor" ;
            gdpr:hasObligation gdpr:ProcessingAgreement .
        
        gdpr:ProcessingAgreement a gdpr:LegalDocument ;
            rdfs:label "Data Processing Agreement" ;
            gdpr:requiredBy gdpr:Article28 .
        """
    }
    
    print("Sample workflow for multiple TTL files:")
    print(f"Found {len(sample_files)} sample files")
    
    # Combine sample content (simulating file reading)
    combined_content = ""
    for filename, content in sample_files.items():
        combined_content += f"\n# === Content from: {filename} ===\n"
        combined_content += content
        combined_content += f"\n# === End of {filename} ===\n"
    
    print("\nPerforming comprehensive analysis...")
    
    # Perform analysis (using the comprehensive_analysis method directly for demo)
    analysis = await reasoning_system.comprehensive_analysis(combined_content)
    
    print(f"\n=== ANALYSIS RESULTS ===")
    print(f"Analysis ID: {analysis['analysis_id']}")
    print(f"Processing Time: {analysis['processing_duration_seconds']:.2f}s")
    
    # File information (would come from file_source_metadata in real path analysis)
    print(f"\n=== FILE INFORMATION ===")
    print(f"Files processed: {len(sample_files)}")
    print(f"Combined content size: {len(combined_content)} characters")
    
    # Domain discovery
    domain_info = analysis['domain_discovery'].get('domain_classification', {})
    print(f"\n=== DOMAIN DISCOVERY ===")
    print(f"Detected domain: {domain_info.get('primary_domain', 'unknown')}")
    print(f"Confidence: {domain_info.get('confidence', 0.0):.1%}")
    
    # Key insights
    insights = analysis['consolidated_insights']
    print(f"\n=== KEY INSIGHTS ===")
    print(f"Quality score: {insights.get('overall_assessment', {}).get('quality_score', 0.0):.1%}")
    print(f"Consistency score: {insights.get('overall_assessment', {}).get('consistency_score', 0.0):.1%}")
    
    recommendations = insights.get('actionable_recommendations', [])
    if recommendations:
        print(f"\n=== TOP RECOMMENDATIONS ===")
        for i, rec in enumerate(recommendations[:3], 1):
            print(f"{i}. {rec.get('recommendation', 'N/A')} (Priority: {rec.get('priority', 'N/A')})")
    
    print("\n=== WORKFLOW COMPLETE ===")
    print("The system successfully:")
    print("✓ Combined multiple TTL files")
    print("✓ Preserved all original information")
    print("✓ Discovered domain-specific patterns")
    print("✓ Performed adaptive reasoning")
    print("✓ Generated actionable insights")
    print("✓ Used global configuration management")


if __name__ == "__main__":
    print("Enhanced Legal Knowledge Graph Reasoning System")
    print("Now with global configuration support!")
    
    print(f"\n=== CURRENT GLOBAL CONFIGURATION ===")
    print(f"API Base URL: {CONFIG.openai_base_url}")
    print(f"API Key: {'*' * 20 + CONFIG.openai_api_key[-8:] if len(CONFIG.openai_api_key) > 8 else 'NOT_SET'}")
    print(f"Default Model: {CONFIG.default_model}")
    print(f"Default TTL Directory: {CONFIG.default_ttl_directory}")
    print(f"Default Output Directory: {CONFIG.default_output_directory}")
    print(f"Default Pattern: {CONFIG.default_pattern}")
    print(f"Max Reasoning Depth: {CONFIG.max_reasoning_depth}")
    print(f"Reasoning Breadth: {CONFIG.reasoning_breadth}")
    
    if CONFIG.openai_api_key == "your-api-key-here":
        print("\n⚠️  WARNING: Please set your API key in the global configuration!")
        print("   You can either:")
        print("   1. Edit OPENAI_API_KEY at the top of this file")
        print("   2. Set environment variable: export OPENAI_API_KEY=your-key")
        print("   3. Pass it when initializing: GeneralPurposeLegalReasoningSystem(api_key='your-key')")
    
    print("\nChoose demonstration:")
    print("1. General-purpose reasoning (original)")
    print("2. File path analysis features")
    print("3. Complete workflow with multiple files")
    print("4. Configuration management demo")
    
    choice = input("\nEnter choice (1-4): ").strip()
    
    if choice == "1":
        asyncio.run(demonstrate_general_purpose_reasoning())
    elif choice == "2":
        asyncio.run(demonstrate_file_path_analysis())
    elif choice == "3":
        asyncio.run(demonstrate_complete_workflow())
    elif choice == "4":
        asyncio.run(demonstrate_configuration_management())
    else:
        print("Invalid choice. Running all demonstrations...")
        asyncio.run(demonstrate_general_purpose_reasoning())
        print("\n" + "="*50 + "\n")
        asyncio.run(demonstrate_file_path_analysis())
        print("\n" + "="*50 + "\n")
        asyncio.run(demonstrate_complete_workflow())
        print("\n" + "="*50 + "\n")
        asyncio.run(demonstrate_configuration_management())

async def demonstrate_configuration_management():
    """Demonstrate configuration management features"""
    
    print("=== CONFIGURATION MANAGEMENT DEMONSTRATION ===")
    
    print("\n1. Using default global configuration:")
    print("   reasoning_system = GeneralPurposeLegalReasoningSystem()")
    print(f"   # Uses: {CONFIG.default_model} @ {CONFIG.openai_base_url}")
    
    print("\n2. Overriding specific parameters:")
    print("   reasoning_system = GeneralPurposeLegalReasoningSystem(model='gpt-4')")
    print("   # Uses: gpt-4 @ [global base_url] with [global api_key]")
    
    print("\n3. Environment variable support:")
    print("   export OPENAI_API_KEY=your-key")
    print("   export DEFAULT_MODEL=gpt-4")
    print("   export DEFAULT_TTL_DIRECTORY=/my/ttl/files/")
    print("   # These are automatically loaded into CONFIG")
    
    print("\n4. Using default paths:")
    system = GeneralPurposeLegalReasoningSystem()
    print(f"   await system.analyze_default_directory()  # Analyzes: {CONFIG.default_ttl_directory}")
    print(f"   await system.analyze_default_pattern()    # Uses pattern: {CONFIG.default_pattern}")
    
    print("\n5. Configuration validation:")
    try:
        CONFIG.validate()
        print("   ✓ Configuration is valid")
    except Exception as e:
        print(f"   ✗ Configuration error: {e}")
    
    print("\n6. Runtime configuration changes:")
    print("   # You can modify CONFIG at runtime:")
    original_model = CONFIG.default_model
    CONFIG.default_model = "gpt-4-turbo"
    print(f"   CONFIG.default_model = 'gpt-4-turbo'  # Changed from {original_model}")
    
    # Restore original
    CONFIG.default_model = original_model
    print(f"   # Restored to: {CONFIG.default_model}")
    
    print("\n7. Configuration persistence:")
    print("   CONFIG.save_to_file('my_config.json')  # Save current settings")
    print("   CONFIG.load_from_file('my_config.json')  # Load saved settings")
    
    print("\n8. Configuration inspection:")
    print("   print(CONFIG)  # Shows masked API key and all settings")
    print("\nCurrent configuration:")
    print(str(CONFIG))
    
    print("\n=== CONFIGURATION BENEFITS ===")
    print("✓ Single point of configuration")
    print("✓ Environment variable support")
    print("✓ Easy parameter overrides")
    print("✓ Automatic directory creation")
    print("✓ Configuration validation")
    print("✓ Default path methods")
    print("✓ Runtime configuration changes")
    print("✓ Configuration file persistence")
    print("✓ Automatic config loading on startup")
    
    print("\n=== EXAMPLE USAGE PATTERNS ===")
    
    print("\n# Minimal setup - uses all defaults:")
    print("system = GeneralPurposeLegalReasoningSystem()")
    print("analysis = await system.analyze_default_directory()")
    
    print("\n# Custom API but default paths:")
    print("system = GeneralPurposeLegalReasoningSystem(api_key='custom-key')")
    print("analysis = await system.analyze_from_path('/custom/path')")
    
    print("\n# Full customization:")
    print("system = GeneralPurposeLegalReasoningSystem(")
    print("    base_url='https://custom-api.com/v1',")
    print("    api_key='custom-key',")
    print("    model='custom-model'")
    print(")")
    print("analysis = await system.comprehensive_analysis(ttl_content)")
    
    print("\nConfiguration management demonstration complete!")

async def demonstrate_configuration_management():
    """Demonstrate configuration management features"""
    
    print("=== CONFIGURATION MANAGEMENT DEMONSTRATION ===")
    
    print("\n1. Using default global configuration:")
    print("   reasoning_system = GeneralPurposeLegalReasoningSystem()")
    print(f"   # Uses: {CONFIG.default_model} @ {CONFIG.openai_base_url}")
    
    print("\n2. Overriding specific parameters:")
    print("   reasoning_system = GeneralPurposeLegalReasoningSystem(model='gpt-4')")
    print("   # Uses: gpt-4 @ [global base_url] with [global api_key]")
    
    print("\n3. Environment variable support:")
    print("   export OPENAI_API_KEY=your-key")
    print("   export DEFAULT_MODEL=gpt-4")
    print("   export DEFAULT_TTL_DIRECTORY=/my/ttl/files/")
    print("   # These are automatically loaded into CONFIG")
    
    print("\n4. Using default paths:")
    system = GeneralPurposeLegalReasoningSystem()
    print(f"   await system.analyze_default_directory()  # Analyzes: {CONFIG.default_ttl_directory}")
    print(f"   await system.analyze_default_pattern()    # Uses pattern: {CONFIG.default_pattern}")
    
    print("\n5. Configuration validation:")
    try:
        CONFIG.validate()
        print("   ✓ Configuration is valid")
    except Exception as e:
        print(f"   ✗ Configuration error: {e}")
    
    print("\n6. Runtime configuration changes:")
    print("   # You can modify CONFIG at runtime:")
    original_model = CONFIG.default_model
    CONFIG.default_model = "gpt-4-turbo"
    print(f"   CONFIG.default_model = 'gpt-4-turbo'  # Changed from {original_model}")
    
    # Restore original
    CONFIG.default_model = original_model
    print(f"   # Restored to: {CONFIG.default_model}")
    
    print("\n7. Configuration persistence:")
    print("   CONFIG.save_to_file('my_config.json')  # Save current settings")
    print("   CONFIG.load_from_file('my_config.json')  # Load saved settings")
    
    print("\n8. Configuration inspection:")
    print("   print(CONFIG)  # Shows masked API key and all settings")
    print("\nCurrent configuration:")
    print(str(CONFIG))
    
    print("\n=== CONFIGURATION BENEFITS ===")
    print("✓ Single point of configuration")
    print("✓ Environment variable support")
    print("✓ Easy parameter overrides")
    print("✓ Automatic directory creation")
    print("✓ Configuration validation")
    print("✓ Default path methods")
    print("✓ Runtime configuration changes")
    print("✓ Configuration file persistence")
    print("✓ Automatic config loading on startup")
    
    print("\n=== EXAMPLE USAGE PATTERNS ===")
    
    print("\n# Minimal setup - uses all defaults:")
    print("system = GeneralPurposeLegalReasoningSystem()")
    print("analysis = await system.analyze_default_directory()")
    
    print("\n# Custom API but default paths:")
    print("system = GeneralPurposeLegalReasoningSystem(api_key='custom-key')")
    print("analysis = await system.analyze_from_path('/custom/path')")
    
    print("\n# Full customization:")
    print("system = GeneralPurposeLegalReasoningSystem(")
    print("    base_url='https://custom-api.com/v1',")
    print("    api_key='custom-key',")
    print("    model='custom-model'")
    print(")")
    print("analysis = await system.comprehensive_analysis(ttl_content)")
    
    print("\nConfiguration management demonstration complete!")
