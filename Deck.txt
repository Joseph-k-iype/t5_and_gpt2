#!/usr/bin/env python3
"""
Zero Data Loss TTL Merger
Simple, reliable, single-threaded approach that guarantees no data loss
"""

import os
import glob
import sys
import time
from typing import List, Tuple, Optional, Dict
from rdflib import Graph

class ZeroLossTTLMerger:
    def __init__(self, show_progress: bool = True, strict_validation: bool = True):
        self.show_progress = show_progress
        self.strict_validation = strict_validation
        self.merged_graph = Graph()
        self.stats = {
            'files_processed': 0,
            'files_failed': 0,
            'total_triples_loaded': 0,
            'final_unique_triples': 0,
            'duplicates_removed': 0,
            'processing_time': 0,
            'failed_files': [],
            'file_details': []
        }
    
    def _parse_and_merge_file(self, filepath: str) -> Tuple[bool, int, Optional[str]]:
        """
        Parse and immediately merge a single file
        Returns: (success, triples_loaded, error_message)
        """
        try:
            # Track initial state
            initial_count = len(self.merged_graph)
            
            if self.show_progress:
                file_size = os.path.getsize(filepath)
                print(f"üìñ Processing: {os.path.basename(filepath)} ({self._format_size(file_size)})")
            
            # Try multiple encodings to handle different file formats
            encodings_to_try = ['utf-8', 'utf-8-sig', 'latin1', 'cp1252', 'ascii']
            
            parsed_successfully = False
            last_error = None
            
            for encoding in encodings_to_try:
                try:
                    # Parse directly into the merged graph
                    self.merged_graph.parse(filepath, format="turtle", encoding=encoding)
                    parsed_successfully = True
                    break
                except UnicodeDecodeError as e:
                    last_error = f"Encoding {encoding} failed: {e}"
                    continue
                except Exception as e:
                    # Non-encoding error, don't try other encodings
                    last_error = str(e)
                    break
            
            if not parsed_successfully:
                # Final attempt without specifying encoding (auto-detect)
                try:
                    self.merged_graph.parse(filepath, format="turtle")
                    parsed_successfully = True
                except Exception as e:
                    last_error = str(e)
            
            if not parsed_successfully:
                return False, 0, last_error
            
            # Calculate how many triples were added
            final_count = len(self.merged_graph)
            triples_loaded = final_count - initial_count
            
            if self.show_progress:
                print(f"   ‚úÖ Loaded {triples_loaded:,} new triples (graph now has {final_count:,} total)")
            
            # Store detailed info
            self.stats['file_details'].append({
                'filepath': filepath,
                'triples_loaded': triples_loaded,
                'graph_size_after': final_count
            })
            
            return True, triples_loaded, None
            
        except Exception as e:
            return False, 0, f"Unexpected error: {str(e)}"
    
    def _validate_individual_file(self, filepath: str) -> Tuple[bool, int, Optional[str]]:
        """
        Validate a single file can be parsed (without merging)
        Returns: (success, expected_triples, error_message)
        """
        try:
            temp_graph = Graph()
            temp_graph.parse(filepath, format="turtle")
            return True, len(temp_graph), None
        except Exception as e:
            return False, 0, str(e)
    
    def _comprehensive_validation(self, input_files: List[str]) -> Dict:
        """
        Perform comprehensive validation before and after merge
        """
        validation_results = {
            'pre_merge_validation': True,
            'post_merge_validation': True,
            'total_expected_triples': 0,
            'total_unique_triples': len(self.merged_graph),
            'files_validated': 0,
            'validation_errors': [],
            'per_file_expected': {}
        }
        
        if self.show_progress:
            print(f"\nüîç Performing comprehensive validation...")
        
        # Pre-merge validation: check each file individually
        for filepath in input_files:
            if self.show_progress:
                print(f"   üîé Validating: {os.path.basename(filepath)}")
            
            success, expected_triples, error = self._validate_individual_file(filepath)
            
            if success:
                validation_results['files_validated'] += 1
                validation_results['total_expected_triples'] += expected_triples
                validation_results['per_file_expected'][filepath] = expected_triples
                
                if self.show_progress:
                    print(f"      ‚úÖ Expected {expected_triples:,} triples")
            else:
                validation_results['pre_merge_validation'] = False
                validation_results['validation_errors'].append(f"{filepath}: {error}")
                if self.show_progress:
                    print(f"      ‚ùå Validation failed: {error}")
        
        # Post-merge validation
        duplicates_detected = validation_results['total_expected_triples'] - validation_results['total_unique_triples']
        
        if duplicates_detected < 0:
            validation_results['post_merge_validation'] = False
            validation_results['validation_errors'].append(
                f"More triples in output ({validation_results['total_unique_triples']:,}) "
                f"than expected ({validation_results['total_expected_triples']:,})"
            )
        
        return validation_results
    
    def merge_files(self, input_pattern: str, output_file: str, 
                   output_format: str = "turtle") -> bool:
        """
        Merge TTL files with zero data loss guarantee
        """
        start_time = time.time()
        
        if self.show_progress:
            print(f"üõ°Ô∏è  Zero Data Loss TTL Merger")
            print(f"üìÇ Input pattern: {input_pattern}")
            print(f"üìÑ Output file: {output_file}")
            print(f"üìù Output format: {output_format}")
            print()
        
        # Get file list
        ttl_files = glob.glob(input_pattern)
        if not ttl_files:
            print(f"‚ùå No TTL files found matching: {input_pattern}")
            return False
        
        # Filter accessible files
        accessible_files = []
        for filepath in ttl_files:
            if os.path.exists(filepath) and os.access(filepath, os.R_OK):
                accessible_files.append(filepath)
            else:
                if self.show_progress:
                    print(f"‚ö†Ô∏è  Skipping inaccessible: {filepath}")
        
        if not accessible_files:
            print("‚ùå No accessible files found")
            return False
        
        if self.show_progress:
            print(f"üîç Found {len(accessible_files)} accessible TTL files:")
            total_size = 0
            for filepath in accessible_files:
                size = os.path.getsize(filepath)
                total_size += size
                print(f"   üìÑ {os.path.basename(filepath)} ({self._format_size(size)})")
            print(f"üìä Total input size: {self._format_size(total_size)}")
            print()
        
        # Pre-validation if strict mode enabled
        validation_results = None
        if self.strict_validation:
            validation_results = self._comprehensive_validation(accessible_files)
            if not validation_results['pre_merge_validation']:
                print("‚ùå Pre-merge validation failed!")
                for error in validation_results['validation_errors']:
                    print(f"   ‚Ä¢ {error}")
                return False
            
            if self.show_progress:
                print(f"‚úÖ Pre-merge validation passed")
                print(f"   Expected total triples: {validation_results['total_expected_triples']:,}")
                print()
        
        # Process files one by one (SERIAL ONLY - NO THREADING)
        if self.show_progress:
            print(f"üîÑ Processing {len(accessible_files)} files sequentially...")
        
        for i, filepath in enumerate(accessible_files):
            if self.show_progress:
                print(f"\n[{i+1}/{len(accessible_files)}]", end=" ")
            
            success, triples_loaded, error = self._parse_and_merge_file(filepath)
            
            if success:
                self.stats['files_processed'] += 1
                self.stats['total_triples_loaded'] += triples_loaded
            else:
                self.stats['files_failed'] += 1
                self.stats['failed_files'].append((filepath, error))
                if self.show_progress:
                    print(f"   ‚ùå Failed: {error}")
                
                # In strict mode, any failure is unacceptable
                if self.strict_validation:
                    print(f"\n‚ùå STRICT MODE: Aborting due to file processing failure")
                    return False
        
        # Final statistics
        self.stats['final_unique_triples'] = len(self.merged_graph)
        self.stats['duplicates_removed'] = (
            self.stats['total_triples_loaded'] - self.stats['final_unique_triples']
        )
        self.stats['processing_time'] = time.time() - start_time
        
        if self.stats['files_processed'] == 0:
            print("‚ùå No files were successfully processed")
            return False
        
        # Post-merge validation
        if self.strict_validation and validation_results:
            expected = validation_results['total_expected_triples']
            actual = self.stats['final_unique_triples']
            
            if actual + self.stats['duplicates_removed'] != expected:
                print(f"‚ùå POST-MERGE VALIDATION FAILED!")
                print(f"   Expected: {expected:,} total triples")
                print(f"   Got: {actual:,} unique + {self.stats['duplicates_removed']:,} duplicates = {actual + self.stats['duplicates_removed']:,}")
                return False
        
        # Write output
        try:
            if self.show_progress:
                print(f"\nüíæ Writing {len(self.merged_graph):,} unique triples to {output_file}...")
            
            # Serialize with error handling
            self.merged_graph.serialize(destination=output_file, format=output_format)
            
            # Verify the output file was created and has content
            if not os.path.exists(output_file):
                print(f"‚ùå Output file was not created: {output_file}")
                return False
            
            output_size = os.path.getsize(output_file)
            if output_size == 0:
                print(f"‚ùå Output file is empty: {output_file}")
                return False
            
            if self.show_progress:
                self._print_final_stats(output_file)
            
            return True
            
        except Exception as e:
            print(f"‚ùå Error writing output: {e}")
            return False
    
    def _print_final_stats(self, output_file: str):
        """Print comprehensive final statistics"""
        print(f"\nüéâ MERGE COMPLETED SUCCESSFULLY!")
        print(f"=" * 50)
        print(f"üìÅ Output file: {output_file}")
        print(f"üìä Files processed: {self.stats['files_processed']}")
        
        if self.stats['files_failed'] > 0:
            print(f"‚ùå Files failed: {self.stats['files_failed']}")
            for filepath, error in self.stats['failed_files']:
                print(f"   ‚Ä¢ {os.path.basename(filepath)}: {error}")
        
        print(f"üîó Total triples loaded: {self.stats['total_triples_loaded']:,}")
        print(f"‚ú® Unique triples in output: {self.stats['final_unique_triples']:,}")
        
        if self.stats['duplicates_removed'] > 0:
            dup_pct = (self.stats['duplicates_removed'] / self.stats['total_triples_loaded']) * 100
            print(f"üîÑ Duplicates removed: {self.stats['duplicates_removed']:,} ({dup_pct:.1f}%)")
        else:
            print(f"‚úÖ No duplicates found")
        
        print(f"‚è±Ô∏è  Total processing time: {self.stats['processing_time']:.2f}s")
        
        if self.stats['processing_time'] > 0:
            throughput = self.stats['final_unique_triples'] / self.stats['processing_time']
            print(f"üöÄ Average throughput: {throughput:,.0f} triples/second")
        
        # Output file info
        if os.path.exists(output_file):
            size = os.path.getsize(output_file)
            print(f"üìè Output file size: {self._format_size(size)}")
        
        print(f"\n‚úÖ ZERO DATA LOSS GUARANTEED")
        
        # Show per-file breakdown if requested
        if self.show_progress and len(self.stats['file_details']) <= 10:
            print(f"\nüìã Per-file breakdown:")
            for detail in self.stats['file_details']:
                name = os.path.basename(detail['filepath'])
                loaded = detail['triples_loaded']
                print(f"   üìÑ {name}: {loaded:,} triples loaded")
    
    @staticmethod
    def _format_size(size_bytes: int) -> str:
        """Format file size in human readable format"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"

def merge_ttl_zero_loss(input_pattern: str, output_file: str, 
                       output_format: str = "turtle", **kwargs) -> bool:
    """
    Zero data loss TTL merger - simple and bulletproof
    """
    merger = ZeroLossTTLMerger(
        show_progress=kwargs.get('show_progress', True),
        strict_validation=kwargs.get('strict_validation', True)
    )
    
    return merger.merge_files(input_pattern, output_file, output_format)

def main():
    """Main function - simple and reliable"""
    print("üõ°Ô∏è  ZERO DATA LOSS TTL MERGER")
    print("=" * 40)
    print("Simple ‚Ä¢ Reliable ‚Ä¢ Bulletproof")
    print()
    
    # Parse arguments
    if len(sys.argv) < 2 or "--help" in sys.argv:
        print("üí° Usage:")
        print("  python merge_ttl.py [pattern] [output] [format] [options]")
        print("\nOptions:")
        print("  --no-validation    Skip strict validation (faster, less safe)")
        print("  --quiet           Minimal output")
        print("  --help            Show this help")
        print("\nExamples:")
        print("  python merge_ttl.py '*.ttl' merged.ttl")
        print("  python merge_ttl.py 'data/*.ttl' output.ttl turtle")
        print("  python merge_ttl.py '*.ttl' merged.rdf xml")
        print("  python merge_ttl.py '*.ttl' out.ttl --no-validation")
        print("\nüõ°Ô∏è  This version guarantees ZERO data loss by:")
        print("     ‚Ä¢ Single-threaded processing (no race conditions)")
        print("     ‚Ä¢ Comprehensive validation before and after merge")
        print("     ‚Ä¢ Multiple encoding support (UTF-8, Latin1, etc.)")
        print("     ‚Ä¢ Immediate error detection and reporting")
        print("     ‚Ä¢ Strict mode that aborts on any failure")
        return
    
    input_pattern = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "merged.ttl"
    output_format = sys.argv[3] if len(sys.argv) > 3 else "turtle"
    
    # Parse options
    strict_validation = "--no-validation" not in sys.argv
    show_progress = "--quiet" not in sys.argv
    
    # Validate format
    valid_formats = ["turtle", "xml", "n3", "nt", "json-ld", "trig", "trix", "nquads"]
    if output_format not in valid_formats:
        print(f"‚ùå Invalid format: {output_format}")
        print(f"Valid formats: {', '.join(valid_formats)}")
        return
    
    # Check if files exist
    if not glob.glob(input_pattern):
        print(f"‚ùå No files found matching: {input_pattern}")
        return
    
    # Run the merger
    success = merge_ttl_zero_loss(
        input_pattern=input_pattern,
        output_file=output_file,
        output_format=output_format,
        strict_validation=strict_validation,
        show_progress=show_progress
    )
    
    if success:
        print(f"\nüéâ SUCCESS: All data merged with zero loss!")
        sys.exit(0)
    else:
        print(f"\n‚ùå FAILED: Merge could not be completed safely")
        sys.exit(1)

if __name__ == "__main__":
    try:
        import rdflib
        main()
    except ImportError:
        print("‚ùå rdflib required: pip install rdflib")
        sys.exit(1)
