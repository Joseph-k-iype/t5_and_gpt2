#!/usr/bin/env python3
"""
Contextual Case Mapping System using LangChain, LangGraph, and OpenAI o3-mini
Uses ReAct agent pattern for intelligent matching with reasoning and confidence scores.
Updated for LangChain v0.3+ and Pydantic v2
"""

import json
import csv
import os
from typing import Dict, List, Any, Annotated, Literal
from dataclasses import dataclass
from pathlib import Path

# Modern LangChain imports (v0.3+)
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

# Pydantic v2 imports
from pydantic import BaseModel, Field, ConfigDict

# Standard library imports
import logging
from datetime import datetime
import re

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MappingResult:
    """Result structure for case mapping"""
    case_id: str
    case_text: str
    matched_name: str
    confidence_score: float
    reasoning: str
    definition_used: str

class ContextualMapper:
    """Main class for contextual case mapping using LangGraph ReAct agent"""
    
    def __init__(self, openai_api_key: str = None):
        """Initialize the mapper with OpenAI API key"""
        self.api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API key is required. Set OPENAI_API_KEY environment variable or pass it directly.")
        
        # Initialize o3-mini model
        self.llm = ChatOpenAI(
            model="o3-mini",
            api_key=self.api_key,
            temperature=0.1,  # Low temperature for consistent reasoning
            max_tokens=2048
        )
        
        self.names_definitions = {}
        self.cases = []
        self.agent = None
        
    def setup_tools_and_agent(self):
        """Setup tools and create the ReAct agent"""
        if not self.names_definitions:
            raise ValueError("Names and definitions must be loaded before setting up the agent")
        
        # Convert definitions to a formatted string for the tools
        definitions_text = json.dumps(self.names_definitions, indent=2)
        
        @tool
        def analyze_case_similarity(case_text: str) -> str:
            """
            Analyze semantic similarity between a case and all available name-definition pairs.
            Returns analysis of how well the case matches each possible name.
            """
            analysis_results = []
            
            for name, definition in self.names_definitions.items():
                analysis_results.append({
                    'name': name,
                    'definition': definition,
                    'analysis_needed': f"Compare case '{case_text}' with {name}: {definition}"
                })
            
            return json.dumps({
                'case_analyzed': case_text,
                'available_options': analysis_results,
                'instruction': 'Analyze semantic similarity and relevance for each option'
            }, indent=2)
        
        @tool
        def calculate_confidence_and_reasoning(
            case_text: str, 
            analysis_summary: str
        ) -> str:
            """
            Calculate final confidence score and provide detailed reasoning for the best match.
            Takes the case text and analysis summary to determine the most appropriate match.
            """
            return json.dumps({
                'case': case_text,
                'analysis_input': analysis_summary,
                'instruction': 'Provide final decision with confidence score (0.0-1.0) and detailed reasoning',
                'required_format': {
                    'matched_name': 'best_matching_name',
                    'confidence_score': 'float_between_0_and_1',
                    'reasoning': 'detailed_explanation',
                    'definition_used': 'definition_that_led_to_match'
                }
            }, indent=2)
        
        # Create tools list
        tools = [analyze_case_similarity, calculate_confidence_and_reasoning]
        
        # Create system prompt
        system_prompt = f"""You are an expert at contextual matching and semantic analysis. Your task is to match cases to the most appropriate names based on their definitions.

Available names and definitions:
{definitions_text}

Process:
1. Use analyze_case_similarity to understand how the case relates to each name/definition
2. Use calculate_confidence_and_reasoning to make the final decision
3. Provide your final answer in this EXACT JSON format:

{{
    "matched_name": "the_best_matching_name",
    "confidence_score": 0.XX,
    "reasoning": "detailed explanation of why this match was chosen, considering the case content and definition",
    "definition_used": "the exact definition that led to this match"
}}

Be thorough in your analysis and provide clear reasoning for your decisions."""

        # Create the ReAct agent with memory
        memory = MemorySaver()
        
        self.agent = create_react_agent(
            model=self.llm,
            tools=tools,
            checkpointer=memory
        )
        
        logger.info("ReAct agent created successfully with o3-mini model")
    
    def load_json_definitions(self, json_file_path: str) -> None:
        """Load name-definition mappings from JSON file"""
        try:
            with open(json_file_path, 'r', encoding='utf-8') as file:
                data = json.load(file)
                
            # Handle different JSON structures
            if isinstance(data, list):
                # If it's a list of objects with name and definition
                for item in data:
                    if 'name' in item and 'definition' in item:
                        self.names_definitions[item['name']] = item['definition']
            elif isinstance(data, dict):
                # If it's a direct name->definition mapping
                if all(isinstance(v, str) for v in data.values()):
                    self.names_definitions = data
                else:
                    # If it's a dict with name/definition structure
                    for key, value in data.items():
                        if isinstance(value, dict) and 'definition' in value:
                            self.names_definitions[key] = value['definition']
                        elif isinstance(value, str):
                            self.names_definitions[key] = value
            
            logger.info(f"Loaded {len(self.names_definitions)} name-definition pairs")
            
        except FileNotFoundError:
            raise FileNotFoundError(f"JSON file not found: {json_file_path}")
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON format in {json_file_path}: {e}")
    
    def load_csv_cases(self, csv_file_path: str) -> None:
        """Load cases from CSV file"""
        try:
            with open(csv_file_path, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                self.cases = []
                
                for row in reader:
                    if 'id' in row and 'case' in row:
                        self.cases.append({
                            'id': row['id'].strip(),
                            'case': row['case'].strip()
                        })
                
            logger.info(f"Loaded {len(self.cases)} cases from CSV")
            
        except FileNotFoundError:
            raise FileNotFoundError(f"CSV file not found: {csv_file_path}")
        except Exception as e:
            raise ValueError(f"Error reading CSV file {csv_file_path}: {e}")
    
    def match_case_to_name(self, case_id: str, case_text: str) -> MappingResult:
        """Match a single case to the most appropriate name"""
        if not self.agent:
            self.setup_tools_and_agent()
        
        # Create the user message
        user_message = f"""Please analyze and match this case to the most appropriate name:

Case ID: {case_id}
Case Text: "{case_text}"

Use the tools systematically to analyze the case and provide your final decision in the required JSON format."""

        # Configure the conversation
        config = {"configurable": {"thread_id": f"case_{case_id}"}}
        
        try:
            # Invoke the agent
            response = self.agent.invoke(
                {"messages": [HumanMessage(content=user_message)]},
                config
            )
            
            # Extract the final result from the agent's response
            final_message = response["messages"][-1].content
            result_data = self._extract_json_result(final_message)
            
            return MappingResult(
                case_id=case_id,
                case_text=case_text,
                matched_name=result_data.get('matched_name', 'Unknown'),
                confidence_score=float(result_data.get('confidence_score', 0.0)),
                reasoning=result_data.get('reasoning', 'No reasoning provided'),
                definition_used=result_data.get('definition_used', 'No definition found')
            )
            
        except Exception as e:
            logger.error(f"Error processing case {case_id}: {e}")
            return MappingResult(
                case_id=case_id,
                case_text=case_text,
                matched_name='Error',
                confidence_score=0.0,
                reasoning=f'Error during processing: {str(e)}',
                definition_used='N/A'
            )
    
    def _extract_json_result(self, text: str) -> Dict[str, Any]:
        """Extract JSON result from agent response"""
        try:
            # Try to find JSON in the text
            json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
            matches = re.findall(json_pattern, text, re.DOTALL)
            
            for match in matches:
                try:
                    parsed = json.loads(match)
                    if 'matched_name' in parsed and 'confidence_score' in parsed:
                        return parsed
                except json.JSONDecodeError:
                    continue
            
            # Fallback: look for specific patterns in text
            matched_name = self._extract_field(text, 'matched_name')
            confidence = self._extract_field(text, 'confidence_score')
            reasoning = self._extract_field(text, 'reasoning')
            definition = self._extract_field(text, 'definition_used')
            
            return {
                'matched_name': matched_name or 'Unknown',
                'confidence_score': float(confidence) if confidence else 0.5,
                'reasoning': reasoning or 'Could not parse reasoning from response',
                'definition_used': definition or 'N/A'
            }
            
        except Exception as e:
            logger.warning(f"Error extracting JSON result: {e}")
            return {
                'matched_name': 'Parse Error',
                'confidence_score': 0.0,
                'reasoning': 'Failed to parse agent response',
                'definition_used': 'N/A'
            }
    
    def _extract_field(self, text: str, field_name: str) -> str:
        """Extract a specific field from text using patterns"""
        patterns = [
            rf'"{field_name}":\s*"([^"]+)"',
            rf'{field_name}:\s*"([^"]+)"',
            rf'{field_name}:\s*([^\n,}}]+)',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1).strip()
        
        return None
    
    def process_all_cases(self) -> List[MappingResult]:
        """Process all loaded cases and return mapping results"""
        if not self.cases:
            raise ValueError("No cases loaded. Use load_csv_cases() first.")
        
        if not self.names_definitions:
            raise ValueError("No definitions loaded. Use load_json_definitions() first.")
        
        results = []
        total_cases = len(self.cases)
        
        logger.info(f"Processing {total_cases} cases...")
        
        for i, case in enumerate(self.cases, 1):
            logger.info(f"Processing case {i}/{total_cases}: {case['id']}")
            
            result = self.match_case_to_name(case['id'], case['case'])
            results.append(result)
            
            # Log progress
            if i % 5 == 0 or i == total_cases:
                logger.info(f"Completed {i}/{total_cases} cases")
        
        return results
    
    def save_results(self, results: List[MappingResult], output_file: str) -> None:
        """Save mapping results to a JSON file"""
        output_data = []
        
        for result in results:
            output_data.append({
                'case_id': result.case_id,
                'case_text': result.case_text,
                'matched_name': result.matched_name,
                'confidence_score': result.confidence_score,
                'reasoning': result.reasoning,
                'definition_used': result.definition_used,
                'timestamp': datetime.now().isoformat()
            })
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Results saved to {output_file}")
    
    def print_summary(self, results: List[MappingResult]) -> None:
        """Print a summary of the mapping results"""
        if not results:
            print("No results to summarize.")
            return
        
        print("\n" + "="*50)
        print("CONTEXTUAL MAPPING SUMMARY")
        print("="*50)
        
        # Overall statistics
        total_cases = len(results)
        avg_confidence = sum(r.confidence_score for r in results) / total_cases
        high_confidence = sum(1 for r in results if r.confidence_score >= 0.8)
        
        print(f"Total Cases Processed: {total_cases}")
        print(f"Average Confidence: {avg_confidence:.2f}")
        print(f"High Confidence Matches (≥0.8): {high_confidence}")
        print(f"Success Rate: {(high_confidence/total_cases)*100:.1f}%")
        
        # Name distribution
        name_counts = {}
        for result in results:
            name_counts[result.matched_name] = name_counts.get(result.matched_name, 0) + 1
        
        print(f"\nName Distribution:")
        for name, count in sorted(name_counts.items()):
            print(f"  {name}: {count} cases")
        
        # Sample results
        print(f"\nSample Results:")
        for i, result in enumerate(results[:3], 1):
            print(f"\n{i}. Case ID: {result.case_id}")
            print(f"   Case: {result.case_text[:100]}...")
            print(f"   Matched: {result.matched_name}")
            print(f"   Confidence: {result.confidence_score:.2f}")
            print(f"   Reasoning: {result.reasoning[:150]}...")

def main():
    """Main function to run the contextual mapping"""
    # Configuration
    JSON_FILE = "names_definitions.json"  # Update with your JSON file path
    CSV_FILE = "cases.csv"                # Update with your CSV file path
    OUTPUT_FILE = "mapping_results.json"
    
    # Initialize the mapper
    try:
        mapper = ContextualMapper()
        
        # Load data
        print("Loading data files...")
        mapper.load_json_definitions(JSON_FILE)
        mapper.load_csv_cases(CSV_FILE)
        
        # Process cases
        print("Setting up ReAct agent...")
        results = mapper.process_all_cases()
        
        # Save and display results
        mapper.save_results(results, OUTPUT_FILE)
        mapper.print_summary(results)
        
        print(f"\nProcessing complete! Results saved to {OUTPUT_FILE}")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}")
        print(f"Error: {e}")

if __name__ == "__main__":
    main()
