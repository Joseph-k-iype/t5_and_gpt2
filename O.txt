def import_terms_from_csv(self, csv_path: str, batch_size: int = 100) -> int:
        """
        Import business terms from a CSV file.
        
        Args:
            csv_path: Path to the CSV file
            batch_size: Size of batches for adding to ChromaDB
            
        Returns:
            Number of terms imported
        """
        try:
            # First, get all existing terms from the collection
            existing_terms = {}
            try:
                results = self.collection.get(limit=10000)
                if results["ids"]:
                    for i, term_id in enumerate(results["ids"]):
                        name = results["metadatas"][i]["name"]
                        description = results["metadatas"][i]["description"]
                        # Create a key to identify unique terms
                        term_key = f"{name}::{description}"
                        existing_terms[term_key] = term_id
                logger.info(f"Found {len(existing_terms)} existing terms in ChromaDB")
            except Exception as e:
                logger.warning(f"Error getting existing terms: {e}")
                existing_terms = {}
            
            # Read the CSV and track which terms exist in it
            csv_term_keys = set()
            terms_to_add = []
            
            with open(csv_path, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                
                for row in reader:
                    if 'name' not in row or 'description' not in row:
                        logger.warning(f"Skipping row missing required fields: {row}")
                        continue
                    
                    name = row['name'].strip()
                    description = row['description'].strip()
                    term_key = f"{name}::{description}"
                    csv_term_keys.add(term_key)
                    
                    # If this term already exists in ChromaDB, skip it
                    if term_key in existing_terms:
                        continue
                    
                    # Add new term to our list to process
                    term_id = str(uuid.uuid4())
                    terms_to_add.append({
                        "id": term_id,
                        "name": name,
                        "description": description,
                        "term_key": term_key
                    })
            
            # Process new terms in batches
            added_count = 0
            for i in range(0, len(terms_to_add), batch_size):
                batch = terms_to_add[i:i+batch_size]
                
                # Process this batch
                ids = []
                embeddings = []
                metadatas = []
                documents = []
                
                for term in batch:
                    # Create document for embedding
                    doc = MyDocument(
                        id=term["id"],
                        text=f"{term['name']}. {term['description']}"
                    )
                    
                    # Generate embedding
                    doc_with_embedding = self.embedding_client.generate_embeddings(doc)
                    
                    if not doc_with_embedding.embedding:
                        logger.warning(f"Could not generate embedding for term: {term['name']}. Skipping.")
                        continue
                    
                    # Add to lists for batch addition
                    ids.append(term["id"])
                    embeddings.append(doc_with_embedding.embedding)
                    metadatas.append({
                        "name": term["name"],
                        "description": term["description"]
                    })
                    documents.append(f"{term['name']}. {term['description']}")
                
                # Add batch to ChromaDB
                if ids:
                    self.collection.add(
                        ids=ids,
                        embeddings=embeddings,
                        metadatas=metadatas,
                        documents=documents
                    )
                    added_count += len(ids)
                    logger.info(f"Added batch of {len(ids)} terms to ChromaDB")
            
            # Find terms to delete (in ChromaDB but not in CSV)
            terms_to_delete = []
            for term_key, term_id in existing_terms.items():
                if term_key not in csv_term_keys:
                    terms_to_delete.append(term_id)
            
            # Delete terms in batches
            deleted_count = 0
            for i in range(0, len(terms_to_delete), batch_size):
                batch = terms_to_delete[i:i+batch_size]
                self.collection.delete(ids=batch)
                deleted_count += len(batch)
                logger.info(f"Deleted batch of {len(batch)} terms from ChromaDB")
            
            logger.info(f"Import complete: Added {added_count} new terms, deleted {deleted_count} terms")
            return added_count
            
        except Exception as e:
            logger.error(f"Error importing terms from CSV: {e}")
            raise
