"""
Application Settings - Configuration settings and utilities for the API.

This module provides functions to retrieve and manage application settings, 
including language model configuration, vector database selection, and other
global settings.
"""

import logging
import os
from typing import Optional, Union, Dict, Any, TYPE_CHECKING
from langchain_openai import AzureChatOpenAI
from azure.identity import get_bearer_token_provider
from app.config.environment import get_os_env

# TYPE_CHECKING is used to avoid circular imports during type checking
if TYPE_CHECKING:
    from app.core.vector_store import VectorStore

logger = logging.getLogger(__name__)

def get_vector_db_type() -> str:
    """
    Get the vector database type from environment settings.
    
    Returns:
        str: Vector database type (e.g., "chroma", "postgresql")
    """
    env = get_os_env()
    return env.get("VECTOR_DB_TYPE", "chroma").lower()  # Default to 'chroma' instead of 'postgresql'

def get_vector_store(vector_db_type: Optional[str] = None) -> 'VectorStore':
    """
    Get the vector store implementation based on settings.
    
    Args:
        vector_db_type: Override the vector database type from environment
    
    Returns:
        VectorStore: The vector store implementation
    """
    from app.core.vector_store import VectorStore
    
    # Get type from parameter or environment
    if vector_db_type is None:
        vector_db_type = get_vector_db_type()
    
    if vector_db_type in ["chroma", "chromadb"]:
        from app.core.vector_store_chroma import ChromaDBVectorStore
        persist_dir = os.environ.get("CHROMA_PERSIST_DIR", "./data/chroma_db")
        collection_name = os.environ.get("CHROMA_COLLECTION", "business_terms")
        logger.info(f"Using ChromaDB as vector store with collection '{collection_name}' in '{persist_dir}'")
        return ChromaDBVectorStore(collection_name=collection_name, persist_dir=persist_dir)
    else:
        # Use PostgreSQL if requested
        from app.core.vector_store_pg import PostgreSQLVectorStore
        logger.info("Using PostgreSQL with pgvector as vector store")
        return PostgreSQLVectorStore()

def get_llm(proxy_enabled: Optional[bool] = None) -> AzureChatOpenAI:
    """
    Get the language model for the application.
    
    Args:
        proxy_enabled: Override the PROXY_ENABLED setting in the config file
    
    Returns:
        AzureChatOpenAI: The language model
    """
    # Get environment with proxy setting override if provided
    env = get_os_env(proxy_enabled=proxy_enabled)
    
    logger.info(f"Setting up Azure OpenAI client with proxy enabled: {env.get('PROXY_ENABLED', 'False')}")
    
    # Get token provider for Azure AD auth
    token_provider = get_bearer_token_provider(
        env.credential,
        "https://cognitiveservices.azure.com/.default"
    )
    
    # Get model configuration
    model_name = env.get("MODEL_NAME", "gpt-4o")
    temperature = float(env.get("TEMPERATURE", "0.3"))  # Lower temperature for more deterministic outputs
    max_tokens = int(env.get("MAX_TOKENS", "2000"))
    api_version = env.get("API_VERSION", "2023-05-15")
    azure_endpoint = env.get("AZURE_ENDPOINT", "")
    
    logger.info(f"Using model: {model_name}, temperature: {temperature}, max_tokens: {max_tokens}")
    
    # Create and return the LLM
    return AzureChatOpenAI(
        model_name=model_name,
        temperature=temperature,
        max_tokens=max_tokens,
        api_version=api_version,
        azure_endpoint=azure_endpoint,
        azure_ad_token_provider=token_provider
    )

def get_app_settings() -> Dict[str, Any]:
    """
    Get all application settings.
    
    Returns:
        Dict[str, Any]: Dictionary containing all application settings
    """
    env = get_os_env()
    
    # Vector database settings
    vector_db_type = get_vector_db_type()
    vector_db_settings = {
        "type": vector_db_type
    }
    
    if vector_db_type in ["chroma", "chromadb"]:
        vector_db_settings.update({
            "persist_dir": env.get("CHROMA_PERSIST_DIR", "./data/chroma_db"),
            "collection": env.get("CHROMA_COLLECTION", "business_terms")
        })
    
    # PostgreSQL settings
    pg_settings = {
        "host": env.get("PG_HOST", "localhost"),
        "port": int(env.get("PG_PORT", "5432")),
        "database": env.get("PG_DB", "metadata_db"),
        "user": env.get("PG_USER", "postgres"),
        "schema": env.get("PG_SCHEMA", "ai_stitching_platform"),
        "min_connections": int(env.get("PG_MIN_CONNECTIONS", "2")),
        "max_connections": int(env.get("PG_MAX_CONNECTIONS", "10"))
    }
    
    # OpenAI model settings
    model_settings = {
        "model": env.get("MODEL_NAME", "gpt-4o"),
        "temperature": float(env.get("TEMPERATURE", "0.3")),
        "max_tokens": int(env.get("MAX_TOKENS", "2000")),
        "api_version": env.get("API_VERSION", "2023-05-15"),
        "azure_endpoint": env.get("AZURE_ENDPOINT", "")
    }
    
    # Proxy settings
    proxy_settings = {
        "enabled": env.get("PROXY_ENABLED", "False").lower() in ("true", "t", "1", "yes", "y"),
        "domain": env.get("HTTPS_PROXY_DOMAIN", "")
    }
    
    # General settings
    general_settings = {
        "similarity_threshold": float(env.get("SIMILARITY_THRESHOLD", "0.5")),
        "monitoring_interval": int(env.get("MONITORING_INTERVAL", "300")),
        "secured_endpoints": env.get("SECURED_ENDPOINTS", "False").lower() in ("true", "t", "1", "yes", "y")
    }
    
    return {
        "version": "1.0.0",
        "vector_database": vector_db_settings,
        "postgresql": pg_settings,
        "model": model_settings,
        "proxy": proxy_settings,
        "general": general_settings
    }
