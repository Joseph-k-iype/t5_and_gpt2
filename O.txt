import os
import sys
import uuid
import json
import logging
import chardet
import pandas as pd
import networkx as nx
import numpy as np
from typing import Optional, Any, Dict, List, Union, Tuple, Callable
from pathlib import Path
from datetime import datetime
from functools import partial

# Add LangGraph and additional imports
from langgraph.graph import StateGraph, END
# Updated imports for LangGraph - removing problematic tools import
from langgraph.prebuilt import ToolNode
import chromadb
from chromadb.config import Settings
# Import OpenAIEmbeddingFunction for ChromaDB 0.5.3
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
from tqdm import tqdm

# Class for handling CSV data and preprocessing
class CSVDataProcessor:
    def __init__(self, first_csv_path: str, second_csv_path: str):
        """
        Initialize the CSVDataProcessor with paths to both CSV files.
        
        Args:
            first_csv_path: Path to the first CSV file (name, definition, owned by)
            second_csv_path: Path to the second CSV file (code, taxonomy path 1, taxonomy path 2, parent, name, description, record examples)
        """
        self.first_csv_path = first_csv_path
        self.second_csv_path = second_csv_path
        self.first_df = None
        self.second_df = None
        
    def _detect_encoding(self, file_path: str) -> str:
        """Detect the encoding of a file."""
        with open(file_path, 'rb') as f:
            result = chardet.detect(f.read())
        return result['encoding']
    
    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Load both CSV files with proper encoding detection."""
        try:
            first_encoding = self._detect_encoding(self.first_csv_path)
            second_encoding = self._detect_encoding(self.second_csv_path)
            
            self.first_df = pd.read_csv(self.first_csv_path, encoding=first_encoding)
            self.second_df = pd.read_csv(self.second_csv_path, encoding=second_encoding)
            
            logger.info(f"First CSV loaded with {len(self.first_df)} rows")
            logger.info(f"Second CSV loaded with {len(self.second_df)} rows")
            
            return self.first_df, self.second_df
        except Exception as e:
            logger.error(f"Error loading CSV files: {e}")
            raise
    
    def preprocess_dataframes(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Preprocess dataframes by cleaning text and handling missing values."""
        if self.first_df is None or self.second_df is None:
            self.load_data()
        
        # Clean column names
        self.first_df.columns = [col.strip().lower() for col in self.first_df.columns]
        self.second_df.columns = [col.strip().lower() for col in self.second_df.columns]
        
        # Fill missing values
        self.first_df = self.first_df.fillna('')
        self.second_df = self.second_df.fillna('')
        
        # Ensure required columns exist
        required_cols_first = ['name', 'definition', 'owned by']
        required_cols_second = ['code', 'taxonomy path 1', 'taxonomy path 2', 'parent', 'name', 'description', 'record examples']
        
        for col in required_cols_first:
            if col not in self.first_df.columns:
                self.first_df[col] = ''
        
        for col in required_cols_second:
            if col not in self.second_df.columns:
                self.second_df[col] = ''
        
        return self.first_df, self.second_df
    
    def create_context_enriched_names(self) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        Create context-enriched documents for both datasets to improve semantic matching.
        Returns lists of document dictionaries for both datasets.
        """
        if self.first_df is None or self.second_df is None:
            self.preprocess_dataframes()
        
        first_documents = []
        second_documents = []
        
        # Create documents for the first dataset
        for idx, row in self.first_df.iterrows():
            doc_id = f"first_{idx}"
            text = f"Name: {row['name']}\nDefinition: {row['definition']}\nOwned by: {row['owned by']}"
            metadata = {
                "source": "first_csv",
                "name": row['name'],
                "definition": row['definition'],
                "owned_by": row['owned by'],
                "original_index": idx
            }
            first_documents.append({
                "id": doc_id,
                "text": text,
                "metadata": metadata
            })
        
        # Create documents for the second dataset with rich context
        for idx, row in self.second_df.iterrows():
            doc_id = f"second_{idx}"
            text = f"Name: {row['name']}\nCode: {row['code']}\nTaxonomy Path 1: {row['taxonomy path 1']}\n"
            text += f"Taxonomy Path 2: {row['taxonomy path 2']}\nParent: {row['parent']}\n"
            text += f"Description: {row['description']}\nRecord Examples: {row['record examples']}"
            
            metadata = {
                "source": "second_csv",
                "name": row['name'],
                "code": row['code'],
                "taxonomy_path_1": row['taxonomy path 1'],
                "taxonomy_path_2": row['taxonomy path 2'],
                "parent": row['parent'],
                "description": row['description'],
                "record_examples": row['record examples'],
                "original_index": idx
            }
            second_documents.append({
                "id": doc_id,
                "text": text,
                "metadata": metadata
            })
        
        return first_documents, second_documents

# Extended VectorDB class using ChromaDB with SQLite persistence
class VectorDB:
    def __init__(self, persist_directory: str = "./chroma_db", embedding_client: Optional[Any] = None):
        """
        Initialize the VectorDB with ChromaDB using SQLite persistence.
        
        Args:
            persist_directory: Directory to persist vectors
            embedding_client: EmbeddingClient instance for generating embeddings
        """
        self.persist_directory = persist_directory
        self.embedding_client = embedding_client
        self.client = self._setup_chroma_client()
        self.collections = {}
        self.embedding_function = None
        if embedding_client:
            self._setup_embedding_function()
    
    def _setup_embedding_function(self):
        """Set up an embedding function adapter for ChromaDB 0.5.3."""
        # Custom embedding function that uses our embedding client
        class CustomEmbeddingFunction:
            def __init__(self, embedding_client):
                self.embedding_client = embedding_client
            
            def __call__(self, texts):
                embeddings = []
                for text in texts:
                    doc = MyDocument(id="temp", text=text)
                    embedded_doc = self.embedding_client.generate_embeddings(doc)
                    embeddings.append(embedded_doc.embedding)
                return embeddings
        
        self.embedding_function = CustomEmbeddingFunction(self.embedding_client)
        
    def _setup_chroma_client(self):
        """Set up ChromaDB client with SQLite persistence and telemetry disabled."""
        try:
            # Create directory if it doesn't exist
            os.makedirs(self.persist_directory, exist_ok=True)
            
            # Initialize ChromaDB with persistence and telemetry disabled (for version 0.5.3)
            client = chromadb.PersistentClient(
                path=self.persist_directory,
                settings=Settings(anonymized_telemetry=False)
            )
            
            logger.info(f"ChromaDB initialized with persistence at {self.persist_directory}")
            return client
        except Exception as e:
            logger.error(f"Error setting up ChromaDB: {e}")
            raise
        except Exception as e:
            logger.error(f"Error setting up ChromaDB: {e}")
            raise
    
    def get_or_create_collection(self, collection_name: str):
        """Get an existing collection or create a new one."""
        try:
            if collection_name in self.collections:
                return self.collections[collection_name]
            
            # Check if collection exists
            try:
                # For ChromaDB 0.5.3, we need to use get_collection with the embedding function
                if self.embedding_function:
                    collection = self.client.get_or_create_collection(
                        name=collection_name,
                        embedding_function=self.embedding_function
                    )
                else:
                    collection = self.client.get_or_create_collection(name=collection_name)
                
                logger.info(f"Retrieved or created collection: {collection_name}")
            except Exception as e:
                logger.error(f"Error with collection {collection_name}: {e}")
                raise
            
            self.collections[collection_name] = collection
            return collection
        except Exception as e:
            logger.error(f"Error getting or creating collection {collection_name}: {e}")
            raise
    
    def add_documents(self, documents: List[Dict[str, Any]], collection_name: str):
        """
        Add documents to a ChromaDB collection.
        
        Args:
            documents: List of document dictionaries (id, text, metadata)
            collection_name: Name of the collection to add documents to
        """
        try:
            collection = self.get_or_create_collection(collection_name)
            
            # Get existing IDs to avoid duplicates (compatible with ChromaDB 0.5.3)
            existing_ids = []
            if collection.count() > 0:
                try:
                    existing_ids = collection.get(include=[])["ids"]
                except Exception as e:
                    logger.warning(f"Error getting existing IDs, proceeding anyway: {e}")
            
            new_docs = [doc for doc in documents if doc["id"] not in existing_ids]
            
            if not new_docs:
                logger.info(f"No new documents to add to collection {collection_name}")
                return
            
            # Prepare document batches
            doc_ids = [doc["id"] for doc in new_docs]
            doc_texts = [doc["text"] for doc in new_docs]
            doc_metadatas = [doc["metadata"] for doc in new_docs]
            
            # Add documents to collection - ChromaDB 0.5.3 handles embeddings through the embedding function
            logger.info(f"Adding {len(new_docs)} documents to collection {collection_name}")
            
            # Process in batches to prevent memory issues with large datasets
            batch_size = 100
            for i in tqdm(range(0, len(new_docs), batch_size), desc=f"Adding documents to {collection_name}"):
                batch_end = min(i + batch_size, len(new_docs))
                collection.add(
                    ids=doc_ids[i:batch_end],
                    documents=doc_texts[i:batch_end],
                    metadatas=doc_metadatas[i:batch_end]
                )
            
            logger.info(f"Added {len(new_docs)} documents to collection {collection_name}")
            
        except Exception as e:
            logger.error(f"Error adding documents to collection {collection_name}: {e}")
            raise
    
    def query_similar(self, query_text: str, collection_name: str, n_results: int = 5, where: Optional[Dict[str, Any]] = None):
        """
        Query for similar documents in a collection.
        
        Args:
            query_text: Text to find similar documents for
            collection_name: Name of the collection to query
            n_results: Number of results to return
            where: Optional filter criteria
            
        Returns:
            Query results
        """
        try:
            collection = self.get_or_create_collection(collection_name)
            
            # In ChromaDB 0.5.3, the embedding_function in the collection handles embedding
            # We can directly query with text
            results = collection.query(
                query_texts=[query_text],
                n_results=n_results,
                where=where
            )
            
            return results
        except Exception as e:
            logger.error(f"Error querying collection {collection_name}: {e}")
            raise

# Semantic Name Mapper that uses the vector DB and embedding client
class SemanticNameMapper:
    def __init__(self, vector_db: VectorDB, embedding_client: Optional[Any] = None):
        """
        Initialize the Semantic Name Mapper.
        
        Args:
            vector_db: VectorDB instance for storing and querying vectors
            embedding_client: Optional embedding client for generating embeddings
        """
        self.vector_db = vector_db
        self.embedding_client = embedding_client
        self.first_collection_name = "first_csv_data"
        self.second_collection_name = "second_csv_data"
        
    def load_and_index_data(self, csv_processor: CSVDataProcessor):
        """
        Load data from CSV files and index them in the vector database.
        
        Args:
            csv_processor: CSVDataProcessor instance with loaded data
        """
        try:
            # Get context-enriched documents for both datasets
            first_documents, second_documents = csv_processor.create_context_enriched_names()
            
            # Add documents to their respective collections
            logger.info("Indexing first CSV data...")
            self.vector_db.add_documents(first_documents, self.first_collection_name)
            
            logger.info("Indexing second CSV data...")
            self.vector_db.add_documents(second_documents, self.second_collection_name)
            
            logger.info("Data indexing complete")
        except Exception as e:
            logger.error(f"Error loading and indexing data: {e}")
            raise
    
    def find_best_match(self, second_csv_name: str, context: str = "", n_results: int = 5) -> Dict[str, Any]:
        """
        Find the best match in the first CSV for a name from the second CSV.
        
        Args:
            second_csv_name: Name from the second CSV to find matches for
            context: Additional context to improve matching
            n_results: Number of results to return
            
        Returns:
            Dictionary with match results and scores
        """
        try:
            # Create a rich query text including the name and context
            query_text = f"Name: {second_csv_name}"
            if context:
                query_text += f"\nContext: {context}"
            
            # Query for similar names in the first collection
            results = self.vector_db.query_similar(
                query_text=query_text,
                collection_name=self.first_collection_name,
                n_results=n_results
            )
            
            # Process and format results
            matches = []
            for i in range(len(results["ids"][0])):
                match = {
                    "id": results["ids"][0][i],
                    "name": results["metadatas"][0][i]["name"],
                    "definition": results["metadatas"][0][i]["definition"],
                    "owned_by": results["metadatas"][0][i]["owned_by"],
                    "original_index": results["metadatas"][0][i]["original_index"],
                    "distance": results["distances"][0][i] if "distances" in results else None,
                    "similarity": 1 - (results["distances"][0][i] / 2) if "distances" in results else None  # Convert distance to similarity score
                }
                matches.append(match)
            
            return {
                "query": second_csv_name,
                "query_with_context": query_text,
                "matches": matches
            }
        except Exception as e:
            logger.error(f"Error finding best match for {second_csv_name}: {e}")
            raise

# LangGraph agent for name matching evaluation and suggestions
class NameMatchingAgent:
    def __init__(self, azure_chatbot: AzureChatbot, confidence_threshold: float = 0.75):
        """
        Initialize the Name Matching Agent.
        
        Args:
            azure_chatbot: AzureChatbot instance for LLM access
            confidence_threshold: Threshold for considering a match good quality
        """
        self.azure_chatbot = azure_chatbot
        self.confidence_threshold = confidence_threshold
        self.graph = self._create_agent_graph()
    
    def _create_agent_graph(self):
        """Create the LangGraph for the name matching workflow."""
        try:
            # Define state type
            class AgentState(dict):
                """State for the name matching agent graph."""
                source_name: str
                target_matches: List[Dict[str, Any]]
                best_match: Optional[Dict[str, Any]] = None
                confidence_score: Optional[float] = None
                suggestion: Optional[str] = None
                
            # Define the nodes in our graph
            def evaluate_match_quality(state):
                """Evaluate the quality of the best match and assign a confidence score."""
                source_name = state["source_name"]
                matches = state["target_matches"]
                
                if not matches:
                    return {
                        "best_match": None,
                        "confidence_score": 0.0,
                        "suggestion": None
                    }
                
                best_match = matches[0]
                
                # Create a prompt for the LLM to evaluate the match
                prompt = f"""
                Evaluate the quality of this semantic name match and provide a confidence score between 0 and 1:
                
                Source name: {source_name}
                Target match: {best_match['name']}
                
                Source definition/context: {state.get('source_context', 'No context provided')}
                Target definition: {best_match['definition']}
                
                Based on semantic meaning, how confident are you that these names refer to the same concept?
                Provide your response as a JSON with the following structure:
                {{
                    "confidence_score": [score between 0 and 1],
                    "reasoning": "[your detailed reasoning]"
                }}
                """
                
                # Get evaluation from LLM
                response = self.azure_chatbot.conversation.run(prompt)
                
                # Parse the JSON response
                try:
                    # Extract JSON from the response
                    json_str = response.strip()
                    if "```json" in json_str:
                        json_str = json_str.split("```json")[1].split("```")[0].strip()
                    elif "```" in json_str:
                        json_str = json_str.split("```")[1].split("```")[0].strip()
                    
                    evaluation = json.loads(json_str)
                    confidence_score = float(evaluation["confidence_score"])
                    
                    return {
                        "best_match": best_match,
                        "confidence_score": confidence_score,
                        "reasoning": evaluation.get("reasoning", "")
                    }
                except Exception as e:
                    logger.error(f"Error parsing LLM response: {e}")
                    # Default to using similarity score if parsing fails
                    confidence_score = best_match.get("similarity", 0.5)
                    return {
                        "best_match": best_match,
                        "confidence_score": confidence_score,
                        "reasoning": f"Failed to parse LLM response, using similarity score instead: {confidence_score}"
                    }
            
            def suggest_better_name(state):
                """Suggest a better name if the match quality is poor."""
                confidence_score = state["confidence_score"]
                source_name = state["source_name"]
                best_match = state["best_match"]
                
                if confidence_score >= self.confidence_threshold or not best_match:
                    # No need for suggestion if confidence is high enough
                    return {"suggestion": None}
                
                # Create a prompt for the LLM to suggest a better name
                prompt = f"""
                The current match for "{source_name}" is "{best_match['name']}" with a confidence score of {confidence_score}.
                This score is below the threshold of {self.confidence_threshold}.
                
                Source context: {state.get('source_context', 'No context provided')}
                Target definition: {best_match['definition']}
                
                Please suggest a better name from the first dataset that would be a more accurate match.
                If you cannot think of a better name, suggest how the current names could be standardized or harmonized.
                
                Provide your response as a JSON with the following structure:
                {{
                    "suggestion": "[your suggested name or standardization approach]",
                    "explanation": "[your detailed explanation]"
                }}
                """
                
                # Get suggestion from LLM
                response = self.azure_chatbot.conversation.run(prompt)
                
                # Parse the JSON response
                try:
                    # Extract JSON from the response
                    json_str = response.strip()
                    if "```json" in json_str:
                        json_str = json_str.split("```json")[1].split("```")[0].strip()
                    elif "```" in json_str:
                        json_str = json_str.split("```")[1].split("```")[0].strip()
                    
                    suggestion_data = json.loads(json_str)
                    return {
                        "suggestion": suggestion_data["suggestion"],
                        "explanation": suggestion_data.get("explanation", "")
                    }
                except Exception as e:
                    logger.error(f"Error parsing LLM suggestion: {e}")
                    return {
                        "suggestion": "Error generating suggestion",
                        "explanation": f"Failed to parse LLM response: {str(e)}"
                    }
            
            def router(state):
                """Route to the next node based on confidence score."""
                confidence_score = state["confidence_score"]
                
                if confidence_score is None:
                    return "evaluate_match"
                elif confidence_score < self.confidence_threshold:
                    return "suggest_better_name"
                else:
                    return END
            
            # Create the graph
            workflow = StateGraph(AgentState)
            
            # Add nodes
            workflow.add_node("evaluate_match", evaluate_match_quality)
            workflow.add_node("suggest_better_name", suggest_better_name)
            
            # Set the entry point
            workflow.set_entry_point("evaluate_match")
            
            # Add edges
            workflow.add_conditional_edges("evaluate_match", router)
            workflow.add_edge("suggest_better_name", END)
            
            # Compile the graph
            return workflow.compile()
        
        except Exception as e:
            logger.error(f"Error creating agent graph: {e}")
            raise
    
    def evaluate_match(self, source_name: str, source_context: str, target_matches: List[Dict[str, Any]]):
        """
        Evaluate the quality of name matches and suggest improvements if needed.
        
        Args:
            source_name: Name from the second CSV
            source_context: Context for the name from the second CSV
            target_matches: List of potential matches from the first CSV
            
        Returns:
            Evaluation results including confidence score and suggestions
        """
        try:
            # Initialize the state
            initial_state = {
                "source_name": source_name,
                "source_context": source_context,
                "target_matches": target_matches,
                "best_match": None,
                "confidence_score": None,
                "suggestion": None
            }
            
            # Run the graph
            result = self.graph.invoke(initial_state)
            
            return {
                "source_name": source_name,
                "best_match": result["best_match"],
                "confidence_score": result["confidence_score"],
                "suggestion": result.get("suggestion"),
                "explanation": result.get("explanation", ""),
                "reasoning": result.get("reasoning", "")
            }
        except Exception as e:
            logger.error(f"Error evaluating match for {source_name}: {e}")
            raise

# Main function to run the semantic name mapping
def run_semantic_name_mapping(first_csv_path: str, second_csv_path: str, config_file: str, creds_file: str, cert_file: str, persist_dir: str = "./chroma_db"):
    """
    Run the semantic name mapping process.
    
    Args:
        first_csv_path: Path to the first CSV file (name, definition, owned by)
        second_csv_path: Path to the second CSV file with taxonomy data
        config_file: Path to the config file
        creds_file: Path to the credentials file
        cert_file: Path to the certificate file
        persist_dir: Directory to persist vector database
    """
    try:
        # Setup environment
        env = OSEnv(config_file, creds_file, cert_file)
        
        # Initialize embedding client
        embedding_client = EmbeddingClient(
            azure_api_version=env.get("AZURE_API_VERSION", "2023-05-15"),
            embeddings_model=env.get("EMBEDDINGS_MODEL", "text-embedding-3-large")
        )
        
        # Initialize vector database with embedding client
        vector_db = VectorDB(persist_directory=persist_dir, embedding_client=embedding_client)
        
        # Initialize CSV processor
        csv_processor = CSVDataProcessor(first_csv_path, second_csv_path)
        csv_processor.load_data()
        csv_processor.preprocess_dataframes()
        
        # Initialize semantic name mapper
        name_mapper = SemanticNameMapper(vector_db, embedding_client)
        name_mapper.load_and_index_data(csv_processor)
        
        # Initialize Azure chatbot for the agent
        azure_chatbot = AzureChatbot(config_file, creds_file, cert_file)
        
        # Initialize name matching agent
        agent = NameMatchingAgent(azure_chatbot)
        
        # Process each name in the second CSV
        results = []
        logger.info("Starting semantic name mapping...")
        
        # Process the items, but handle errors for individual items gracefully
        for idx, row in tqdm(csv_processor.second_df.iterrows(), total=len(csv_processor.second_df), desc="Mapping names"):
            try:
                # Get name and context from second CSV
                name = row['name']
                context = f"Code: {row['code']}, Taxonomy Path 1: {row['taxonomy path 1']}, Taxonomy Path 2: {row['taxonomy path 2']}, "
                context += f"Parent: {row['parent']}, Description: {row['description']}, Record Examples: {row['record examples']}"
                
                # Find potential matches
                match_results = name_mapper.find_best_match(name, context)
                
                # Evaluate matches with the agent
                evaluation = agent.evaluate_match(name, context, match_results["matches"])
                
                # Store results
                result = {
                    "second_csv_index": idx,
                    "second_csv_name": name,
                    "context": context,
                    "best_match_name": evaluation["best_match"]["name"] if evaluation["best_match"] else None,
                    "best_match_index": evaluation["best_match"]["original_index"] if evaluation["best_match"] else None,
                    "confidence_score": evaluation["confidence_score"],
                    "suggestion": evaluation["suggestion"],
                    "explanation": evaluation["explanation"],
                    "reasoning": evaluation["reasoning"]
                }
                results.append(result)
            except Exception as e:
                logger.error(f"Error processing row {idx} ({name}): {e}")
                # Add a placeholder result for failed items
                results.append({
                    "second_csv_index": idx,
                    "second_csv_name": name,
                    "error": str(e),
                    "confidence_score": 0.0,
                    "best_match_name": None,
                    "best_match_index": None
                })
        
        # Save results to CSV
        results_df = pd.DataFrame(results)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_df.to_csv(f"name_mapping_results_{timestamp}.csv", index=False)
        
        # Print summary
        good_matches = results_df[results_df['confidence_score'] >= agent.confidence_threshold]
        logger.info(f"Completed semantic name mapping with {len(results_df)} names")
        logger.info(f"Good matches: {len(good_matches)} ({len(good_matches)/len(results_df)*100:.2f}%)")
        logger.info(f"Results saved to name_mapping_results_{timestamp}.csv")
        
        return results_df
    
    except Exception as e:
        logger.error(f"Error running semantic name mapping: {e}")
        raise

# Command-line interface
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Semantic name mapping between two CSV files")
    parser.add_argument("--first-csv", required=True, help="Path to the first CSV file (name, definition, owned by)")
    parser.add_argument("--second-csv", required=True, help="Path to the second CSV file with taxonomy data")
    parser.add_argument("--config", default=CONFIG_PATH, help="Path to the config file")
    parser.add_argument("--creds", default=CREDS_PATH, help="Path to the credentials file")
    parser.add_argument("--cert", default=CERT_PATH, help="Path to the certificate file")
    parser.add_argument("--persist-dir", default="./chroma_db", help="Directory to persist vector database")
    
    args = parser.parse_args()
    
    run_semantic_name_mapping(
        first_csv_path=args.first_csv,
        second_csv_path=args.second_csv,
        config_file=args.config,
        creds_file=args.creds,
        cert_file=args.cert,
        persist_dir=args.persist_dir
    )
