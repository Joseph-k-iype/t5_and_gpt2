"""
Tagging Workflow - LangGraph workflow for matching data elements with business terms.

This module provides a LangGraph-based workflow for the process of tagging data elements
with appropriate business terms, including LLM-based semantic matching and vector similarity.
"""

import logging
from typing import Dict, Any, List, Optional, TypedDict, Union
from pydantic import BaseModel, Field
from langchain_openai import AzureChatOpenAI
from langgraph.graph import StateGraph, END

from app.core.models import TaggingResult, TaggingValidationResult, EnhancedDataElement
from app.agents.tagging_agent import TaggingAgent
from app.core.business_terms import BusinessTermManager

logger = logging.getLogger(__name__)

# Define workflow state
class TaggingWorkflowState(TypedDict):
    """State for the tagging workflow."""
    element_id: str
    element_name: str
    element_description: str
    matching_terms: List[Dict[str, Any]]
    confidence_scores: List[float]
    validation_result: Optional[Dict[str, Any]]
    is_complete: bool
    modeling_required: bool
    error: Optional[str]
    message: str
    use_llm_first: bool

class DataTaggingWorkflow:
    """LangGraph workflow for tagging data elements with business terms."""
    
    def __init__(self, llm: AzureChatOpenAI):
        """
        Initialize the tagging workflow.
        
        Args:
            llm: The language model to use for semantic matching and validation
        """
        self.llm = llm
        self.tagging_agent = TaggingAgent(llm)
        self.business_term_manager = BusinessTermManager()
        self.graph = self._build_graph()
    
    async def _find_matching_terms(self, state: TaggingWorkflowState) -> TaggingWorkflowState:
        """
        Find matching business terms for the data element.
        
        Args:
            state: The current workflow state
            
        Returns:
            Updated workflow state
        """
        try:
            # Use the tagging agent to find matching terms based on strategy
            result = await self.tagging_agent.tag_element(
                element_id=state["element_id"],
                element_name=state["element_name"],
                element_description=state["element_description"],
                top_k=5,  # Get more for better filtering
                use_llm_first=state["use_llm_first"]
            )
            
            # Update state with the results
            state["matching_terms"] = result.matching_terms
            state["confidence_scores"] = result.confidence_scores
            state["modeling_required"] = result.modeling_required
            state["message"] = result.message
            
            return state
        except Exception as e:
            logger.error(f"Error finding matching terms: {e}")
            state["error"] = f"Error finding matching terms: {str(e)}"
            state["is_complete"] = True
            return state
    
    async def _validate_matches(self, state: TaggingWorkflowState) -> TaggingWorkflowState:
        """
        Validate the matches using detailed LLM reasoning.
        
        Args:
            state: The current workflow state
            
        Returns:
            Updated workflow state
        """
        try:
            # Skip if no matching terms found or modeling is required
            if not state["matching_terms"] or state["modeling_required"]:
                state["is_complete"] = True
                return state
            
            # Recreate the tagging result for validation
            tagging_result = TaggingResult(
                element_id=state["element_id"],
                element_name=state["element_name"],
                element_description=state["element_description"],
                matching_terms=state["matching_terms"],
                confidence_scores=state["confidence_scores"],
                modeling_required=state["modeling_required"],
                message=state["message"]
            )
            
            # Perform validation with reasoning
            confidence, reasoning = await self.business_term_manager.evaluate_tagging_with_reasoning(tagging_result)
            
            # Update state with validation result
            state["validation_result"] = {
                "confidence": confidence,
                "reasoning": reasoning,
                "is_valid": confidence >= 0.5
            }
            
            # Update the modeling_required based on validation
            if confidence < 0.5:
                state["modeling_required"] = True
                state["message"] = f"Low validation confidence ({confidence:.2f}). Modeling should be considered."
            else:
                state["message"] = f"Validated matches with confidence {confidence:.2f}"
            
            state["is_complete"] = True
            return state
        except Exception as e:
            logger.error(f"Error validating matches: {e}")
            state["error"] = f"Error validating matches: {str(e)}"
            state["is_complete"] = True
            return state
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow."""
        workflow = StateGraph(TaggingWorkflowState)
        
        # Add nodes
        workflow.add_node("find_matching_terms", self._find_matching_terms)
        workflow.add_node("validate_matches", self._validate_matches)
        
        # Add edges
        workflow.add_edge("find_matching_terms", "validate_matches")
        workflow.add_edge("validate_matches", END)
        
        # Set entrypoint
        workflow.set_entry_point("find_matching_terms")
        
        return workflow.compile()
    
    async def run(self, element_id: str, element_name: str, element_description: str, 
                 use_llm_first: bool = True) -> TaggingResult:
        """
        Run the tagging workflow on a data element.
        
        Args:
            element_id: Unique identifier for the element
            element_name: Name of the element
            element_description: Description of the element
            use_llm_first: Whether to use LLM matching first before vector similarity
        
        Returns:
            TaggingResult containing matching terms and confidence scores
        """
        logger.info(f"Starting tagging workflow for element: {element_id} with LLM first: {use_llm_first}")
        
        initial_state: TaggingWorkflowState = {
            "element_id": element_id,
            "element_name": element_name,
            "element_description": element_description,
            "matching_terms": [],
            "confidence_scores": [],
            "validation_result": None,
            "is_complete": False,
            "modeling_required": False,
            "error": None,
            "message": "",
            "use_llm_first": use_llm_first
        }
        
        # Run the workflow
        result = await self.graph.ainvoke(initial_state)
        
        if result.get("error"):
            logger.error(f"Workflow error: {result['error']}")
            return TaggingResult(
                element_id=element_id,
                element_name=element_name,
                element_description=element_description,
                matching_terms=[],
                confidence_scores=[],
                modeling_required=True,
                message=result["error"]
            )
        
        return TaggingResult(
            element_id=result["element_id"],
            element_name=result["element_name"],
            element_description=result["element_description"],
            matching_terms=result["matching_terms"],
            confidence_scores=result["confidence_scores"],
            modeling_required=result["modeling_required"],
            message=result["message"]
        )
        
    async def tag_enhanced_element(self, enhanced_element: EnhancedDataElement, 
                                 use_llm_first: bool = True) -> TaggingResult:
        """
        Tag an enhanced data element with appropriate business terms.
        
        Args:
            enhanced_element: The enhanced data element
            use_llm_first: Whether to use LLM matching first
            
        Returns:
            TaggingResult with matching terms and confidence scores
        """
        return await self.run(
            element_id=enhanced_element.id,
            element_name=enhanced_element.enhanced_name,
            element_description=enhanced_element.enhanced_description,
            use_llm_first=use_llm_first
        )
