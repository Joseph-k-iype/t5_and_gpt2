"""
Embedding Client for generating vector embeddings using Azure OpenAI.
"""

import logging
import numpy as np
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI
from app.config.environment import get_os_env
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

logger = logging.getLogger(__name__)

class MyDocument(BaseModel):
    """Model representing a document with its embedding."""
    id: str = ""
    text: str = ""
    embedding: List[float] = []
    metadata: Dict[str, Any] = {}


class EmbeddingClient:
    """Client for generating embeddings for documents using Azure OpenAI."""
    
    def __init__(self, azure_api_version: str = "2023-05-15", embeddings_model: str = None):
        """Initialize the embedding client."""
        self.env = get_os_env()
        self.azure_api_version = azure_api_version
        
        # Get embedding model from environment or use default
        # Note: text-embedding-3-small produces 1536-dimensional vectors
        # text-embedding-3-large produces 3072-dimensional vectors
        self.embeddings_model = embeddings_model or self.env.get("EMBEDDING_MODEL", "text-embedding-3-small")
        
        # Log the model being used
        logger.info(f"Initializing embedding client with model: {self.embeddings_model}")
        
        self.direct_azure_client = self._get_direct_azure_client()
        logger.info(f"Embedding client initialized with model: {self.embeddings_model}")
    
    def _get_direct_azure_client(self):
        """Get the Azure OpenAI client for generating embeddings."""
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            return AzureOpenAI(
                azure_endpoint=azure_endpoint,
                api_version=self.azure_api_version,
                azure_ad_token_provider=token_provider
            )
        except Exception as e:
            logger.error(f"Error initializing Azure OpenAI client: {e}")
            raise
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((Exception)),
        reraise=True
    )
    def generate_embeddings(self, doc: MyDocument) -> MyDocument:
        """Generate embeddings for a document with retry logic."""
        try:
            # Check if text is empty
            if not doc.text or len(doc.text.strip()) == 0:
                logger.warning(f"Empty text for document ID: {doc.id}")
                return doc
                
            # Generate embedding
            response = self.direct_azure_client.embeddings.create(
                model=self.embeddings_model,
                input=doc.text
            ).data[0].embedding
            
            doc.embedding = response
            
            # Log the dimension of the embedding for debugging
            logger.debug(f"Generated embedding with dimension: {len(doc.embedding)}")
            
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings (attempt will be retried): {e}")
            raise
    
    def batch_generate_embeddings(self, docs: List[MyDocument], batch_size: int = 20) -> List[MyDocument]:
        """Generate embeddings for multiple documents in batches."""
        results = []
        
        # Process in batches to avoid rate limits
        for i in range(0, len(docs), batch_size):
            batch = docs[i:i + batch_size]
            
            for doc in batch:
                try:
                    doc_with_embedding = self.generate_embeddings(doc)
                    results.append(doc_with_embedding)
                except Exception as e:
                    logger.error(f"Error generating embedding for document {doc.id}: {e}")
                    # Add the document without embedding
                    results.append(doc)
        
        return results
            
    # Alias method with more descriptive name - supports both naming conventions
    def generate_embeddings_for_document(self, doc: MyDocument) -> MyDocument:
        """Alias for generate_embeddings."""
        return self.generate_embeddings(doc)
    
    def compute_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """Compute the cosine similarity between two embeddings."""
        if not embedding1 or not embedding2 or len(embedding1) != len(embedding2):
            return 0.0
            
        # Convert to numpy arrays
        a = np.array(embedding1)
        b = np.array(embedding2)
        
        # Compute cosine similarity
        dot_product = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
            
        similarity = dot_product / (norm_a * norm_b)
        return max(0.0, min(similarity, 1.0))  # Ensure in range [0, 1]
