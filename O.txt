"""
Tagging Workflow - LangGraph workflow for matching data elements with business terms.

This module provides a LangGraph-based workflow for the process of tagging data elements
with appropriate business terms, including LLM-based semantic matching, vector similarity,
and AI-powered evaluation.
"""

import logging
from typing import Dict, Any, List, Optional, TypedDict, Union
from pydantic import BaseModel, Field
from langchain_openai import AzureChatOpenAI
from langgraph.graph import StateGraph, END

from app.core.models import TaggingResult, TaggingValidationResult, EnhancedDataElement
from app.agents.tagging_agent import TaggingAgent
from app.core.business_terms import BusinessTermManager
from app.agents.tagging_evaluation_agent import AITaggingEvaluationAgent

logger = logging.getLogger(__name__)

# Define workflow state
class TaggingWorkflowState(TypedDict):
    """State for the tagging workflow."""
    element_id: str
    element_name: str
    element_description: str
    matching_terms: List[Dict[str, Any]]
    confidence_scores: List[float]
    validation_result: Optional[Dict[str, Any]]
    ai_evaluation_result: Optional[Dict[str, Any]]  # New field for AI evaluation
    is_complete: bool
    modeling_required: bool
    error: Optional[str]
    message: str
    use_llm_first: bool
    cdm: Optional[str]  # Added CDM to workflow state
    example: Optional[str]  # Added example to workflow state
    process_name: Optional[str]  # Added process name to workflow state
    process_description: Optional[str]  # Added process description to workflow state

class DataTaggingWorkflow:
    """LangGraph workflow for tagging data elements with business terms."""
    
    def __init__(self, llm: AzureChatOpenAI):
        """
        Initialize the tagging workflow.
        
        Args:
            llm: The language model to use for semantic matching and validation
        """
        self.llm = llm
        self.tagging_agent = TaggingAgent(llm)
        self.business_term_manager = BusinessTermManager()
        self.ai_evaluation_agent = AITaggingEvaluationAgent()
        self.graph = self._build_graph()
    
    async def _find_matching_terms(self, state: TaggingWorkflowState) -> TaggingWorkflowState:
        """
        Find matching business terms for the data element.
        
        Args:
            state: The current workflow state
            
        Returns:
            Updated workflow state
        """
        try:
            # Use the tagging agent to find matching terms based on strategy
            if state["use_llm_first"]:
                # For LLM-first matching, use the tagging agent's approach
                result = await self.tagging_agent.tag_element(
                    element_id=state["element_id"],
                    element_name=state["element_name"],
                    element_description=state["element_description"],
                    top_k=5,  # Get more for better filtering
                    use_llm_first=state["use_llm_first"],
                    cdm=state.get("cdm"),
                    example=state.get("example"),
                    process_name=state.get("process_name"),
                    process_description=state.get("process_description")
                )
            else:
                # For vector-first approach, use the business term manager directly
                result = await self.business_term_manager.tag_element(
                    element_id=state["element_id"],
                    name=state["element_name"],
                    description=state["element_description"],
                    top_k=5,  # Get more for better filtering
                    threshold=0.3,
                    cdm=state.get("cdm"),
                    example=state.get("example"),
                    process_name=state.get("process_name"),
                    process_description=state.get("process_description")
                )
            
            # Update state with the results
            state["matching_terms"] = result.matching_terms
            state["confidence_scores"] = result.confidence_scores
            state["modeling_required"] = result.modeling_required
            state["message"] = result.message
            
            return state
        except Exception as e:
            logger.error(f"Error finding matching terms: {e}")
            state["error"] = f"Error finding matching terms: {str(e)}"
            state["is_complete"] = True
            return state
    
    async def _ai_evaluate_matches(self, state: TaggingWorkflowState) -> TaggingWorkflowState:
        """
        Evaluate the matches using AI reasoning.
        
        Args:
            state: The current workflow state
            
        Returns:
            Updated workflow state
        """
        try:
            # Skip if no matching terms found or modeling is required
            if not state["matching_terms"] or state["modeling_required"]:
                state["is_complete"] = True
                return state
            
            # Create a tagging result for evaluation
            tagging_result = TaggingResult(
                element_id=state["element_id"],
                element_name=state["element_name"],
                element_description=state["element_description"],
                matching_terms=state["matching_terms"],
                confidence_scores=state["confidence_scores"],
                modeling_required=state["modeling_required"],
                message=state["message"]
            )
            
            # Evaluate with AI
            is_valid, overall_confidence, reasoning, improved_result = await self.ai_evaluation_agent.evaluate_tagging_result(tagging_result)
            
            # Update state with AI evaluation
            state["ai_evaluation_result"] = {
                "is_valid": is_valid,
                "confidence": overall_confidence,
                "reasoning": reasoning
            }
            
            # Use the improved matches from AI evaluation
            state["matching_terms"] = improved_result.matching_terms
            state["confidence_scores"] = improved_result.confidence_scores
            state["modeling_required"] = improved_result.modeling_required
            state["message"] = improved_result.message
            
            # If modeling is required but we have matches, try to find better matches
            if state["modeling_required"] and state["matching_terms"]:
                # Get all terms for AI-based selection
                all_terms = self.business_term_manager.get_all_terms()
                all_term_dicts = [term.dict() for term in all_terms]
                
                # Find better matches
                better_matches = await self.ai_evaluation_agent.find_better_matches(
                    state["element_name"],
                    state["element_description"],
                    all_term_dicts,
                    state["matching_terms"],
                    max_suggestions=5
                )
                
                # If better matches were found, update the state
                if better_matches:
                    state["matching_terms"] = better_matches
                    state["confidence_scores"] = [term.get("similarity", 0.5) for term in better_matches]
                    state["message"] = f"AI found better matches with confidence {max(state['confidence_scores'] or [0]):.2f}"
                    
                    # Update modeling_required based on best confidence
                    state["modeling_required"] = max(state["confidence_scores"] or [0]) < 0.5
            
            state["is_complete"] = True
            return state
        except Exception as e:
            logger.error(f"Error in AI evaluation: {e}")
            state["error"] = f"Error in AI evaluation: {str(e)}"
            state["is_complete"] = True
            return state
    
    def _build_graph(self) -> StateGraph:
        """Build the LangGraph workflow."""
        workflow = StateGraph(TaggingWorkflowState)
        
        # Add nodes
        workflow.add_node("find_matching_terms", self._find_matching_terms)
        workflow.add_node("ai_evaluate_matches", self._ai_evaluate_matches)
        
        # Add edges
        workflow.add_edge("find_matching_terms", "ai_evaluate_matches")
        workflow.add_edge("ai_evaluate_matches", END)
        
        # Set entrypoint
        workflow.set_entry_point("find_matching_terms")
        
        return workflow.compile()
    
    async def run(self, 
                 element_id: str, 
                 element_name: str, 
                 element_description: str, 
                 use_llm_first: bool = True,
                 cdm: Optional[str] = None,
                 example: Optional[str] = None,
                 process_name: Optional[str] = None,
                 process_description: Optional[str] = None) -> TaggingResult:
        """
        Run the tagging workflow on a data element.
        
        Args:
            element_id: Unique identifier for the element
            element_name: Name of the element
            element_description: Description of the element
            use_llm_first: Whether to use LLM matching first before vector similarity
            cdm: Optional CDM to prioritize in the matching
            example: Optional example for additional context
            process_name: Optional process name for additional context
            process_description: Optional process description for additional context
        
        Returns:
            TaggingResult containing matching terms and confidence scores
        """
        logger.info(f"Starting tagging workflow for element: {element_id} with LLM first: {use_llm_first}, CDM: {cdm}")
        
        initial_state: TaggingWorkflowState = {
            "element_id": element_id,
            "element_name": element_name,
            "element_description": element_description,
            "matching_terms": [],
            "confidence_scores": [],
            "validation_result": None,
            "ai_evaluation_result": None,
            "is_complete": False,
            "modeling_required": False,
            "error": None,
            "message": "",
            "use_llm_first": use_llm_first,
            "cdm": cdm,
            "example": example,
            "process_name": process_name,
            "process_description": process_description
        }
        
        # Run the workflow
        result = await self.graph.ainvoke(initial_state)
        
        if result.get("error"):
            logger.error(f"Workflow error: {result['error']}")
            return TaggingResult(
                element_id=element_id,
                element_name=element_name,
                element_description=element_description,
                matching_terms=[],
                confidence_scores=[],
                modeling_required=True,
                message=result["error"]
            )
        
        # Include AI evaluation reasoning in the message if available
        message = result["message"]
        if result.get("ai_evaluation_result") and result["ai_evaluation_result"].get("reasoning"):
            reasoning_snippet = result["ai_evaluation_result"]["reasoning"]
            # Limit reasoning to first 100 characters to keep message concise
            if len(reasoning_snippet) > 100:
                reasoning_snippet = reasoning_snippet[:100] + "..."
            message = f"{message} - AI evaluation: {reasoning_snippet}"
        
        return TaggingResult(
            element_id=result["element_id"],
            element_name=result["element_name"],
            element_description=result["element_description"],
            matching_terms=result["matching_terms"],
            confidence_scores=result["confidence_scores"],
            modeling_required=result["modeling_required"],
            message=message
        )
        
    async def tag_enhanced_element(self, 
                                 enhanced_element: EnhancedDataElement, 
                                 use_llm_first: bool = True,
                                 cdm: Optional[str] = None,
                                 example: Optional[str] = None,
                                 process_name: Optional[str] = None,
                                 process_description: Optional[str] = None) -> TaggingResult:
        """
        Tag an enhanced data element with appropriate business terms.
        
        Args:
            enhanced_element: The enhanced data element
            use_llm_first: Whether to use LLM matching first
            cdm: Optional CDM to prioritize in the matching
            example: Optional example from the original data element if available
            process_name: Optional process name from the original data element if available
            process_description: Optional process description from the original data element if available
            
        Returns:
            TaggingResult with matching terms and confidence scores
        """
        # Use any provided example/process info, or get from enhanced element if available
        example = example or enhanced_element.example
        process_name = process_name or enhanced_element.process_name
        process_description = process_description or enhanced_element.process_description
        
        return await self.run(
            element_id=enhanced_element.id,
            element_name=enhanced_element.enhanced_name,
            element_description=enhanced_element.enhanced_description,
            use_llm_first=use_llm_first,
            cdm=cdm,
            example=example,
            process_name=process_name,
            process_description=process_description
        )
