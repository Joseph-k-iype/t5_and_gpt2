"""
Embedding Client for generating vector embeddings using Azure OpenAI.
"""

import logging
import numpy as np
from typing import List, Dict, Any, Optional, Union, Tuple
from pydantic import BaseModel
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI
from app.config.environment import get_os_env
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

logger = logging.getLogger(__name__)

class MyDocument(BaseModel):
    """Model representing a document with its embedding."""
    id: str = ""
    text: str = ""
    embedding: List[float] = []
    metadata: Dict[str, Any] = {}


class EmbeddingClient:
    """Client for generating embeddings for documents using Azure OpenAI."""
    
    # Define model dimension mappings for reference
    MODEL_DIMENSIONS = {
        "text-embedding-3-small": 1536,
        "text-embedding-3-large": 3072,
        "text-embedding-ada-002": 1536
    }
    
    # Maximum dimension supported by pgvector
    PGVECTOR_MAX_DIMENSION = 2000
    
    def __init__(self, azure_api_version: str = "2023-05-15", embeddings_model: str = None, target_dimension: int = None):
        """
        Initialize the embedding client.
        
        Args:
            azure_api_version: API version for Azure OpenAI
            embeddings_model: Model to use for embeddings
            target_dimension: Target dimension for embeddings (for pgvector compatibility)
        """
        self.env = get_os_env()
        self.azure_api_version = azure_api_version
        
        # Get embedding model from environment or use default
        self.embeddings_model = embeddings_model or self.env.get("EMBEDDING_MODEL", "text-embedding-3-small")
        
        # Determine expected dimension for this model
        self.expected_dimension = self.MODEL_DIMENSIONS.get(self.embeddings_model, 1536)
        
        # Set target dimension - important for pgvector compatibility
        self.target_dimension = target_dimension or int(self.env.get("TARGET_DIMENSION", 
                             str(min(self.expected_dimension, self.PGVECTOR_MAX_DIMENSION))))
        
        logger.info(f"Initializing embedding client with model: {self.embeddings_model} "
                   f"(native dim: {self.expected_dimension}, target dim: {self.target_dimension})")
        
        self.direct_azure_client = self._get_direct_azure_client()
        logger.info(f"Embedding client initialized with model: {self.embeddings_model}")
    
    def _get_direct_azure_client(self):
        """Get the Azure OpenAI client for generating embeddings."""
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            return AzureOpenAI(
                azure_endpoint=azure_endpoint,
                api_version=self.azure_api_version,
                azure_ad_token_provider=token_provider
            )
        except Exception as e:
            logger.error(f"Error initializing Azure OpenAI client: {e}")
            raise
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((Exception)),
        reraise=True
    )
    def generate_embeddings(self, doc: MyDocument, auto_reduce: bool = True) -> MyDocument:
        """
        Generate embeddings for a document with retry logic.
        
        Args:
            doc: Document to generate embeddings for
            auto_reduce: Whether to automatically reduce dimensions to target
            
        Returns:
            Document with embedding
        """
        try:
            # Check if text is empty
            if not doc.text or len(doc.text.strip()) == 0:
                logger.warning(f"Empty text for document ID: {doc.id}")
                return doc
                
            # Generate embedding
            response = self.direct_azure_client.embeddings.create(
                model=self.embeddings_model,
                input=doc.text
            ).data[0].embedding
            
            # Log the dimension of the embedding for debugging
            original_dim = len(response)
            logger.debug(f"Generated embedding for '{doc.id}' with dimension: {original_dim}")
            
            # Automatically reduce dimensions if needed
            if auto_reduce and original_dim > self.target_dimension:
                reduced_embedding = self.reduce_dimensions(response, self.target_dimension)
                doc.embedding = reduced_embedding
                logger.debug(f"Reduced embedding dimensions from {original_dim} to {len(reduced_embedding)}")
            else:
                doc.embedding = response
            
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings (attempt will be retried): {e}")
            raise
    
    def batch_generate_embeddings(self, docs: List[MyDocument], batch_size: int = 20, auto_reduce: bool = True) -> List[MyDocument]:
        """
        Generate embeddings for multiple documents in batches.
        
        Args:
            docs: List of documents to generate embeddings for
            batch_size: Number of documents to process in each batch
            auto_reduce: Whether to automatically reduce dimensions to target
            
        Returns:
            List of documents with embeddings
        """
        results = []
        
        # Process in batches to avoid rate limits
        for i in range(0, len(docs), batch_size):
            batch = docs[i:i + batch_size]
            
            for doc in batch:
                try:
                    doc_with_embedding = self.generate_embeddings(doc, auto_reduce=auto_reduce)
                    results.append(doc_with_embedding)
                except Exception as e:
                    logger.error(f"Error generating embedding for document {doc.id}: {e}")
                    # Add the document without embedding
                    results.append(doc)
        
        return results
    
    def reduce_dimensions(self, embedding: List[float], target_dim: int) -> List[float]:
        """
        Reduce the dimensionality of an embedding vector.
        
        Multiple strategies are implemented - the default is uniform sampling.
        
        Args:
            embedding: Original embedding vector
            target_dim: Target dimension for the reduced vector
            
        Returns:
            Reduced embedding vector
        """
        if len(embedding) <= target_dim:
            return embedding
        
        # Strategy: Uniform sampling (take evenly spaced dimensions)
        # This preserves more of the original information than truncation
        indices = np.round(np.linspace(0, len(embedding) - 1, target_dim)).astype(int)
        reduced = [embedding[i] for i in indices]
        
        # Alternative strategies (commented out):
        
        # Strategy 1: Simple truncation (first N dimensions)
        # return embedding[:target_dim]
        
        # Strategy 2: Average pooling (average groups of dimensions)
        # chunk_size = len(embedding) / target_dim
        # reduced = []
        # for i in range(target_dim):
        #     start_idx = int(i * chunk_size)
        #     end_idx = int((i + 1) * chunk_size)
        #     reduced.append(np.mean(embedding[start_idx:end_idx]))
        # return reduced
        
        # Strategy 3: Principal Component Analysis (PCA)
        # This would require scikit-learn and keeping state between calls
        
        return reduced
    
    def expand_dimensions(self, embedding: List[float], target_dim: int) -> List[float]:
        """
        Expand the dimensionality of an embedding vector.
        
        Args:
            embedding: Original embedding vector
            target_dim: Target dimension for the expanded vector
            
        Returns:
            Expanded embedding vector
        """
        if len(embedding) >= target_dim:
            return embedding
        
        # Strategy: Zero padding (add zeros to reach target dimension)
        return embedding + [0.0] * (target_dim - len(embedding))
    
    def adjust_embedding_dimension(self, embedding: List[float], target_dim: int) -> List[float]:
        """
        Adjust embedding vector dimensions to match the target dimension.
        This handles both reducing and expanding dimensions.
        
        Args:
            embedding: Original embedding vector
            target_dim: Target dimension
        
        Returns:
            Adjusted embedding vector with target dimensions
        """
        current_dim = len(embedding)
        
        if current_dim == target_dim:
            return embedding
        
        logger.debug(f"Adjusting embedding dimension from {current_dim} to {target_dim}")
        
        if current_dim > target_dim:
            # Reduce dimensions
            return self.reduce_dimensions(embedding, target_dim)
        else:
            # Expand dimensions
            return self.expand_dimensions(embedding, target_dim)
    
    # Alias method with more descriptive name - supports both naming conventions
    def generate_embeddings_for_document(self, doc: MyDocument, auto_reduce: bool = True) -> MyDocument:
        """Alias for generate_embeddings."""
        return self.generate_embeddings(doc, auto_reduce=auto_reduce)
    
    def compute_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        Compute the cosine similarity between two embeddings.
        
        Args:
            embedding1: First embedding vector
            embedding2: Second embedding vector
            
        Returns:
            Similarity score between 0 and 1
        """
        if not embedding1 or not embedding2:
            return 0.0
            
        # Make sure embeddings have same dimension
        if len(embedding1) != len(embedding2):
            # Adjust to shorter dimension for comparison
            target_dim = min(len(embedding1), len(embedding2))
            embedding1 = self.adjust_embedding_dimension(embedding1, target_dim)
            embedding2 = self.adjust_embedding_dimension(embedding2, target_dim)
            
        # Convert to numpy arrays
        a = np.array(embedding1)
        b = np.array(embedding2)
        
        # Compute cosine similarity
        dot_product = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
            
        similarity = dot_product / (norm_a * norm_b)
        return max(0.0, min(similarity, 1.0))  # Ensure in range [0, 1]
