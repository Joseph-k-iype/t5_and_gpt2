#!/usr/bin/env python
"""
Enhanced database initialization and migration script for PostgreSQL with pgvector.
This script creates the ai_stitching_platform schema and sets up all required tables.

Usage:
    python setup_db.py [options]
"""

import sys
import os
import logging
import argparse
import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Add parent directory to Python path if needed
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import from app if available, otherwise use local environment variables
try:
    from app.config.environment import get_os_env
except ImportError:
    # Fallback if imports fail
    import os as env_os
    
    def get_os_env():
        return {
            "PG_HOST": env_os.environ.get("PG_HOST", "localhost"),
            "PG_PORT": env_os.environ.get("PG_PORT", "5432"),
            "PG_USER": env_os.environ.get("PG_USER", "postgres"),
            "PG_PASSWORD": env_os.environ.get("PG_PASSWORD", "postgres"),
            "PG_DB": env_os.environ.get("PG_DB", "metadata_db")
        }

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# Schema name - this will be used throughout the script
SCHEMA_NAME = "ai_stitching_platform"

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Initialize PostgreSQL database with schema and pgvector extension")
    parser.add_argument("--host", type=str, help="PostgreSQL host")
    parser.add_argument("--port", type=int, help="PostgreSQL port")
    parser.add_argument("--user", type=str, help="PostgreSQL user")
    parser.add_argument("--password", type=str, help="PostgreSQL password")
    parser.add_argument("--db", type=str, help="PostgreSQL database name")
    parser.add_argument("--create-db", action="store_true", help="Create the database if it doesn't exist")
    parser.add_argument("--create-extension", action="store_true", help="Create the pgvector extension")
    parser.add_argument("--drop-tables", action="store_true", help="Drop existing tables before creating new ones")
    parser.add_argument("--schema", type=str, default=SCHEMA_NAME, help=f"Schema name (default: {SCHEMA_NAME})")
    
    return parser.parse_args()

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((psycopg2.OperationalError)),
    reraise=True
)
def create_database(env, db_name):
    """Create the PostgreSQL database if it doesn't exist."""
    try:
        # Connect to default 'postgres' database to create a new database
        conn = psycopg2.connect(
            host=env.get("PG_HOST"),
            port=env.get("PG_PORT"),
            user=env.get("PG_USER"),
            password=env.get("PG_PASSWORD"),
            database="postgres"
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        
        with conn.cursor() as cursor:
            # Check if database exists
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
            exists = cursor.fetchone()
            
            if not exists:
                logger.info(f"Creating database '{db_name}'...")
                cursor.execute(f"CREATE DATABASE {db_name}")
                logger.info(f"Database '{db_name}' created successfully")
            else:
                logger.info(f"Database '{db_name}' already exists")
        
        conn.close()
        return True
    except Exception as e:
        logger.error(f"Error creating database: {e}")
        raise

def get_connection(env):
    """Get a PostgreSQL connection."""
    return psycopg2.connect(
        host=env.get("PG_HOST"),
        port=env.get("PG_PORT"),
        user=env.get("PG_USER"),
        password=env.get("PG_PASSWORD"),
        database=env.get("PG_DB")
    )

def create_schema(conn, schema_name):
    """Create the schema if it doesn't exist."""
    try:
        with conn.cursor() as cursor:
            logger.info(f"Creating schema '{schema_name}' if it doesn't exist...")
            cursor.execute(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
            conn.commit()
            logger.info(f"Schema '{schema_name}' is ready")
        return True
    except Exception as e:
        logger.error(f"Error creating schema: {e}")
        conn.rollback()
        return False

def create_extension(conn):
    """Create the pgvector extension."""
    try:
        with conn.cursor() as cursor:
            logger.info("Creating pgvector extension...")
            cursor.execute("CREATE EXTENSION IF NOT EXISTS vector")
            conn.commit()
            logger.info("pgvector extension created successfully")
            
            # Verify extension
            cursor.execute("SELECT * FROM pg_extension WHERE extname = 'vector'")
            if cursor.fetchone():
                logger.info("Verified pgvector extension is installed")
            else:
                logger.error("Failed to verify pgvector extension installation")
                return False
        
        return True
    except Exception as e:
        logger.error(f"Error creating pgvector extension: {e}")
        conn.rollback()
        return False

def drop_tables(conn, schema_name):
    """Drop existing tables to start fresh."""
    try:
        with conn.cursor() as cursor:
            logger.info(f"Dropping existing tables in schema '{schema_name}'...")
            
            # List tables to drop
            tables = ["business_terms", "jobs", "system_stats"]
            
            for table in tables:
                try:
                    cursor.execute(f"DROP TABLE IF EXISTS {schema_name}.{table} CASCADE")
                    logger.info(f"Dropped table '{schema_name}.{table}'")
                except Exception as table_error:
                    logger.error(f"Error dropping table '{schema_name}.{table}': {table_error}")
            
            conn.commit()
            logger.info("All tables dropped successfully")
        
        return True
    except Exception as e:
        logger.error(f"Error dropping tables: {e}")
        conn.rollback()
        return False

def create_tables(conn, schema_name):
    """Create the necessary tables for the application within the specified schema."""
    try:
        with conn.cursor() as cursor:
            logger.info(f"Creating tables in schema '{schema_name}'...")
            
            # Create business_terms table with vector support
            cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {schema_name}.business_terms (
                id VARCHAR(255) PRIMARY KEY,
                name VARCHAR(255) NOT NULL,
                description TEXT NOT NULL,
                embedding vector(1536),
                metadata JSONB
            )
            """)
            
            # Create index on vector column for similarity search
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS business_terms_embedding_idx 
            ON {schema_name}.business_terms 
            USING ivfflat (embedding vector_cosine_ops) 
            WITH (lists = 100)
            """)
            
            # Create jobs table for tracking enhancement and tagging jobs
            cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {schema_name}.jobs (
                id VARCHAR(255) PRIMARY KEY,
                job_type VARCHAR(50) NOT NULL,
                status VARCHAR(50) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                data JSONB
            )
            """)
            
            # Create stats table for monitoring
            cursor.execute(f"""
            CREATE TABLE IF NOT EXISTS {schema_name}.system_stats (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                cpu_usage FLOAT,
                memory_usage FLOAT,
                db_size BIGINT,
                active_connections INTEGER,
                enhancement_jobs_count INTEGER,
                tagging_jobs_count INTEGER
            )
            """)
            
            conn.commit()
            logger.info(f"Tables created successfully in schema '{schema_name}'")
        
        return True
    except Exception as e:
        logger.error(f"Error creating tables: {e}")
        conn.rollback()
        return False

def create_indexes(conn, schema_name):
    """Create additional indexes for better performance."""
    try:
        with conn.cursor() as cursor:
            logger.info(f"Creating indexes in schema '{schema_name}'...")
            
            # Create index on business_terms table
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS business_terms_name_idx 
            ON {schema_name}.business_terms (name)
            """)
            
            # Create indexes on jobs table
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS jobs_type_idx 
            ON {schema_name}.jobs (job_type)
            """)
            
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS jobs_status_idx 
            ON {schema_name}.jobs (status)
            """)
            
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS jobs_updated_idx 
            ON {schema_name}.jobs (updated_at)
            """)
            
            # Create index on system_stats table
            cursor.execute(f"""
            CREATE INDEX IF NOT EXISTS system_stats_timestamp_idx 
            ON {schema_name}.system_stats (timestamp)
            """)
            
            conn.commit()
            logger.info("Indexes created successfully")
        
        return True
    except Exception as e:
        logger.error(f"Error creating indexes: {e}")
        conn.rollback()
        return False

def verify_database_setup(conn, schema_name):
    """Verify the database setup."""
    try:
        with conn.cursor() as cursor:
            # Check PostgreSQL version
            cursor.execute("SELECT version()")
            version = cursor.fetchone()[0]
            
            # Check pgvector extension
            cursor.execute("SELECT extversion FROM pg_extension WHERE extname = 'vector'")
            vector_row = cursor.fetchone()
            vector_version = vector_row[0] if vector_row else "Not installed"
            vector_enabled = vector_row is not None
            
            # Check schema
            cursor.execute(f"SELECT 1 FROM information_schema.schemata WHERE schema_name = '{schema_name}'")
            schema_exists = cursor.fetchone() is not None
            
            # Check tables
            cursor.execute(f"""
            SELECT table_name, (
                SELECT count(*) FROM information_schema.columns 
                WHERE table_schema = '{schema_name}' AND table_name = t.table_name
            ) as column_count
            FROM information_schema.tables t
            WHERE table_schema = '{schema_name}'
            """)
            tables = cursor.fetchall()
            
            # Display results
            logger.info("\n=== Database Setup Verification ===")
            logger.info(f"PostgreSQL Version: {version}")
            logger.info(f"pgvector Extension: {'Enabled (v' + vector_version + ')' if vector_enabled else 'Not installed'}")
            logger.info(f"Schema '{schema_name}': {'Exists' if schema_exists else 'Not found'}")
            logger.info(f"Tables in schema '{schema_name}':")
            for table_name, column_count in tables:
                logger.info(f"  - {table_name} ({column_count} columns)")
            logger.info("===================================")
            
            return vector_enabled and schema_exists and len(tables) > 0
    except Exception as e:
        logger.error(f"Error verifying database setup: {e}")
        return False

def main():
    """Run the database initialization and migration."""
    args = parse_args()
    
    # Override environment variables with command line arguments
    if args.host:
        os.environ["PG_HOST"] = args.host
    if args.port:
        os.environ["PG_PORT"] = str(args.port)
    if args.user:
        os.environ["PG_USER"] = args.user
    if args.password:
        os.environ["PG_PASSWORD"] = args.password
    if args.db:
        os.environ["PG_DB"] = args.db
    
    # Use the provided schema name or default
    schema_name = args.schema
    
    # Get environment
    try:
        env = get_os_env()
    except Exception:
        env = {
            "PG_HOST": os.environ.get("PG_HOST", "localhost"),
            "PG_PORT": os.environ.get("PG_PORT", "5432"),
            "PG_USER": os.environ.get("PG_USER", "postgres"),
            "PG_PASSWORD": os.environ.get("PG_PASSWORD", "postgres"),
            "PG_DB": os.environ.get("PG_DB", "metadata_db")
        }
    
    # Log the configuration
    logger.info(f"PostgreSQL configuration:")
    logger.info(f"  Host: {env.get('PG_HOST')}")
    logger.info(f"  Port: {env.get('PG_PORT')}")
    logger.info(f"  User: {env.get('PG_USER')}")
    logger.info(f"  Database: {env.get('PG_DB')}")
    logger.info(f"  Schema: {schema_name}")
    
    # Create database if requested
    if args.create_db:
        create_database(env, env.get("PG_DB"))
    
    try:
        # Get a connection to the database
        conn = get_connection(env)
        
        success = True
        
        # Create schema
        if not create_schema(conn, schema_name):
            success = False
        
        # Create pgvector extension if requested
        if args.create_extension and success:
            if not create_extension(conn):
                success = False
        
        # Drop tables if requested
        if args.drop_tables and success:
            if not drop_tables(conn, schema_name):
                success = False
        
        # Create tables
        if success:
            if not create_tables(conn, schema_name):
                success = False
        
        # Create indexes
        if success:
            if not create_indexes(conn, schema_name):
                success = False
        
        # Verify setup
        if success:
            verify_database_setup(conn, schema_name)
        
        # Close connection
        conn.close()
        
        if success:
            logger.info("Database setup completed successfully")
        else:
            logger.error("Database setup failed")
            sys.exit(1)
    
    except Exception as e:
        logger.error(f"Error setting up database: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
