"""
Database initialization and migration script for PostgreSQL with pgvector.
Run this script once to set up the database schema with pgvector extension.

Usage:
    python -m migrations.init_db
"""

import sys
import os
import logging
import argparse
import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# Add parent directory to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config.environment import get_os_env
from app.core.db_manager import DBManager

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Initialize PostgreSQL database with pgvector extension")
    parser.add_argument("--host", type=str, help="PostgreSQL host")
    parser.add_argument("--port", type=int, help="PostgreSQL port")
    parser.add_argument("--user", type=str, help="PostgreSQL user")
    parser.add_argument("--password", type=str, help="PostgreSQL password")
    parser.add_argument("--db", type=str, help="PostgreSQL database name")
    parser.add_argument("--create-db", action="store_true", help="Create the database if it doesn't exist")
    parser.add_argument("--create-extension", action="store_true", help="Create the pgvector extension")
    parser.add_argument("--drop-tables", action="store_true", help="Drop existing tables before creating new ones")
    
    return parser.parse_args()

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((psycopg2.OperationalError)),
    reraise=True
)
def create_database(env, db_name):
    """Create the PostgreSQL database if it doesn't exist."""
    try:
        # Connect to default 'postgres' database to create a new database
        conn = psycopg2.connect(
            host=env.get("PG_HOST"),
            port=env.get("PG_PORT"),
            user=env.get("PG_USER"),
            password=env.get("PG_PASSWORD"),
            database="postgres"
        )
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        
        with conn.cursor() as cursor:
            # Check if database exists
            cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (db_name,))
            exists = cursor.fetchone()
            
            if not exists:
                logger.info(f"Creating database '{db_name}'...")
                cursor.execute(f"CREATE DATABASE {db_name}")
                logger.info(f"Database '{db_name}' created successfully")
            else:
                logger.info(f"Database '{db_name}' already exists")
        
        conn.close()
        return True
    except Exception as e:
        logger.error(f"Error creating database: {e}")
        raise

def create_extension(db_manager):
    """Create the pgvector extension."""
    try:
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                logger.info("Creating pgvector extension...")
                cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                conn.commit()
                logger.info("pgvector extension created successfully")
                
                # Verify extension
                cursor.execute("SELECT * FROM pg_extension WHERE extname = 'vector';")
                if cursor.fetchone():
                    logger.info("Verified pgvector extension is installed")
                else:
                    logger.error("Failed to verify pgvector extension installation")
        
        return True
    except Exception as e:
        logger.error(f"Error creating pgvector extension: {e}")
        return False

def drop_tables(db_manager):
    """Drop existing tables to start fresh."""
    try:
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                logger.info("Dropping existing tables...")
                
                # List tables to drop
                tables = ["business_terms", "jobs", "system_stats"]
                
                for table in tables:
                    try:
                        cursor.execute(f"DROP TABLE IF EXISTS {table} CASCADE;")
                        logger.info(f"Dropped table '{table}'")
                    except Exception as table_error:
                        logger.error(f"Error dropping table '{table}': {table_error}")
                
                conn.commit()
                logger.info("All tables dropped successfully")
        
        return True
    except Exception as e:
        logger.error(f"Error dropping tables: {e}")
        return False

def create_tables(db_manager):
    """Create the necessary tables for the application."""
    try:
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                logger.info("Creating tables...")
                
                # Create business_terms table with vector support
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS business_terms (
                    id VARCHAR(255) PRIMARY KEY,
                    name VARCHAR(255) NOT NULL,
                    description TEXT NOT NULL,
                    embedding vector(1536),
                    metadata JSONB
                );
                """)
                
                # Create index on vector column for similarity search
                cursor.execute("""
                CREATE INDEX IF NOT EXISTS business_terms_embedding_idx 
                ON business_terms 
                USING ivfflat (embedding vector_cosine_ops) 
                WITH (lists = 100);
                """)
                
                # Create jobs table for tracking enhancement and tagging jobs
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS jobs (
                    id VARCHAR(255) PRIMARY KEY,
                    job_type VARCHAR(50) NOT NULL,
                    status VARCHAR(50) NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    data JSONB
                );
                """)
                
                # Create stats table for monitoring
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS system_stats (
                    id SERIAL PRIMARY KEY,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    cpu_usage FLOAT,
                    memory_usage FLOAT,
                    db_size BIGINT,
                    active_connections INTEGER,
                    enhancement_jobs_count INTEGER,
                    tagging_jobs_count INTEGER
                );
                """)
                
                conn.commit()
                logger.info("Tables created successfully")
        
        return True
    except Exception as e:
        logger.error(f"Error creating tables: {e}")
        return False

def create_indexes(db_manager):
    """Create additional indexes for better performance."""
    try:
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                logger.info("Creating indexes...")
                
                # Create index on business_terms table
                cursor.execute("""
                CREATE INDEX IF NOT EXISTS business_terms_name_idx ON business_terms (name);
                """)
                
                # Create indexes on jobs table
                cursor.execute("""
                CREATE INDEX IF NOT EXISTS jobs_type_idx ON jobs (job_type);
                CREATE INDEX IF NOT EXISTS jobs_status_idx ON jobs (status);
                CREATE INDEX IF NOT EXISTS jobs_updated_idx ON jobs (updated_at);
                """)
                
                # Create index on system_stats table
                cursor.execute("""
                CREATE INDEX IF NOT EXISTS system_stats_timestamp_idx ON system_stats (timestamp);
                """)
                
                conn.commit()
                logger.info("Indexes created successfully")
        
        return True
    except Exception as e:
        logger.error(f"Error creating indexes: {e}")
        return False

def main():
    """Run the database initialization and migration."""
    args = parse_args()
    
    # Get environment
    env = get_os_env()
    
    # Override environment variables with command line arguments
    if args.host:
        os.environ["PG_HOST"] = args.host
    if args.port:
        os.environ["PG_PORT"] = str(args.port)
    if args.user:
        os.environ["PG_USER"] = args.user
    if args.password:
        os.environ["PG_PASSWORD"] = args.password
    if args.db:
        os.environ["PG_DB"] = args.db
    
    # Log the configuration
    logger.info(f"PostgreSQL configuration:")
    logger.info(f"  Host: {env.get('PG_HOST')}")
    logger.info(f"  Port: {env.get('PG_PORT')}")
    logger.info(f"  User: {env.get('PG_USER')}")
    logger.info(f"  Database: {env.get('PG_DB')}")
    
    # Create database if requested
    if args.create_db:
        create_database(env, env.get("PG_DB"))
    
    # Get the database manager
    db_manager = DBManager()
    
    # Create pgvector extension if requested
    if args.create_extension:
        create_extension(db_manager)
    
    # Drop tables if requested
    if args.drop_tables:
        drop_tables(db_manager)
    
    # Create tables
    create_tables(db_manager)
    
    # Create indexes
    create_indexes(db_manager)
    
    # Verify database setup
    try:
        health = db_manager.health_check()
        if health["status"] == "healthy":
            logger.info("Database setup completed successfully:")
            logger.info(f"  PostgreSQL Version: {health['version']}")
            logger.info(f"  pgvector Extension: {'Enabled' if health['vector_enabled'] else 'Disabled'}")
            logger.info(f"  Database Size: {health['db_size_mb']:.2f} MB")
            logger.info(f"  Business Terms: {health['terms_count']}")
            logger.info(f"  Active Connections: {health['active_connections']}")
        else:
            logger.error(f"Database setup verification failed: {health.get('error', 'Unknown error')}")
    except Exception as e:
        logger.error(f"Error verifying database setup: {e}")

if __name__ == "__main__":
    main()
