def process_knowledge_base(self, pdf_metadata=None):
    """Process all PDFs in the knowledge base and add to vector store.
    
    Args:
        pdf_metadata (dict, optional): A dictionary mapping PDF filenames to their metadata.
    """
    # Add debug logging for metadata
    if pdf_metadata:
        logger.info(f"Processing knowledge base with metadata for {len(pdf_metadata)} documents")
        # Log a sample of the metadata
        for filename, meta in list(pdf_metadata.items())[:2]:  # Log first 2 items only
            logger.info(f"Sample metadata for {filename}: {meta}")
    else:
        logger.info("Processing knowledge base without metadata")
    
    # Process PDFs to extract text
    texts_dict = self.pdf_processor.batch_process_pdfs()
    
    if not texts_dict:
        logger.warning("No text extracted from PDFs")
        return False
    
    # Log document count
    logger.info(f"Extracted text from {len(texts_dict)} documents")
    
    # Chunk the texts with enhanced metadata
    chunked_docs = []
    
    for filename, text in texts_dict.items():
        # Get metadata for this file if available
        metadata = {"source": filename}
        
        # Add any additional metadata from CSV if available
        metadata_prefix = ""
        if pdf_metadata and filename in pdf_metadata:
            # Add metadata to the document content itself for better retrieval
            metadata_prefix = "DOCUMENT METADATA:\n"
            for key, value in pdf_metadata[filename].items():
                metadata_prefix += f"{key}: {value}\n"
            metadata_prefix += "\nDOCUMENT CONTENT:\n"
            
            # Also add to metadata dictionary for direct access
            metadata.update(pdf_metadata[filename])
            logger.info(f"Added metadata to {filename}: {pdf_metadata[filename]}")
        
        # Add metadata prefix to the text
        enhanced_text = metadata_prefix + text
        
        # Auto-select optimal strategy for this text
        self.text_chunker.auto_select_strategy(enhanced_text)
        logger.info(f"Selected {self.text_chunker.strategy} chunking strategy for {filename}")
        
        # Chunk the text with metadata
        chunks = self.text_chunker.chunk_text(enhanced_text, metadata)
        chunked_docs.extend(chunks)
    
    logger.info(f"Created {len(chunked_docs)} chunks from {len(texts_dict)} documents")
    
    # After creating chunks, check a few to verify metadata was attached
    if chunked_docs:
        for i in range(min(3, len(chunked_docs))):
            logger.info(f"Sample chunk {i} metadata: {chunked_docs[i].metadata}")
            logger.info(f"Sample chunk {i} content preview: {chunked_docs[i].page_content[:100]}...")
    
    if not chunked_docs:
        logger.warning("No chunks created from documents")
        return False
    
    # Initialize vector store before adding documents
    if self.chroma_manager.vectorstore is None:
        logger.info("Initializing vector store before adding documents")
        try:
            self.chroma_manager.init_vectorstore(force_new=True)
        except Exception as e:
            logger.error(f"Failed to initialize vector store: {e}")
            return False
    
    # Add to vector store
    logger.info(f"Adding {len(chunked_docs)} document chunks to vector store")
    try:
        self.chroma_manager.add_documents(chunked_docs)
    except Exception as e:
        logger.error(f"Failed to add documents to vector store: {e}")
        return False
    
    # Re-initialize QA chain with updated vector store
    logger.info("Setting up QA chain with new documents")
    try:
        self._setup_qa_chain()
    except Exception as e:
        logger.error(f"Failed to set up QA chain: {e}")
        return False
    
    logger.info("Knowledge base processed successfully")
    return True
