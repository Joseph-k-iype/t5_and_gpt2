"""
PostgreSQL Database Manager with pgvector extension support.
Handles connection pooling, vector operations, and database initialization.
"""

import logging
import os
import time
from contextlib import contextmanager
from typing import List, Dict, Any, Optional, Generator, Tuple

import numpy as np
import psycopg2
from psycopg2 import pool
from psycopg2.extras import execute_values, DictCursor
from sqlalchemy import create_engine, text, MetaData, Table, Column, String, Float, JSON, Integer
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.config.environment import get_os_env

logger = logging.getLogger(__name__)

Base = declarative_base()

class DBManager:
    """PostgreSQL Database Manager with pgvector support."""
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern to ensure only one instance of the database connection pool."""
        if cls._instance is None:
            cls._instance = super(DBManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the PostgreSQL connection and pgvector extension."""
        if self._initialized:
            return
        
        self._initialized = True
        self.env = get_os_env()
        
        # Get PostgreSQL connection details
        self.pg_host = self.env.get("PG_HOST", "localhost")
        self.pg_port = int(self.env.get("PG_PORT", "5432"))
        self.pg_user = self.env.get("PG_USER", "postgres")
        self.pg_password = self.env.get("PG_PASSWORD", "postgres")
        self.pg_db = self.env.get("PG_DB", "metadata_db")
        
        # Configure connection pooling
        self.min_connections = int(self.env.get("PG_MIN_CONNECTIONS", "2"))
        self.max_connections = int(self.env.get("PG_MAX_CONNECTIONS", "10"))
        
        # Initialize connection pool and engine
        self._setup_connection_pool()
        self._setup_sqlalchemy()
        self._initialize_database()
        
        # Track connection statistics
        self.connection_attempts = 0
        self.successful_connections = 0
        self.failed_connections = 0
        
        logger.info(f"Database manager initialized with host={self.pg_host}, port={self.pg_port}, db={self.pg_db}")
    
    def _setup_connection_pool(self):
        """Set up a connection pool for PostgreSQL."""
        try:
            self.connection_pool = pool.ThreadedConnectionPool(
                minconn=self.min_connections,
                maxconn=self.max_connections,
                host=self.pg_host,
                port=self.pg_port,
                user=self.pg_user,
                password=self.pg_password,
                database=self.pg_db
            )
            logger.info(f"Connection pool created with {self.min_connections}-{self.max_connections} connections")
        except Exception as e:
            logger.error(f"Failed to create connection pool: {e}")
            self.connection_pool = None
    
    def _setup_sqlalchemy(self):
        """Set up SQLAlchemy engine for ORM operations."""
        try:
            db_url = f"postgresql://{self.pg_user}:{self.pg_password}@{self.pg_host}:{self.pg_port}/{self.pg_db}"
            self.engine = create_engine(db_url, pool_pre_ping=True)
            self.Session = sessionmaker(bind=self.engine)
            logger.info("SQLAlchemy engine initialized")
        except Exception as e:
            logger.error(f"Failed to create SQLAlchemy engine: {e}")
            self.engine = None
            self.Session = None
    
    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((psycopg2.OperationalError, psycopg2.InterfaceError)),
        reraise=True
    )
    def _initialize_database(self):
        """Initialize database with required extensions and tables."""
        with self.get_connection() as conn:
            with conn.cursor() as cursor:
                try:
                    # Create pgvector extension if it doesn't exist
                    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                    
                    # Create business_terms table with vector support
                    cursor.execute("""
                    CREATE TABLE IF NOT EXISTS business_terms (
                        id VARCHAR(255) PRIMARY KEY,
                        name VARCHAR(255) NOT NULL,
                        description TEXT NOT NULL,
                        embedding vector(1536),
                        metadata JSONB
                    );
                    """)
                    
                    # Create index on vector column for similarity search
                    cursor.execute("""
                    CREATE INDEX IF NOT EXISTS business_terms_embedding_idx 
                    ON business_terms 
                    USING ivfflat (embedding vector_cosine_ops) 
                    WITH (lists = 100);
                    """)
                    
                    # Create jobs table for tracking enhancement and tagging jobs
                    cursor.execute("""
                    CREATE TABLE IF NOT EXISTS jobs (
                        id VARCHAR(255) PRIMARY KEY,
                        job_type VARCHAR(50) NOT NULL,
                        status VARCHAR(50) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        data JSONB
                    );
                    """)
                    
                    # Create stats table for monitoring
                    cursor.execute("""
                    CREATE TABLE IF NOT EXISTS system_stats (
                        id SERIAL PRIMARY KEY,
                        timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        cpu_usage FLOAT,
                        memory_usage FLOAT,
                        db_size BIGINT,
                        active_connections INTEGER,
                        enhancement_jobs_count INTEGER,
                        tagging_jobs_count INTEGER
                    );
                    """)
                    
                    conn.commit()
                    logger.info("Database initialized with required tables and extensions")
                except Exception as e:
                    conn.rollback()
                    logger.error(f"Error initializing database: {e}")
                    raise
    
    @contextmanager
    def get_connection(self) -> Generator:
        """Get a connection from the pool with automatic cleanup."""
        conn = None
        self.connection_attempts += 1
        
        try:
            if self.connection_pool is None:
                # Try to recreate the pool if it's None
                self._setup_connection_pool()
                
            conn = self.connection_pool.getconn()
            self.successful_connections += 1
            yield conn
        except Exception as e:
            self.failed_connections += 1
            logger.error(f"Error getting database connection: {e}")
            raise
        finally:
            if conn is not None:
                self.connection_pool.putconn(conn)
    
    @contextmanager
    def get_session(self) -> Generator:
        """Get a SQLAlchemy session with automatic cleanup."""
        if self.Session is None:
            raise ValueError("SQLAlchemy Session not initialized")
            
        session = self.Session()
        try:
            yield session
        finally:
            session.close()
    
    def health_check(self) -> Dict[str, Any]:
        """Check the health of the database connection."""
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    # Check connection
                    cursor.execute("SELECT version();")
                    version = cursor.fetchone()[0]
                    
                    # Check pgvector extension
                    cursor.execute("SELECT * FROM pg_extension WHERE extname = 'vector';")
                    vector_enabled = cursor.fetchone() is not None
                    
                    # Get database size
                    cursor.execute(f"SELECT pg_database_size('{self.pg_db}');")
                    db_size = cursor.fetchone()[0]
                    
                    # Get table counts
                    cursor.execute("SELECT COUNT(*) FROM business_terms;")
                    terms_count = cursor.fetchone()[0]
                    
                    # Get connection stats
                    cursor.execute("SELECT count(*) FROM pg_stat_activity WHERE datname = %s;", (self.pg_db,))
                    active_connections = cursor.fetchone()[0]
                    
                    return {
                        "status": "healthy",
                        "version": version,
                        "vector_enabled": vector_enabled,
                        "db_size_mb": round(db_size / (1024 * 1024), 2),
                        "terms_count": terms_count,
                        "active_connections": active_connections,
                        "connection_pool_stats": {
                            "attempts": self.connection_attempts,
                            "successful": self.successful_connections,
                            "failed": self.failed_connections
                        }
                    }
        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    def store_vector(self, id: str, name: str, description: str, embedding: List[float], metadata: Dict = None) -> bool:
        """
        Store a vector in the database.
        
        Args:
            id: Unique identifier for the term
            name: Name of the term
            description: Description of the term
            embedding: Vector embedding as a list of floats
            metadata: Additional metadata as a dictionary
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    # Convert embedding to PostgreSQL vector format
                    pg_vector = f"[{','.join(map(str, embedding))}]"
                    
                    # Insert or update the term
                    cursor.execute("""
                    INSERT INTO business_terms (id, name, description, embedding, metadata)
                    VALUES (%s, %s, %s, %s::vector, %s)
                    ON CONFLICT (id) 
                    DO UPDATE SET 
                        name = EXCLUDED.name,
                        description = EXCLUDED.description,
                        embedding = EXCLUDED.embedding,
                        metadata = EXCLUDED.metadata;
                    """, (id, name, description, pg_vector, psycopg2.extras.Json(metadata or {})))
                    
                    conn.commit()
                    return True
        except Exception as e:
            logger.error(f"Error storing vector: {e}")
            return False
    
    def batch_store_vectors(self, items: List[Dict[str, Any]]) -> int:
        """
        Store multiple vectors in the database.
        
        Args:
            items: List of dictionaries with id, name, description, embedding, and optional metadata
            
        Returns:
            int: Number of items successfully stored
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    data = []
                    for item in items:
                        # Convert embedding to PostgreSQL vector format
                        pg_vector = f"[{','.join(map(str, item['embedding']))}]"
                        
                        data.append((
                            item['id'],
                            item['name'],
                            item['description'],
                            pg_vector,
                            psycopg2.extras.Json(item.get('metadata', {}))
                        ))
                    
                    # Use execute_values for efficient batch insert
                    execute_values(cursor, """
                    INSERT INTO business_terms (id, name, description, embedding, metadata)
                    VALUES %s
                    ON CONFLICT (id) 
                    DO UPDATE SET 
                        name = EXCLUDED.name,
                        description = EXCLUDED.description,
                        embedding = EXCLUDED.embedding,
                        metadata = EXCLUDED.metadata;
                    """, data, template="(%s, %s, %s, %s::vector, %s)")
                    
                    conn.commit()
                    return len(items)
        except Exception as e:
            logger.error(f"Error batch storing vectors: {e}")
            return 0
    
    def find_similar_vectors(self, query_vector: List[float], top_k: int = 5, threshold: float = 0.5) -> List[Dict[str, Any]]:
        """
        Find similar vectors in the database.
        
        Args:
            query_vector: Vector to compare against
            top_k: Number of results to return
            threshold: Minimum similarity threshold (0-1)
            
        Returns:
            List of dictionaries with id, name, description, similarity, and metadata
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    # Convert query vector to PostgreSQL vector format
                    pg_vector = f"[{','.join(map(str, query_vector))}]"
                    
                    # Query for similar vectors using cosine similarity
                    cursor.execute("""
                    SELECT 
                        id, 
                        name, 
                        description, 
                        metadata,
                        1 - (embedding <=> %s::vector) as similarity
                    FROM business_terms
                    WHERE 1 - (embedding <=> %s::vector) >= %s
                    ORDER BY similarity DESC
                    LIMIT %s;
                    """, (pg_vector, pg_vector, threshold, top_k))
                    
                    results = []
                    for row in cursor.fetchall():
                        results.append({
                            "id": row["id"],
                            "name": row["name"],
                            "description": row["description"],
                            "similarity": float(row["similarity"]),
                            "metadata": row["metadata"]
                        })
                    
                    return results
        except Exception as e:
            logger.error(f"Error finding similar vectors: {e}")
            return []
    
    def get_all_terms(self) -> List[Dict[str, Any]]:
        """
        Get all business terms from the database.
        
        Returns:
            List of dictionaries with id, name, description, and metadata
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                    SELECT id, name, description, metadata
                    FROM business_terms;
                    """)
                    
                    return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"Error getting all terms: {e}")
            return []
    
    def get_term_by_id(self, term_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a specific business term by ID.
        
        Args:
            term_id: ID of the term to retrieve
            
        Returns:
            Dictionary with term details or None if not found
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                    SELECT id, name, description, metadata
                    FROM business_terms
                    WHERE id = %s;
                    """, (term_id,))
                    
                    row = cursor.fetchone()
                    if row:
                        return dict(row)
                    return None
        except Exception as e:
            logger.error(f"Error getting term by ID: {e}")
            return None
    
    def delete_term(self, term_id: str) -> bool:
        """
        Delete a business term from the database.
        
        Args:
            term_id: ID of the term to delete
            
        Returns:
            True if successful, False otherwise
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                    DELETE FROM business_terms
                    WHERE id = %s;
                    """, (term_id,))
                    
                    conn.commit()
                    return cursor.rowcount > 0
        except Exception as e:
            logger.error(f"Error deleting term: {e}")
            return False
    
    def store_job(self, job_id: str, job_type: str, status: str, data: Dict[str, Any]) -> bool:
        """
        Store a job in the database.
        
        Args:
            job_id: Unique identifier for the job
            job_type: Type of job (enhancement, tagging)
            status: Status of the job
            data: Job data as a dictionary
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                    INSERT INTO jobs (id, job_type, status, data, updated_at)
                    VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
                    ON CONFLICT (id) 
                    DO UPDATE SET 
                        status = EXCLUDED.status,
                        data = EXCLUDED.data,
                        updated_at = CURRENT_TIMESTAMP;
                    """, (job_id, job_type, status, psycopg2.extras.Json(data)))
                    
                    conn.commit()
                    return True
        except Exception as e:
            logger.error(f"Error storing job: {e}")
            return False
    
    def get_job(self, job_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a job from the database.
        
        Args:
            job_id: ID of the job to retrieve
            
        Returns:
            Dictionary with job details or None if not found
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                    SELECT id, job_type, status, created_at, updated_at, data
                    FROM jobs
                    WHERE id = %s;
                    """, (job_id,))
                    
                    row = cursor.fetchone()
                    if row:
                        return dict(row)
                    return None
        except Exception as e:
            logger.error(f"Error getting job: {e}")
            return None
    
    def get_jobs_by_type_and_status(self, job_type: str, status: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        Get jobs by type and optional status.
        
        Args:
            job_type: Type of jobs to retrieve
            status: Optional status filter
            
        Returns:
            List of dictionaries with job details
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    if status:
                        cursor.execute("""
                        SELECT id, job_type, status, created_at, updated_at, data
                        FROM jobs
                        WHERE job_type = %s AND status = %s
                        ORDER BY updated_at DESC;
                        """, (job_type, status))
                    else:
                        cursor.execute("""
                        SELECT id, job_type, status, created_at, updated_at, data
                        FROM jobs
                        WHERE job_type = %s
                        ORDER BY updated_at DESC;
                        """, (job_type,))
                    
                    return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"Error getting jobs by type and status: {e}")
            return []
    
    def delete_job(self, job_id: str) -> bool:
        """
        Delete a job from the database.
        
        Args:
            job_id: ID of the job to delete
            
        Returns:
            True if successful, False otherwise
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                    DELETE FROM jobs
                    WHERE id = %s;
                    """, (job_id,))
                    
                    conn.commit()
                    return cursor.rowcount > 0
        except Exception as e:
            logger.error(f"Error deleting job: {e}")
            return False
    
    def record_system_stats(self, cpu_usage: float, memory_usage: float, 
                           enhancement_jobs_count: int, tagging_jobs_count: int) -> bool:
        """
        Record system statistics for monitoring.
        
        Args:
            cpu_usage: CPU usage percentage
            memory_usage: Memory usage percentage
            enhancement_jobs_count: Number of enhancement jobs
            tagging_jobs_count: Number of tagging jobs
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor() as cursor:
                    # Get database size
                    cursor.execute(f"SELECT pg_database_size('{self.pg_db}');")
                    db_size = cursor.fetchone()[0]
                    
                    # Get active connections
                    cursor.execute("SELECT count(*) FROM pg_stat_activity WHERE datname = %s;", (self.pg_db,))
                    active_connections = cursor.fetchone()[0]
                    
                    # Insert stats
                    cursor.execute("""
                    INSERT INTO system_stats 
                    (cpu_usage, memory_usage, db_size, active_connections, 
                     enhancement_jobs_count, tagging_jobs_count)
                    VALUES (%s, %s, %s, %s, %s, %s);
                    """, (cpu_usage, memory_usage, db_size, active_connections, 
                          enhancement_jobs_count, tagging_jobs_count))
                    
                    conn.commit()
                    return True
        except Exception as e:
            logger.error(f"Error recording system stats: {e}")
            return False
    
    def get_system_stats(self, limit: int = 100) -> List[Dict[str, Any]]:
        """
        Get recent system statistics.
        
        Args:
            limit: Maximum number of records to retrieve
            
        Returns:
            List of dictionaries with system statistics
        """
        try:
            with self.get_connection() as conn:
                with conn.cursor(cursor_factory=DictCursor) as cursor:
                    cursor.execute("""
                    SELECT timestamp, cpu_usage, memory_usage, db_size, 
                           active_connections, enhancement_jobs_count, tagging_jobs_count
                    FROM system_stats
                    ORDER BY timestamp DESC
                    LIMIT %s;
                    """, (limit,))
                    
                    return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"Error getting system stats: {e}")
            return []
    
    def compute_cosine_similarity(self, vector1: List[float], vector2: List[float]) -> float:
        """
        Compute cosine similarity between two vectors.
        
        Args:
            vector1: First vector
            vector2: Second vector
            
        Returns:
            float: Cosine similarity between 0 and 1
        """
        # Convert to numpy arrays
        a = np.array(vector1)
        b = np.array(vector2)
        
        # Compute cosine similarity
        dot_product = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        similarity = dot_product / (norm_a * norm_b)
        return max(0.0, min(similarity, 1.0))  # Ensure in range [0, 1]
