"""
Term Matching Agent – LangGraph-based ReAct agent for matching
data elements to business terms.
This implementation uses LangGraph's built-in ReAct framework for
more reliable tool usage and better state management during the matching process.
"""

import logging
import json
import re
import uuid
import asyncio
from typing import List, Dict, Any, Optional, Tuple

from pydantic import BaseModel, Field
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import tool

from app.core.models import TaggingResult
from app.config.settings import get_llm
from app.core.embedding import MyDocument

logger = logging.getLogger(__name__)


class TermMatchingAgent:
    """Agent for matching data elements to business terms using LangGraph's ReAct framework."""
    
    def __init__(self, business_term_manager):
        """Initialize the term matching agent with a business term manager."""
        self.business_term_manager = business_term_manager
        self.llm = get_llm()
        self.agent_executor = self._setup_react_agent()
    
    def _setup_react_agent(self):
        """Set up the ReAct agent with the necessary tools."""
        
        @tool
        def search_terms_by_vector(query: str, threshold: float = 0.1, max_results: int = 10) -> Dict[str, Any]:
            try:
                logger.info(f"Searching by vector with query: {query}")
                element_id = f"temp-{uuid.uuid4()}"
                doc = MyDocument(id=element_id, text=query)
                doc_with_embedding = self.business_term_manager.embedding_client.generate_embeddings(doc)
                if not doc_with_embedding.embedding:
                    return {"error": "Failed to generate embedding", "results": [], "count": 0}
                
                similar = self.business_term_manager.vector_store.find_similar_vectors(
                    query_vector=doc_with_embedding.embedding,
                    top_k=max_results,
                    threshold=threshold
                )
                return {"results": similar or [], "count": len(similar or [])}
            except Exception as e:
                logger.error(f"Error in search_terms_by_vector: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def search_terms_by_text(query: str, max_results: int = 10) -> Dict[str, Any]:
            try:
                logger.info(f"Searching by text with query: {query}")
                terms = self.business_term_manager.search_terms(query, limit=max_results)
                results = []
                for term in terms:
                    results.append(term.dict() if hasattr(term, "dict") else term)
                return {"results": results, "count": len(results)}
            except Exception as e:
                logger.error(f"Error in search_terms_by_text: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def get_term_by_id(term_id: str) -> Dict[str, Any]:
            try:
                term = self.business_term_manager.get_term_by_id(term_id)
                if not term:
                    return {"error": f"Term {term_id} not found"}
                return term.dict() if hasattr(term, "dict") else term
            except Exception as e:
                logger.error(f"Error in get_term_by_id: {e}")
                return {"error": str(e)}
        
        @tool
        def filter_terms_by_cdm(terms: List[Dict[str, Any]], cdm: str) -> Dict[str, Any]:
            try:
                filtered = []
                for term in terms:
                    md = term.get("metadata", {}) or {}
                    term_cdm = md.get("cdm") or term.get("cdm")
                    if term_cdm and term_cdm.lower() == cdm.lower():
                        filtered.append(term)
                return {"results": filtered, "count": len(filtered)}
            except Exception as e:
                logger.error(f"Error in filter_terms_by_cdm: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def compare_terms(element_name: str, element_description: str, terms: List[Dict[str, Any]]) -> Dict[str, Any]:
            try:
                if not terms:
                    return {"error": "No terms to compare", "matches": []}
                matches = []
                for term in terms:
                    term_id = term.get("id")
                    name = term.get("name", "")
                    desc = term.get("description", "")
                    sim = term.get("similarity", 0.5)
                    name_match = element_name.lower() in name.lower() or name.lower() in element_name.lower()
                    if name_match:
                        sim = max(sim, 0.7)
                        reasoning = f"Name match between '{element_name}' and '{name}'"
                    else:
                        reasoning = "Semantic similarity based on vector matching"
                    matches.append({
                        "term_id": term_id,
                        "confidence": sim,
                        "reasoning": reasoning
                    })
                matches.sort(key=lambda x: x["confidence"], reverse=True)
                return {"matches": matches}
            except Exception as e:
                logger.error(f"Error in compare_terms: {e}")
                return {"error": str(e), "matches": []}
        
        tools = [
            search_terms_by_vector,
            search_terms_by_text,
            get_term_by_id,
            filter_terms_by_cdm,
            compare_terms
        ]
        
        return create_react_agent(self.llm, tools)
    
    async def find_matching_terms(
        self,
        element_id: str,
        element_name: str,
        element_description: str,
        top_k: int = 3,
        cdm: Optional[str] = None,
        example: Optional[str] = None,
        process_name: Optional[str] = None,
        process_description: Optional[str] = None
    ) -> Tuple[List[Dict[str, Any]], List[float]]:
        """
        Find matching business terms using the ReAct agent.
        """
        try:
            # Build the user prompt
            prompt = (
                f"You are an expert agent matching data elements to business terms.\n\n"
                f"DATA ELEMENT:\n"
                f"  Name: {element_name}\n"
                f"  Description: {element_description}\n"
            )
            if example:
                prompt += f"\nExample: {example}"
            if process_name:
                prompt += f"\nProcess Name: {process_name}"
            if process_description:
                prompt += f"\nProcess Description: {process_description}"
            if cdm:
                prompt += f"\nPreferred CDM: {cdm} (prioritize terms from this CDM)"
            
            prompt += (
                "\n\nINSTRUCTIONS:\n"
                "1. Search via vector similarity on name and description separately.\n"
                "2. If needed, search by text match.\n"
                "3. If CDM is specified, prioritize those terms.\n"
                "4. Retrieve full details for candidates.\n"
                "5. Compare candidates and rank by confidence.\n"
                f"6. Return up to {top_k} matches as JSON:\n"
                "```json\n"
                "{\n"
                '  \"matches\": [\n'
                "    { \"term_id\": \"...\", \"confidence\": 0.0, \"reasoning\": \"...\" },\n"
                "    ...\n"
                "  ]\n"
                "}\n"
                "```"
            )
            
            # === FIXED INVOCATION: supply 'messages' ===
            response = await self.agent_executor.ainvoke({
                "messages": [
                    HumanMessage(content=prompt)
                ]
            })
            
            # Extract the assistant's final reply
            all_msgs: List[Any] = response.get("messages", [])
            final_response = None
            for msg in reversed(all_msgs):
                if isinstance(msg, AIMessage):
                    final_response = msg.content
                    break
            
            logger.info(f"Agent raw response:\n{final_response}")
            
            # Parse JSON block if present
            matching_terms: List[Dict[str, Any]] = []
            confidence_scores: List[float] = []
            if final_response:
                m = re.search(r"```json\n(.*)\n```", final_response, re.DOTALL)
                if m:
                    try:
                        data = json.loads(m.group(1))
                        for match in data.get("matches", [])[:top_k]:
                            tid = match.get("term_id")
                            conf = float(match.get("confidence", 0.5))
                            term_obj = self.business_term_manager.get_term_by_id(tid)
                            if term_obj:
                                term_dict = term_obj.dict() if hasattr(term_obj, "dict") else term_obj
                                term_dict["similarity"] = conf
                                matching_terms.append(term_dict)
                                confidence_scores.append(conf)
                    except json.JSONDecodeError:
                        logger.warning("Failed to decode JSON from agent response")
            
            # Fallback: no matches → direct vector search
            if not matching_terms:
                logger.info("Falling back to direct vector search")
                combined = f"{element_name}. {element_description}"
                doc = MyDocument(id=element_id, text=combined)
                doc_emb = self.business_term_manager.embedding_client.generate_embeddings(doc)
                if doc_emb.embedding:
                    similar = self.business_term_manager.vector_store.find_similar_vectors(
                        query_vector=doc_emb.embedding,
                        top_k=top_k,
                        threshold=0.1
                    )
                    for term in similar:
                        matching_terms.append(term)
                        confidence_scores.append(term.get("similarity", 0.5))
            
            return matching_terms[:top_k], confidence_scores[:top_k]
        
        except Exception as e:
            logger.error(f"Error in find_matching_terms: {e}")
            return [], []
