import os
import sys
import pandas as pd
import logging
from flask import Flask, render_template, request, jsonify, send_from_directory
from werkzeug.utils import secure_filename

# Import your RAG chatbot components
# You'll need to replace this with your actual import
from your_rag_module import RAGChatbot, ChatbotConfig

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Define paths
ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"
UPLOAD_FOLDER = "./knowledge_base"
METADATA_FOLDER = "./metadata"
ALLOWED_EXTENSIONS = {'pdf', 'csv'}

# Initialize Flask app
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['METADATA_FOLDER'] = METADATA_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16 MB max upload

# Create upload and metadata folders if they don't exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(METADATA_FOLDER, exist_ok=True)

# Initialize chatbot
chatbot_config = ChatbotConfig(
    pdf_directory=UPLOAD_FOLDER,
    vector_store_dir="./vector_db"
)

try:
    chatbot = RAGChatbot(CONFIG_PATH, CREDS_PATH, CERT_PATH, chatbot_config)
    logger.info("RAG Chatbot initialized successfully!")
except Exception as e:
    logger.error(f"Error initializing chatbot: {e}")
    chatbot = None

# Track the active metadata file
active_metadata_file = None
metadata_df = None

def allowed_file(filename):
    """Check if a file has an allowed extension."""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def validate_metadata_csv(filepath):
    """Validate and preprocess the CSV metadata file."""
    try:
        # Read the CSV
        df = pd.read_csv(filepath)
        
        # Check for required column
        if 'pdf_filename' not in df.columns:
            logger.error("CSV metadata file missing required 'pdf_filename' column")
            return None
            
        # Normalize column names (lowercase, replace spaces with underscores)
        df.columns = [col.lower().replace(' ', '_') for col in df.columns]
        
        # Clean pdf_filename values (e.g., remove leading/trailing whitespace)
        df['pdf_filename'] = df['pdf_filename'].str.strip()
        
        # Convert all string columns to strings (in case they're numeric)
        for col in df.columns:
            if col != 'pdf_filename' and df[col].dtype != 'object':
                df[col] = df[col].astype(str)
        
        # Log the columns found
        logger.info(f"Metadata CSV columns: {', '.join(df.columns.tolist())}")
        logger.info(f"Found {len(df)} rows in metadata CSV")
        
        # Check if any filenames are empty
        empty_filenames = df['pdf_filename'].isna().sum()
        if empty_filenames > 0:
            logger.warning(f"Found {empty_filenames} rows with empty pdf_filename values")
            # Filter out rows with empty filenames
            df = df.dropna(subset=['pdf_filename'])
        
        # Convert DataFrame to dictionary for easier processing
        metadata_dict = {}
        for _, row in df.iterrows():
            pdf_name = row['pdf_filename']
            # Extract only metadata fields (exclude pdf_filename)
            metadata = {k: v for k, v in row.items() if k != 'pdf_filename' and pd.notna(v)}
            metadata_dict[pdf_name] = metadata
        
        # Log a sample of the processed metadata
        logger.info(f"Processed metadata for {len(metadata_dict)} PDFs")
        if metadata_dict:
            for filename, meta in list(metadata_dict.items())[:2]:  # Log first 2 items only
                logger.info(f"Sample processed metadata for {filename}: {meta}")
            
        return metadata_dict
    except Exception as e:
        logger.error(f"Error validating metadata CSV: {e}")
        return None

@app.route('/')
def index():
    """Serve the main chat interface."""
    return render_template('index.html')

@app.route('/uploads/<path:filename>')
def uploaded_file(filename):
    """Serve uploaded files."""
    folder = app.config['METADATA_FOLDER'] if filename.lower().endswith('.csv') else app.config['UPLOAD_FOLDER']
    return send_from_directory(folder, filename)

@app.route('/upload', methods=['POST'])
def upload_file():
    """Handle file uploads."""
    if 'file' not in request.files:
        return jsonify({'success': False, 'message': 'No file part'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'message': 'No file selected'}), 400
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        
        # Determine if it's a PDF or CSV and save to appropriate folder
        if filename.lower().endswith('.pdf'):
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        else:  # CSV
            file_path = os.path.join(app.config['METADATA_FOLDER'], filename)
            
        file.save(file_path)
        
        # If it's a CSV, validate it
        if filename.lower().endswith('.csv'):
            metadata_dict = validate_metadata_csv(file_path)
            if metadata_dict is None:
                return jsonify({
                    'success': True,
                    'warning': True,
                    'message': 'CSV uploaded but could not be validated. Make sure it has a pdf_filename column.',
                    'filename': filename
                })
            
            # Set as active metadata file
            global active_metadata_file, metadata_df
            active_metadata_file = filename
            metadata_df = pd.read_csv(file_path)  # Keep the original DataFrame for display
            
            return jsonify({
                'success': True,
                'message': f'Metadata file uploaded and validated with {len(metadata_dict)} entries',
                'filename': filename,
                'is_metadata': True
            })
        
        return jsonify({
            'success': True, 
            'message': f'File uploaded successfully',
            'filename': filename,
            'is_metadata': False
        })
    
    return jsonify({'success': False, 'message': 'Invalid file type. Only PDF and CSV files are allowed'}), 400

@app.route('/process', methods=['POST'])
def process_knowledge_base():
    """Process the knowledge base with metadata if available."""
    global chatbot, active_metadata_file, metadata_df
    
    if chatbot is None:
        return jsonify({'success': False, 'message': 'Chatbot not initialized'}), 500
    
    try:
        # Get metadata for PDF files if available
        pdf_metadata = None
        if active_metadata_file and metadata_df is not None:
            try:
                # Get the file path for the active metadata
                metadata_path = os.path.join(app.config['METADATA_FOLDER'], active_metadata_file)
                
                # Validate the metadata
                pdf_metadata = validate_metadata_csv(metadata_path)
                
                if pdf_metadata:
                    logger.info(f"Prepared metadata for {len(pdf_metadata)} PDF documents")
                else:
                    return jsonify({'success': False, 'message': 'Failed to validate active metadata file'}), 500
            except Exception as e:
                logger.error(f"Error processing metadata: {e}")
                return jsonify({'success': False, 'message': f'Error processing metadata: {str(e)}'}), 500
        
        # Process knowledge base with metadata
        success = chatbot.process_knowledge_base(pdf_metadata=pdf_metadata)
        
        if success:
            metadata_msg = f" with metadata from {active_metadata_file}" if active_metadata_file else ""
            return jsonify({'success': True, 'message': f'Knowledge base processed successfully{metadata_msg}'})
        else:
            return jsonify({'success': False, 'message': 'Failed to process knowledge base'}), 500
    except Exception as e:
        logger.error(f"Error processing knowledge base: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/ask', methods=['POST'])
def ask_question():
    """Answer a question using the chatbot."""
    global chatbot
    
    if chatbot is None:
        return jsonify({'success': False, 'message': 'Chatbot not initialized'}), 500
    
    data = request.json
    question = data.get('question', '')
    
    if not question:
        return jsonify({'success': False, 'message': 'No question provided'}), 400
    
    try:
        result = chatbot.answer_question(question)
        return jsonify({
            'success': True,
            'question': result['question'],
            'answer': result['answer'],
            'sources': result['sources']
        })
    except Exception as e:
        logger.error(f"Error answering question: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/files', methods=['GET'])
def list_files():
    """List all files in the knowledge base and metadata directories."""
    try:
        pdf_files = []
        for filename in os.listdir(app.config['UPLOAD_FOLDER']):
            if os.path.isfile(os.path.join(app.config['UPLOAD_FOLDER'], filename)) and filename.lower().endswith('.pdf'):
                pdf_files.append({'name': filename, 'type': 'pdf'})
        
        metadata_files = []
        for filename in os.listdir(app.config['METADATA_FOLDER']):
            if os.path.isfile(os.path.join(app.config['METADATA_FOLDER'], filename)) and filename.lower().endswith('.csv'):
                is_active = (filename == active_metadata_file)
                metadata_files.append({'name': filename, 'type': 'csv', 'active': is_active})
        
        return jsonify({
            'success': True, 
            'pdf_files': pdf_files, 
            'metadata_files': metadata_files,
            'active_metadata': active_metadata_file
        })
    except Exception as e:
        logger.error(f"Error listing files: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/delete/<filename>', methods=['DELETE'])
def delete_file(filename):
    """Delete a file from the knowledge base or metadata directory."""
    try:
        global active_metadata_file, metadata_df
        
        if filename.lower().endswith('.pdf'):
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], secure_filename(filename))
        else:  # CSV
            file_path = os.path.join(app.config['METADATA_FOLDER'], secure_filename(filename))
        
        if os.path.exists(file_path):
            os.remove(file_path)
            
            # Reset active metadata if that file was deleted
            if filename == active_metadata_file:
                active_metadata_file = None
                metadata_df = None
                
            return jsonify({'success': True, 'message': f'File {filename} deleted successfully'})
        else:
            return jsonify({'success': False, 'message': f'File {filename} not found'}), 404
    except Exception as e:
        logger.error(f"Error deleting file: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/activate-metadata/<filename>', methods=['POST'])
def activate_metadata(filename):
    """Set a CSV file as the active metadata source."""
    global active_metadata_file, metadata_df
    
    try:
        file_path = os.path.join(app.config['METADATA_FOLDER'], secure_filename(filename))
        
        if not os.path.exists(file_path):
            return jsonify({'success': False, 'message': f'Metadata file {filename} not found'}), 404
        
        # Validate the CSV
        metadata_dict = validate_metadata_csv(file_path)
        if metadata_dict is None:
            return jsonify({
                'success': False,
                'message': 'CSV is invalid or missing required columns'
            }), 400
        
        # Set as active metadata
        active_metadata_file = filename
        metadata_df = pd.read_csv(file_path)
        
        return jsonify({
            'success': True,
            'message': f'Metadata file {filename} validated and set as active',
            'pdf_count': len(metadata_dict)
        })
    except Exception as e:
        logger.error(f"Error activating metadata file: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/metadata-info', methods=['GET'])
def metadata_info():
    """Get information about the active metadata file."""
    global active_metadata_file, metadata_df
    
    if not active_metadata_file or metadata_df is None:
        return jsonify({
            'success': True,
            'active': False,
            'message': 'No active metadata file'
        })
    
    try:
        # Get basic stats and column information
        columns = list(metadata_df.columns)
        row_count = len(metadata_df)
        pdf_count = metadata_df['pdf_filename'].nunique()
        
        # Sample of linked PDFs
        linked_pdfs = metadata_df['pdf_filename'].unique().tolist()[:5]  # First 5 for display
        
        return jsonify({
            'success': True,
            'active': True,
            'filename': active_metadata_file,
            'columns': columns,
            'row_count': row_count,
            'pdf_count': pdf_count,
            'linked_pdfs_sample': linked_pdfs,
            'message': f'Active metadata: {active_metadata_file}'
        })
    except Exception as e:
        logger.error(f"Error getting metadata info: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/metadata-preview/<filename>', methods=['GET'])
def metadata_preview(filename):
    """Get a preview of a metadata file."""
    try:
        file_path = os.path.join(app.config['METADATA_FOLDER'], secure_filename(filename))
        
        if not os.path.exists(file_path):
            return jsonify({'success': False, 'message': f'Metadata file {filename} not found'}), 404
        
        # Read the CSV
        df = pd.read_csv(file_path)
        
        # Check for required column
        if 'pdf_filename' not in df.columns:
            return jsonify({
                'success': False,
                'message': 'CSV is missing "pdf_filename" column required to link to PDFs'
            }), 400
        
        # Get a preview (first 10 rows)
        preview_rows = []
        for i, row in df.head(10).iterrows():
            preview_rows.append(row.to_dict())
        
        return jsonify({
            'success': True,
            'filename': filename,
            'columns': list(df.columns),
            'row_count': len(df),
            'preview': preview_rows
        })
    except Exception as e:
        logger.error(f"Error getting metadata preview: {e}")
        return jsonify({'success': False, 'message': f'Error: {str(e)}'}), 500

@app.route('/health', methods=['GET'])
def health_check():
    """Check if the API is healthy."""
    return jsonify({
        'status': 'healthy',
        'chatbot_initialized': chatbot is not None,
        'active_metadata': active_metadata_file
    })

@app.errorhandler(413)
def request_entity_too_large(error):
    """Handle file size limit exceeded."""
    return jsonify({
        'success': False,
        'message': 'File size exceeds the 16MB limit'
    }), 413

@app.errorhandler(500)
def internal_server_error(error):
    """Handle internal server errors."""
    logger.error(f"Internal server error: {error}")
    return jsonify({
        'success': False,
        'message': 'Internal server error occurred'
    }), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('FLASK_DEBUG', 'True').lower() == 'true'
    
    print(f"Starting RAG Chatbot UI server on port {port}, debug mode: {debug}")
    app.run(host='0.0.0.0', port=port, debug=debug)
