"""
Tagging API - Routes for tagging data elements with business terms.

Uses LLM Context approach that provides the full business term repository to the LLM,
enabling comprehensive semantic matching with complete knowledge of available terms.
"""

import os
import logging
import uuid
import chardet
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks, Depends, Query
from pydantic import BaseModel

from app.core.business_terms import BusinessTermManager
from app.core.db_manager import DBManager
from app.core.models import EnhancedDataElement, TaggingRequest, TaggingResponse
from app.agents.llm_context_tagging_agent import LLMContextTaggingAgent

logger = logging.getLogger(__name__)

# Create API router
router = APIRouter(prefix="/api/v1", tags=["business-terms"])

# In-memory cache for tagging jobs
tagging_jobs: Dict[str, Dict[str, Any]] = {}

# Business Term Manager instance
business_term_manager = BusinessTermManager()

# LLM Context Tagging Agent instance
tagging_agent = LLMContextTaggingAgent()

def get_db():
    """Get the database manager."""
    return DBManager()

class ImportResponse(BaseModel):
    """Response model for importing business terms."""
    success: bool
    message: str
    imported_count: int

@router.post("/terms/import", response_model=ImportResponse)
async def import_business_terms(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks = None
):
    """
    Import business terms from a CSV file.
    The CSV must have 'id', 'name', and 'description' columns.
    
    Additional columns will be imported as metadata.
    """
    try:
        # Create a unique temp file path
        temp_file_path = f"temp_{uuid.uuid4()}.csv"
        
        # Read and save the uploaded file
        file_content = await file.read()
        
        # Detect the encoding
        detection = chardet.detect(file_content)
        encoding = detection['encoding'] or 'utf-8'
        logger.info(f"Detected CSV encoding: {encoding} with confidence {detection['confidence']}")
        
        # Save the file with the detected encoding
        with open(temp_file_path, "wb") as buffer:
            buffer.write(file_content)
        
        # Import terms with encoding information
        try:
            logger.info(f"Importing terms from {file.filename} with encoding {encoding}")
            import_count = business_term_manager.import_terms_from_csv(temp_file_path, encoding=encoding)
            
            # Clean up the temp file
            try:
                if background_tasks:
                    background_tasks.add_task(os.unlink, temp_file_path)
                else:
                    os.unlink(temp_file_path)
            except Exception as e:
                logger.warning(f"Error deleting temporary file: {e}")
            
            # Re-initialize the tagging agent after importing new terms
            global tagging_agent
            tagging_agent = LLMContextTaggingAgent()
            
            return ImportResponse(
                success=True,
                message=f"Successfully imported {import_count} business terms from {file.filename}",
                imported_count=import_count
            )
        except Exception as e:
            logger.error(f"Error importing terms: {str(e)}")
            raise HTTPException(status_code=500, detail=f"Error importing terms: {str(e)}")
            
    except Exception as e:
        logger.error(f"Error processing file upload: {str(e)}")
        # Clean up the temp file in case of error
        if 'temp_file_path' in locals() and os.path.exists(temp_file_path):
            try:
                os.unlink(temp_file_path)
            except Exception as cleanup_error:
                logger.warning(f"Error cleaning up temporary file: {cleanup_error}")
        
        raise HTTPException(status_code=500, detail=f"Error importing terms: {str(e)}")

@router.post("/tag", response_model=TaggingResponse)
async def tag_element(
    request: TaggingRequest,
    db: DBManager = Depends(get_db)
):
    """
    Tag a data element with business terms using LLM Context approach.
    The LLM is given the full business term repository for comprehensive semantic matching.
    
    Args:
        request: The tagging request containing element information
        db: Database manager
        
    Returns:
        TaggingResponse with matching terms and confidence scores
    """
    try:
        # Check if we already have this job in memory
        request_id = request.element_id
        if request_id in tagging_jobs:
            logger.info(f"Returning existing tagging result from memory for {request_id}")
            job = tagging_jobs[request_id]
            return TaggingResponse(
                request_id=request_id,
                element_name=job["tagging_result"]["element_name"],
                matching_terms=job["tagging_result"]["matching_terms"],
                confidence_scores=job["tagging_result"]["confidence_scores"],
                validation_result=job.get("validation_result"),
                modeling_required=job["tagging_result"]["modeling_required"],
                message=job["tagging_result"]["message"]
            )
        
        # Check if job exists in database
        db_job = db.get_job(request_id)
        if db_job is not None and db_job["job_type"] == "tagging":
            logger.info(f"Returning existing tagging result from database for {request_id}")
            
            # Load into memory cache
            tagging_jobs[request_id] = db_job["data"]
            
            return TaggingResponse(
                request_id=request_id,
                element_name=db_job["data"]["tagging_result"]["element_name"],
                matching_terms=db_job["data"]["tagging_result"]["matching_terms"],
                confidence_scores=db_job["data"]["tagging_result"]["confidence_scores"],
                validation_result=db_job["data"].get("validation_result"),
                modeling_required=db_job["data"]["tagging_result"]["modeling_required"],
                message=db_job["data"]["tagging_result"]["message"]
            )
        
        # Use the LLM Context tagging agent
        logger.info(f"Tagging element with LLM Context approach: {request.element_id} - {request.element_name}")
        tagging_result = await tagging_agent.tag_element(
            element_id=request.element_id,
            name=request.element_name,
            description=request.element_description,
            top_k=request.top_k
        )
        
        # Create validation result based on tagging result
        validation_result = {
            "is_valid": not tagging_result.modeling_required and bool(tagging_result.matching_terms),
            "feedback": tagging_result.message,
            "suggested_alternatives": []
        }
        
        # Prepare the job data
        job_data = {
            "tagging_result": tagging_result.dict(),
            "validation_result": validation_result
        }
        
        # Store the result in memory
        tagging_jobs[request_id] = job_data
        
        # Store in database
        db.store_job(
            job_id=request_id,
            job_type="tagging",
            status="completed",
            data=job_data
        )
        
        return TaggingResponse(
            request_id=request_id,
            element_name=request.element_name,
            matching_terms=tagging_result.matching_terms,
            confidence_scores=tagging_result.confidence_scores,
            validation_result=validation_result,
            modeling_required=tagging_result.modeling_required,
            message=tagging_result.message
        )
    except Exception as e:
        logger.error(f"Error tagging element: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error tagging element: {str(e)}")

@router.post("/tag/enhanced", response_model=TaggingResponse)
async def tag_enhanced_element(
    element: EnhancedDataElement,
    db: DBManager = Depends(get_db)
):
    """
    Tag an enhanced data element with business terms.
    
    Args:
        element: Enhanced data element from the enhancement process
        db: Database manager
        
    Returns:
        TaggingResponse with matching terms and confidence scores
    """
    try:
        # Create a tagging request from the enhanced element
        request = TaggingRequest(
            element_id=element.id,
            element_name=element.enhanced_name,
            element_description=element.enhanced_description,
            top_k=3
        )
        
        # Use the main tagging endpoint
        return await tag_element(request, db)
    except Exception as e:
        logger.error(f"Error tagging enhanced element: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error tagging element: {str(e)}")

@router.get("/tag/{element_id}", response_model=TaggingResponse)
async def get_tagging_result(
    element_id: str,
    db: DBManager = Depends(get_db)
):
    """
    Get the result of a tagging request.
    
    Args:
        element_id: ID of the tagged element
        db: Database manager
        
    Returns:
        TaggingResponse with matching terms and confidence scores
    """
    # Check in memory first
    if element_id in tagging_jobs:
        job = tagging_jobs[element_id]
        tagging_result = job["tagging_result"]
        validation_result = job.get("validation_result")
        
        return TaggingResponse(
            request_id=element_id,
            element_name=tagging_result["element_name"],
            matching_terms=tagging_result["matching_terms"],
            confidence_scores=tagging_result["confidence_scores"],
            validation_result=validation_result,
            modeling_required=tagging_result.get("modeling_required", False),
            message=tagging_result.get("message", "")
        )
    
    # Check in database
    db_job = db.get_job(element_id)
    if db_job is None or db_job["job_type"] != "tagging":
        raise HTTPException(status_code=404, detail=f"Tagging result {element_id} not found")
    
    # Load into memory cache
    tagging_jobs[element_id] = db_job["data"]
    
    tagging_result = db_job["data"]["tagging_result"]
    validation_result = db_job["data"].get("validation_result")
    
    return TaggingResponse(
        request_id=element_id,
        element_name=tagging_result["element_name"],
        matching_terms=tagging_result["matching_terms"],
        confidence_scores=tagging_result["confidence_scores"],
        validation_result=validation_result,
        modeling_required=tagging_result.get("modeling_required", False),
        message=tagging_result.get("message", "")
    )

@router.delete("/tag/{element_id}", response_model=Dict[str, Any])
async def delete_tagging_result(
    element_id: str,
    db: DBManager = Depends(get_db)
):
    """
    Delete a tagging result from the system.
    
    Args:
        element_id: ID of the tagged element to delete
        db: Database manager
        
    Returns:
        Dictionary with deletion message
    """
    # Check if the job exists
    if element_id not in tagging_jobs and db.get_job(element_id) is None:
        raise HTTPException(status_code=404, detail=f"Tagging result {element_id} not found")
    
    # Delete from memory
    if element_id in tagging_jobs:
        del tagging_jobs[element_id]
    
    # Delete from database
    db.delete_job(element_id)
    
    return {"message": f"Tagging result for {element_id} deleted successfully"}

@router.get("/terms", response_model=List[Dict[str, Any]])
async def get_all_terms(
    limit: int = Query(100, ge=1, le=1000, description="Maximum number of terms to return"),
    offset: int = Query(0, ge=0, description="Offset for pagination")
):
    """
    Get all business terms in the collection with pagination.
    
    Args:
        limit: Maximum number of terms to return (1-1000)
        offset: Offset for pagination
        
    Returns:
        List of business terms
    """
    try:
        terms = business_term_manager.get_all_terms()
        
        # Apply pagination
        paginated_terms = terms[offset:offset + limit]
        
        return [term.dict() for term in paginated_terms]
    except Exception as e:
        logger.error(f"Error getting terms: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting terms: {str(e)}")

@router.get("/terms/search", response_model=List[Dict[str, Any]])
async def search_terms(
    query: str = Query(..., description="Search query"),
    limit: int = Query(20, ge=1, le=100, description="Maximum number of results")
):
    """
    Search for business terms by name or description.
    
    Args:
        query: Search query
        limit: Maximum number of results to return
        
    Returns:
        List of matching business terms
    """
    try:
        terms = business_term_manager.search_terms(query, limit)
        return [term.dict() for term in terms]
    except Exception as e:
        logger.error(f"Error searching terms: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error searching terms: {str(e)}")

@router.get("/terms/{term_id}", response_model=Dict[str, Any])
async def get_term(term_id: str):
    """
    Get a business term by its ID.
    
    Args:
        term_id: ID of the business term
        
    Returns:
        Business term details
    """
    try:
        term = business_term_manager.get_term_by_id(term_id)
        if not term:
            raise HTTPException(status_code=404, detail=f"Term {term_id} not found")
        return term.dict()
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting term: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting term: {str(e)}")

@router.post("/tag/batch", response_model=List[str])
async def batch_tag_elements(
    requests: List[TaggingRequest], 
    background_tasks: BackgroundTasks,
    db: DBManager = Depends(get_db)
):
    """
    Tag multiple data elements in batch mode.
    Returns a list of element IDs that can be used to check status.
    
    Args:
        requests: List of tagging requests
        background_tasks: FastAPI background tasks
        db: Database manager
        
    Returns:
        List of element IDs for tracking
    """
    element_ids = []
    
    for request in requests:
        element_id = request.element_id
        element_ids.append(element_id)
        
        # Skip if already processed
        if element_id in tagging_jobs:
            continue
            
        # Check if already in database
        db_job = db.get_job(element_id)
        if db_job is not None and db_job["job_type"] == "tagging":
            # Load into memory cache
            tagging_jobs[element_id] = db_job["data"]
            continue
        
        # Add tagging task to background tasks
        background_tasks.add_task(tag_element, request, db)
    
    return element_ids

@router.get("/terms/count", response_model=Dict[str, int])
async def get_term_count():
    """
    Get the total count of business terms in the repository.
    
    Returns:
        Dictionary with the count of business terms
    """
    try:
        count = business_term_manager.get_term_count()
        return {"count": count}
    except Exception as e:
        logger.error(f"Error getting term count: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting term count: {str(e)}")
