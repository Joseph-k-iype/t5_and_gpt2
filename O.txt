"""
Business Terms Manager using PostgreSQL with pgvector for semantic similarity matching.
Manages the storage, retrieval, and similarity search of business terms.
"""

import csv
import logging
import os
import time
import re
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from pydantic import BaseModel
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.core.db_manager import DBManager
from app.core.embedding import EmbeddingClient, MyDocument
from app.core.models import TaggingResult, TaggingValidationResult
from app.config.environment import get_os_env

logger = logging.getLogger(__name__)

class BusinessTerm(BaseModel):
    """Model representing a business term in the repository."""
    id: str
    name: str
    description: str
    metadata: Dict[str, Any] = {}
    
    def dict(self):
        """Convert the business term to a dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "metadata": self.metadata
        }

class BusinessTermManager:
    """
    Manager for business terms, handling storage, retrieval, and similarity matching.
    Uses pgvector for semantic similarity search via PostgreSQL.
    """
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern to ensure only one instance is created."""
        if cls._instance is None:
            cls._instance = super(BusinessTermManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the business term manager."""
        if self._initialized:
            return
            
        self._initialized = True
        self.env = get_os_env()
        
        # Get embedding model from environment
        embedding_model = self.env.get("EMBEDDING_MODEL", "text-embedding-3-small")
        logger.info(f"Using embedding model: {embedding_model}")
        
        # Initialize database manager and get vector dimension
        self.db_manager = DBManager()
        self.vector_dimension = self._get_vector_dimension()
        
        # Initialize embedding client with target dimension from database
        self.embedding_client = EmbeddingClient(embeddings_model=embedding_model, 
                                               target_dimension=self.vector_dimension)
        
        self.similarity_threshold = float(self.env.get("SIMILARITY_THRESHOLD", "0.5"))  # 50% similarity threshold
        
        # Verify database connection and pgvector extension
        self._verify_database()
        
        logger.info("Business term manager initialized with PostgreSQL backend")
    
    def _get_vector_dimension(self) -> int:
        """
        Get the vector dimension from the database schema.
        
        Returns:
            int: Vector dimension, or 1536 if not determinable
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    # Check if the business_terms table exists
                    cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'business_terms'
                    );
                    """)
                    
                    table_exists = cursor.fetchone()[0]
                    if not table_exists:
                        logger.warning("business_terms table doesn't exist yet, using default dimension")
                        return 1536  # Default dimension
                    
                    # Check the vector dimension in the table
                    cursor.execute("""
                    SELECT 
                        a.attname, 
                        format_type(a.atttypid, a.atttypmod)
                    FROM pg_catalog.pg_attribute a
                    WHERE a.attrelid = 'business_terms'::regclass
                    AND a.attname = 'embedding'
                    AND a.attnum > 0 
                    AND NOT a.attisdropped
                    """)
                    
                    embedding_info = cursor.fetchone()
                    if embedding_info:
                        # Get the dimension from the type
                        # The format is typically 'vector(N)' where N is the dimension
                        match = re.search(r'vector\((\d+)\)', embedding_info[1])
                        if match:
                            dimension = int(match.group(1))
                            logger.info(f"Database vector dimension: {dimension}")
                            return dimension
            
            # Default to 1536 if dimension can't be determined
            logger.warning("Could not determine vector dimension from schema, using default 1536")
            return 1536
        except Exception as e:
            logger.error(f"Error getting vector dimension: {e}")
            return 1536  # Default to 1536 if there's an error
    
    def _verify_database(self) -> bool:
        """
        Verify database connection and pgvector extension.
        
        Returns:
            bool: True if verification succeeds, False otherwise
        """
        try:
            # Check database health
            health = self.db_manager.health_check()
            
            if health["status"] != "healthy":
                logger.error(f"Database health check failed: {health.get('error', 'Unknown error')}")
                return False
            
            # Check if pgvector extension is enabled
            if not health.get("vector_enabled", False):
                logger.error("pgvector extension is not enabled in the database")
                return False
            
            # Check if business_terms table exists
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_name = 'business_terms'
                    );
                    """)
                    
                    table_exists = cursor.fetchone()[0]
                    
                    if not table_exists:
                        logger.error("business_terms table does not exist in the database")
                        return False
                    
                    # Compare with the expected dimension from our embedding model
                    embedding_model = self.env.get("EMBEDDING_MODEL", "text-embedding-3-small")
                    
                    # Get the expected dimension for this model
                    model_dimensions = {
                        "text-embedding-3-small": 1536,
                        "text-embedding-3-large": 3072,
                        "text-embedding-ada-002": 1536
                    }
                    
                    expected_dim = model_dimensions.get(embedding_model, 1536)
                    
                    # If model dimension exceeds pgvector's capabilities, log appropriately
                    if expected_dim > 2000:
                        logger.warning(f"Model {embedding_model} produces {expected_dim} dimensions, "
                                      f"but pgvector has a limit of 2000 dimensions. "
                                      f"Embeddings will be reduced to {self.vector_dimension} dimensions.")
                    elif self.vector_dimension != expected_dim:
                        logger.warning(f"Vector dimension mismatch: database uses {self.vector_dimension}, "
                                      f"but model {embedding_model} produces {expected_dim}. "
                                      f"Embeddings will be adjusted to match database dimension.")
            
            return True
        
        except Exception as e:
            logger.error(f"Database verification failed: {e}")
            return False
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type(Exception),
        reraise=True
    )
    def import_terms_from_csv(self, csv_path: str, encoding: str = 'utf-8', batch_size: int = 100) -> int:
        """
        Import business terms from a CSV file.
        
        Args:
            csv_path: Path to the CSV file
            encoding: File encoding (auto-detected if not provided)
            batch_size: Number of terms to process in each batch
            
        Returns:
            Number of terms imported
        """
        try:
            # Get existing terms
            existing_terms = {}
            for term in self.get_all_terms():
                term_key = f"{term.name}::{term.description}"
                existing_terms[term_key] = term.id
            
            # Track terms in CSV
            csv_term_keys = set()
            terms_to_add = []
            
            # Read terms from CSV
            with open(csv_path, 'r', encoding=encoding) as csvfile:
                reader = csv.DictReader(csvfile)
                for row in reader:
                    if 'id' not in row or 'name' not in row or 'description' not in row:
                        logger.warning(f"Skipping row with missing required fields: {row}")
                        continue
                    
                    term_id = row['id'].strip()
                    name = row['name'].strip()
                    description = row['description'].strip()
                    
                    if not term_id:
                        logger.warning(f"Skipping term with empty ID: {name}")
                        continue
                    
                    term_key = f"{name}::{description}"
                    csv_term_keys.add(term_key)
                    
                    # Skip if term already exists and is unchanged
                    if term_key in existing_terms and existing_terms[term_key] == term_id:
                        continue
                    
                    # Extract metadata if present in CSV
                    metadata = {}
                    for key, value in row.items():
                        if key not in ['id', 'name', 'description'] and value:
                            metadata[key] = value
                    
                    terms_to_add.append({
                        "id": term_id,
                        "name": name,
                        "description": description,
                        "term_key": term_key,
                        "metadata": metadata
                    })
            
            logger.info(f"Found {len(terms_to_add)} terms to add from CSV file")
            
            # Process terms one by one to handle dimension mismatches
            added_count = 0
            start_time = time.time()
            total_terms = len(terms_to_add)
            
            for i, term in enumerate(terms_to_add):
                try:
                    # Generate embedding for the term
                    doc = MyDocument(
                        id=term["id"],
                        text=f"{term['name']}. {term['description']}"
                    )
                    
                    # Auto-reduce is True by default in generate_embeddings to match target dimension
                    doc_with_embedding = self.embedding_client.generate_embeddings(doc)
                    
                    if not doc_with_embedding.embedding:
                        logger.warning(f"Skipping term without embedding: {term['name']}")
                        continue
                    
                    # Check if embedding dimensions match database expectations
                    embedding_dim = len(doc_with_embedding.embedding)
                    
                    # Double-check that dimensions match (should already be handled by auto_reduce)
                    if embedding_dim != self.vector_dimension:
                        logger.warning(f"Dimension mismatch after auto-reduce: {embedding_dim} vs {self.vector_dimension}")
                        logger.warning(f"Manually adjusting dimensions for term {term['id']}")
                        doc_with_embedding.embedding = self.embedding_client.adjust_embedding_dimension(
                            doc_with_embedding.embedding, 
                            self.vector_dimension
                        )
                    
                    # Store the term with embedding
                    success = self.db_manager.store_vector(
                        id=term["id"],
                        name=term["name"],
                        description=term["description"],
                        embedding=doc_with_embedding.embedding,
                        metadata=term.get("metadata", {})
                    )
                    
                    if success:
                        added_count += 1
                        
                        # Print progress occasionally
                        if added_count % 10 == 0 or added_count == total_terms:
                            elapsed = time.time() - start_time
                            rate = added_count / elapsed if elapsed > 0 else 0
                            remaining = (total_terms - added_count) / rate if rate > 0 else 0
                            logger.info(f"Added {added_count}/{total_terms} terms ({rate:.2f} terms/sec, ~{remaining:.1f}s remaining)")
                    else:
                        logger.warning(f"Failed to add term: {term['id']} - {term['name']}")
                
                except Exception as e:
                    logger.error(f"Error processing term '{term['id']}': {e}")
                    # Continue with next term
                    continue
            
            # Handle term deletion (terms that exist in the database but not in the CSV)
            deleted_count = 0
            terms_to_delete = []
            for term_key, term_id in existing_terms.items():
                if term_key not in csv_term_keys:
                    terms_to_delete.append(term_id)
            
            # Delete in batches to improve performance
            logger.info(f"Deleting {len(terms_to_delete)} terms that are not in the CSV")
            
            for i in range(0, len(terms_to_delete), batch_size):
                batch = terms_to_delete[i:i + batch_size]
                deleted_in_batch = 0
                
                for term_id in batch:
                    if self.db_manager.delete_term(term_id):
                        deleted_in_batch += 1
                
                deleted_count += deleted_in_batch
                if deleted_in_batch > 0:
                    logger.info(f"Deleted batch of {deleted_in_batch} terms")
            
            total_time = time.time() - start_time
            logger.info(f"Import completed in {total_time:.2f}s")
            logger.info(f"Import summary: Added {added_count} terms, deleted {deleted_count} terms")
            
            return added_count
        
        except Exception as e:
            logger.error(f"Error importing terms from CSV: {e}")
            raise
    
    def tag_element(self, element_id: str, name: str, description: str, top_k: int = 3) -> TaggingResult:
        """
        Tag a data element with the most similar business terms.
        
        Args:
            element_id: Unique identifier for the element
            name: Enhanced name of the element
            description: Enhanced description of the element
            top_k: Number of top matching terms to return
            
        Returns:
            TaggingResult containing matching terms and confidence scores
        """
        try:
            # Validate inputs
            if not name or not description:
                logger.warning(f"Empty name or description for element: {element_id}")
                return TaggingResult(
                    element_id=element_id,
                    element_name=name or "",
                    element_description=description or "",
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message="Name or description is empty. Modeling should be performed."
                )
            
            # Create document with embedding
            doc = MyDocument(
                id=element_id,
                text=f"{name}. {description}"
            )
            
            # Auto-reduce is True by default in generate_embeddings to match target dimension
            doc_with_embedding = self.embedding_client.generate_embeddings(doc)
            
            if not doc_with_embedding.embedding:
                logger.warning(f"Could not generate embedding for element: {name}")
                return TaggingResult(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message="Could not generate embedding. Modeling should be performed."
                )
            
            # Double-check dimensions match database expectations
            embedding_dim = len(doc_with_embedding.embedding)
            if embedding_dim != self.vector_dimension:
                logger.warning(f"Dimension mismatch: {embedding_dim} vs {self.vector_dimension}")
                doc_with_embedding.embedding = self.embedding_client.adjust_embedding_dimension(
                    doc_with_embedding.embedding, 
                    self.vector_dimension
                )
            
            # Query for similar terms
            similar_terms = self.db_manager.find_similar_vectors(
                query_vector=doc_with_embedding.embedding,
                top_k=top_k * 2,  # Fetch more and filter later
                threshold=self.similarity_threshold
            )
            
            # If no similar terms found, recommend modeling
            if not similar_terms:
                return TaggingResult(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message=f"Similarity is less than {self.similarity_threshold*100}%. Modeling should be performed."
                )
            
            # Format matching terms and filter by top_k
            matching_terms = []
            confidence_scores = []
            
            # Sort by similarity (in case DB didn't return in sorted order)
            similar_terms.sort(key=lambda x: x["similarity"], reverse=True)
            
            # Take top_k items
            for term in similar_terms[:top_k]:
                matching_terms.append({
                    "id": term["id"],
                    "name": term["name"],
                    "description": term["description"],
                    "similarity": term["similarity"]
                })
                confidence_scores.append(term["similarity"])
            
            return TaggingResult(
                element_id=element_id,
                element_name=name,
                element_description=description,
                matching_terms=matching_terms,
                confidence_scores=confidence_scores,
                modeling_required=False,
                message=""
            )
            
        except Exception as e:
            logger.error(f"Error tagging element: {e}", exc_info=True)
            
            # Attempt fallback matching using direct vector comparison
            try:
                logger.info(f"Attempting fallback matching for element: {element_id}")
                
                # Get all terms
                all_terms = self.get_all_terms()
                if not all_terms:
                    logger.warning("No business terms available for fallback matching")
                    return TaggingResult(
                        element_id=element_id,
                        element_name=name,
                        element_description=description,
                        matching_terms=[],
                        confidence_scores=[],
                        modeling_required=True,
                        message="Business terms repository is not available. Modeling should be performed."
                    )
                
                # Compare directly with available terms using dot product
                # This is a slow fallback method but ensures we can still match
                # even if the database query fails
                return TaggingResult(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message=f"Error during tagging: {str(e)}. Modeling should be performed."
                )
            except Exception as fallback_error:
                logger.error(f"Fallback matching also failed: {fallback_error}")
                return TaggingResult(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message=f"Error during tagging: {str(e)}. Modeling should be performed."
                )
    
    async def validate_tagging(self, tagging_result: TaggingResult) -> TaggingValidationResult:
        """
        Validate the tagging result.
        
        Args:
            tagging_result: Result of tagging to validate
            
        Returns:
            TaggingValidationResult with validation status and suggestions
        """
        try:
            # Skip validation if modeling is required
            if tagging_result.modeling_required:
                return TaggingValidationResult(
                    is_valid=False,
                    feedback=tagging_result.message,
                    suggested_alternatives=[]
                )
                
            # If no matching terms, validation fails
            if not tagging_result.matching_terms:
                return TaggingValidationResult(
                    is_valid=False,
                    feedback="No matching terms found",
                    suggested_alternatives=[]
                )
            
            # Get highest confidence score
            highest_confidence = max(tagging_result.confidence_scores) if tagging_result.confidence_scores else 0.0
            
            # If highest confidence is barely above threshold, find alternatives
            if highest_confidence < 0.75:
                # Try to find better alternatives
                alternative_doc = MyDocument(
                    id=tagging_result.element_id,
                    text=tagging_result.element_name  # Use just the name for alternative searching
                )
                
                alternative_doc_with_embedding = self.embedding_client.generate_embeddings(alternative_doc)
                
                if alternative_doc_with_embedding.embedding:
                    # Exclude already matched terms
                    matched_ids = [term["id"] for term in tagging_result.matching_terms]
                    
                    all_similar_terms = self.db_manager.find_similar_vectors(
                        query_vector=alternative_doc_with_embedding.embedding,
                        top_k=10,  # Get more to filter out already matched terms
                        threshold=self.similarity_threshold
                    )
                    
                    # Filter out already matched terms
                    alternative_terms = [
                        term for term in all_similar_terms
                        if term["id"] not in matched_ids
                    ][:3]  # Limit to top 3 alternatives
                    
                    if alternative_terms:
                        return TaggingValidationResult(
                            is_valid=False,
                            feedback="Low confidence in matching terms. Alternative terms found.",
                            suggested_alternatives=alternative_terms
                        )
            
            # Default case - validation passes
            return TaggingValidationResult(
                is_valid=True,
                feedback="Matching terms found with good confidence",
                suggested_alternatives=[]
            )
            
        except Exception as e:
            logger.error(f"Error validating tagging: {e}")
            return TaggingValidationResult(
                is_valid=False,
                feedback=f"Error during validation: {str(e)}",
                suggested_alternatives=[]
            )
    
    def get_all_terms(self) -> List[BusinessTerm]:
        """
        Get all business terms in the collection.
        
        Returns:
            List of BusinessTerm objects
        """
        try:
            term_dicts = self.db_manager.get_all_terms()
            
            terms = []
            for term_dict in term_dicts:
                terms.append(BusinessTerm(
                    id=term_dict["id"],
                    name=term_dict["name"],
                    description=term_dict["description"],
                    metadata=term_dict.get("metadata", {})
                ))
                
            return terms
        except Exception as e:
            logger.error(f"Error retrieving all terms: {e}")
            return []
    
    def get_term_by_id(self, term_id: str) -> Optional[BusinessTerm]:
        """
        Get a business term by its ID.
        
        Args:
            term_id: Unique identifier of the term
            
        Returns:
            BusinessTerm if found, None otherwise
        """
        try:
            term_dict = self.db_manager.get_term_by_id(term_id)
            
            if term_dict:
                return BusinessTerm(
                    id=term_dict["id"],
                    name=term_dict["name"],
                    description=term_dict["description"],
                    metadata=term_dict.get("metadata", {})
                )
            
            return None
        except Exception as e:
            logger.error(f"Error retrieving term by ID: {e}")
            return None
    
    def get_term_count(self) -> int:
        """
        Get the total count of business terms.
        
        Returns:
            Total number of terms
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT COUNT(*) FROM business_terms")
                    return cursor.fetchone()[0]
        except Exception as e:
            logger.error(f"Error getting term count: {e}")
            return 0
    
    def delete_term(self, term_id: str) -> bool:
        """
        Delete a business term by ID.
        
        Args:
            term_id: ID of the term to delete
            
        Returns:
            True if successful, False otherwise
        """
        try:
            return self.db_manager.delete_term(term_id)
        except Exception as e:
            logger.error(f"Error deleting term: {e}")
            return False
    
    def delete_all_terms(self) -> int:
        """
        Delete all business terms.
        
        Returns:
            Number of terms deleted
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("DELETE FROM business_terms")
                    deleted = cursor.rowcount
                    conn.commit()
                    return deleted
        except Exception as e:
            logger.error(f"Error deleting all terms: {e}")
            return 0
    
    def search_terms(self, query: str, limit: int = 20) -> List[BusinessTerm]:
        """
        Search for business terms by name or description.
        
        Args:
            query: Search query
            limit: Maximum number of results
            
        Returns:
            List of matching BusinessTerm objects
        """
        try:
            with self.db_manager.get_connection() as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                    SELECT id, name, description, metadata
                    FROM business_terms
                    WHERE 
                        name ILIKE %s OR 
                        description ILIKE %s
                    ORDER BY 
                        CASE WHEN name ILIKE %s THEN 0 ELSE 1 END,
                        CASE WHEN description ILIKE %s THEN 0 ELSE 1 END,
                        name
                    LIMIT %s
                    """, (f"%{query}%", f"%{query}%", f"{query}%", f"{query}%", limit))
                    
                    results = []
                    for row in cursor.fetchall():
                        id, name, description, metadata = row
                        results.append(BusinessTerm(
                            id=id,
                            name=name,
                            description=description,
                            metadata=metadata or {}
                        ))
                    
                    return results
        except Exception as e:
            logger.error(f"Error searching terms: {e}")
            return []
    
    def compute_similarity(self, text1: str, text2: str) -> float:
        """
        Compute semantic similarity between two text strings.
        
        Args:
            text1: First text
            text2: Second text
            
        Returns:
            Similarity score between 0 and 1
        """
        try:
            # Generate embeddings
            doc1 = MyDocument(id="temp1", text=text1)
            doc2 = MyDocument(id="temp2", text=text2)
            
            doc1_with_embedding = self.embedding_client.generate_embeddings(doc1)
            doc2_with_embedding = self.embedding_client.generate_embeddings(doc2)
            
            if not doc1_with_embedding.embedding or not doc2_with_embedding.embedding:
                logger.warning("Could not generate embeddings for similarity computation")
                return 0.0
            
            # Compute cosine similarity
            return self.embedding_client.compute_similarity(
                doc1_with_embedding.embedding,
                doc2_with_embedding.embedding
            )
        except Exception as e:
            logger.error(f"Error computing similarity: {e}")
            return 0.0
