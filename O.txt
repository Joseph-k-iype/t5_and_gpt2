#!/usr/bin/env python
"""
Migration utility to migrate data from ChromaDB to PostgreSQL with pgvector.
This script is used to migrate business terms and their embeddings from ChromaDB to PostgreSQL.

Usage:
    python -m migrations.migrate_from_chroma --chroma-dir=./chroma_db --help
"""

import os
import sys
import json
import logging
import argparse
import sqlite3
from typing import List, Dict, Any, Optional
import numpy as np
import psycopg2
from psycopg2.extras import execute_values

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.config.environment import get_os_env
from app.core.db_manager import DBManager

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)

logger = logging.getLogger(__name__)

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Migrate data from ChromaDB to PostgreSQL with pgvector")
    
    parser.add_argument("--chroma-dir", type=str, required=True,
                        help="Directory containing ChromaDB data")
    
    parser.add_argument("--pg-host", type=str, 
                        help="PostgreSQL host")
    parser.add_argument("--pg-port", type=int, 
                        help="PostgreSQL port")
    parser.add_argument("--pg-user", type=str, 
                        help="PostgreSQL user")
    parser.add_argument("--pg-password", type=str, 
                        help="PostgreSQL password")
    parser.add_argument("--pg-db", type=str, 
                        help="PostgreSQL database name")
    
    parser.add_argument("--collection", type=str, default="business_terms",
                        help="ChromaDB collection name to migrate (default: business_terms)")
    
    parser.add_argument("--batch-size", type=int, default=100,
                        help="Batch size for inserts (default: 100)")
    
    parser.add_argument("--dry-run", action="store_true",
                        help="Dry run - don't actually insert data")
    
    parser.add_argument("--force", action="store_true",
                        help="Force migration even if PostgreSQL already has data")
    
    return parser.parse_args()

def find_chroma_db_file(chroma_dir: str, collection_name: str) -> Optional[str]:
    """
    Find the ChromaDB SQLite file for the given collection.
    
    Args:
        chroma_dir: Directory containing ChromaDB data
        collection_name: Name of the collection
        
    Returns:
        Path to the SQLite file, or None if not found
    """
    # Look for SQLite files in the chroma directory
    for dirpath, dirnames, filenames in os.walk(chroma_dir):
        for filename in filenames:
            if filename.endswith(".sqlite3"):
                # Check if this is a ChromaDB file
                try:
                    db_path = os.path.join(dirpath, filename)
                    conn = sqlite3.connect(db_path)
                    cursor = conn.cursor()
                    
                    # Check if this file has the collection table
                    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='collections'")
                    if cursor.fetchone():
                        # Check if our collection exists
                        cursor.execute("SELECT name FROM collections WHERE name=?", (collection_name,))
                        row = cursor.fetchone()
                        if row:
                            conn.close()
                            return db_path
                    
                    conn.close()
                except Exception as e:
                    logger.warning(f"Error checking SQLite file {filename}: {e}")
                    continue
    
    return None

def get_chroma_embeddings(db_file: str, collection_name: str) -> List[Dict[str, Any]]:
    """
    Extract embeddings and metadata from ChromaDB SQLite file.
    
    Args:
        db_file: Path to ChromaDB SQLite file
        collection_name: Name of the collection
        
    Returns:
        List of dictionaries with id, embedding, and metadata
    """
    try:
        conn = sqlite3.connect(db_file)
        cursor = conn.cursor()
        
        # Get collection ID
        cursor.execute("SELECT id FROM collections WHERE name=?", (collection_name,))
        collection_id = cursor.fetchone()[0]
        
        # Get embeddings and metadata
        cursor.execute("""
        SELECT e.id, e.embedding, e.document, m.metadata
        FROM embeddings e
        LEFT JOIN metadata m ON e.id = m.id
        WHERE e.collection_id=?
        """, (collection_id,))
        
        results = []
        for row in cursor.fetchall():
            id, embedding_blob, document, metadata_blob = row
            
            # Parse embedding
            embedding = np.frombuffer(embedding_blob, dtype=np.float32).tolist()
            
            # Parse metadata if available
            metadata = {}
            if metadata_blob:
                metadata = json.loads(metadata_blob)
            
            # Get name and description from metadata or document
            name = ""
            description = ""
            
            if document:
                # Try to extract from document
                parts = document.split(". ", 1)
                if len(parts) > 0:
                    name = parts[0].strip()
                    description = parts[1].strip() if len(parts) > 1 else ""
            
            # Check if metadata has name/description
            if "name" in metadata:
                name = metadata["name"]
            if "description" in metadata:
                description = metadata["description"]
            
            # Create result
            results.append({
                "id": id,
                "name": name,
                "description": description,
                "embedding": embedding,
                "metadata": metadata
            })
        
        conn.close()
        return results
    
    except Exception as e:
        logger.error(f"Error extracting embeddings from ChromaDB: {e}")
        return []

def migrate_to_postgres(embeddings: List[Dict[str, Any]], args, db_manager: DBManager) -> int:
    """
    Migrate embeddings to PostgreSQL.
    
    Args:
        embeddings: List of embeddings with metadata
        args: Command line arguments
        db_manager: Database manager instance
        
    Returns:
        Number of records migrated
    """
    try:
        if not embeddings:
            logger.warning("No embeddings to migrate")
            return 0
        
        if args.dry_run:
            logger.info(f"Dry run - would migrate {len(embeddings)} embeddings")
            return 0
        
        # Check if PostgreSQL already has data
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) FROM business_terms")
                count = cursor.fetchone()[0]
                
                if count > 0 and not args.force:
                    logger.warning(f"PostgreSQL already has {count} records. Use --force to overwrite.")
                    return 0
        
        # Insert in batches
        batch_size = args.batch_size
        total_migrated = 0
        
        for i in range(0, len(embeddings), batch_size):
            batch = embeddings[i:i + batch_size]
            
            migrated = db_manager.batch_store_vectors(batch)
            total_migrated += migrated
            
            logger.info(f"Migrated batch: {i+1}-{min(i+batch_size, len(embeddings))} ({migrated} records)")
        
        logger.info(f"Total migrated: {total_migrated} records")
        return total_migrated
    
    except Exception as e:
        logger.error(f"Error migrating to PostgreSQL: {e}")
        return 0

def main():
    """Run the migration."""
    args = parse_args()
    
    # Set environment variables from command line
    if args.pg_host:
        os.environ["PG_HOST"] = args.pg_host
    if args.pg_port:
        os.environ["PG_PORT"] = str(args.pg_port)
    if args.pg_user:
        os.environ["PG_USER"] = args.pg_user
    if args.pg_password:
        os.environ["PG_PASSWORD"] = args.pg_password
    if args.pg_db:
        os.environ["PG_DB"] = args.pg_db
    
    # Get environment
    env = get_os_env()
    
    # Check ChromaDB directory
    if not os.path.isdir(args.chroma_dir):
        logger.error(f"ChromaDB directory not found: {args.chroma_dir}")
        sys.exit(1)
    
    # Find ChromaDB SQLite file
    logger.info(f"Looking for ChromaDB collection '{args.collection}' in {args.chroma_dir}")
    db_file = find_chroma_db_file(args.chroma_dir, args.collection)
    
    if not db_file:
        logger.error(f"Could not find ChromaDB collection: {args.collection}")
        sys.exit(1)
    
    logger.info(f"Found ChromaDB SQLite file: {db_file}")
    
    # Extract embeddings from ChromaDB
    logger.info("Extracting embeddings from ChromaDB...")
    embeddings = get_chroma_embeddings(db_file, args.collection)
    
    if not embeddings:
        logger.error("No embeddings found in ChromaDB")
        sys.exit(1)
    
    logger.info(f"Extracted {len(embeddings)} embeddings from ChromaDB")
    
    # Initialize DB manager
    logger.info("Initializing PostgreSQL connection...")
    db_manager = DBManager()
    
    # Check database connection
    db_health = db_manager.health_check()
    if db_health["status"] != "healthy":
        logger.error(f"PostgreSQL connection failed: {db_health.get('error', 'Unknown error')}")
        sys.exit(1)
    
    logger.info(f"Connected to PostgreSQL ({db_health['version']})")
    logger.info(f"pgvector extension: {'Enabled' if db_health['vector_enabled'] else 'Disabled'}")
    
    # Migrate to PostgreSQL
    logger.info("Migrating embeddings to PostgreSQL...")
    migrated = migrate_to_postgres(embeddings, args, db_manager)
    
    if migrated > 0:
        logger.info(f"Migration completed successfully. Migrated {migrated} embeddings.")
    else:
        logger.warning("No embeddings were migrated.")

if __name__ == "__main__":
    main()
