"""
Term Matching Agent - LangGraph-based ReAct agent for matching data elements to business terms.

This implementation uses LangGraph's built-in ReAct framework for more reliable tool usage
and better state management during the matching process.
"""

import logging
import json
import re
import os
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from pydantic import BaseModel, Field

from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import tool
import uuid

from app.core.models import TaggingResult
from app.config.settings import get_llm
from app.core.embedding import MyDocument

logger = logging.getLogger(__name__)

class TermMatchingAgent:
    """Agent for matching data elements to business terms using LangGraph's ReAct framework."""
    
    def __init__(self, business_term_manager):
        """Initialize the term matching agent with a business term manager."""
        self.business_term_manager = business_term_manager
        self.llm = get_llm()
        # Create agent with tools
        self.agent_executor = self._setup_react_agent()
    
    def _setup_react_agent(self):
        """Set up the ReAct agent with the necessary tools."""
        @tool
        def search_terms_by_vector(query: str, threshold: float = 0.1, max_results: int = 10) -> Dict[str, Any]:
            try:
                logger.info(f"Searching by vector with query: {query}")
                element_id = f"temp-{uuid.uuid4()}"
                
                # Generate embedding for query
                doc = MyDocument(id=element_id, text=query)
                doc_with_embedding = self.business_term_manager.embedding_client.generate_embeddings(doc)
                
                if not doc_with_embedding.embedding:
                    return {"error": "Failed to generate embedding for query", "results": [], "count": 0}
                
                # Search for similar vectors
                similar_terms = self.business_term_manager.vector_store.find_similar_vectors(
                    query_vector=doc_with_embedding.embedding,
                    top_k=max_results,
                    threshold=threshold
                )
                
                if not similar_terms:
                    logger.info("No vector search results found")
                    return {"results": [], "count": 0}
                
                logger.info(f"Found {len(similar_terms)} terms via vector search")
                return {"results": similar_terms, "count": len(similar_terms)}
                
            except Exception as e:
                logger.error(f"Error in search_terms_by_vector: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def search_terms_by_text(query: str, max_results: int = 10) -> Dict[str, Any]:
            try:
                logger.info(f"Searching by text with query: {query}")
                terms = self.business_term_manager.search_terms(query, limit=max_results)
                
                # Convert results to a list of dictionaries
                results = []
                for term in terms:
                    if hasattr(term, "dict"):
                        term_dict = term.dict()
                    else:
                        term_dict = term
                    results.append(term_dict)
                
                logger.info(f"Found {len(results)} terms via text search")
                return {"results": results, "count": len(results)}
                
            except Exception as e:
                logger.error(f"Error in search_terms_by_text: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def get_term_by_id(term_id: str) -> Dict[str, Any]:
            try:
                term = self.business_term_manager.get_term_by_id(term_id)
                if not term:
                    return {"error": f"Term with ID {term_id} not found"}
                
                if hasattr(term, "dict"):
                    term_dict = term.dict()
                else:
                    term_dict = term
                
                return term_dict
                
            except Exception as e:
                logger.error(f"Error in get_term_by_id: {e}")
                return {"error": str(e)}
        
        @tool
        def filter_terms_by_cdm(terms: List[Dict[str, Any]], cdm: str) -> Dict[str, Any]:
            try:
                filtered_terms = []
                for term in terms:
                    metadata = term.get("metadata", {}) or {}
                    term_cdm = metadata.get("cdm") or term.get("cdm")
                    if term_cdm and term_cdm.lower() == cdm.lower():
                        filtered_terms.append(term)
                return {"results": filtered_terms, "count": len(filtered_terms)}
            except Exception as e:
                logger.error(f"Error in filter_terms_by_cdm: {e}")
                return {"error": str(e), "results": [], "count": 0}
        
        @tool
        def compare_terms(element_name: str, element_description: str, terms: List[Dict[str, Any]]) -> Dict[str, Any]:
            try:
                if not terms:
                    return {"error": "No terms provided for comparison", "matches": []}
                
                matches = []
                for term in terms:
                    term_id = term.get("id")
                    term_name = term.get("name", "")
                    term_description = term.get("description", "")
                    
                    similarity = term.get("similarity", 0.5)
                    name_match = False
                    if element_name.lower() in term_name.lower() or term_name.lower() in element_name.lower():
                        name_match = True
                        similarity = max(similarity, 0.7)
                    
                    if name_match:
                        reasoning = f"Name match between '{element_name}' and '{term_name}'"
                    else:
                        reasoning = f"Semantic similarity based on vector matching"
                    
                    matches.append({
                        "term_id": term_id,
                        "confidence": similarity,
                        "reasoning": reasoning
                    })
                
                matches.sort(key=lambda x: x["confidence"], reverse=True)
                return {"matches": matches}
                
            except Exception as e:
                logger.error(f"Error in compare_terms: {e}")
                return {"error": str(e), "matches": []}
        
        tools = [
            search_terms_by_vector,
            search_terms_by_text,
            get_term_by_id,
            filter_terms_by_cdm,
            compare_terms
        ]
        
        # Create the agent
        agent_executor = create_react_agent(self.llm, tools)
        return agent_executor
    
    async def find_matching_terms(
        self, 
        element_id: str, 
        element_name: str, 
        element_description: str, 
        top_k: int = 3, 
        cdm: Optional[str] = None, 
        example: Optional[str] = None,
        process_name: Optional[str] = None,
        process_description: Optional[str] = None
    ) -> Tuple[List[Dict[str, Any]], List[float]]:
        """
        Find matching business terms using the ReAct agent.
        """
        try:
            prompt = f"""
            You are an expert data governance agent tasked with matching data elements to appropriate business terms.
            
            DATA ELEMENT:
            Name: {element_name}
            Description: {element_description}
            """
            
            if example:
                prompt += f"\nExample: {example}"
            if process_name:
                prompt += f"\nProcess Name: {process_name}"
            if process_description:
                prompt += f"\nProcess Description: {process_description}"
            if cdm:
                prompt += f"\nPreferred CDM: {cdm} (prioritize terms from this CDM)"
            
            prompt += f"""
            
            INSTRUCTIONS:
            1. First, search for candidate terms using vector similarity with the element name and description separately
            2. If needed, also search by text matching for additional candidates
            3. If a CDM is specified, prioritize terms from that CDM
            4. For promising candidates, get their full details
            5. Compare the terms to find the best matches
            6. Return up to {top_k} best matching terms with confidence scores
            
            IMPORTANT:
            - Focus on semantic equivalence rather than exact text matching
            - For example, "account number" may match with "account identifier" if they represent the same concept
            - Use both the name and description for matching, but prioritize name matching
            """
            
            # === FIX: supply 'messages' instead of 'input' ===
            response = await self.agent_executor.ainvoke({
                "messages": [
                    HumanMessage(content=prompt)
                ]
            })  # now satisfies the graph’s requirement  [oai_citation:2‡LangChain](https://langchain-ai.github.io/langgraph/reference/agents/?utm_source=chatgpt.com)
            
            final_response = response.get("output")
            logger.info(f"Agent response: {final_response}")
            
            matching_terms: List[Dict[str, Any]] = []
            confidence_scores: List[float] = []
            
            # Try JSON parsing
            json_match = re.search(r'```json\n(.*?)\n```', final_response or "", re.DOTALL)
            if json_match:
                try:
                    json_data = json.loads(json_match.group(1))
                    for match in json_data.get("matches", [])[:top_k]:
                        tid = match.get("term_id")
                        conf = match.get("confidence", 0.5)
                        term_obj = self.business_term_manager.get_term_by_id(tid)
                        if term_obj:
                            term_dict = term_obj.dict() if hasattr(term_obj, "dict") else term_obj
                            term_dict["similarity"] = conf
                            matching_terms.append(term_dict)
                            confidence_scores.append(conf)
                except json.JSONDecodeError:
                    logger.warning(f"Could not parse JSON from agent response")
            
            # Regex fallback
            if not matching_terms:
                pattern = r'(?:term|id)[:\s]+([a-zA-Z0-9_-]+)[^\n]*?(?:confidence|score)[:\s]+(\d+\.\d+)'
                for m in re.finditer(pattern, final_response or "", re.IGNORECASE):
                    term_id = m.group(1).strip()
                    try:
                        conf = float(m.group(2))
                        conf = max(0.0, min(1.0, conf))
                    except ValueError:
                        conf = 0.5
                    term_obj = self.business_term_manager.get_term_by_id(term_id)
                    if term_obj:
                        term_dict = term_obj.dict() if hasattr(term_obj, "dict") else term_obj
                        term_dict["similarity"] = conf
                        matching_terms.append(term_dict)
                        confidence_scores.append(conf)
            
            # Fallback to direct vector search
            if not matching_terms:
                logger.info("No matches found from agent response, falling back to direct vector search")
                try:
                    search_query = f"{element_name}. {element_description}"
                    doc = MyDocument(id=element_id, text=search_query)
                    doc_emb = self.business_term_manager.embedding_client.generate_embeddings(doc)
                    if doc_emb.embedding:
                        similar_terms = self.business_term_manager.vector_store.find_similar_vectors(
                            query_vector=doc_emb.embedding,
                            top_k=top_k,
                            threshold=0.1
                        )
                        matching_terms = similar_terms
                        confidence_scores = [t.get("similarity", 0.5) for t in similar_terms]
                except Exception as e:
                    logger.error(f"Error in fallback vector search: {e}")
            
            return matching_terms[:top_k], confidence_scores[:top_k]
        
        except Exception as e:
            logger.error(f"Error in find_matching_terms: {e}")
            return [], []
