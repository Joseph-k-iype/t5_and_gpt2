The error is happening in the `process_knowledge_base` method of your `RAGChatbot` class. Let's fix that specific function:

```python
def process_knowledge_base(self, pdf_metadata=None):
    """Process all PDFs in the knowledge base and add to vector store.
    
    Args:
        pdf_metadata (dict, optional): A dictionary mapping PDF filenames to their metadata.
    """
    # Add debug logging for metadata
    if pdf_metadata:
        logger.info(f"Processing knowledge base with metadata for {len(pdf_metadata)} documents")
        # Log a sample of the metadata
        for filename, meta in list(pdf_metadata.items())[:2]:  # Log first 2 items only
            logger.info(f"Sample metadata for {filename}: {meta}")
    else:
        logger.info("Processing knowledge base without metadata")
    
    # Process PDFs to extract text
    texts_dict = self.pdf_processor.batch_process_pdfs()
    
    if not texts_dict:
        logger.warning("No text extracted from PDFs")
        return False
    
    # Log document count
    logger.info(f"Extracted text from {len(texts_dict)} documents")
    
    # Chunk the texts with enhanced metadata
    chunked_docs = []
    
    for filename, text in texts_dict.items():
        # Get metadata for this file if available
        metadata = {"source": filename}
        
        # Add any additional metadata from CSV if available
        metadata_prefix = ""
        if pdf_metadata and filename in pdf_metadata:
            # Add metadata to the document content itself for better retrieval
            metadata_prefix = "DOCUMENT METADATA:\n"
            for key, value in pdf_metadata[filename].items():
                metadata_prefix += f"{key}: {value}\n"
            metadata_prefix += "\nDOCUMENT CONTENT:\n"
            
            # Also add to metadata dictionary for direct access
            metadata.update(pdf_metadata[filename])
            logger.info(f"Added metadata to {filename}: {pdf_metadata[filename]}")
        
        # Add metadata prefix to the text
        enhanced_text = metadata_prefix + text
        
        # Auto-select optimal strategy for this text
        self.text_chunker.auto_select_strategy(enhanced_text)
        logger.info(f"Selected {self.text_chunker.strategy} chunking strategy for {filename}")
        
        # Chunk the text with metadata
        chunks = self.text_chunker.chunk_text(enhanced_text, metadata)
        
        # Validate chunks before adding
        if chunks and isinstance(chunks, list):
            logger.info(f"Created {len(chunks)} chunks for {filename}")
            chunked_docs.extend(chunks)
        else:
            logger.warning(f"Invalid chunks for {filename}: {type(chunks)}")
    
    # Validate chunked_docs before proceeding
    if not chunked_docs:
        logger.warning("No valid chunks created from documents")
        return False
    
    if not isinstance(chunked_docs, list):
        logger.error(f"chunked_docs is not a list: {type(chunked_docs)}")
        return False
    
    try:
        # Check the first chunk for debugging
        first_chunk = chunked_docs[0]
        logger.info(f"First chunk type: {type(first_chunk)}")
        logger.info(f"First chunk metadata: {first_chunk.metadata}")
        logger.info(f"First chunk content length: {len(first_chunk.page_content)}")
    except Exception as e:
        logger.error(f"Error examining chunks: {e}")
    
    logger.info(f"Created total of {len(chunked_docs)} chunks from {len(texts_dict)} documents")
    
    # Initialize vector store before adding documents
    if self.chroma_manager.vectorstore is None:
        logger.info("Initializing vector store before adding documents")
        try:
            self.chroma_manager.init_vectorstore(force_new=True)
        except Exception as e:
            logger.error(f"Failed to initialize vector store: {e}")
            return False
    
    # Add to vector store
    logger.info(f"Adding {len(chunked_docs)} document chunks to vector store")
    try:
        # Try adding in smaller batches
        batch_size = 50  # Adjust this number based on your system capabilities
        for i in range(0, len(chunked_docs), batch_size):
            batch = chunked_docs[i:i+batch_size]
            logger.info(f"Adding batch {i//batch_size + 1}/{(len(chunked_docs)-1)//batch_size + 1} with {len(batch)} chunks")
            self.chroma_manager.add_documents(batch)
            logger.info(f"Successfully added batch {i//batch_size + 1}")
    except Exception as e:
        logger.error(f"Failed to add documents to vector store: {e}")
        # Print full stack trace for better debugging
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False
    
    # Re-initialize QA chain with updated vector store
    logger.info("Setting up QA chain with new documents")
    try:
        self._setup_qa_chain()
    except Exception as e:
        logger.error(f"Failed to set up QA chain: {e}")
        return False
    
    logger.info("Knowledge base processed successfully")
    return True
```

This updated method includes:

1. Much more detailed validation of the chunks before adding them to the vector store
2. Better error handling with full stack traces for debugging
3. Batch processing of documents to avoid overwhelming the vector store
4. Detailed validation of the first chunk to see what might be causing the error
5. Type checking of all critical variables to catch any type errors early

Make sure your `TextChunker.chunk_text` method is returning a list of valid `LC_DOCUMENT` objects, not integers or other unexpected types. 

Additionally, please check your `chunk_text` method to make sure it's correctly handling the chunking - it might be incorrectly returning an integer somewhere in its logic. If you continue to have issues, sharing the implementation of your `TextChunker` class would be helpful.​​​​​​​​​​​​​​​​
