This error occurs when there's a type mismatch in your code. In the `process_knowledge_base` method, you're trying to call `len()` on an integer value, which isn't supported. Let's fix this issue:

```python
def process_knowledge_base(self, pdf_metadata=None):
    """Process all PDFs in the knowledge base and add to vector store."""
    # Process PDFs to extract text
    texts_dict = self.pdf_processor.batch_process_pdfs()
    
    if not texts_dict:
        logger.warning("No text extracted from PDFs")
        return False
    
    # Chunk the texts with enhanced metadata
    chunked_docs = []
    
    for filename, text in texts_dict.items():
        # Get metadata for this file if available
        metadata = {"source": filename}
        
        # Add any additional metadata from CSV if available
        metadata_prefix = ""
        if pdf_metadata and filename in pdf_metadata:
            # Convert all metadata values to strings to avoid type issues
            safe_metadata = {}
            for key, value in pdf_metadata[filename].items():
                # Convert any non-string values to strings
                safe_metadata[key] = str(value) if value is not None else ""
            
            # Add metadata to the document content
            metadata_prefix = "DOCUMENT METADATA:\n"
            for key, value in safe_metadata.items():
                metadata_prefix += f"{key}: {value}\n"
            metadata_prefix += "\nDOCUMENT CONTENT:\n"
            
            # Add to metadata dictionary
            metadata.update(safe_metadata)
            logger.info(f"Added metadata to {filename}: {safe_metadata}")
        
        # Add metadata prefix to the text
        enhanced_text = metadata_prefix + text
        
        # Auto-select optimal strategy for this text
        self.text_chunker.auto_select_strategy(enhanced_text)
        logger.info(f"Selected {self.text_chunker.strategy} chunking strategy for {filename}")
        
        # Chunk the text with metadata
        chunks = self.text_chunker.chunk_text(enhanced_text, metadata)
        chunked_docs.extend(chunks)
    
    logger.info(f"Created {len(chunked_docs)} chunks from {len(texts_dict)} documents")
    
    if not chunked_docs:
        logger.warning("No chunks created from documents")
        return False
    
    # Debug check for each chunk's structure before adding to vector store
    for i, chunk in enumerate(chunked_docs):
        # Ensure page_content is a string
        if not isinstance(chunk.page_content, str):
            logger.warning(f"Chunk {i} has non-string page_content: {type(chunk.page_content)}")
            chunk.page_content = str(chunk.page_content)
        
        # Ensure metadata is a dictionary with string values
        if not isinstance(chunk.metadata, dict):
            logger.warning(f"Chunk {i} has non-dict metadata: {type(chunk.metadata)}")
            chunk.metadata = {"source": "unknown", "error": "metadata_corrupted"}
        else:
            # Convert all metadata values to strings
            for k, v in chunk.metadata.items():
                if not isinstance(v, str):
                    logger.warning(f"Metadata value for '{k}' is not a string: {type(v)}")
                    chunk.metadata[k] = str(v)
    
    # Add to vector store
    try:
        self.chroma_manager.add_documents(chunked_docs)
    except Exception as e:
        logger.error(f"Failed to add documents to vector store: {e}")
        # Try to add detailed error information
        if "has no len" in str(e):
            logger.error("This is likely due to a type mismatch: expected a collection but received a single value")
            # Attempt to debug the first few chunks
            for i, chunk in enumerate(chunked_docs[:3]):
                logger.error(f"Debug chunk {i}:")
                logger.error(f"  Type: {type(chunk)}")
                logger.error(f"  Content type: {type(chunk.page_content)}")
                logger.error(f"  Metadata: {chunk.metadata}")
        return False
    
    # Re-initialize QA chain with updated vector store
    self._setup_qa_chain()
    
    return True
```

This fix does several important things:

1. **Converts all metadata values to strings**: This prevents type mismatches when dealing with numeric values in your metadata
2. **Adds validation for each chunk before adding to the vector store**: Ensures all page content is a string and all metadata values are strings
3. **Adds detailed error logging**: If an error occurs, it provides more context to help diagnose the issue
4. **Adds specific handling for the "has no len" error**: Includes additional debug information for this exact error

The most likely cause is that your CSV file contains numeric values (integers, floats) in some columns, and these are causing issues when they're added to the document metadata. The fix ensures everything is properly converted to strings.

Add this updated method to your RAGChatbot class, then try processing the documents again. The additional error logging should also help diagnose any remaining issues if they occur.​​​​​​​​​​​​​​​​
