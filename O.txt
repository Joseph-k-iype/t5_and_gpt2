import os
import sys
import uuid
import json
import logging
import pandas as pd
import numpy as np
import instructor
from typing import List, Dict, Any, Optional, TypeVar, Generic, Type, Union, Literal
from pathlib import Path
from dotenv import load_dotenv, dotenv_values
from pydantic import BaseModel, Field, ValidationError, field_validator
from azure.identity import DefaultAzureCredential, get_bearer_token_provider, ClientSecretCredential
from openai import AzureOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import AzureChatOpenAI
from langchain.chains import ConversationChain
from collections import namedtuple
from langgraph.graph import StateGraph, END

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

# Define paths
ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

# Create ENV_DIR if it doesn't exist
os.makedirs(ENV_DIR, exist_ok=True)

# Type variable for generic response model
T = TypeVar('T', bound=BaseModel)

# Utility functions
def is_file_readable(filepath: str) -> bool:
    """Check if a file is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        return False
    return True

def str_to_bool(s: str) -> bool:
    """Convert a string to a boolean."""
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean value: {s}")

class OSEnv:
    """Class to manage environment variables"""
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.bulk_set(config_file, True)
        self.bulk_set(creds_file, False)
        
        if is_file_readable(certificate_path):
            self.set_certificate_path(certificate_path)
        
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self.get_azure_token()
        else:
            self.token = None
        
        self.credential = self._get_credential()
    
    def _get_credential(self):
        if str_to_bool(self.get("USE_MANAGED_IDENTITY", "False")):
            return DefaultAzureCredential()
        else:
            return ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"), 
                client_id=self.get("AZURE_CLIENT_ID"), 
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
    
    def set_certificate_path(self, path: str):
        try:
            if not os.path.isabs(path):
                path = os.path.abspath(path)
            if not is_file_readable(path):
                raise FileNotFoundError(f"The file '{path}' does not exist or is not readable")
            
            self.set("REQUESTS_CA_BUNDLE", path)
            self.set("SSL_CERT_FILE", path)
            self.set("CURL_CA_BUNDLE", path)
        except Exception as e:
            logger.error(f"Error setting certificate path: {e}")
            raise
    
    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        try:
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
            if not is_file_readable(dotenvfile):
                logger.warning(f"Environment file not found or not readable: {dotenvfile}")
                return
                
            temp_dict = dotenv_values(dotenvfile)
            for key, value in temp_dict.items():
                self.set(key, value, print_val)
            del temp_dict
        except Exception as e:
            logger.error(f"Error loading environment variables from {dotenvfile}: {e}")
            raise
    
    def set(self, key: str, value: str, print_val: bool = False) -> None:
        try:
            os.environ[key] = value
            if key not in self.var_list:
                self.var_list.append(key)
            if print_val:
                logger.info(f"{key}: {value}")
        except Exception as e:
            logger.error(f"Error setting environment variable {key}: {e}")
            raise
    
    def get(self, key: str, default: Optional[str] = None) -> str:
        try:
            return os.environ.get(key, default)
        except Exception as e:
            logger.error(f"Error getting environment variable {key}: {e}")
            raise
    
    def set_proxy(self) -> None:
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            if not all([ad_username, ad_password, proxy_domain]):
                raise ValueError("Proxy settings are incomplete")
            proxy_url = f"https://{ad_username}:{ad_password}@{proxy_domain}"
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains), print_val=False)
        except Exception as e:
            logger.error(f"Error setting proxy: {e}")
            raise
    
    def get_azure_token(self) -> str:
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token set")
            return token.token
        except Exception as e:
            logger.error(f"Error retrieving Azure token: {e}")
            return None
    
    def list_env_vars(self) -> None:
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [REDACTED]")
            else:
                logger.info(f"{var}: {os.getenv(var)}")


class AzureChatbot:
    """Azure OpenAI chatbot with Instructor integration"""
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
        self._setup_instructor_client()
    
    def _setup_chat_model(self):
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            temperature = float(self.env.get("TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2023-05-15")
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token_provider=token_provider
            )
        except Exception as e:
            logger.error(f"Error setting up chatbot: {e}")
            raise
    
    def _setup_instructor_client(self):
        try:
            # Create the direct Azure client for instructor
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            api_version = self.env.get("API_VERSION", "2023-05-15")
            
            direct_client = AzureOpenAI(
                azure_endpoint=azure_endpoint,
                api_version=api_version,
                azure_ad_token_provider=get_bearer_token_provider(
                    self.env.credential,
                    "https://cognitiveservices.azure.com/.default"
                )
            )
            
            # Apply instructor to the client
            self.instructor_client = instructor.from_openai(direct_client)
            logger.info("Instructor client set up successfully")
        except Exception as e:
            logger.error(f"Error setting up instructor client: {e}")
            raise
    
    def query(self, user_input: str) -> str:
        """Standard chat query that returns a text response"""
        try:
            return self.conversation.predict(input=user_input)
        except Exception as e:
            logger.error(f"Error in chat query: {e}")
            return f"Error: {str(e)}"
    
    def structured_query(self, user_input: str, response_model: Type[T]) -> T:
        """
        Query that returns a structured response using instructor and Pydantic model
        
        Args:
            user_input: The user's query text
            response_model: A Pydantic model class defining the expected response structure
            
        Returns:
            An instance of the response_model populated with extracted data
        """
        try:
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            
            # Use instructor to get structured output
            result = self.instructor_client.chat.completions.create(
                model=model_name,
                response_model=response_model,
                messages=[
                    {"role": "user", "content": user_input}
                ]
            )
            
            # Add the interaction to memory for context
            self.memory.save_context(
                {"input": user_input}, 
                {"output": f"Extracted structured data: {result.model_dump_json()}"}
            )
            
            return result
        except Exception as e:
            logger.error(f"Error in structured query: {e}")
            raise


# Define Pydantic models for structured outputs
class IncidentFeatures(BaseModel):
    """Extracted relevant features from an incident"""
    id: str
    summary: str
    resolution_name: str
    resolution_details: str
    category: str
    subcategory: str
    
    # Extracted indicators that might suggest a data issue
    contains_data_terms: bool = Field(
        description="Whether the incident contains terms related to data issues (e.g., 'data', 'database', 'query', 'missing records', 'corrupt data')"
    )
    contains_system_terms: bool = Field(
        description="Whether the incident contains terms related to system issues (e.g., 'server', 'network', 'hardware', 'connectivity')"
    )
    is_categorized_as_data: bool = Field(
        description="Whether the incident is explicitly categorized as 'Business Process or Usage' or 'database' in category or subcategory"
    )

class ClassificationReason(BaseModel):
    """A single reason supporting the classification with its impact on confidence"""
    reason: str = Field(description="Specific evidence or observation supporting the classification")
    impact: float = Field(description="How much this reason impacts the confidence score (0.0 to 1.0)", ge=0.0, le=1.0)
    
class IncidentClassification(BaseModel):
    """The final classification of an incident"""
    incident_id: str
    is_data_issue: bool
    confidence_score: float = Field(description="Confidence score from 0.0 to 1.0", ge=0.0, le=1.0)
    supporting_reasons: List[ClassificationReason] = Field(
        description="List of reasons supporting this classification"
    )
    contrary_reasons: List[ClassificationReason] = Field(
        description="List of reasons that contradict this classification"
    )
    
class AgentMessage(BaseModel):
    """Message passed between agents"""
    content: str
    metadata: Dict[str, Any] = {}

class ClassificationState(BaseModel):
    """The state maintained throughout the classification process"""
    incident: Optional[IncidentFeatures] = None
    feature_extraction_complete: bool = False
    preliminary_classification: Optional[IncidentClassification] = None
    final_classification: Optional[IncidentClassification] = None
    
    # Messages between agents
    messages: List[AgentMessage] = Field(default_factory=list)
    current_agent: str = "feature_extractor"
    
    # Additional metadata
    metadata: Dict[str, Any] = Field(default_factory=dict)

# Multi-agent system for incident classification
class IncidentClassifier:
    """Multi-agent system for classifying IT incidents as data issues"""
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        # Initialize the chatbot for agent operations
        self.chatbot = AzureChatbot(
            config_file=config_file, 
            creds_file=creds_file, 
            cert_file=cert_file
        )
        
        # Create the state graph
        self.graph = self._build_graph()
        
    def _build_graph(self):
        """Build the LangGraph for the multi-agent system"""
        # Define the graph
        graph = StateGraph(ClassificationState)
        
        # Add nodes to the graph
        graph.add_node("feature_extractor", self.feature_extractor)
        graph.add_node("classifier", self.classifier)
        graph.add_node("reasoning_agent", self.reasoning_agent)
        graph.add_node("confidence_evaluator", self.confidence_evaluator)
        
        # Add edges to connect the nodes
        graph.add_edge("feature_extractor", "classifier")
        graph.add_edge("classifier", "reasoning_agent")
        graph.add_edge("reasoning_agent", "confidence_evaluator")
        graph.add_edge("confidence_evaluator", END)
        
        # Return the compiled graph
        return graph.compile()
    
    def feature_extractor(self, state: ClassificationState) -> ClassificationState:
        """Extract features from the incident text"""
        if state.feature_extraction_complete:
            return state
        
        # Using instructor to enforce structured output for feature extraction
        try:
            features = self.chatbot.structured_query(
                f"""
                Extract key features from this IT incident:
                ID: {state.metadata.get('id', 'Unknown')}
                Summary: {state.metadata.get('summary', '')}
                Resolution Name: {state.metadata.get('resolution_name', '')}
                Resolution Details: {state.metadata.get('resolution_details', '')}
                Category: {state.metadata.get('category', '')}
                Subcategory: {state.metadata.get('subcategory', '')}
                
                Analyze the text and determine if it contains terms related to data issues,
                system issues, and if it's categorized explicitly as a data-related issue.
                """,
                IncidentFeatures
            )
            
            # Update the state with the extracted features
            state.incident = features
            state.feature_extraction_complete = True
            state.current_agent = "classifier"
            
            # Add a message to the state
            state.messages.append(
                AgentMessage(
                    content="Successfully extracted features from the incident",
                    metadata={"agent": "feature_extractor", "success": True}
                )
            )
        except Exception as e:
            logger.error(f"Error in feature extraction: {e}")
            state.messages.append(
                AgentMessage(
                    content=f"Error extracting features: {str(e)}",
                    metadata={"agent": "feature_extractor", "success": False}
                )
            )
        
        return state
    
    def classifier(self, state: ClassificationState) -> ClassificationState:
        """Perform initial classification of the incident"""
        if state.preliminary_classification:
            return state
        
        if not state.incident:
            state.messages.append(
                AgentMessage(
                    content="Cannot classify without extracted features",
                    metadata={"agent": "classifier", "success": False}
                )
            )
            return state
        
        try:
            # Create a simple preliminary classification
            is_data_issue = (
                state.incident.is_categorized_as_data or 
                state.incident.contains_data_terms
            )
            
            # Create an initial classification with a basic confidence score
            classification = IncidentClassification(
                incident_id=state.incident.id,
                is_data_issue=is_data_issue,
                confidence_score=0.7 if is_data_issue else 0.3,
                supporting_reasons=[
                    ClassificationReason(
                        reason=f"Incident {'is' if state.incident.is_categorized_as_data else 'is not'} explicitly categorized as data-related",
                        impact=0.6
                    )
                ],
                contrary_reasons=[]
            )
            
            state.preliminary_classification = classification
            state.current_agent = "reasoning_agent"
            
            state.messages.append(
                AgentMessage(
                    content=f"Initial classification: {'Data issue' if is_data_issue else 'Not a data issue'}",
                    metadata={"agent": "classifier", "success": True}
                )
            )
        except Exception as e:
            logger.error(f"Error in classification: {e}")
            state.messages.append(
                AgentMessage(
                    content=f"Error in classification: {str(e)}",
                    metadata={"agent": "classifier", "success": False}
                )
            )
        
        return state
    
    def reasoning_agent(self, state: ClassificationState) -> ClassificationState:
        """Develop reasoning and evidence for the classification"""
        if not state.preliminary_classification:
            state.messages.append(
                AgentMessage(
                    content="Cannot provide reasoning without preliminary classification",
                    metadata={"agent": "reasoning_agent", "success": False}
                )
            )
            return state
        
        try:
            # Use instructor for structured output
            improved_classification = self.chatbot.structured_query(
                f"""
                Analyze this IT incident in detail and provide reasoning for why it should or should not
                be classified as a data issue:
                
                ID: {state.incident.id}
                Summary: {state.incident.summary}
                Resolution Name: {state.incident.resolution_name}
                Resolution Details: {state.incident.resolution_details}
                Category: {state.incident.category}
                Subcategory: {state.incident.subcategory}
                
                Current classification: 
                - Is data issue: {state.preliminary_classification.is_data_issue}
                - Confidence: {state.preliminary_classification.confidence_score}
                
                Provide a detailed list of supporting reasons (evidence that it IS a data issue)
                and contrary reasons (evidence that it is NOT a data issue).
                
                Each reason should have an impact score (0.0 to 1.0) indicating how much this 
                particular reason should influence the final confidence score.
                """,
                IncidentClassification
            )
            
            # Update the state
            state.final_classification = improved_classification
            state.current_agent = "confidence_evaluator"
            
            state.messages.append(
                AgentMessage(
                    content="Developed detailed reasoning for classification",
                    metadata={"agent": "reasoning_agent", "success": True}
                )
            )
        except Exception as e:
            logger.error(f"Error in reasoning: {e}")
            state.messages.append(
                AgentMessage(
                    content=f"Error in reasoning: {str(e)}",
                    metadata={"agent": "reasoning_agent", "success": False}
                )
            )
            # Fall back to preliminary classification
            state.final_classification = state.preliminary_classification
        
        return state
    
    def confidence_evaluator(self, state: ClassificationState) -> ClassificationState:
        """Evaluate and finalize the confidence score"""
        if not state.final_classification:
            state.messages.append(
                AgentMessage(
                    content="Cannot evaluate confidence without classification",
                    metadata={"agent": "confidence_evaluator", "success": False}
                )
            )
            return state
        
        try:
            # Calculate a final confidence score based on supporting and contrary reasons
            supporting_impact = sum(reason.impact for reason in state.final_classification.supporting_reasons)
            contrary_impact = sum(reason.impact for reason in state.final_classification.contrary_reasons)
            
            total_impact = supporting_impact + contrary_impact
            if total_impact > 0:
                # Normalized confidence between 0.5-1.0 if supporting > contrary, 0.0-0.5 otherwise
                if supporting_impact > contrary_impact:
                    confidence = 0.5 + (0.5 * (supporting_impact - contrary_impact) / total_impact)
                else:
                    confidence = 0.5 - (0.5 * (contrary_impact - supporting_impact) / total_impact)
            else:
                confidence = 0.5  # Neutral confidence if no impacts
            
            # Update the final classification
            state.final_classification.confidence_score = round(confidence, 2)
            
            state.messages.append(
                AgentMessage(
                    content=f"Final confidence score: {state.final_classification.confidence_score}",
                    metadata={"agent": "confidence_evaluator", "success": True}
                )
            )
        except Exception as e:
            logger.error(f"Error in confidence evaluation: {e}")
            state.messages.append(
                AgentMessage(
                    content=f"Error in confidence evaluation: {str(e)}",
                    metadata={"agent": "confidence_evaluator", "success": False}
                )
            )
        
        return state
    
    def classify_incident(self, incident_data: Dict[str, str]) -> IncidentClassification:
        """
        Classify a single incident using the multi-agent system
        
        Args:
            incident_data: Dictionary containing incident fields
            
        Returns:
            IncidentClassification object with classification results
        """
        # Create the initial state
        initial_state = ClassificationState(
            metadata={
                "id": incident_data.get("Id", "Unknown"),
                "summary": incident_data.get("IT_INCIDENT_SUMMARY", ""),
                "resolution_name": incident_data.get("IT_INCIDENT_RESOLUTION_DETAILS_NAME", ""),
                "resolution_details": incident_data.get("IT_INCIDENT_RESOLUTION_DESC", ""),
                "category": incident_data.get("IT_INCIDENT_AREA_CATEGORY", ""),
                "subcategory": incident_data.get("IT_INCIDENT_AREA_SUBCATEGORY", "")
            }
        )
        
        # Run the graph
        try:
            final_state = self.graph.invoke(initial_state)
            return final_state.final_classification
        except Exception as e:
            logger.error(f"Error running classification graph: {e}")
            # Return a fallback classification
            return IncidentClassification(
                incident_id=incident_data.get("Id", "Unknown"),
                is_data_issue=False,
                confidence_score=0.0,
                supporting_reasons=[],
                contrary_reasons=[
                    ClassificationReason(
                        reason=f"Classification failed with error: {str(e)}",
                        impact=1.0
                    )
                ]
            )
    
    def process_csv(self, csv_path: str, output_path: str = None) -> List[IncidentClassification]:
        """
        Process a CSV file containing incident data
        
        Args:
            csv_path: Path to the CSV file
            output_path: Optional path to save results to JSON
            
        Returns:
            List of IncidentClassification objects
        """
        try:
            # Load the CSV
            df = pd.read_csv(csv_path)
            logger.info(f"Loaded {len(df)} incidents from {csv_path}")
            
            # Process each incident
            results = []
            for i, row in df.iterrows():
                logger.info(f"Processing incident {i+1}/{len(df)}: {row.get('Id', 'Unknown')}")
                incident_data = row.to_dict()
                classification = self.classify_incident(incident_data)
                results.append(classification)
                
                # Log the result
                logger.info(
                    f"Incident {classification.incident_id}: "
                    f"{'Data issue' if classification.is_data_issue else 'Not a data issue'} "
                    f"(Confidence: {classification.confidence_score})"
                )
            
            # Save to JSON if output path provided
            if output_path:
                with open(output_path, 'w') as f:
                    json.dump([r.model_dump() for r in results], f, indent=2)
                logger.info(f"Saved results to {output_path}")
            
            return results
        except Exception as e:
            logger.error(f"Error processing CSV: {e}")
            raise


def create_sample_data(csv_path: str):
    """Create a sample CSV with IT incident data for testing"""
    sample_data = [
        {
            "Id": "INC001",
            "IT_INCIDENT_SUMMARY": "Database query timeout affecting customer reports",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Database Optimization",
            "IT_INCIDENT_RESOLUTION_DESC": "Identified slow running query in the customer database. Optimized the query by adding proper indexing and correcting the join conditions.",
            "IT_INCIDENT_AREA_CATEGORY": "Database",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Query Performance"
        },
        {
            "Id": "INC002",
            "IT_INCIDENT_SUMMARY": "Network connectivity issues in Building B",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Router Replacement",
            "IT_INCIDENT_RESOLUTION_DESC": "Found faulty router in Building B that was causing intermittent connectivity issues. Replaced the hardware and verified connectivity.",
            "IT_INCIDENT_AREA_CATEGORY": "Network",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Hardware Failure"
        },
        {
            "Id": "INC003",
            "IT_INCIDENT_SUMMARY": "Missing customer records in monthly report",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Data Correction",
            "IT_INCIDENT_RESOLUTION_DESC": "Found data integrity issue where customer records were being filtered out incorrectly. Fixed the data validation rules and regenerated reports.",
            "IT_INCIDENT_AREA_CATEGORY": "Business Process or Usage",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Data Integrity"
        },
        {
            "Id": "INC004",
            "IT_INCIDENT_SUMMARY": "Application crashing during end-of-month processing",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Memory Allocation",
            "IT_INCIDENT_RESOLUTION_DESC": "Application was running out of memory during large batch processes. Increased memory allocation and optimized the processing algorithm.",
            "IT_INCIDENT_AREA_CATEGORY": "Application",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Performance"
        },
        {
            "Id": "INC005",
            "IT_INCIDENT_SUMMARY": "Duplicate transactions appearing in financial database",
            "IT_INCIDENT_RESOLUTION_DETAILS_NAME": "Transaction Deduplication",
            "IT_INCIDENT_RESOLUTION_DESC": "Identified issue in the transaction processing where network timeouts were causing retries without proper checking. Implemented proper idempotency checks and cleaned up duplicate data.",
            "IT_INCIDENT_AREA_CATEGORY": "Database",
            "IT_INCIDENT_AREA_SUBCATEGORY": "Data Consistency"
        }
    ]
    
    # Create DataFrame and save to CSV
    df = pd.DataFrame(sample_data)
    df.to_csv(csv_path, index=False)
    logger.info(f"Created sample data with {len(df)} incidents")
    return df


def create_config_files():
    """Create sample configuration files if they don't exist"""
    # Create config.env
    if not os.path.exists(CONFIG_PATH):
        with open(CONFIG_PATH, 'w') as f:
            f.write("""MODEL_NAME=gpt-4o-mini
TEMPERATURE=0.1
MAX_TOKENS=1000
API_VERSION=2023-05-15
AZURE_ENDPOINT=https://your-azure-endpoint.openai.azure.com/
""")
        logger.info(f"Created sample config file at {CONFIG_PATH}")
    
    # Create credentials.env
    if not os.path.exists(CREDS_PATH):
        with open(CREDS_PATH, 'w') as f:
            f.write("""AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-client-id
AZURE_CLIENT_SECRET=your-client-secret
USE_MANAGED_IDENTITY=False
SECURED_ENDPOINTS=True
""")
        logger.info(f"Created sample credentials file at {CREDS_PATH}")


def print_classification_results(results: List[IncidentClassification]):
    """Print a summary of the classification results"""
    data_issues = [r for r in results if r.is_data_issue]
    high_confidence = [r for r in results if r.confidence_score >= 0.8]
    
    print("\n===== CLASSIFICATION RESULTS =====")
    print(f"Total incidents analyzed: {len(results)}")
    print(f"Data issues found: {len(data_issues)} ({len(data_issues)/len(results)*100:.1f}%)")
    print(f"High confidence classifications: {len(high_confidence)} ({len(high_confidence)/len(results)*100:.1f}%)")
    
    # Display a few examples
    print("\n===== SAMPLE CLASSIFICATIONS =====")
    for i, result in enumerate(results[:min(3, len(results))]):  # Show first 3 results or fewer
        print(f"\nIncident ID: {result.incident_id}")
        print(f"Classification: {'DATA ISSUE' if result.is_data_issue else 'NOT DATA ISSUE'}")
        print(f"Confidence: {result.confidence_score:.2f}")
        
        print("\nSupporting Reasons:")
        for reason in result.supporting_reasons[:min(2, len(result.supporting_reasons))]:  # Show top 2 reasons
            print(f"- {reason.reason} (Impact: {reason.impact:.2f})")
        
        print("\nContrary Reasons:")
        for reason in result.contrary_reasons[:min(2, len(result.contrary_reasons))]:  # Show top 2 reasons
            print(f"- {reason.reason} (Impact: {reason.impact:.2f})")
        
        if i < min(2, len(results) - 1):  # Don't print separator after last item
            print("\n" + "-" * 50)


def main():
    """Main function to run the IT Incident Classifier"""
    print("IT Incident Data Issue Classifier")
    print("=" * 40)
    
    # Create configuration files if they don't exist
    create_config_files()
    
    # Define paths
    csv_path = "it_incidents.csv"
    output_path = "classification_results.json"
    
    # Create sample data if CSV doesn't exist
    if not os.path.exists(csv_path):
        print(f"Sample CSV not found at {csv_path}, creating a sample dataset...")
        create_sample_data(csv_path)
    
    # Check if configuration is set up properly
    if not os.path.exists(CONFIG_PATH) or not os.path.exists(CREDS_PATH):
        print("Error: Configuration files not found.")
        print(f"Please configure {CONFIG_PATH} and {CREDS_PATH} with your Azure OpenAI credentials.")
        return
    
    # Ask for confirmation before proceeding
    print("\nThis script will:")
    print("1. Connect to Azure OpenAI using your credentials")
    print("2. Process IT incidents from the CSV file")
    print("3. Classify each incident as a data issue or not")
    print("4. Save results to a JSON file")
    
    proceed = input("\nDo you want to proceed? (y/n): ").lower()
    if proceed != 'y':
        print("Exiting...")
        return
    
    try:
        # Initialize the classifier
        print("\nInitializing IT Incident Classifier...")
        classifier = IncidentClassifier()
        
        # Process the CSV
        print(f"Processing incidents from {csv_path}...")
        results = classifier.process_csv(csv_path, output_path)
        
        # Print results
        print_classification_results(results)
        print(f"\nResults saved to {output_path}")
        
    except Exception as e:
        logger.error(f"Error running classifier: {e}")
        print(f"\nError: {str(e)}")
        print("\nTroubleshooting tips:")
        print("1. Check your Azure OpenAI credentials in the env files")
        print("2. Verify that your Azure OpenAI service is set up correctly")
        print("3. Ensure you have the required Python packages installed")
        
        # Provide more detailed error information
        import traceback
        print("\nDetailed error:")
        traceback.print_exc()


if __name__ == "__main__":
    main()
