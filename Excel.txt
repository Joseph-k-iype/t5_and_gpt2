import os
from langchain.chat_models import AzureChatOpenAI
from langchain_community.graphs.index_creator import GraphIndexCreator
from langchain_community.chains.graph_qa.base import GraphQAChain
from langchain.vectorstores import Chroma
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor
from chromadb.config import Settings

# Your custom imports
from azoai_embedding_client import EmbeddingClient, Document as AzoaiDocument
from genai_env_setup import OSEnv
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings

class EmbeddingClientLangChainAdapter(Embeddings):
    def __init__(self, embedding_client: EmbeddingClient, embeddings_model: str = "text-embedding-3-large"):
        self.embedding_client = embedding_client
        self.embeddings_model = embeddings_model

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        embeddings = []
        for txt in texts:
            doc = AzoaiDocument(text=txt, id="")
            updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
            embeddings.append(updated_doc.embedding)
        return embeddings

    def embed_query(self, text: str) -> list[float]:
        doc = AzoaiDocument(text=text, id="")
        updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
        return updated_doc.embedding

class SemanticSearchAgent:
    """
    Creates a single knowledge graph from multiple docs and a Chroma vector store.
    Uses AzureChatOpenAI with azure_endpoint, azure_api_version, azure_ad_token (no single quotes).
    """
    def __init__(self, kb, env: OSEnv):
        self.kb = kb
        self.env = env

        # 1) Set environment -> sets azure_ad_token, etc.
        self.env.set_azure_token()

        # 2) Embedding client
        embedding_client = EmbeddingClient()
        self.embedding = EmbeddingClientLangChainAdapter(embedding_client)

        # 3) Chroma settings
        CHROMA_SETTINGS = Settings(
            anonymized_telemetry=False,
            persist_directory="chromadb-data"
        )

        # 4) Build a Chroma vector store
        self.vs = Chroma.from_documents(
            documents=self.kb.docs,
            embedding=self.embedding,
            collection_name="kb_collection",
            client_settings=CHROMA_SETTINGS
        )

        # 5) AzureChatOpenAI with correct environment variables (NO extra quotes)
        self.llm = AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),       # No single quotes
            azure_api_version=os.getenv("AZURE_OPENAI_API_VERSION"), # No single quotes
            deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
            azure_ad_token=os.getenv("azure_ad_token")               # set by OSEnv, no quotes
        )

        # 6) Build a knowledge graph from docs (loop + from_text)
        graph_creator = GraphIndexCreator(llm=self.llm)
        main_graph = graph_creator.graph_type()  # Empty NetworkxEntityGraph

        for doc in self.kb.docs:
            partial_graph = graph_creator.from_text(doc.page_content)
            for triple in partial_graph.get_triples():
                main_graph.add_triple(triple)

        self.graph = main_graph
        self.graph_qa_chain = GraphQAChain.from_llm(self.llm, graph=self.graph)

        # 7) Tools for the agent
        self.tools = [
            Tool(
                name="GraphQATool",
                func=self._graph_qa,
                description="Query the knowledge graph for relationships/definitions."
            ),
            Tool(
                name="VectorStoreSearch",
                func=self._vectorstore_search,
                description="Find semantically similar definitions with confidence, rating, reason."
            ),
        ]

        # 8) Create an Agent
        prefix = """You are an AI assistant with access to the following tools:"""
        suffix = """Begin!"""
        prompt = ZeroShotAgent.create_prompt(
            self.tools,
            prefix=prefix,
            suffix=suffix,
            input_variables=["input"]
        )
        agent = ZeroShotAgent(llm=self.llm, tools=self.tools, prompt=prompt, verbose=True)
        self.agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=self.tools, verbose=True)

    def _graph_qa(self, query: str) -> str:
        return self.graph_qa_chain.run(query)

    def _vectorstore_search(self, query: str) -> str:
        results = self.vs.similarity_search_with_score(query, k=3)
        if not results:
            return "No relevant matches found."

        lines = []
        for idx, (doc, score) in enumerate(results, start=1):
            confidence = max(0.0, min(1.0, 1.0 - score))
            if confidence >= 0.8:
                rating = "Green"
            elif confidence >= 0.5:
                rating = "Amber"
            else:
                rating = "Red"

            reason = (
                f"Confidence is {confidence:.2f}, which falls into {rating}. "
                f"Definition matched: {doc.page_content}"
            )
            line = (
                f"Match #{idx}\n"
                f"Name: {doc.metadata.get('name', 'Unknown')}\n"
                f"ID: {doc.metadata.get('id', 'No ID found')}\n"
                f"Confidence: {confidence:.2f}\n"
                f"Rating: {rating}\n"
                f"Reason: {reason}\n"
            )
            lines.append(line)

        return "\n".join(lines)

    def run_query(self, query: str) -> str:
        return self.agent_executor.run(query)
