import os
import sys
import json
import logging
import re
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Dict, List

# (Assume all the previously defined classes, functions, and imports remain here.)

# Helper function to process a single data item
def process_item(item: Dict[str, Any], bot: AzureChatbot) -> Dict[str, Any]:
    try:
        # Ensure that the name and definition are strings, then clean them.
        cleaned_name = clean_text(str(item.get("name", "")))
        cleaned_definition = clean_text(str(item.get("definition", "")))
        cleaned_item = {"name": cleaned_name, "definition": cleaned_definition}
        
        # Run classification using the cleaned input.
        classification_result = bot.classify_data(cleaned_item)
        return {"input": cleaned_item, "result": classification_result}
    except Exception as e:
        logger.error(f"Error processing item {item}: {e}")
        return {"input": item, "error": str(e)}

def main():
    input_filename = "input_data.json"
    
    # Load the input JSON file (supports a list of objects)
    try:
        with open(input_filename, "r") as infile:
            input_data = json.load(infile)
        # If the input is a single dict, wrap it in a list
        if isinstance(input_data, dict):
            input_data = [input_data]
        elif isinstance(input_data, list):
            for item in input_data:
                if "name" not in item or "definition" not in item:
                    raise ValueError("Each object in the JSON list must contain 'name' and 'definition' keys.")
        else:
            raise ValueError("Input JSON must be an object or a list of objects.")
    except Exception as e:
        logger.error(f"Error reading input file: {e}")
        sys.exit(1)
    
    # Initialize the chatbot and classification workflow once.
    bot = AzureChatbot(CONFIG_PATH, CREDS_PATH, CERT_PATH)
    
    results = []
    # Adjust max_workers as needed; too many might hit rate limits.
    max_workers = 20
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_item, item, bot) for item in input_data]
        for future in as_completed(futures):
            results.append(future.result())
    
    # Save the results as a JSON file.
    output_json_file = "isr_results.json"
    try:
        with open(output_json_file, "w") as outfile:
            json.dump(results, outfile, indent=2)
        logger.info(f"Classification results saved to {output_json_file}")
    except Exception as e:
        logger.error(f"Error saving JSON result: {e}")
    
    # Convert the JSON result to CSV using pandas.
    try:
        df = pd.json_normalize(results)
        output_csv_file = "isr_results.csv"
        df.to_csv(output_csv_file, index=False)
        logger.info(f"Classification results converted and saved to {output_csv_file}")
    except Exception as e:
        logger.error(f"Error converting result to CSV: {e}")

if __name__ == "__main__":
    main()
