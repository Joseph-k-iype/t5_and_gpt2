import os
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings
from langchain.chat_models import AzureChatOpenAI
from langchain.vectorstores import Chroma
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor

# Community Graph imports
from langchain_community.graphs.index_creator import GraphIndexCreator
from langchain_community.graphs.networkx_graph import NetworkxEntityGraph
from langchain_community.chains.graph_qa.base import GraphQAChain

# Chroma config
from chromadb.config import Settings

# Your custom imports
from azoai_embedding_client import EmbeddingClient, Document as AzoaiDocument
from genai_env_setup import OSEnv  # Make sure set_azure_token() sets azure_ad_token

###############################################################################
# EmbeddingClientLangChainAdapter
###############################################################################
class EmbeddingClientLangChainAdapter(Embeddings):
    """
    Adapter that implements the interface LangChain expects:
      - embed_documents(List[str]) -> List[List[float]]
      - embed_query(str) -> List[float]

    Internally calls EmbeddingClient.generate_embeddings(document).
    """
    def __init__(self, embedding_client: EmbeddingClient, embeddings_model: str = "text-embedding-3-large"):
        self.embedding_client = embedding_client
        self.embeddings_model = embeddings_model

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        embeddings = []
        for txt in texts:
            # Pass id="", so pydantic sees 'id' field (avoiding validation error)
            doc = AzoaiDocument(text=txt, id="")
            updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
            embeddings.append(updated_doc.embedding)
        return embeddings

    def embed_query(self, text: str) -> list[float]:
        doc = AzoaiDocument(text=text, id="")
        updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
        return updated_doc.embedding


###############################################################################
# SemanticSearchAgent: builds a single knowledge graph by merging partial graphs
###############################################################################
class SemanticSearchAgent:
    """
    - Merges knowledge from each doc by calling GraphIndexCreator.from_text(doc_text).
    - Creates a Chroma vector store for semantic search.
    - Defines a multi-tool agent:
        1) GraphQATool -> answers questions from the merged knowledge graph
        2) VectorStoreSearch -> returns top matches from the vector store
           with confidence, rating (R/A/G), and reason.
    """
    def __init__(self, kb, env: OSEnv):
        self.kb = kb
        self.env = env

        # 1) Environment setup -> sets azure_ad_token, etc.
        self.env.set_azure_token()

        # 2) Instantiate your EmbeddingClient
        embedding_client = EmbeddingClient()

        # 3) Wrap it with the adapter
        self.embedding = EmbeddingClientLangChainAdapter(embedding_client)

        # 4) Create Chroma settings (persist data in "chromadb-data")
        CHROMA_SETTINGS = Settings(
            anonymized_telemetry=False,
            persist_directory="chromadb-data"
        )

        # 5) Build a Chroma vector store from the documents
        self.vs = Chroma.from_documents(
            documents=self.kb.docs,
            embedding=self.embedding,
            collection_name="kb_collection",
            client_settings=CHROMA_SETTINGS
        )

        # 6) Create an LLM that uses Azure OpenAI with azure_endpoint (no openai_api_base)
        self.llm = AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),    # e.g. "https://YOUR-RESOURCE.openai.azure.com"
            azure_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),  # e.g. "2023-03-15-preview"
            deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
            azure_ad_token=os.getenv("azure_ad_token"),           # set by OSEnv
        )

        # 7) Merge partial graphs from each doc
        #    GraphIndexCreator has only from_text() for a single text -> partial graph
        #    We'll combine them into one main NetworkxEntityGraph
        graph_creator = GraphIndexCreator(llm=self.llm, graph_type=NetworkxEntityGraph)
        main_graph = graph_creator.graph_type()  # an empty NetworkxEntityGraph

        # For each doc, call from_text(...) and merge the resulting partial graph
        for doc in self.kb.docs:
            partial_graph = graph_creator.from_text(doc.page_content)
            # Merge partial_graph's triples into main_graph
            for triple in partial_graph.get_triples():
                main_graph.add_triple(triple)

        self.graph = main_graph  # the merged knowledge graph

        # 8) Create a Graph QA chain for knowledge-graph queries
        self.graph_qa_chain = GraphQAChain.from_llm(self.llm, graph=self.graph)

        # 9) Define Tools for the agent
        self.tools = [
            Tool(
                name="GraphQATool",
                func=self._graph_qa,
                description=(
                    "Use this to query the knowledge graph for relationships, "
                    "hierarchies, or definitions found in the CSV-based knowledge."
                ),
            ),
            Tool(
                name="VectorStoreSearch",
                func=self._vectorstore_search,
                description=(
                    "Use this to find semantically similar definitions in the CSV-based knowledge. "
                    "It returns top matches with confidence, R/A/G rating, and a reason."
                ),
            ),
        ]

        # 10) Create an Agent that can call these Tools
        prefix = """You are an AI assistant with access to the following tools:"""
        suffix = """Begin!"""
        prompt = ZeroShotAgent.create_prompt(
            self.tools,
            prefix=prefix,
            suffix=suffix,
            input_variables=["input"]
        )

        agent = ZeroShotAgent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt,
            verbose=True
        )
        self.agent_executor = AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=self.tools,
            verbose=True
        )

    def _graph_qa(self, query: str) -> str:
        """Use GraphQAChain to answer a question by traversing the knowledge graph."""
        return self.graph_qa_chain.run(query)

    def _vectorstore_search(self, query: str) -> str:
        """
        Search the Chroma vector store for the top 3 matches.
        Provide:
         - Confidence (0â€“1, from cosine similarity or 1 - distance)
         - Red/Amber/Green rating
         - Reason for the rating
        """
        results = self.vs.similarity_search_with_score(query, k=3)
        if not results:
            return "No relevant matches found."

        lines = []
        for idx, (doc, score) in enumerate(results, start=1):
            # If 'score' is distance, confidence = 1 - distance
            confidence = max(0.0, min(1.0, 1.0 - score))

            # Determine R/A/G rating
            if confidence >= 0.8:
                rating = "Green"
            elif confidence >= 0.5:
                rating = "Amber"
            else:
                rating = "Red"

            # Basic reason text
            reason = (
                f"Confidence is {confidence:.2f}, which falls into the {rating} range. "
                f"Definition matched: {doc.page_content}"
            )

            line = (
                f"Match #{idx}\n"
                f"Name: {doc.metadata.get('name', 'Unknown')}\n"
                f"ID: {doc.metadata.get('id', 'No ID found')}\n"
                f"Confidence: {confidence:.2f}\n"
                f"Rating: {rating}\n"
                f"Reason: {reason}\n"
            )
            lines.append(line)

        return "\n".join(lines)

    def run_query(self, query: str) -> str:
        """Send the query to the multi-tool agent. The agent decides which tool(s) to call."""
        return self.agent_executor.run(query)
