import logging
from typing import List, Dict, Any
from langchain.chat_models import AzureChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory

logger = logging.getLogger(__name__)

class AzureChatbot:
    def __init__(self, config_file: str, creds_file: str, cert_file: str):
        logger.info("Initializing chatbot...")
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()

    def _setup_chat_model(self) -> None:
        # Instead of azure_endpoint, we do openai_api_base
        openai_api_base = self.env.get("OPENAI_API_BASE")  # from your new .env variable
        if not openai_api_base:
            raise ValueError("Missing OPENAI_API_BASE. Please set in .env (e.g. 'https://my-resource.openai.azure.com').")

        openai_api_version = self.env.get("API_VERSION", "2023-05-15")
        deployment_name = self.env.get("MODEL_NAME", "gpt-4o-mini")  # your Azure deployment name
        temperature = float(self.env.get("MODEL_TEMPERATURE", "0.7"))
        max_tokens = int(self.env.get("MAX_TOKENS", "800"))

        # Must have an AD token if using azure_ad
        if not self.env.token:
            raise ValueError("Missing Azure AD token. Please set SECURED_ENDPOINTS=True and provide credentials.")

        # Use new param style for Azure Chat in LangChain
        self.llm = AzureChatOpenAI(
            openai_api_base=openai_api_base,
            openai_api_version=openai_api_version,
            openai_api_type="azure_ad",    # for bearer token usage
            openai_api_key=self.env.token, # pass your bearer token here
            deployment_name=deployment_name,
            temperature=temperature,
            max_tokens=max_tokens,
        )

        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
        logger.info("Chat model initialized successfully")

    def validate_matches(self, query: str, matches: List[Dict[str, Any]]) -> str:
        prompt = f"""You are an expert validation agent. Given the query:
"{query}"
and the following candidate matches:
"""
        for idx, match in enumerate(matches, start=1):
            prompt += f"\n{idx}. Name: {match.get('name')}\n   Definition: {match.get('definition')}\n"
        prompt += "\nIf these matches are satisfactory, simply reply OK. Otherwise, suggest the best matching candidate..."

        try:
            response = self.conversation.predict(input=prompt)
            return response.strip()
        except Exception as e:
            logger.error(f"Validation agent error: {str(e)}")
            return "Validation failed"

    def chat(self, message: str) -> str:
        if not message.strip():
            return "Please provide a non-empty message."
        try:
            response = self.conversation.predict(input=message)
            return response
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return f"An error occurred: {str(e)}"
