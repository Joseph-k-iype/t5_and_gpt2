#!/usr/bin/env python3
"""
Chunked Prompt Approach for Matching:
-------------------------------------
We have:
- source.csv => columns: [name, definition]
- target.csv => columns: [pbt-name, pbt-definition]

We want to find the best "pbt-name" match for each "name", using Azure Chat 
(GPT) via your existing OSEnv logic, but without exceeding the model's 
128k token context limit.

Implementation:
1) Load CSVs.
2) For each row in source.csv, chunk the target PBT list into smaller pieces.
3) "Tournament" style queries: pick the best from each chunk, 
   then unify the winners until 1 final best remains.
4) Save results to CSV/JSON.

This solution avoids sending a massive single prompt that might exceed 
128k tokens (which was causing a 194382-token error).
"""

import os
import time
import json
import logging
from pathlib import Path
from typing import List, Dict, Tuple, Optional
import pandas as pd

from azure.identity import ClientSecretCredential
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

#############################
#   OSEnv Class (as before)
#############################
def is_file_readable(filepath: str) -> bool:
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str) -> bool:
    s_lower = s.strip().lower()
    if s_lower == 'true':
        return True
    elif s_lower == 'false':
        return False
    else:
        raise ValueError(f"Invalid boolean string: {s}")

class OSEnv:
    """
    Minimal environment loader. 
    (Adjust if you still want proxy/cert logic from your original OSEnv code.)
    """

    def __init__(self, config_file: str, creds_file: str, cert_file: str):
        self.var_list = []
        self._load_env_file(config_file, print_val=True)
        self._load_env_file(creds_file, print_val=False)
        
        # Optionally handle certificate
        cert_abs = os.path.abspath(cert_file)
        if os.path.isfile(cert_abs):
            os.environ["REQUESTS_CA_BUNDLE"] = cert_abs
            os.environ["SSL_CERT_FILE"] = cert_abs
            os.environ["CURL_CA_BUNDLE"] = cert_abs
            logger.info(f"Using certificate: {cert_abs}")

        # If SECURED_ENDPOINTS => get token
        if str_to_bool(self.get("SECURED_ENDPOINTS", "false")):
            self.token = self._get_azure_token()
        else:
            self.token = None

    def _load_env_file(self, file_path: str, print_val: bool):
        if os.path.isfile(file_path):
            with open(file_path) as f:
                for line in f:
                    line=line.strip()
                    if line and not line.startswith("#"):
                        key_val = line.split("=", 1)
                        if len(key_val)==2:
                            k, v = key_val
                            k = k.strip()
                            v = v.strip().strip("'\"")
                            os.environ[k] = v
                            if k not in self.var_list:
                                self.var_list.append(k)
                            if print_val:
                                logger.info(f"Set {k}={v}")

    def get(self, key: str, default_val:str="") -> str:
        return os.getenv(key, default_val)

    def _get_azure_token(self) -> str:
        try:
            tenant_id = self.get("AZURE_TENANT_ID")
            client_id = self.get("AZURE_CLIENT_ID")
            client_secret = self.get("AZURE_CLIENT_SECRET")
            credential = ClientSecretCredential(tenant_id, client_id, client_secret)
            token_obj = credential.get_token("https://cognitiveservices.azure.com/.default")
            logger.info("Got AAD token for Azure OpenAI")
            return token_obj.token
        except Exception as e:
            logger.error(f"Failed to get token: {str(e)}")
            raise

#############################
#   ChunkedChatbot Class
#############################
class ChunkedChatbot:
    """
    Uses AzureChatOpenAI with chunked prompts to avoid exceeding 128k tokens.
    """

    def __init__(self, env: OSEnv):
        self.env = env
        self._setup_chat_model()
        # Adjust chunk size as needed for your environment
        self.chunk_size = int(self.env.get("CHUNK_SIZE", "50"))

    def _setup_chat_model(self):
        model_name = self.env.get("MODEL_NAME","gpt-4")
        temperature = float(self.env.get("MODEL_TEMPERATURE","0.7"))
        max_tokens = int(self.env.get("MAX_TOKENS","800"))
        api_version = self.env.get("API_VERSION","2023-03-15-preview")
        endpoint = self.env.get("AZURE_OPENAI_ENDPOINT","")
        azure_ad_token = self.env.token

        self.llm = AzureChatOpenAI(
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            openai_api_version=api_version,
            azure_endpoint=endpoint,
            azure_ad_token=azure_ad_token
        )
        logger.info(f"Chat model {model_name} set up with temperature={temperature}, max_tokens={max_tokens}")

    ############################
    #   Multi-step CHUNK logic
    ############################
    def pick_best_pbt_in_chunk(
        self, 
        name: str, 
        definition: str, 
        pbt_chunk: List[Dict[str,str]]
    ) -> Dict[str,str]:
        """
        Return a single PBT (as dict: {"pbt-name":"...", "pbt-definition":"..."}) 
        from this chunk that best matches 'name'/'definition'.
        """
        system_prompt = (
            "You are an assistant that picks exactly one best-matching PBT from a chunk. "
            "Return only the pbt-name and pbt-definition. Do not mention anything else."
        )
        user_prompt = (
            f"Original Name: {name}\n"
            f"Original Definition: {definition}\n\n"
            f"Here is a chunk of PBTs:\n"
        )

        # Add chunk content
        for idx, pbt in enumerate(pbt_chunk, start=1):
            user_prompt += (
                f"({idx}) pbt-name: {pbt['pbt-name']}\n"
                f"    pbt-definition: {pbt['pbt-definition']}\n\n"
            )

        user_prompt += (
            "Among these, which single pbt-name best matches the original concept? "
            "Return your final answer in JSON with keys pbt-name and pbt-definition."
        )

        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]
        try:
            response = self.llm(messages)
            ans = response.content.strip()
            # We'll do a naive parse looking for pbt-name and pbt-definition
            # If the model is well-instructed, it might produce e.g.:
            # { "pbt-name": "Customer ID", "pbt-definition": "A unique identification..." }
            # We'll try a simple parse:
            best = self._extract_pbt_from_json(ans)
            return best
        except Exception as e:
            logger.error(f"Error picking best from chunk: {e}")
            # fallback: just pick the first if error
            return pbt_chunk[0]

    def _extract_pbt_from_json(self, text:str) -> Dict[str,str]:
        """
        Very naive parse. 
        Looks for "pbt-name" and "pbt-definition" in the text. 
        Improve as needed or instruct the model to output valid JSON.
        """
        import re
        # Regex approach. If not found, fallback.
        name_match = re.search(r'"pbt-name"\s*:\s*"([^"]+)"', text)
        def_match = re.search(r'"pbt-definition"\s*:\s*"([^"]+)"', text)

        if name_match and def_match:
            return {
                "pbt-name": name_match.group(1),
                "pbt-definition": def_match.group(1)
            }
        else:
            # If parse fails, fallback
            return {
                "pbt-name": "UNKNOWN",
                "pbt-definition": "UNKNOWN"
            }

    def pick_best_pbt_across_all(
        self, 
        name:str, 
        definition:str, 
        pbt_list: List[Dict[str,str]]
    ) -> Dict[str,str]:
        """
        1) Break pbt_list into chunks
        2) For each chunk, pick best with pick_best_pbt_in_chunk
        3) If multiple chunk-winners, do a "tournament" until only 1 remains
        """
        # Step 1: chunk
        chunks = [
            pbt_list[i : i+self.chunk_size] 
            for i in range(0, len(pbt_list), self.chunk_size)
        ]
        logger.info(f"Number of chunks: {len(chunks)} (chunk_size={self.chunk_size}).")

        # Step 2: get chunk winners
        winners = []
        for c_idx, chunk in enumerate(chunks, start=1):
            logger.info(f"Processing chunk {c_idx}/{len(chunks)} with size={len(chunk)}")
            winner = self.pick_best_pbt_in_chunk(name, definition, chunk)
            winners.append(winner)

        # Step 3: if winners > 1, do a tournament approach
        # keep going until we have 1 final winner
        while len(winners) > 1:
            logger.info(f"Tournament round with {len(winners)} winners to compare.")
            new_winners = []
            # chunk the "winners" again
            chunked_winners = [
                winners[i : i+self.chunk_size]
                for i in range(0, len(winners), self.chunk_size)
            ]
            for w_chunk in chunked_winners:
                if len(w_chunk)==1:
                    new_winners.append(w_chunk[0])
                else:
                    # pick best from this chunk of winners
                    w = self.pick_best_pbt_in_chunk(name, definition, w_chunk)
                    new_winners.append(w)
            winners = new_winners

        # final single winner
        if winners:
            return winners[0]
        else:
            return {
                "pbt-name": "NO MATCH",
                "pbt-definition": "NO MATCH"
            }

############################
#       main()
############################
def main():
    """
    1) Load env + CSVs
    2) For each row in source, chunk + do multi-step picking
    3) Save results
    """
    try:
        base_dir = Path(__file__).parent.parent
        env_dir = base_dir / "env"
        data_dir = base_dir / "data"
        output_dir = base_dir / "output"
        log_dir = base_dir / "logs"

        for directory in [env_dir, data_dir, output_dir, log_dir]:
            directory.mkdir(exist_ok=True)

        config_file = env_dir / "config.env"
        creds_file = env_dir / "credentials.env"
        cert_file = env_dir / "cacert.pem"
        source_csv = data_dir / "source.csv"
        target_csv = data_dir / "target.csv"

        missing = []
        for f in [config_file, creds_file, cert_file, source_csv, target_csv]:
            if not f.exists():
                missing.append(str(f))
        if missing:
            logger.error(f"Missing required files: {missing}")
            return

        # 1) ENV
        env_setup = OSEnv(str(config_file), str(creds_file), str(cert_file))

        # 2) Chat Model with chunk logic
        chatbot = ChunkedChatbot(env_setup)

        # 3) Load CSVs
        src_df = pd.read_csv(str(source_csv)).fillna("")
        tgt_df = pd.read_csv(str(target_csv)).fillna("")
        if not {"name","definition"}.issubset(src_df.columns):
            raise ValueError("source.csv must have columns: [name, definition]")
        if not {"pbt-name","pbt-definition"}.issubset(tgt_df.columns):
            raise ValueError("target.csv must have columns: [pbt-name, pbt-definition]")

        pbt_list = tgt_df.to_dict("records")
        logger.info(f"Source size={len(src_df)}, Target size={len(pbt_list)}")

        # 4) For each row, do chunked approach
        results = []
        for idx, row in src_df.iterrows():
            name_val = row["name"]
            def_val = row["definition"]
            logger.info(f"Row {idx+1}/{len(src_df)} => name='{name_val}'")

            best_pbt = chatbot.pick_best_pbt_across_all(name_val, def_val, pbt_list)
            results.append({
                "source_name": name_val,
                "source_definition": def_val,
                "best_pbt_name": best_pbt["pbt-name"],
                "best_pbt_definition": best_pbt["pbt-definition"]
            })

        # 5) Save results
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        out_csv = output_dir / f"matches_{timestamp}.csv"
        pd.DataFrame(results).to_csv(str(out_csv), index=False)

        out_json = out_csv.with_suffix(".json")
        with open(out_json,"w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\nDone! Results saved:\n  - {out_csv}\n  - {out_json}")

    except Exception as e:
        logger.exception(f"Unexpected error: {str(e)}")
        print(f"Error: {str(e)}")

if __name__=="__main__":
    main()
