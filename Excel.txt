import os
import sys
import uuid
import json
import logging
import chardet
import re  # Added for enhanced normalization
import pandas as pd
import networkx as nx
from typing import Optional, Dict, Any, List, Union
from pathlib import Path

from dotenv import dotenv_values
from azure.identity import ClientSecretCredential, DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI
from pydantic import BaseModel

# LangChain + Chroma
from langchain.chat_models import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from chromadb.config import Settings

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ... [Keep all constants and OSEnv class unchanged] ...

class QualityCheckChain:
    """
    Enhanced version with robust key normalization and error handling
    """
    def __init__(self, llm):
        self.llm = llm

        template = """
You MUST return JSON with exactly these 2 fields: "rating" and "reason".
Rating must be one of ["Green","Amber","Red"]. Example:
{{
  "rating": "Green",
  "reason": "Strong match"
}}

User input: {user_input}
Candidate doc: {candidate_doc}"""
        self.prompt = PromptTemplate(
            input_variables=["user_input", "candidate_doc"],
            template=template
        )
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)

    def _normalize_keys(self, data: dict) -> dict:
        """Atomic key normalization handling all edge cases"""
        normalized = {}
        for k, v in data.items():
            # Remove all non-alphanumeric/underscore characters
            new_k = re.sub(r'[^\w]', '', k)
            # Convert to lowercase
            new_k = new_k.lower()
            normalized[new_k] = v
        return normalized

    def check_quality(self, user_input: str, candidate_doc: str) -> Dict[str, str]:
        """Robust quality checking with enhanced parsing"""
        try:
            resp = self.chain.run(
                user_input=user_input,
                candidate_doc=candidate_doc
            ).strip()
            
            logger.debug(f"LLM Response: {resp}")  # Debug logging

            # Attempt 1: Direct parse
            try:
                data = json.loads(resp)
                data = self._normalize_keys(data)
                return {
                    "rating": data.get("rating", "Red"),
                    "reason": data.get("reason", "No reason provided")
                }
            except json.JSONDecodeError:
                pass

            # Attempt 2: Extract JSON substring
            json_str = resp[resp.find('{'):resp.rfind('}')+1]
            try:
                data = json.loads(json_str)
                data = self._normalize_keys(data)
                return {
                    "rating": data.get("rating", "Red"),
                    "reason": data.get("reason", "No reason provided")
                }
            except json.JSONDecodeError:
                return {"rating": "Red", "reason": "Invalid JSON format"}

        except Exception as e:
            logger.error(f"Quality check error: {str(e)}", exc_info=True)
            return {"rating": "Red", "reason": "Evaluation failed"}

class AzureChatbot:
    # ... [Keep existing init and other methods unchanged] ...

    def _setup_vectorstore(self):
        """Explicit cosine similarity configuration"""
        try:
            embedding = AzureOpenAIEmbeddings(
                azure_api_version=self.env.get("EMBEDDINGS_API_VERSION", "2023-05-15"),
                embeddings_model=self.env.get("EMBEDDINGS_MODEL", "text-embedding-3-large")
            )
            
            self.vs = Chroma.from_documents(
                documents=self.kb.docs,
                embedding=embedding,
                collection_name="kb_collection",
                client_settings=Settings(
                    anonymized_telemetry=False,
                    persist_directory="chromadb-data",
                ),
                collection_metadata={"hnsw:space": "cosine"}  # Explicit cosine
            )
            logger.info("Chroma vectorstore initialized with cosine similarity")
        except Exception as e:
            logger.error(f"Vectorstore setup failed: {str(e)}")
            raise

# ... [Keep remaining code identical: run_tests, process_input_json_with_quality, main] ...

if __name__ == "__main__":
    main()
