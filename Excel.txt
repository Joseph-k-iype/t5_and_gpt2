from typing import Dict, Any, List
from pydantic import BaseModel, ValidationError
import logging

logger = logging.getLogger(__name__)

class QualityResult(BaseModel):
    rating: str  # Green/Amber/Red
    reason: str
    confidence: Optional[float] = None
    matched_name: Optional[str] = None
    matched_definition: Optional[str] = None

    @classmethod
    def parse_response(cls, raw: str, confidence: float, name: str, definition: str):
        try:
            # Find JSON substring in response
            start = raw.find('{')
            end = raw.rfind('}') + 1
            json_str = raw[start:end] if start != -1 and end != 0 else raw
            
            # Case-insensitive key matching
            data = json.loads(json_str)
            normalized_data = {k.strip().lower(): v for k, v in data.items()}
            
            return cls(
                rating=normalized_data.get('rating', 'Red').capitalize(),
                reason=normalized_data.get('reason', 'No reason provided'),
                confidence=confidence,
                matched_name=name,
                matched_definition=definition
            )
        except (json.JSONDecodeError, KeyError, ValidationError) as e:
            return cls(
                rating="Red",
                reason=f"Invalid response format: {str(e)}",
                confidence=confidence,
                matched_name=name,
                matched_definition=definition
            )

def rag_quality_check_item(self, name: str, definition: str, top_k: int = 4) -> Dict[str, Any]:
    """
    Full implementation of RAG quality check with:
    - Combined name+definition vector search
    - Top 4 results analysis
    - Pydantic validation
    - Detailed error handling
    """
    results = {
        "input": {"name": name, "definition": definition},
        "matches": [],
        "best_result": None,
        "final_rating": "Red",
        "final_reason": "No valid matches found"
    }

    try:
        # 1. Create combined query for vector search
        query_text = f"Name: {name}\nDefinition: {definition}"
        
        # 2. Get top matches from vector store
        vector_results = self.vs.similarity_search_with_score(query_text, k=top_k)
        if not vector_results:
            logger.warning("No vector matches found")
            return results

        # 3. Process each match
        valid_matches = []
        for doc, score in vector_results:
            try:
                # Extract match details
                match_name = doc.metadata.get('name', 'Unknown')
                match_def = doc.metadata.get('definition', 'No definition')
                confidence = max(0.0, 1.0 - score)  # Convert distance to confidence
                
                # Create candidate text for quality check
                candidate_text = f"Name: {match_name}\nDefinition: {match_def}"
                
                # 4. Get quality assessment
                raw_response = self.quality_chain.chain.run(
                    user_input=query_text,
                    candidate_doc=candidate_text
                ).strip()
                
                # 5. Parse and validate response
                quality_result = QualityResult.parse_response(
                    raw=raw_response,
                    confidence=confidence,
                    name=match_name,
                    definition=match_def
                )
                
                # 6. Store match details
                match_data = {
                    "name": match_name,
                    "definition": match_def,
                    "confidence": confidence,
                    "rating": quality_result.rating,
                    "reason": quality_result.reason,
                    "metadata": doc.metadata
                }
                results["matches"].append(match_data)
                
                # 7. Track best valid result
                if quality_result.rating != "Red":
                    valid_matches.append(quality_result)
                    
            except Exception as match_error:
                logger.error(f"Error processing match: {str(match_error)}")
                results["matches"].append({
                    "error": str(match_error),
                    "metadata": doc.metadata
                })

        # 8. Determine final rating from valid matches
        if valid_matches:
            # Find highest confidence valid match
            best_match = max(valid_matches, key=lambda x: x.confidence)
            results["best_result"] = best_match.dict()
            results["final_rating"] = best_match.rating
            results["final_reason"] = best_match.reason

        # 9. Add confidence scores even for Red ratings
        for match in results["matches"]:
            if "confidence" not in match:
                match["confidence"] = 0.0

    except Exception as e:
        logger.error(f"RAG quality check failed: {str(e)}")
        results["error"] = str(e)
        
    # 10. Ensure exactly 4 matches in response
    results["matches"] = results["matches"][:top_k]
    
    return results
