import os
import logging
import pandas as pd
from typing import List, Tuple, Dict, Any
from pathlib import Path
from dotenv import dotenv_values
from pymilvus import MilvusClient, DataType
from langchain_openai import AzureOpenAIEmbeddings
from azure.identity import ClientSecretCredential

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OSEnv:
    """Enhanced environment manager with security features"""
    
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.token = None
        
        # Load configuration
        self._load_env_file(config_file, True)
        self._load_env_file(creds_file, False)
        
        # Security setup
        self._set_certificate_path(certificate_path)
        
        if self.str_to_bool(self.get("PROXY_ENABLED", "False")):
            self._configure_proxy()
            
        if self.str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self._get_azure_token()

    def _load_env_file(self, file_path: str, log_values: bool) -> None:
        """Load environment variables from .env file"""
        try:
            abs_path = Path(file_path).resolve()
            if not abs_path.exists():
                raise FileNotFoundError(f"Env file not found: {abs_path}")
                
            config = dotenv_values(abs_path)
            for k, v in config.items():
                self.set(k, v, log_values)
                
        except Exception as e:
            logger.error(f"Failed to load {file_path}: {str(e)}")
            raise

    def _set_certificate_path(self, cert_path: str) -> None:
        """Configure SSL certificate settings"""
        cert_path = Path(cert_path).resolve()
        if not cert_path.exists():
            raise FileNotFoundError(f"Certificate not found: {cert_path}")
            
        self.set("REQUESTS_CA_BUNDLE", str(cert_path))
        self.set("SSL_CERT_FILE", str(cert_path))
        self.set("CURL_CA_BUNDLE", str(cert_path))

    def _configure_proxy(self) -> None:
        """Set up authenticated proxy configuration"""
        proxy_url = (
            f"http://{self.get('AD_USERNAME')}:{self.get('AD_USER_PW')}"
            f"@{self.get('HTTPS_PROXY_DOMAIN')}"
        )
        self.set("HTTP_PROXY", proxy_url, False)
        self.set("HTTPS_PROXY", proxy_url, False)

    def _get_azure_token(self) -> str:
        """Acquire Azure AD token"""
        credential = ClientSecretCredential(
            tenant_id=self.get("AZURE_TENANT_ID"),
            client_id=self.get("AZURE_CLIENT_ID"),
            client_secret=self.get("AZURE_CLIENT_SECRET")
        )
        return credential.get_token("https://cognitiveservices.azure.com/.default").token

    def set(self, var_name: str, value: str, log: bool = True) -> None:
        """Set environment variable securely"""
        os.environ[var_name] = value
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if log:
            logger.info(f"Set {var_name}")

    def get(self, var_name: str, default: Any = None) -> Any:
        """Get environment variable safely"""
        return os.environ.get(var_name, default)

    @staticmethod
    def str_to_bool(s: str) -> bool:
        """Convert string to boolean safely"""
        return s.lower() in ['true', '1', 't', 'y', 'yes']

class VectorStoreManager:
    """Milvus vector store manager with Azure OpenAI integration"""
    
    def __init__(self, env: OSEnv):
        self.env = env
        self.client = MilvusClient(
            uri=f"http://{env.get('MILVUS_HOST', 'localhost')}:{env.get('MILVUS_PORT', '19530')}"
        )
        self.embeddings = self._init_embeddings()
        self.collection_name = None

    def _init_embeddings(self) -> AzureOpenAIEmbeddings:
        """Initialize Azure OpenAI embeddings with security"""
        return AzureOpenAIEmbeddings(
            deployment=self.env.get("AZURE_EMBEDDING_DEPLOYMENT"),
            model=self.env.get("AZURE_EMBEDDING_MODEL"),
            api_version=self.env.get("AZURE_API_VERSION"),
            azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=self.env.token,
            openai_api_key="placeholder"  # Required by SDK but not used with AD token
        )

    def create_collection(self, csv_path: Path, text_column: str) -> None:
        """Create collection from CSV with dynamic schema"""
        try:
            df = pd.read_csv(csv_path)
            if text_column not in df.columns:
                raise ValueError(f"Text column '{text_column}' not found")
                
            schema = self._generate_schema(df, text_column)
            self.collection_name = csv_path.stem.lower()
            
            if self.client.has_collection(self.collection_name):
                self.client.drop_collection(self.collection_name)
                
            self.client.create_collection(
                collection_name=self.collection_name,
                schema=schema
            )
            
            self._insert_data(df, text_column)
            self.client.load_collection(self.collection_name)
            
        except Exception as e:
            logger.error(f"Collection creation failed: {str(e)}")
            raise

    def _generate_schema(self, df: pd.DataFrame, text_column: str) -> dict:
        """Generate dynamic schema based on CSV structure"""
        fields = [
            {"name": "id", "dtype": DataType.INT64, "is_primary": True, "auto_id": True},
            {"name": "text", "dtype": DataType.VARCHAR, "max_length": 65535},
            {"name": "embedding", "dtype": DataType.FLOAT_VECTOR, "dim": 3072}
        ]
        
        # Add metadata columns
        for col in df.columns:
            if col != text_column:
                fields.append({
                    "name": col.lower().replace(" ", "_"),
                    "dtype": DataType.VARCHAR,
                    "max_length": 65535
                })
                
        return {"fields": fields}

    def _insert_data(self, df: pd.DataFrame, text_column: str) -> None:
        """Batch insert data with embeddings"""
        batch_size = 100
        metadata_cols = [col for col in df.columns if col != text_column]
        
        for i in range(0, len(df), batch_size):
            batch = df.iloc[i:i+batch_size]
            embeddings = self.embeddings.embed_documents(batch[text_column].tolist())
            
            entities = [{
                "text": row[text_column],
                "embedding": embeddings[idx],
                **{col: str(row[col]) for col in metadata_cols}
            } for idx, (_, row) in enumerate(batch.iterrows())]
            
            self.client.insert(self.collection_name, entities)

    def search(self, query: str, k: int = 5) -> List[Tuple[str, float, Dict]]:
        """Perform vector search with metadata"""
        try:
            query_embedding = self.embeddings.embed_query(query)
            results = self.client.search(
                collection_name=self.collection_name,
                data=[query_embedding],
                anns_field="embedding",
                param={"metric_type": "COSINE", "params": {"nprobe": 128}},
                limit=k,
                output_fields=["text"] + self.metadata_fields
            )
            
            return [
                (
                    hit.entity.get("text"),
                    1 - hit.distance,
                    {k: v for k, v in hit.entity.items() if k != "text"}
                )
                for hit in results[0]
            ]
            
        except Exception as e:
            logger.error(f"Search failed: {str(e)}")
            raise

    @property
    def metadata_fields(self) -> List[str]:
        """Get list of metadata fields"""
        if not self.collection_name:
            return []
            
        return [f["name"] for f in self.client.describe_collection(self.collection_name)["fields"]
                if f["name"] not in ["id", "text", "embedding"]]

    def close(self):
        """Clean up resources"""
        if self.collection_name:
            self.client.release_collection(self.collection_name)
        self.client.close()

def main():
    """Main application workflow"""
    try:
        # Initialize environment
        env_dir = Path(__file__).parent.parent / "env"
        env = OSEnv(
            config_file=env_dir / "config.env",
            creds_file=env_dir / "credentials.env",
            certificate_path=env_dir / "cacert.pem"
        )
        
        # Initialize vector store
        vsm = VectorStoreManager(env)
        
        # CSV processing
        csv_path = Path(input("Enter CSV file path: ").strip()).resolve()
        df = pd.read_csv(csv_path)
        
        print("Available columns:")
        for idx, col in enumerate(df.columns):
            print(f"{idx+1}. {col}")
            
        text_col = df.columns[int(input("Enter text column number: "))-1]
        
        vsm.create_collection(csv_path, text_col)
        
        # Interactive search
        while True:
            query = input("\nEnter search query (or 'exit'): ").strip()
            if query.lower() == "exit":
                break
                
            results = vsm.search(query)
            
            print(f"\nResults for '{query}':")
            for i, (text, score, metadata) in enumerate(results, 1):
                print(f"\n{i}. Similarity: {score:.4f}")
                print(f"Text: {text}")
                print("Metadata:")
                for k, v in metadata.items():
                    print(f"  - {k}: {v}")
                    
    except Exception as e:
        logger.error(f"Application error: {str(e)}")
    finally:
        vsm.close()
        logger.info("Application shutdown complete")

if __name__ == "__main__":
    main()
