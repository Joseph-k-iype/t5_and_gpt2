# main.py

import os
import sys
import csv
import uuid
import logging

# 1) Import your existing code (unchanged)
from genai_env_setup import OSEnv
from azoai_embedding_client import EmbeddingClient, Document as AzoaiDocument

# LangChain + Community imports
from langchain.chat_models import AzureChatOpenAI
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor
from langchain_community.graphs.index_creator import GraphIndexCreator
from langchain_community.graphs.networkx_graph import NetworkxEntityGraph
from langchain_community.chains.graph_qa.base import GraphQAChain
from chromadb.config import Settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

###############################################################################
# GLOBAL CONSTANTS (instead of script_dir)
###############################################################################
ENV_DIR = "../env"
CONFIG_PATH = "../env/config.env"
CREDS_PATH = "../env/credentials.env"
CERT_PATH = "../env/cacert.pem"
CSV_PATH = "knowledgebase.csv"

###############################################################################
# KnowledgeBase: Loads CSV, autogenerates an ID for each row
###############################################################################
class KnowledgeBase:
    """
    Loads CSV rows as LangChain Document objects.
    Expects 'name' and 'definition' columns in the CSV.
    """
    def __init__(self, csv_path: str):
        self.csv_path = csv_path
        self.docs = self._load_csv_as_documents()

    def _load_csv_as_documents(self):
        docs = []
        with open(self.csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                text = f"{row['name']}: {row['definition']}"
                doc_id = str(uuid.uuid4())
                metadata = {"name": row["name"], "id": doc_id}
                docs.append(LC_Document(page_content=text, metadata=metadata))
        return docs

###############################################################################
# EmbeddingClientLangChainAdapter: Wrap your EmbeddingClient for LangChain
###############################################################################
class EmbeddingClientLangChainAdapter(Embeddings):
    def __init__(self, embedding_client: EmbeddingClient, embeddings_model: str = "text-embedding-3-large"):
        self.embedding_client = embedding_client
        self.embeddings_model = embeddings_model

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        embeddings = []
        for txt in texts:
            doc = AzoaiDocument(text=txt, id="")
            updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
            embeddings.append(updated_doc.embedding)
        return embeddings

    def embed_query(self, text: str) -> list[float]:
        doc = AzoaiDocument(text=text, id="")
        updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
        return updated_doc.embedding

###############################################################################
# AzureChatRAG: RAG flow with vector store + knowledge graph
###############################################################################
class AzureChatRAG:
    """
    Combines:
      - OSEnv for environment
      - AzureChatOpenAI for chat
      - Chroma vector store for semantic search
      - Graph index for knowledge-graph QA
      - Multi-tool agent for RAG
    """
    def __init__(self, config_file: str, creds_file: str, cert_file: str, csv_path: str):
        logger.info("Initializing AzureChatRAG environment...")
        self.env = OSEnv(config_file, creds_file, cert_file)

        # 1) Setup chat model
        self._setup_chat_model()

        # 2) Load knowledge base from CSV
        self.kb = KnowledgeBase(csv_path)

        # 3) Build embeddings + vector store
        self._setup_vectorstore()

        # 4) Build knowledge graph
        self._setup_graph()

        # 5) Create multi-tool agent
        self._setup_agent()

        logger.info("AzureChatRAG initialized successfully!")

    def _setup_chat_model(self) -> None:
        """Use environment variables from OSEnv to configure AzureChatOpenAI."""
        try:
            # Example fallback logic
            model_name = self.env.get("MODEL_NAME") or "gpt-4o-mini"
            api_version = self.env.get("API_VERSION") or "2023-05-15"
            azure_endpoint = self.env.get("AZURE_OPENAI_ENDPOINT") or ""
            temperature_str = self.env.get("MODEL_TEMPERATURE") or "0.7"
            max_tokens_str = self.env.get("MAX_TOKENS") or "800"

            temperature = float(temperature_str)
            max_tokens = int(max_tokens_str)

            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                openai_api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token=self.env.token
            )
            logger.info("Chat model initialized successfully")

        except Exception as e:
            logger.error(f"Failed to initialize chat model: {str(e)}")
            raise

    def _setup_vectorstore(self) -> None:
        """Create a Chroma vector store from the CSV docs."""
        try:
            embedding_client = EmbeddingClient()
            adapter = EmbeddingClientLangChainAdapter(embedding_client)
            chroma_settings = Settings(anonymized_telemetry=False, persist_directory="chromadb-data")
            self.vs = Chroma.from_documents(
                documents=self.kb.docs,
                embedding=adapter,
                collection_name="kb_collection",
                client_settings=chroma_settings
            )
            logger.info("Chroma vector store created successfully")
        except Exception as e:
            logger.error(f"Failed to set up vector store: {str(e)}")
            raise

    def _setup_graph(self) -> None:
        """Build a single knowledge graph by merging partial graphs from each doc."""
        try:
            graph_creator = GraphIndexCreator(llm=self.llm, graph_type=NetworkxEntityGraph)
            main_graph = graph_creator.graph_type()  # empty
            for doc in self.kb.docs:
                partial_graph = graph_creator.from_text(doc.page_content)
                for triple in partial_graph.get_triples():
                    main_graph.add_triple(triple)
            self.graph = main_graph
            self.graph_qa_chain = GraphQAChain.from_llm(self.llm, graph=self.graph)
            logger.info("Knowledge graph created successfully")
        except Exception as e:
            logger.error(f"Failed to set up knowledge graph: {str(e)}")
            raise

    def _setup_agent(self) -> None:
        """Define Tools (GraphQATool, VectorStoreSearch), create a multi-tool agent."""
        try:
            def _graph_qa(query: str) -> str:
                return self.graph_qa_chain.run(query)

            def _vectorstore_search(query: str) -> str:
                results = self.vs.similarity_search_with_score(query, k=3)
                if not results:
                    return "No relevant matches found."
                lines = []
                for idx, (doc, score) in enumerate(results, start=1):
                    confidence = max(0.0, min(1.0, 1.0 - score))
                    rating = "Green" if confidence >= 0.8 else ("Amber" if confidence >= 0.5 else "Red")
                    reason = f"Confidence {confidence:.2f}, {rating} rating. Matched: {doc.page_content}"
                    line = (
                        f"Match #{idx}\n"
                        f"Name: {doc.metadata.get('name','Unknown')}\n"
                        f"ID: {doc.metadata.get('id','No ID')}\n"
                        f"Confidence: {confidence:.2f}\n"
                        f"Rating: {rating}\n"
                        f"Reason: {reason}\n"
                    )
                    lines.append(line)
                return "\n".join(lines)

            graph_tool = Tool(
                name="GraphQATool",
                func=_graph_qa,
                description="Query the knowledge graph for relationships/definitions"
            )
            vs_tool = Tool(
                name="VectorStoreSearch",
                func=_vectorstore_search,
                description="Semantic search with R/A/G rating, confidence, reason"
            )

            self.tools = [graph_tool, vs_tool]
            prefix = "You are an AI assistant with access to the following tools:"
            suffix = "Begin!"
            prompt = ZeroShotAgent.create_prompt(self.tools, prefix=prefix, suffix=suffix, input_variables=["input"])
            agent = ZeroShotAgent(llm=self.llm, tools=self.tools, prompt=prompt, verbose=True)
            self.agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=self.tools, verbose=True)
            logger.info("Multi-tool agent created successfully")
        except Exception as e:
            logger.error(f"Failed to set up agent: {str(e)}")
            raise

    def chat(self, user_input: str) -> str:
        """Send a query to the multi-tool agent. The agent decides which tool to call."""
        if not user_input.strip():
            return "Please provide a non-empty message."
        try:
            response = self.agent_executor.run(user_input)
            return response
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return f"An error occurred: {str(e)}"

###############################################################################
# main() with global path references (no script_dir)
###############################################################################
def main():
    # 1) Check for missing files
    required_files = {
        "config.env": CONFIG_PATH,
        "credentials.env": CREDS_PATH,
        "cacert.pem": CERT_PATH,
        "knowledgebase.csv": CSV_PATH
    }
    missing = []
    for name, path in required_files.items():
        if not os.path.exists(path):
            missing.append(name)
    if missing:
        print(f"Missing required files: {', '.join(missing)}")
        sys.exit(1)

    # 2) Initialize AzureChatRAG
    try:
        print("Initializing AzureChatRAG with environment + CSV knowledge base...")
        rag_bot = AzureChatRAG(
            config_file=CONFIG_PATH,
            creds_file=CREDS_PATH,
            cert_file=CERT_PATH,
            csv_path=CSV_PATH
        )
        print("AzureChatRAG initialized successfully!\n")
    except Exception as e:
        print(f"Error initializing: {str(e)}")
        sys.exit(1)

    # 3) Interactive loop
    print("Type 'quit' to exit, 'env' to list environment variables, or ask a question.\n")
    while True:
        user_input = input("You: ").strip()
        if user_input.lower() in ["quit", "exit", "bye"]:
            print("Goodbye!")
            break
        if user_input.lower() == "env":
            rag_bot.env.list_env_vars()
            continue
        response = rag_bot.chat(user_input)
        print(f"\nBot: {response}\n")


if __name__ == "__main__":
    main()
