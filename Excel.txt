# main.py

import os
import csv
import json
import uuid  # for generating unique IDs

# 1) Import your existing code (unchanged)
from genai_env_setup import OSEnv
from azoai_embedding_client import EmbeddingClient, Document as AzoaiDocument

# 2) LangChain imports
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings
from langchain.chat_models import AzureChatOpenAI
from langchain.vectorstores import Chroma
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor

# Key: Import from the official "langchain.indexes.graph" and "langchain.chains.graph_qa.base"
from langchain.indexes.graph import GraphIndexCreator
from langchain.chains.graph_qa.base import GraphQAChain

# For building the final knowledge graph
from langchain.indexes.graph.networkx_entity_graph import NetworkxEntityGraph

# Chroma config
from chromadb.config import Settings

# 3) Import tqdm for progress bars
from tqdm import tqdm

###############################################################################
# KnowledgeBase: Loads CSV, autogenerates an ID for each row, shows a progress bar
###############################################################################
class KnowledgeBase:
    """
    Loads CSV rows as LangChain Document objects.
    Expects 'name' and 'definition' columns in the CSV.
    Autogenerates a unique ID for each row (stored in metadata["id"]).
    Shows a tqdm progress bar while loading rows.
    """
    def __init__(self, csv_path: str):
        self.csv_path = csv_path
        self.docs = self._load_csv_as_documents()

    def _load_csv_as_documents(self):
        docs = []
        with open(self.csv_path, "r", encoding="utf-8") as f:
            reader = list(csv.DictReader(f))  # convert to a list so we know how many rows
        for row in tqdm(reader, desc="Loading CSV rows"):
            # Combine 'name' + 'definition' into a single text block
            text = f"{row['name']}: {row['definition']}"

            # Generate a unique ID for each row
            doc_id = str(uuid.uuid4())

            # Store that ID in the metadata
            metadata = {
                "name": row["name"],
                "id": doc_id
            }
            docs.append(LC_Document(page_content=text, metadata=metadata))
        return docs

###############################################################################
# EmbeddingClientLangChainAdapter: Wraps your EmbeddingClient for LangChain
###############################################################################
class EmbeddingClientLangChainAdapter(Embeddings):
    """
    Adapter that implements the interface LangChain expects:
      - embed_documents(List[str]) -> List[List[float]]
      - embed_query(str) -> List[float]

    Internally calls EmbeddingClient.generate_embeddings(document).
    """
    def __init__(self, embedding_client: EmbeddingClient, embeddings_model: str = "text-embedding-3-large"):
        self.embedding_client = embedding_client
        self.embeddings_model = embeddings_model

    def embed_documents(self, texts: list[str]) -> list[list[float]]:
        embeddings = []
        for txt in texts:
            # Pass id="", so pydantic sees 'id' field (avoiding validation error)
            doc = AzoaiDocument(text=txt, id="")
            updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
            embeddings.append(updated_doc.embedding)
        return embeddings

    def embed_query(self, text: str) -> list[float]:
        doc = AzoaiDocument(text=text, id="")
        updated_doc = self.embedding_client.generate_embeddings(doc, embeddings_model=self.embeddings_model)
        return updated_doc.embedding

###############################################################################
# SemanticSearchAgent: Vector store + Graph + Agent
###############################################################################
class SemanticSearchAgent:
    """
    - Creates a single knowledge graph from all CSV Documents (by looping over docs).
    - Creates a Chroma vector store for semantic search.
    - Defines a multi-tool agent:
        1) GraphQATool -> answers questions from the knowledge graph
        2) VectorStoreSearch -> returns top matches from the vector store
           with confidence, rating (R/A/G), and reason.
    """
    def __init__(self, kb: KnowledgeBase, env: OSEnv):
        self.kb = kb
        self.env = env

        # 1) Set up environment variables for Azure AD token, endpoints, etc.
        self.env.set_azure_token()

        # 2) Instantiate your EmbeddingClient (from azoai_embedding_client.py)
        embedding_client = EmbeddingClient()

        # 3) Wrap it with the adapter
        self.embedding = EmbeddingClientLangChainAdapter(embedding_client)

        # 4) Create Chroma settings (persist data in "chromadb-data")
        CHROMA_SETTINGS = Settings(
            anonymized_telemetry=False,
            persist_directory="chromadb-data"
        )

        # 5) Build a Chroma vector store from the documents
        self.vs = Chroma.from_documents(
            documents=self.kb.docs,
            embedding=self.embedding,
            collection_name="kb_collection",
            client_settings=CHROMA_SETTINGS
        )

        # 6) Build a single knowledge graph by looping over docs and merging partial graphs
        #    based on the official GraphIndexCreator docs, which only provide .from_text()
        self.llm = AzureChatOpenAI(
            openai_api_base=os.getenv("AZURE_OPENAI_ENDPOINT"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
            openai_api_key="",  # Not used because we rely on Azure AD token
            headers={"Authorization": f"Bearer {os.getenv('AZURE_TOKEN')}"}
        )

        # Create a GraphIndexCreator, providing our LLM
        graph_creator = GraphIndexCreator(llm=self.llm)

        # Create an empty main graph (NetworkxEntityGraph) to store knowledge from all docs
        main_graph = graph_creator.graph_type()

        # Merge knowledge from each doc
        for doc in self.kb.docs:
            # from_text returns a new graph for each doc
            partial_graph = graph_creator.from_text(doc.page_content)
            # Merge partial_graph's triples into main_graph
            for triple in partial_graph.get_triples():
                main_graph.add_triple(triple)

        # Now main_graph has knowledge from all docs
        self.graph = main_graph

        # 7) Create a Graph QA chain for knowledge-graph queries
        self.graph_qa_chain = GraphQAChain.from_llm(self.llm, graph=self.graph)

        # 8) Define Tools for the agent
        self.tools = [
            Tool(
                name="GraphQATool",
                func=self._graph_qa,
                description=(
                    "Use this to query the knowledge graph for relationships, "
                    "hierarchies, or definitions found in the CSV-based knowledge."
                ),
            ),
            Tool(
                name="VectorStoreSearch",
                func=self._vectorstore_search,
                description=(
                    "Use this to find semantically similar definitions in the CSV-based knowledge. "
                    "It returns top matches with confidence, R/A/G rating, and a reason."
                ),
            ),
        ]

        # 9) Create an Agent that can call these Tools
        prefix = """You are an AI assistant with access to the following tools:"""
        suffix = """Begin!"""
        prompt = ZeroShotAgent.create_prompt(
            self.tools,
            prefix=prefix,
            suffix=suffix,
            input_variables=["input"]
        )

        agent = ZeroShotAgent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt,
            verbose=True
        )
        self.agent_executor = AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=self.tools,
            verbose=True
        )

    def _graph_qa(self, query: str) -> str:
        """Use GraphQAChain to answer a question by traversing the knowledge graph."""
        return self.graph_qa_chain.run(query)

    def _vectorstore_search(self, query: str) -> str:
        """
        Search the Chroma vector store for the top 3 matches.
        Provide:
         - Confidence (0â€“1, from cosine similarity or 1 - distance)
         - Red/Amber/Green rating
         - Reason for the rating
        """
        results = self.vs.similarity_search_with_score(query, k=3)
        if not results:
            return "No relevant matches found."

        lines = []
        for idx, (doc, score) in enumerate(results, start=1):
            # If 'score' is a distance, confidence = 1 - distance
            confidence = max(0.0, min(1.0, 1.0 - score))

            # Determine R/A/G rating
            if confidence >= 0.8:
                rating = "Green"
            elif confidence >= 0.5:
                rating = "Amber"
            else:
                rating = "Red"

            # Basic reason text
            reason = (
                f"Confidence is {confidence:.2f}, which falls into the {rating} range. "
                f"Definition matched: {doc.page_content}"
            )

            line = (
                f"Match #{idx}\n"
                f"Name: {doc.metadata.get('name', 'Unknown')}\n"
                f"ID: {doc.metadata.get('id', 'No ID found')}\n"
                f"Confidence: {confidence:.2f}\n"
                f"Rating: {rating}\n"
                f"Reason: {reason}\n"
            )
            lines.append(line)

        return "\n".join(lines)

    def run_query(self, query: str) -> str:
        """Send the query to the multi-tool agent. The agent decides which tool(s) to call."""
        return self.agent_executor.run(query)

###############################################################################
# Main entry point (with multiple tqdm progress bars)
###############################################################################
def main():
    """
    Main flow:
      - Instantiate environment (OSEnv)
      - Load CSV-based knowledge base (autogenerate IDs for each row)
      - Initialize SemanticSearchAgent
      - Read input.json with {name, definition}
      - Construct query
      - Run query
    """
    # We will have multiple progress bars, one for each major step

    from tqdm import tqdm

    # Step 1: Environment Setup
    with tqdm(total=1, desc="Setting up environment") as pbar:
        env = OSEnv("config/dev", "config/dev.creds", "cacert.pem")
        pbar.update(1)

    # Step 2: Load the CSV-based knowledge base (IDs autogenerated)
    with tqdm(total=1, desc="Loading KnowledgeBase") as pbar:
        kb = KnowledgeBase("knowledgebase.csv")
        pbar.update(1)

    # Step 3: Initialize the multi-tool agent
    with tqdm(total=1, desc="Initializing Agent") as pbar:
        agent = SemanticSearchAgent(kb, env)
        pbar.update(1)

    # Step 4: Read input.json
    with tqdm(total=1, desc="Reading input.json") as pbar:
        with open("input.json", "r", encoding="utf-8") as jf:
            data = json.load(jf)
        pbar.update(1)

    # Step 5: Construct a query from the JSON
    with tqdm(total=1, desc="Constructing Query") as pbar:
        query = f"{data['name']} {data['definition']}"
        pbar.update(1)

    # Step 6: Run the query
    with tqdm(total=1, desc="Running Query") as pbar:
        result = agent.run_query(query)
        pbar.update(1)

    print("\n=== Final Agent Output ===")
    print(result)


if __name__ == "__main__":
    main()
