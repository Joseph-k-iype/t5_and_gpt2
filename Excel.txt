import os
import time
import logging
from pathlib import Path
from typing import Optional, Dict, Any, List, Tuple
from dotenv import load_dotenv, dotenv_values
from azure.identity import ClientSecretCredential
import pandas as pd
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI  # Corrected import
from langchain_community.vectorstores import Milvus
from pymilvus import MilvusClient, DataType
from langchain.schema import HumanMessage, SystemMessage
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def is_file_readable(filepath: str) -> bool:
    """Check if a file exists and is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str) -> bool:
    """Convert string to boolean."""
    if s == 'True':
        return True
    elif s == 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean string: {s}")

class OSEnv:
    """Environment variable and certificate management class."""
    
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        """Initialize with configuration files and certificate."""
        self.var_list = []  # hold vars that were set via this class
        
        # Load main configuration
        self.bulk_set(config_file, True)
        logger.info(f"Loaded main configuration from {config_file}")
        
        # Load credentials
        self.bulk_set(creds_file, False)
        logger.info(f"Loaded credentials from {creds_file}")
        
        # Set up certificates
        self.set_certificate_path(certificate_path)
        logger.info("Certificate path configured")
        
        # Configure proxy if enabled
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
            logger.info("Proxy configured")
        
        # Set up Azure token if secure endpoints enabled
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            logger.info("Securing endpoints")
            self.token = self.get_azure_token()
        else:
            self.token = None

    def set_certificate_path(self, certificate_path: str) -> None:
        """Set up the certificate path for SSL verification."""
        try:
            if not os.path.isabs(certificate_path):
                certificate_path = os.path.abspath(certificate_path)
            
            if not is_file_readable(certificate_path):
                raise Exception("Certificate file missing or not readable")
            
            # Set the certificate environment variables
            self.set("REQUESTS_CA_BUNDLE", certificate_path)
            self.set("SSL_CERT_FILE", certificate_path)
            self.set("CURL_CA_BUNDLE", certificate_path)
            
            logger.info(f"Certificate path set to: {certificate_path}")
            
        except Exception as e:
            logger.error(f"Certificate configuration failed: {str(e)}")
            raise

    def bulk_set(self, dotenvfile: str, print_val: bool = False) -> None:
        """Read and set environment variables from a dotenv file."""
        try:
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
                
            if is_file_readable(dotenvfile):
                logger.info(f"Loading environment variables from {dotenvfile}")
                temp_dict = dotenv_values(dotenvfile)
                for k, v in temp_dict.items():
                    self.set(k, v, print_val)
                del temp_dict
        except Exception as e:
            logger.error(f"Failed to load environment file {dotenvfile}: {str(e)}")
            raise

    def set(self, var_name: str, val: str, print_val: bool = True) -> None:
        """Set an environment variable."""
        try:
            os.environ[var_name] = val
            if var_name not in self.var_list:
                self.var_list.append(var_name)
            if print_val:
                logger.info(f"Set {var_name}={val}")
        except Exception as e:
            logger.error(f"Failed to set environment variable {var_name}: {str(e)}")
            raise

    def get(self, var_name: str, default: Optional[str] = None) -> Optional[str]:
        """Get an environment variable value."""
        try:
            return os.environ[var_name]
        except KeyError:
            logger.warning(f"Environment variable {var_name} not found")
            return default

    def set_proxy(self) -> None:
        """Set up proxy configuration with authentication."""
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            
            if not all([ad_username, ad_password, proxy_domain]):
                raise ValueError("Missing proxy credentials")
            
            proxy_url = f"http://{ad_username}:{ad_password}@{proxy_domain}"
            # Set both uppercase and lowercase proxy variables
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            self.set("http_proxy", proxy_url, print_val=False)
            self.set("https_proxy", proxy_url, print_val=False)
            
            # Set no_proxy for Azure services
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains))
            
            logger.info("Proxy configuration completed")
            
        except Exception as e:
            logger.error(f"Proxy configuration failed: {str(e)}")
            raise

    def get_azure_token(self) -> str:
        """Get Azure authentication token."""
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token acquired successfully")
            return token.token
            
        except Exception as e:
            logger.error(f"Failed to get Azure token: {str(e)}")
            raise

    def list_env_vars(self) -> None:
        """List all environment variables set by this class."""
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [HIDDEN]")
            else:
                logger.info(f"{var}: {self.get(var)}")


class VectorSearch:
    """Vector search implementation using Azure OpenAI embeddings and Milvus."""
    
    def __init__(self, env: OSEnv, host: str = "localhost", port: str = "19530"):
        """
        Initialize with OSEnv configuration.
        
        Args:
            env: OSEnv instance for configuration
            host: Milvus host address
            port: Milvus port number
        """
        self.env = env
        self.host = host
        self.port = port
        self.metadata_column = None  # To store the metadata column name
        self._setup_embeddings()
        self._setup_milvus()
        
    def _setup_embeddings(self) -> None:
        """Configure Azure OpenAI embeddings."""
        try:
            self.embeddings = AzureOpenAIEmbeddings(
                deployment="text-embedding-3-large",
                model="text-embedding-3-large",
                api_version=self.env.get("API_VERSION", "2024-02-01"),
                azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
                azure_ad_token=self.env.token
            )
            logger.info("Azure OpenAI embeddings initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize embeddings: {str(e)}")
            raise

    def _setup_milvus(self) -> None:
        """Configure Milvus connection using MilvusClient."""
        try:
            uri = f"http://{self.host}:{self.port}"
            self.client = MilvusClient(
                uri=uri,
                token=self.env.get("MILVUS_TOKEN", "")  # Optional token if authentication is enabled
            )
            logger.info(f"Connected to Milvus successfully at {uri}")
            
        except Exception as e:
            logger.error(f"Failed to configure Milvus: {str(e)}")
            raise

    def load_data(self, csv_path: str) -> pd.DataFrame:
        """Load data from CSV file."""
        try:
            df = pd.read_csv(csv_path)
            if len(df.columns) != 2:
                raise ValueError(f"CSV must have exactly 2 columns, found {len(df.columns)}")
            logger.info(f"Successfully loaded {len(df)} rows from {csv_path}")
            return df
        except Exception as e:
            logger.error(f"Failed to load CSV data: {str(e)}")
            raise

    def create_vector_store(self, 
                          data: pd.DataFrame,
                          text_column: str,
                          metadata_column: str,
                          collection_name: str) -> None:
        """Create Milvus vector store from DataFrame."""
        try:
            # Drop existing collection if it exists
            if self.client.has_collection(collection_name):
                self.client.drop_collection(collection_name)
                logger.info(f"Dropped existing collection: {collection_name}")
            
            texts = data[text_column].tolist()
            metadata_values = data[metadata_column].tolist()
            metadatas = [{metadata_column: value} for value in metadata_values]
            
            # Store metadata column name for later use
            self.metadata_column = metadata_column
            
            # Create collection with schema
            dim = 3072  # Dimension for text-embedding-3-large
            schema = {
                "fields": [
                    {
                        "name": "id",
                        "dtype": DataType.INT64,
                        "is_primary": True,
                        "auto_id": True
                    },
                    {
                        "name": "text",
                        "dtype": DataType.VARCHAR,
                        "max_length": 65535
                    },
                    {
                        "name": "embedding",
                        "dtype": DataType.FLOAT_VECTOR,
                        "dim": dim
                    }
                ],
                "enable_dynamic_field": True
            }
            
            # Create the collection
            self.client.create_collection(
                collection_name=collection_name,
                schema=schema
            )
            
            # Create index on the embedding field with COSINE metric
            index_params = {
                "metric_type": "COSINE",  # Corrected metric type
                "index_type": "IVF_FLAT",
                "params": {"nlist": 1024}
            }
            self.client.create_index(
                collection_name=collection_name,
                field_name="embedding",
                index_params=index_params
            )
            
            # Insert the data in batches
            batch_size = 100
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i + batch_size]
                batch_embeddings = self.embeddings.embed_documents(batch_texts)
                batch_metadatas = metadatas[i:i + batch_size]
                
                # Prepare batch data with metadata
                entities = [
                    {"text": text, "embedding": embedding, **metadata}
                    for text, embedding, metadata in zip(batch_texts, batch_embeddings, batch_metadatas)
                ]
                
                # Insert batch
                self.client.insert(
                    collection_name=collection_name,
                    data=entities
                )
            
            # Load the collection
            self.client.load_collection(collection_name)
            
            # Store the collection name for later use
            self.collection_name = collection_name
            
            logger.info(f"Successfully created Milvus collection: {collection_name}")
            
        except Exception as e:
            logger.error(f"Failed to create vector store: {str(e)}")
            raise

    def similarity_search(self, 
                        query: str, 
                        k: int = 5) -> List[Tuple[str, float]]:
        """Perform similarity search."""
        try:
            # Generate query embedding
            query_embedding = self.embeddings.embed_query(query)
            
            # Search in Milvus, include metadata in output
            results = self.client.search(
                collection_name=self.collection_name,
                data=[query_embedding],
                field_name="embedding",
                limit=k,
                output_fields=["text", self.metadata_column]  # Include metadata
            )
            
            # Format results with metadata
            search_results = []
            for hit in results[0]:
                text = hit['entity']['text']
                metadata = hit['entity'].get(self.metadata_column, "")
                search_results.append((text, hit['distance'], metadata))
            
            logger.info(f"Successfully performed similarity search for query: {query}")
            return search_results
            
        except Exception as e:
            logger.error(f"Failed to perform similarity search: {str(e)}")
            raise

    def close(self):
        """Close Milvus connection."""
        try:
            if hasattr(self, 'collection_name'):
                self.client.release_collection(self.collection_name)
            logger.info("Released Milvus collection")
        except Exception as e:
            logger.error(f"Error closing Milvus connection: {str(e)}")

class AzureChatbot:
    """Azure OpenAI chatbot using LangChain."""
    
    def __init__(self, config_file: str, creds_file: str, cert_file: str):
        """Initialize the chatbot with configuration files and certificate."""
        logger.info("Initializing chatbot...")
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()

    def _setup_chat_model(self) -> None:
        """Set up the chat model and conversation chain."""
        try:
            self.llm = AzureChatOpenAI(
                azure_deployment=self.env.get("MODEL_NAME", "gpt-4o-mini"),  # Corrected parameter
                temperature=float(self.env.get("MODEL_TEMPERATURE", "0.7")),
                max_tokens=int(self.env.get("MAX_TOKENS", "800")),
                openai_api_version=self.env.get("API_VERSION", "2024-02-01"),
                azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
                azure_ad_token=self.env.token,
                openai_api_key="dummy-key"  # Placeholder for compatibility
            )
            
            self.memory = ConversationBufferMemory()
            self.conversation = ConversationChain(
                llm=self.llm,
                memory=self.memory,
                verbose=True
            )
            
            logger.info("Chat model initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize chat model: {str(e)}")
            raise

    def chat(self, message: str) -> str:
        """Process a single message and return the response."""
        if not message.strip():
            return "Please provide a non-empty message."
        
        try:
            response = self.conversation.predict(input=message)
            return response
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return f"An error occurred: {str(e)}"


def main():
    """Example usage of the vector search system."""
    try:
        # Define paths to config files
        env_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'env')
        config_path = os.path.join(env_dir, 'config.env')
        creds_path = os.path.join(env_dir, 'credentials.env')
        cert_path = os.path.join(env_dir, 'cacert.pem')
        
        # Check if files exist
        required_files = {
            'config.env': config_path,
            'credentials.env': creds_path,
            'cacert.pem': cert_path
        }
        
        missing_files = []
        for name, path in required_files.items():
            if not os.path.exists(path):
                missing_files.append(name)
        
        if missing_files:
            print(f"\nMissing required files in {env_dir}:")
            for file in missing_files:
                print(f"- {file}")
            return
        
        # Initialize environment
        print("\nInitializing environment...")
        env = OSEnv(config_path, creds_path, cert_path)
        
        # Initialize vector search
        print("\nInitializing vector search...")
        host = input("Enter Milvus host [default: localhost]: ") or "localhost"
        port = input("Enter Milvus port [default: 19530]: ") or "19530"
        
        vector_search = VectorSearch(env, host=host, port=port)
        
        try:
            # Load and process data
            csv_path = input("\nEnter the path to your CSV file: ")
            df = vector_search.load_data(csv_path)
            
            # Get column names and let user select text and metadata columns
            print("\nAvailable columns:")
            for idx, col in enumerate(df.columns):
                print(f"{idx + 1}: {col}")
            col_idx = int(input("\nEnter the number of the column containing text data: ")) - 1
            text_column = df.columns[col_idx]
            metadata_column = df.columns[1 - col_idx]  # Get the other column
            
            # Create vector store
            collection_name = input("\nEnter a name for your vector collection: ")
            print("\nCreating vector store...")
            vector_search.create_vector_store(
                data=df,
                text_column=text_column,
                metadata_column=metadata_column,
                collection_name=collection_name
            )
            
            # Interactive search loop
            print("\nVector store created! You can now perform similarity searches.")
            print("Type 'quit' to exit")
            print("\nAvailable commands:")
            print("- 'quit': Exit the program")
                        print("- 'env': Show current environment variables")
            print("- Any other input will be treated as a search query")
            
            while True:
                query = input("\nEnter your search query: ").strip()
                
                if query.lower() == 'quit':
                    break
                elif query.lower() == 'env':
                    env.list_env_vars()
                    continue
                elif not query:
                    print("Please enter a valid query.")
                    continue
                
                try:
                    k = int(input("How many results would you like? [default=5] ") or "5")
                except ValueError:
                    print("Invalid number, using default of 5")
                    k = 5
                
                results = vector_search.similarity_search(query, k=k)
                
                print("\nSearch Results:")
                for i, (text, score, metadata) in enumerate(results, 1):
                    print(f"\n{i}. Similarity Score: {1 - score:.4f}")  # Convert distance to similarity
                    print(f"Text: {text}")
                    print(f"Metadata: {metadata}")
                
        finally:
            # Always close the connection when done
            print("\nClosing connection...")
            vector_search.close()
            
    except Exception as e:
        logger.error(f"An error occurred: {str(e)}")
        raise

if __name__ == "__main__":
    main()
