import os
import sys
import uuid
import json
import logging
import chardet
import pandas as pd
import networkx as nx
from typing import Optional, Dict, Any, List, Union
from pathlib import Path
from pydantic import BaseModel, ValidationError, field_validator

# ... [Keep previous imports and constants unchanged] ...

###############################################################################
# Enhanced Pydantic Models
###############################################################################
class QualityResult(BaseModel):
    rating: str  # Green/Amber/Red
    reason: str
    confidence: Optional[float] = None
    matched_name: Optional[str] = None
    matched_definition: Optional[str] = None

    @field_validator('rating')
    def validate_rating(cls, v):
        if v.lower() not in {'green', 'amber', 'red'}:
            raise ValueError('Invalid rating value')
        return v.capitalize()

class VectorMatchResult(BaseModel):
    name: str
    definition: str
    confidence: float
    quality_result: QualityResult

###############################################################################
# Enhanced KnowledgeBase with Combined Embeddings
###############################################################################
class KnowledgeBase:
    def __init__(self, csv_path: str):
        self.csv_path = csv_path
        self.docs: List[LC_Document] = []
        self.graph = nx.MultiDiGraph()
        self._read_csv_and_build()

    def _read_csv_and_build(self):
        # [Previous CSV reading code unchanged]
        
        # Modified document creation
        for _, row in df.iterrows():
            combined_text = f"Name: {name_val}\nDefinition: {def_val}"  # Combine fields
            doc = LC_Document(
                page_content=combined_text,  # Both name + definition embedded
                metadata={"name": name_val, "definition": def_val, "id": id_val}
            )
            self.docs.append(doc)

###############################################################################
# Enhanced QualityCheckChain with Full Results
###############################################################################
class QualityCheckChain:
    def __init__(self, llm):
        self.llm = llm
        template = """Analyze if user input matches candidate document. Return JSON with:
- "rating": Green/Amber/Red
- "reason": short explanation

User Input: {user_input}
Candidate Document: {candidate_doc}"""
        self.prompt = PromptTemplate(
            input_variables=["user_input", "candidate_doc"],
            template=template
        )
        self.chain = LLMChain(llm=self.llm, prompt=self.prompt)

    def _parse_response(self, raw_response: str) -> QualityResult:
        try:
            # Clean response and find JSON
            json_str = raw_response[raw_response.find('{'):raw_response.rfind('}')+1]
            data = json.loads(json_str)
            
            # Case-insensitive key matching
            return QualityResult(
                rating=data.get('rating', 'Red').capitalize(),
                reason=data.get('reason', 'No reason provided'),
            )
        except (json.JSONDecodeError, KeyError, ValidationError) as e:
            return QualityResult(
                rating="Red",
                reason=f"Parse error: {str(e)}"
            )

    def check_quality(self, user_input: str, candidate_doc: str) -> QualityResult:
        raw_response = self.chain.run(
            user_input=user_input,
            candidate_doc=candidate_doc
        ).strip()
        return self._parse_response(raw_response)

###############################################################################
# Modified AzureChatbot with Full Results
###############################################################################
class AzureChatbot:
    # [Previous initialization code unchanged]

    def rag_quality_check_item(self, name: str, definition: str, top_k: int = 4) -> Dict[str, Any]:
        """
        Returns:
        - Original input
        - All top matches with quality results
        - Final verdict based on best match
        """
        user_input = f"Name: {name}\nDefinition: {definition}"
        
        # Get top matches (now using combined embeddings)
        results = self.vs.similarity_search_with_score(user_input, k=top_k)
        
        all_matches = []
        best_result = None
        
        for doc, score in results:
            confidence = max(0.0, 1.0 - score)
            candidate_text = (
                f"Name: {doc.metadata['name']}\n"
                f"Definition: {doc.metadata['definition']}"
            )
            
            # Get quality assessment
            qc_result = self.quality_chain.check_quality(
                user_input=user_input,
                candidate_doc=candidate_text
            )
            
            # Create full result object
            match_result = VectorMatchResult(
                name=doc.metadata['name'],
                definition=doc.metadata['definition'],
                confidence=confidence,
                quality_result=qc_result
            )
            all_matches.append(match_result)
            
            # Track best valid match
            if not best_result and qc_result.rating != "Red":
                best_result = match_result

        # Final verdict logic
        final_rating = "Red"
        final_reason = "No valid matches found"
        if best_result:
            final_rating = best_result.quality_result.rating
            final_reason = best_result.quality_result.reason

        return {
            "input": {"name": name, "definition": definition},
            "all_matches": [m.dict() for m in all_matches],
            "final_rating": final_rating,
            "final_reason": final_reason,
            "best_match": best_result.dict() if best_result else None
        }

    # [Rest of the class unchanged]
