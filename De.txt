"""
Business Terms Manager - Core component for managing and matching business terms.

This module provides functionality for storing, retrieving, and matching business terms
using vector similarity search with ChromaDB's HNSW indexing, enhanced with AI evaluation
of term matches.
"""

import csv
import logging
import os
import time
import re
import uuid
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.core.db_manager import DBManager # Used for job storage, not vector storage if Chroma is primary
from app.core.embedding import EmbeddingClient, MyDocument
from app.core.models import TaggingResult, TaggingValidationResult
from app.config.environment import get_os_env
from app.config.settings import get_vector_store # This will give ChromaDBVectorStore
from app.agents.tagging_evaluation_agent import AITaggingEvaluationAgent # Ensure this agent exists and is correctly imported

logger = logging.getLogger(__name__)

class BusinessTerm(BaseModel):
    """Model representing a business term in the repository."""
    id: str = Field(..., description="Unique identifier for the term")
    name: str = Field(..., description="Name of the business term")
    description: str = Field(..., description="Description of the business term")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata for the term")
    
    def dict(self) -> Dict[str, Any]:
        """Convert the business term to a dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "metadata": self.metadata
        }

class BusinessTermManager:
    """
    Manager for business terms, handling storage, retrieval, and similarity matching.
    
    Uses ChromaDB with HNSW indexing for vector similarity search, enhanced with
    AI-powered evaluation of term matches.
    """
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern to ensure only one instance is created."""
        if cls._instance is None:
            cls._instance = super(BusinessTermManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the business term manager."""
        if self._initialized:
            return
            
        self._initialized = True
        self.env = get_os_env()
        self.embedding_client = EmbeddingClient() # This will use EMBEDDING_MODEL from env
        
        # Initialize DB manager (PostgreSQL) for job storage or other non-vector tasks
        self.db_manager = DBManager()
        
        self.similarity_threshold = float(self.env.get("SIMILARITY_THRESHOLD", "0.5"))
        
        # Get vector store (ChromaDB based on current settings.py logic)
        self.vector_store = get_vector_store()
        
        # Get the vector database type (will be 'chroma' due to settings.py)
        self.vector_db_type = self.env.get("VECTOR_DB_TYPE", "chroma").lower()
        
        # Initialize AI evaluation agent
        # Ensure AITaggingEvaluationAgent is correctly implemented and imported
        try:
            from app.agents.tagging_evaluation_agent import AITaggingEvaluationAgent
            self.ai_evaluation_agent = AITaggingEvaluationAgent()
        except ImportError:
            logger.warning("AITaggingEvaluationAgent not found. AI-based tagging evaluation will not be available.")
            self.ai_evaluation_agent = None # type: ignore
        
        # Initialize TermMatchingAgent (ensure it exists)
        try:
            from app.agents.term_matching_agent import TermMatchingAgent
            self._term_matching_agent = TermMatchingAgent(self)
        except ImportError:
            logger.warning("TermMatchingAgent not found. Advanced term matching will be limited.")
            self._term_matching_agent = None # type: ignore


        logger.info(f"Business term manager initialized with {self.vector_db_type} backend for vectors.")
        logger.info(f"Embedding model in use by EmbeddingClient: {self.embedding_client.embeddings_model}")
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def import_terms_from_csv(self, csv_path: str, encoding: str = 'utf-8', batch_size: int = 100) -> int:
        """
        Import business terms from a CSV file (id, PBT_NAME, PBT_DESCRIPTION, CDM)
        and generate embeddings using EmbeddingClient.
        
        Args:
            csv_path: Path to the CSV file
            encoding: File encoding (auto-detected if not provided)
            batch_size: Number of terms to process in each batch
            
        Returns:
            Number of terms imported
            
        Raises:
            ValueError: If CSV file is missing required columns
            IOError: If file cannot be read
        """
        try:
            logger.info(f"Starting import from CSV: {csv_path} with encoding: {encoding}")
            # Get existing terms to manage updates/deletions if necessary (optional based on exact requirements)
            # For simplicity, this version focuses on adding/upserting.
            # existing_terms_map = {term.name + "::" + term.description: term.id for term in self.get_all_terms()}

            terms_to_process = []
            
            # Auto-detect encoding if 'auto' or 'detect' is specified
            if encoding.lower() in ['auto', 'detect']:
                try:
                    import chardet # Ensure chardet is available
                    with open(csv_path, 'rb') as rawfile:
                        file_size = os.path.getsize(csv_path)
                        sample_size = min(1024 * 1024, file_size) # Read up to 1MB
                        sample = rawfile.read(sample_size)
                        detected = chardet.detect(sample)
                        encoding = detected['encoding'] or 'utf-8' # Default to utf-8 if detection fails
                        logger.info(f"Auto-detected encoding: {encoding} with confidence {detected['confidence']}")
                except Exception as e:
                    logger.warning(f"Encoding auto-detection failed: {e}. Falling back to specified or default UTF-8.")
                    encoding = 'utf-8' # Fallback

            with open(csv_path, 'r', encoding=encoding, errors='replace') as csvfile:
                reader = csv.DictReader(csvfile)
                if not reader.fieldnames:
                    raise ValueError("CSV file is empty or has no headers.")

                # Normalize field names (case-insensitive)
                normalized_fieldnames = {fn.lower().replace("_", ""): fn for fn in reader.fieldnames}

                # Determine actual column names for required fields
                # Headers: id, PBT_NAME, PBT_DESCRIPTION, CDM
                col_id = normalized_fieldnames.get('id')
                col_pbt_name = normalized_fieldnames.get('pbtname', normalized_fieldnames.get('name'))
                col_pbt_description = normalized_fieldnames.get('pbtdescription', normalized_fieldnames.get('description'))
                col_cdm = normalized_fieldnames.get('cdm')

                if not col_pbt_name or not col_pbt_description:
                    missing_cols = []
                    if not col_pbt_name: missing_cols.append("PBT_NAME or NAME")
                    if not col_pbt_description: missing_cols.append("PBT_DESCRIPTION or DESCRIPTION")
                    raise ValueError(f"CSV file is missing required columns: {', '.join(missing_cols)}. Found headers: {reader.fieldnames}")

                for row_num, row in enumerate(reader, 1):
                    pbt_name = row.get(col_pbt_name, "").strip()
                    pbt_description = row.get(col_pbt_description, "").strip()

                    if not pbt_name or not pbt_description:
                        logger.warning(f"Skipping row {row_num}: PBT_NAME or PBT_DESCRIPTION is empty.")
                        continue

                    term_id = row.get(col_id, "").strip() if col_id else ""
                    if not term_id: # If CSV 'id' is missing or empty, generate one
                        term_id = f"pbt_{uuid.uuid4()}"
                    
                    metadata = {}
                    if col_cdm and row.get(col_cdm):
                        metadata['cdm'] = row.get(col_cdm, "").strip()
                    
                    # Store original CSV ID in metadata if it was present and different from the term_id used
                    if col_id and row.get(col_id, "").strip() and row.get(col_id,"").strip() != term_id:
                         metadata['original_csv_id'] = row.get(col_id,"").strip()

                    # Add other columns from CSV to metadata if they exist
                    for key, value in row.items():
                        if key not in [col_id, col_pbt_name, col_pbt_description, col_cdm] and value and value.strip():
                            # Sanitize metadata keys for ChromaDB (alphanumeric, _, -)
                            meta_key = re.sub(r'\W+', '_', key.lower())
                            metadata[meta_key] = value.strip()
                    
                    terms_to_process.append({
                        "id": term_id, # This will be the ID in ChromaDB
                        "name": pbt_name,
                        "description": pbt_description,
                        "metadata": metadata
                    })
            
            logger.info(f"Found {len(terms_to_process)} terms to process from CSV.")
            added_count = 0
            for i in range(0, len(terms_to_process), batch_size):
                batch = terms_to_process[i:i + batch_size]
                batch_start_time = time.time()
                
                docs_to_embed = []
                for term_data in batch:
                    # Text for embedding combines name and description for richer semantics
                    embedding_text = f"PBT Name: {term_data['name']}. Description: {term_data['description']}"
                    if term_data['metadata'].get('cdm'):
                        embedding_text += f" CDM: {term_data['metadata']['cdm']}"
                    
                    docs_to_embed.append(MyDocument(
                        id=term_data["id"],
                        text=embedding_text,
                        metadata=term_data["metadata"] # Pass metadata to MyDocument if EmbeddingClient uses it
                    ))
                
                logger.debug(f"Generating embeddings for batch of {len(docs_to_embed)} terms...")
                docs_with_embeddings = self.embedding_client.batch_generate_embeddings(docs_to_embed)
                
                vectors_batch_for_store = []
                for doc_with_embedding in docs_with_embeddings:
                    # Find original term_data for this doc_with_embedding.id
                    original_term_data = next((t for t in batch if t["id"] == doc_with_embedding.id), None)
                    if not original_term_data:
                        logger.warning(f"Could not find original term data for document ID {doc_with_embedding.id}, skipping.")
                        continue

                    if not doc_with_embedding.embedding:
                        logger.warning(f"Skipping term '{original_term_data['name']}' (ID: {original_term_data['id']}) due to missing embedding.")
                        continue
                    
                    vectors_batch_for_store.append({
                        "id": original_term_data["id"],
                        "name": original_term_data["name"],
                        "description": original_term_data["description"],
                        "embedding": doc_with_embedding.embedding,
                        "metadata": original_term_data["metadata"] 
                    })
                
                if vectors_batch_for_store:
                    logger.debug(f"Storing batch of {len(vectors_batch_for_store)} vectors...")
                    inserted_in_batch = self.vector_store.batch_store_vectors(vectors_batch_for_store)
                    added_count += inserted_in_batch
                    batch_duration = time.time() - batch_start_time
                    logger.info(f"Processed batch {i//batch_size + 1}/{(len(terms_to_process) + batch_size - 1)//batch_size}: "
                               f"Stored {inserted_in_batch} terms in {batch_duration:.2f}s.")
            
            logger.info(f"CSV import completed. Total terms added/updated: {added_count}")
            return added_count
        
        except FileNotFoundError:
            logger.error(f"CSV file not found at path: {csv_path}")
            raise IOError(f"CSV file not found: {csv_path}")
        except ValueError as ve:
            logger.error(f"ValueError during CSV import: {ve}")
            raise
        except Exception as e:
            logger.error(f"General error importing terms from CSV: {e}", exc_info=True)
            raise
    
    async def tag_element(self, element_id: str, name: str, description: str, 
                   top_k: int = 3, threshold: float = 0.3, 
                   cdm: Optional[str] = None, # CDM from the element itself, if available
                   example: Optional[str] = None,
                   process_name: Optional[str] = None,
                   process_description: Optional[str] = None) -> TaggingResult:
        """
        Tag a data element (or a generic item described by name/description)
        with the most similar business terms using vector search and a RAG-like agent.
        
        Args:
            element_id: Unique identifier for the element/item being tagged
            name: Name of the element/item
            description: Description of the element/item
            top_k: Number of top matching terms to return
            threshold: Minimum similarity threshold (0-1) for initial vector search
            cdm: Optional CDM of the element/item, can be used for context or biasing
            example: Optional example for context
            process_name: Optional process name for context
            process_description: Optional process description for context
                    
        Returns:
            TaggingResult containing matching terms and confidence scores
        """
        try:
            if not name or not description:
                logger.warning(f"Empty name or description for element ID: {element_id}. Cannot perform tagging.")
                return TaggingResult(
                    element_id=element_id,
                    element_name=name or "",
                    element_description=description or "",
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message="Name or description is empty. Modeling should be performed."
                )
            
            if not self._term_matching_agent:
                logger.warning("TermMatchingAgent is not initialized. Falling back to basic vector search.")
                # Fallback to basic vector search if agent is not available
                query_text = f"Item Name: {name}. Description: {description}."
                if example: query_text += f" Example: {example}."
                if process_name: query_text += f" Related Process: {process_name}."
                if process_description: query_text += f" Process Description: {process_description}."
                if cdm: query_text += f" Associated CDM: {cdm}."

                doc = MyDocument(id=element_id, text=query_text)
                doc_with_embedding = self.embedding_client.generate_embeddings(doc)

                if not doc_with_embedding.embedding:
                    raise ValueError("Could not generate embedding for tagging query.")

                vector_matches = self.vector_store.find_similar_vectors(
                    query_vector=doc_with_embedding.embedding,
                    top_k=top_k,
                    threshold=threshold # Use the provided threshold for initial retrieval
                )
                matching_terms_dicts = vector_matches
                confidence_scores = [term["similarity"] for term in vector_matches]
                message = "Tagging performed using basic vector search due to missing TermMatchingAgent."

            else: # Use the TermMatchingAgent
                # The agent is responsible for the RAG pattern:
                # 1. Constructing a good query for vector store (can use name, desc, example, etc.)
                # 2. Retrieving initial candidates from vector store
                # 3. Using LLM to re-rank, filter, or generate explanations for the matches.
                matching_terms_dicts, confidence_scores = await self._term_matching_agent.find_matching_terms(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    top_k=top_k,
                    # Pass all context to the agent; it can decide how to use it.
                    # The agent might construct a richer query for the vector store
                    # or use this context in its LLM prompt for re-ranking/evaluation.
                    cdm_context=cdm, 
                    example_context=example,
                    process_name_context=process_name,
                    process_description_context=process_description,
                    initial_threshold=threshold 
                )
                message = "Tagging performed using TermMatchingAgent."

            # Determine if modeling is required based on final confidence scores and matches
            modeling_required = False
            if not matching_terms_dicts:
                modeling_required = True
                message += " No matching terms found."
            # If TermMatchingAgent returns scores, use them. Otherwise, if it's basic search, scores are similarities.
            elif not confidence_scores or max(confidence_scores, default=0.0) < self.similarity_threshold: # Use manager's threshold for final decision
                modeling_required = True
                message += f" Best match confidence ({max(confidence_scores, default=0.0):.2f}) is below threshold ({self.similarity_threshold})."
            
            if modeling_required:
                 message += " Consider modeling a new term."
            else:
                 message += f" Found {len(matching_terms_dicts)} relevant terms."
            
            return TaggingResult(
                element_id=element_id,
                element_name=name,
                element_description=description,
                matching_terms=matching_terms_dicts, # List of dicts
                confidence_scores=confidence_scores, # List of floats
                modeling_required=modeling_required,
                message=message
            )
                
        except Exception as e:
            logger.error(f"Error tagging element '{name}' (ID: {element_id}): {e}", exc_info=True)
            return TaggingResult(
                element_id=element_id,
                element_name=name,
                element_description=description,
                matching_terms=[],
                confidence_scores=[],
                modeling_required=True,
                message=f"Error during tagging: {str(e)}. Modeling should be performed."
            )

    async def evaluate_tagging_with_reasoning(self, tagging_result: TaggingResult) -> Tuple[float, str]:
        """
        Evaluate the confidence in the tagging with detailed reasoning using the AI evaluation agent.
        """
        if not self.ai_evaluation_agent:
            logger.warning("AITaggingEvaluationAgent not available. Cannot provide AI-based evaluation.")
            # Fallback: calculate average confidence or return simple message
            if not tagging_result.matching_terms:
                return 0.0, "No terms to evaluate."
            avg_confidence = sum(tagging_result.confidence_scores) / len(tagging_result.confidence_scores) if tagging_result.confidence_scores else 0.0
            return avg_confidence, "AI evaluation agent not available. Confidence is based on similarity scores."

        try:
            if tagging_result.modeling_required and not tagging_result.matching_terms:
                return 0.0, "Modeling is required as no suitable matches were found."
            if not tagging_result.matching_terms:
                return 0.0, "No matching terms were found to evaluate."
            
            # Use the AI evaluation agent
            is_valid, overall_confidence, reasoning, _ = await self.ai_evaluation_agent.evaluate_tagging_result(tagging_result)
            return overall_confidence, reasoning
        
        except Exception as e:
            logger.error(f"Error evaluating tagging confidence with reasoning: {e}", exc_info=True)
            return 0.5, f"Error during AI evaluation of tagging: {e}" # Default confidence on error
    
    async def validate_tagging(self, tagging_result: TaggingResult) -> TaggingValidationResult:
        """Validate the tagging result, potentially using an AI agent."""
        if not self.ai_evaluation_agent:
            logger.warning("AITaggingEvaluationAgent not available. Basic validation will be applied.")
            is_valid_basic = bool(tagging_result.matching_terms) and not tagging_result.modeling_required
            feedback_basic = "Tagging seems plausible based on similarity scores." if is_valid_basic else "Tagging may require review or modeling."
            return TaggingValidationResult(
                is_valid=is_valid_basic,
                feedback=feedback_basic,
                suggested_alternatives=[]
            )
        try:
            is_valid, _, reasoning, _ = await self.ai_evaluation_agent.evaluate_tagging_result(tagging_result)
            return TaggingValidationResult(
                is_valid=is_valid,
                feedback=reasoning,
                suggested_alternatives=[] # Agent could populate this
            )
        except Exception as e:
            logger.error(f"Error validating tagging: {e}", exc_info=True)
            return TaggingValidationResult(
                is_valid=False,
                feedback=f"Error during AI validation: {str(e)}",
                suggested_alternatives=[]
            )
            
    # --- Other methods (get_all_terms, get_term_by_id, etc.) remain largely the same ---
    # Ensure they correctly retrieve 'name', 'description', and 'metadata' (including 'cdm')
    # from the vector store. ChromaDBVectorStore handles this by storing name/desc in metadata.

    def get_all_terms(self) -> List[BusinessTerm]:
        """Get all business terms from the collection."""
        try:
            term_dicts = self.vector_store.get_all_terms() # This should return list of dicts
            return [BusinessTerm(**term_dict) for term_dict in term_dicts]
        except Exception as e:
            logger.error(f"Error retrieving all terms: {e}", exc_info=True)
            return []

    def get_term_by_id(self, term_id: str) -> Optional[BusinessTerm]:
        """Get a business term by its ID."""
        try:
            term_dict = self.vector_store.get_term_by_id(term_id)
            return BusinessTerm(**term_dict) if term_dict else None
        except Exception as e:
            logger.error(f"Error retrieving term by ID '{term_id}': {e}", exc_info=True)
            return None

    def get_term_count(self) -> int:
        """Get the total count of business terms."""
        try:
            # ChromaDBVectorStore.get_all_terms() is less efficient for just count.
            # If ChromaDB client allows direct count, use that. Otherwise, this is fine.
            if hasattr(self.vector_store, 'collection') and self.vector_store.collection: # type: ignore
                return self.vector_store.collection.count() # type: ignore
            return len(self.vector_store.get_all_terms())
        except Exception as e:
            logger.error(f"Error getting term count: {e}", exc_info=True)
            return 0

    def delete_term(self, term_id: str) -> bool:
        """Delete a business term by ID."""
        try:
            return self.vector_store.delete_term(term_id)
        except Exception as e:
            logger.error(f"Error deleting term ID '{term_id}': {e}", exc_info=True)
            return False

    def delete_all_terms(self) -> int:
        """Delete all business terms."""
        try:
            return self.vector_store.delete_all_terms()
        except Exception as e:
            logger.error(f"Error deleting all terms: {e}", exc_info=True)
            return 0

    def search_terms(self, query: str, limit: int = 20) -> List[BusinessTerm]:
        """Search for business terms by name or description (text search)."""
        try:
            term_dicts = self.vector_store.search_terms(query, limit)
            return [BusinessTerm(**term_dict) for term_dict in term_dicts]
        except Exception as e:
            logger.error(f"Error searching terms with query '{query}': {e}", exc_info=True)
            return []

    def compute_similarity(self, text1: str, text2: str) -> float:
        """Compute semantic similarity between two text strings."""
        try:
            doc1 = MyDocument(id="temp_sim_1", text=text1)
            doc2 = MyDocument(id="temp_sim_2", text=text2)
            
            doc1_embedded = self.embedding_client.generate_embeddings(doc1)
            doc2_embedded = self.embedding_client.generate_embeddings(doc2)

            if not doc1_embedded.embedding or not doc2_embedded.embedding:
                logger.warning("Could not generate embeddings for similarity computation.")
                return 0.0
            
            return self.vector_store.compute_cosine_similarity(
                doc1_embedded.embedding,
                doc2_embedded.embedding
            )
        except Exception as e:
            logger.error(f"Error computing similarity between texts: {e}", exc_info=True)
            return 0.0

    def get_vector_store_info(self) -> Dict[str, Any]:
        """Get information about the current vector store."""
        try:
            health = self.vector_store.health_check()
            info = {
                "type": self.vector_db_type, # Should be 'chroma'
                "status": health.get("status", "unknown"),
                "term_count": health.get("term_count", self.get_term_count()), # Fallback to direct count
                "details": health.get("details", {})
            }
            return info
        except Exception as e:
            logger.error(f"Error getting vector store info: {e}", exc_info=True)
            return {"type": self.vector_db_type, "status": "error", "error": str(e)}

