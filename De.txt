import pandas as pd
import langchain
import os
from azure.identity import DefaultAzureCredential
from openai import AzureOpenAI
import logging
import requests

# ------------------------------
# Proxy and SSL Settings
# ------------------------------
proxy_url = "http://44444:unuou123.lts@abc.uk.systems:80"
os.environ['HTTP_PROXY'] = proxy_url
os.environ['HTTPS_PROXY'] = proxy_url
os.environ["REQUESTS_CA_BUNDLE"] = 'cacert.pem'

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

# Create a requests session that forces our proxy settings and uses our CA bundle.
session = requests.Session()
session.verify = 'cacert.pem'
session.trust_env = False  # Ignore system proxy settings.
session.proxies = {"http": proxy_url, "https": proxy_url}

# ------------------------------
# Azure and Embeddings Functions
# ------------------------------
try:
    credential = DefaultAzureCredential()
    token = credential.get_token('https://cognitiveservices.azure.com/.default')
    
    def get_embeddings(texts, endpoint, deployment_name="text-embedding-3-large", batch_size=100):
        headers = {
            'Authorization': f'Bearer {token.token}',
            'Content-Type': 'application/json'
        }
        api_url = f"{endpoint}/openai/deployments/{deployment_name}/embeddings?api-version=2023-05-15"
        embeddings = []
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]
            try:
                payload = {"input": batch}
                response = session.post(api_url, headers=headers, json=payload)
                if response.status_code == 200:
                    response_data = response.json()
                    batch_embeddings = [item['embedding'] for item in response_data['data']]
                    embeddings.extend(batch_embeddings)
                    logger.info(f"Received embeddings for batch {i+1}-{min(i+batch_size, len(texts))}")
                else:
                    logger.error(f"Failed to receive embeddings for batch {i+1}-{min(i+batch_size, len(texts))}, status code: {response.status_code}")
                    embeddings.extend([None] * len(batch))
            except Exception as e:
                logger.error(f"Error processing batch {i+1}-{min(i+batch_size, len(texts))}: {str(e)}")
                embeddings.extend([None] * len(batch))
        return embeddings
    
    def test_connection(endpoint):
        try:
            test_texts = ['Hello World']
            embeds = get_embeddings(test_texts, endpoint)
            if embeds and embeds[0]:
                print(f"Embedding Dimension: {len(embeds[0])}")
                return True
            else:
                print("Failed to retrieve embeddings")
                return False
        except Exception as e:
            print(f"Failed to connect to {endpoint}: {str(e)}")
            return False
except Exception as e:
    print(f"Failed to initialize Azure SDK: {str(e)}")
    raise

# ------------------------------
# Main Execution
# ------------------------------
if __name__ == "__main__":
    # Replace with your actual Azure Cognitive Services endpoint
    azure_endpoint = "https://your-azure-endpoint.cognitiveservices.azure.com"
    if test_connection(azure_endpoint):
        print("Connection successful")
    else:
        print("Connection failed")
