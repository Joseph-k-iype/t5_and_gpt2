"""
Business Terms Manager - Core component for managing and matching business terms.

This module provides functionality for storing, retrieving, and matching business terms
using vector similarity search with ChromaDB's HNSW indexing, enhanced with AI evaluation
of term matches.
"""

import csv
import logging
import os
import time
import re
import uuid
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.core.db_manager import DBManager # Used for job storage, not vector storage if Chroma is primary
from app.core.embedding import EmbeddingClient, MyDocument
from app.core.models import TaggingResult, TaggingValidationResult
from app.config.environment import get_os_env
from app.config.settings import get_vector_store # This will give ChromaDBVectorStore
# Ensure AITaggingEvaluationAgent and TermMatchingAgent are correctly imported or handled if missing
try:
    from app.agents.tagging_evaluation_agent import AITaggingEvaluationAgent
except ImportError:
    AITaggingEvaluationAgent = None # type: ignore
try:
    from app.agents.term_matching_agent import TermMatchingAgent
except ImportError:
    TermMatchingAgent = None # type: ignore


logger = logging.getLogger(__name__)

class BusinessTerm(BaseModel):
    """Model representing a business term in the repository."""
    id: str = Field(..., description="Unique identifier for the term")
    name: str = Field(..., description="Name of the business term")
    description: str = Field(..., description="Description of the business term")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata for the term")
    
    def dict(self) -> Dict[str, Any]:
        """Convert the business term to a dictionary."""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "metadata": self.metadata
        }

class BusinessTermManager:
    """
    Manager for business terms, handling storage, retrieval, and similarity matching.
    
    Uses ChromaDB with HNSW indexing for vector similarity search, enhanced with
    AI-powered evaluation of term matches.
    """
    
    _instance = None
    
    def __new__(cls):
        """Singleton pattern to ensure only one instance is created."""
        if cls._instance is None:
            cls._instance = super(BusinessTermManager, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the business term manager."""
        if self._initialized:
            return
            
        self._initialized = True
        self.env = get_os_env()
        self.embedding_client = EmbeddingClient() # This will use EMBEDDING_MODEL from env
        
        self.db_manager = DBManager()
        
        self.similarity_threshold = float(self.env.get("SIMILARITY_THRESHOLD", "0.5"))
        
        self.vector_store = get_vector_store()
        
        self.vector_db_type = self.env.get("VECTOR_DB_TYPE", "chroma").lower()
        
        if AITaggingEvaluationAgent:
            self.ai_evaluation_agent = AITaggingEvaluationAgent()
        else:
            logger.warning("AITaggingEvaluationAgent not found or failed to import. AI-based tagging evaluation will not be available.")
            self.ai_evaluation_agent = None
        
        if TermMatchingAgent:
            self._term_matching_agent = TermMatchingAgent(self)
        else:
            logger.warning("TermMatchingAgent not found or failed to import. Advanced term matching will be limited.")
            self._term_matching_agent = None


        logger.info(f"Business term manager initialized with {self.vector_db_type} backend for vectors.")
        logger.info(f"Embedding model in use by EmbeddingClient: {self.embedding_client.embeddings_model}")
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=10),
        retry=retry_if_exception_type((Exception,)), # More specific exceptions can be added
        reraise=True
    )
    def import_terms_from_csv(self, csv_path: str, encoding: str = 'utf-8', batch_size: int = 100) -> int:
        """
        Import business terms from a CSV file (id, PBT_NAME, PBT_DESCRIPTION, CDM)
        and generate embeddings using EmbeddingClient. Processes the CSV in chunks for memory efficiency.
        
        Args:
            csv_path: Path to the CSV file
            encoding: File encoding ('auto' for auto-detection)
            batch_size: Number of terms to process in each batch for embedding and storage
            
        Returns:
            Number of terms imported/updated
            
        Raises:
            ValueError: If CSV file is missing required columns or is improperly formatted
            IOError: If file cannot be read
        """
        try:
            logger.info(f"Starting import from CSV: {csv_path} with encoding: {encoding}, batch size: {batch_size}")
            
            # Auto-detect encoding if 'auto' or 'detect' is specified
            if encoding.lower() in ['auto', 'detect']:
                try:
                    import chardet # Ensure chardet is available
                    with open(csv_path, 'rb') as rawfile:
                        file_size = os.path.getsize(csv_path)
                        sample_size = min(1024 * 1024, file_size) # Read up to 1MB
                        sample = rawfile.read(sample_size)
                        detected = chardet.detect(sample)
                        original_encoding_detected = encoding # Store user's choice
                        encoding = detected['encoding'] or 'utf-8' # Default to utf-8 if detection fails
                        logger.info(f"Auto-detected encoding: {encoding} with confidence {detected['confidence']} (user requested: {original_encoding_detected})")
                except Exception as e:
                    logger.warning(f"Encoding auto-detection failed: {e}. Falling back to specified or default UTF-8.")
                    encoding = 'utf-8' if encoding.lower() in ['auto', 'detect'] else encoding

            total_added_count = 0
            current_batch_to_process = []
            processed_row_count = 0

            with open(csv_path, 'r', encoding=encoding, errors='replace') as csvfile:
                reader = csv.DictReader(csvfile)
                if not reader.fieldnames:
                    raise ValueError("CSV file is empty or has no headers.")

                normalized_fieldnames = {fn.lower().replace("_", ""): fn for fn in reader.fieldnames}
                col_id = normalized_fieldnames.get('id')
                col_pbt_name = normalized_fieldnames.get('pbtname', normalized_fieldnames.get('name'))
                col_pbt_description = normalized_fieldnames.get('pbtdescription', normalized_fieldnames.get('description'))
                col_cdm = normalized_fieldnames.get('cdm')

                if not col_pbt_name or not col_pbt_description:
                    missing_cols = []
                    if not col_pbt_name: missing_cols.append("PBT_NAME or NAME")
                    if not col_pbt_description: missing_cols.append("PBT_DESCRIPTION or DESCRIPTION")
                    raise ValueError(f"CSV file is missing required columns: {', '.join(missing_cols)}. Found headers: {reader.fieldnames}")

                for row_num, row_data in enumerate(reader, 1):
                    processed_row_count +=1
                    pbt_name = row_data.get(col_pbt_name, "").strip()
                    pbt_description = row_data.get(col_pbt_description, "").strip()

                    if not pbt_name or not pbt_description:
                        logger.warning(f"Skipping row {row_num}: PBT_NAME or PBT_DESCRIPTION is empty.")
                        continue

                    term_id = row_data.get(col_id, "").strip() if col_id else ""
                    if not term_id:
                        term_id = f"pbt_{uuid.uuid4()}"
                    
                    metadata = {}
                    if col_cdm and row_data.get(col_cdm):
                        metadata['cdm'] = row_data.get(col_cdm, "").strip()
                    
                    if col_id and row_data.get(col_id, "").strip() and row_data.get(col_id,"").strip() != term_id:
                         metadata['original_csv_id'] = row_data.get(col_id,"").strip()

                    for key, value in row_data.items():
                        # Check if the original key (before normalization) is one of the main columns
                        original_key_is_main_col = False
                        if col_id and key == col_id: original_key_is_main_col = True
                        if col_pbt_name and key == col_pbt_name: original_key_is_main_col = True
                        if col_pbt_description and key == col_pbt_description: original_key_is_main_col = True
                        if col_cdm and key == col_cdm: original_key_is_main_col = True
                        
                        if not original_key_is_main_col and value and value.strip():
                            meta_key = re.sub(r'\W+', '_', key.lower()) # Sanitize key
                            metadata[meta_key] = value.strip()
                    
                    current_batch_to_process.append({
                        "id": term_id,
                        "name": pbt_name,
                        "description": pbt_description,
                        "metadata": metadata
                    })

                    if len(current_batch_to_process) >= batch_size:
                        logger.info(f"Processing batch of {len(current_batch_to_process)} terms (up to row {row_num})...")
                        batch_added_count = self._process_terms_batch(current_batch_to_process)
                        total_added_count += batch_added_count
                        current_batch_to_process = [] # Reset for next batch
                
                # Process any remaining terms in the last batch
                if current_batch_to_process:
                    logger.info(f"Processing final batch of {len(current_batch_to_process)} terms (total rows read: {row_num})...")
                    batch_added_count = self._process_terms_batch(current_batch_to_process)
                    total_added_count += batch_added_count
            
            logger.info(f"CSV import completed. Total rows processed from CSV: {processed_row_count}. Total terms effectively added/updated in vector store: {total_added_count}")
            return total_added_count
        
        except FileNotFoundError:
            logger.error(f"CSV file not found at path: {csv_path}")
            raise IOError(f"CSV file not found: {csv_path}")
        except ValueError as ve:
            logger.error(f"ValueError during CSV import: {ve}")
            raise
        except Exception as e:
            logger.error(f"General error importing terms from CSV: {e}", exc_info=True)
            raise

    def _process_terms_batch(self, terms_batch: List[Dict[str, Any]]) -> int:
        """
        Helper method to process a batch of terms: embed and store.
        """
        if not terms_batch:
            return 0

        batch_start_time = time.time()
        docs_to_embed = []
        for term_data in terms_batch:
            embedding_text = f"PBT Name: {term_data['name']}. Description: {term_data['description']}"
            if term_data['metadata'].get('cdm'):
                embedding_text += f" CDM: {term_data['metadata']['cdm']}"
            
            docs_to_embed.append(MyDocument(
                id=term_data["id"],
                text=embedding_text,
                metadata=term_data["metadata"]
            ))
        
        logger.debug(f"Generating embeddings for {len(docs_to_embed)} terms in current batch...")
        try:
            docs_with_embeddings = self.embedding_client.batch_generate_embeddings(docs_to_embed)
        except Exception as e:
            logger.error(f"Failed to generate embeddings for a batch: {e}", exc_info=True)
            # Optionally, decide if you want to skip this batch or retry individual items
            return 0 # Or handle partial success

        vectors_batch_for_store = []
        for doc_with_embedding in docs_with_embeddings:
            original_term_data = next((t for t in terms_batch if t["id"] == doc_with_embedding.id), None)
            if not original_term_data:
                logger.warning(f"Internal consistency error: Could not find original term data for document ID {doc_with_embedding.id}, skipping.")
                continue

            if not doc_with_embedding.embedding:
                logger.warning(f"Skipping term '{original_term_data['name']}' (ID: {original_term_data['id']}) due to missing embedding.")
                continue
            
            vectors_batch_for_store.append({
                "id": original_term_data["id"],
                "name": original_term_data["name"],
                "description": original_term_data["description"],
                "embedding": doc_with_embedding.embedding,
                "metadata": original_term_data["metadata"] 
            })
        
        inserted_in_this_batch = 0
        if vectors_batch_for_store:
            logger.debug(f"Storing {len(vectors_batch_for_store)} vectors in current batch...")
            try:
                inserted_in_this_batch = self.vector_store.batch_store_vectors(vectors_batch_for_store)
                batch_duration = time.time() - batch_start_time
                logger.info(f"Stored {inserted_in_this_batch} terms from batch in {batch_duration:.2f}s.")
            except Exception as e:
                logger.error(f"Failed to store a batch of vectors: {e}", exc_info=True)
                # Optionally, decide if you want to retry individual items or log failures
                return 0 # Or handle partial success
        
        return inserted_in_this_batch

    async def tag_element(self, element_id: str, name: str, description: str, 
                   top_k: int = 3, threshold: float = 0.3, 
                   cdm: Optional[str] = None, 
                   example: Optional[str] = None,
                   process_name: Optional[str] = None,
                   process_description: Optional[str] = None) -> TaggingResult:
        """
        Tag a data element (or a generic item described by name/description)
        with the most similar business terms using vector search and a RAG-like agent.
        
        Args:
            element_id: Unique identifier for the element/item being tagged
            name: Name of the element/item
            description: Description of the element/item
            top_k: Number of top matching terms to return
            threshold: Minimum similarity threshold (0-1) for initial vector search
            cdm: Optional CDM of the element/item, can be used for context or biasing
            example: Optional example for context
            process_name: Optional process name for context
            process_description: Optional process description for context
                    
        Returns:
            TaggingResult containing matching terms and confidence scores
        """
        try:
            if not name or not description:
                logger.warning(f"Empty name or description for element ID: {element_id}. Cannot perform tagging.")
                return TaggingResult(
                    element_id=element_id,
                    element_name=name or "",
                    element_description=description or "",
                    matching_terms=[],
                    confidence_scores=[],
                    modeling_required=True,
                    message="Name or description is empty. Modeling should be performed."
                )
            
            if not self._term_matching_agent:
                logger.warning("TermMatchingAgent is not initialized. Falling back to basic vector search.")
                # Fallback to basic vector search if agent is not available
                query_text = f"Item Name: {name}. Description: {description}."
                if example: query_text += f" Example: {example}."
                if process_name: query_text += f" Related Process: {process_name}."
                if process_description: query_text += f" Process Description: {process_description}."
                if cdm: query_text += f" Associated CDM: {cdm}."

                doc = MyDocument(id=element_id, text=query_text)
                doc_with_embedding = self.embedding_client.generate_embeddings(doc)

                if not doc_with_embedding.embedding:
                    raise ValueError("Could not generate embedding for tagging query.")

                vector_matches = self.vector_store.find_similar_vectors(
                    query_vector=doc_with_embedding.embedding,
                    top_k=top_k,
                    threshold=threshold 
                )
                matching_terms_dicts = vector_matches
                confidence_scores = [term["similarity"] for term in vector_matches]
                message = "Tagging performed using basic vector search due to missing TermMatchingAgent."

            else: # Use the TermMatchingAgent
                matching_terms_dicts, confidence_scores = await self._term_matching_agent.find_matching_terms(
                    element_id=element_id,
                    element_name=name,
                    element_description=description,
                    top_k=top_k,
                    cdm_context=cdm, 
                    example_context=example,
                    process_name_context=process_name,
                    process_description_context=process_description,
                    initial_threshold=threshold 
                )
                message = "Tagging performed using TermMatchingAgent."

            modeling_required = False
            if not matching_terms_dicts:
                modeling_required = True
                message += " No matching terms found."
            elif not confidence_scores or max(confidence_scores, default=0.0) < self.similarity_threshold: 
                modeling_required = True
                message += f" Best match confidence ({max(confidence_scores, default=0.0):.2f}) is below threshold ({self.similarity_threshold})."
            
            if modeling_required:
                 message += " Consider modeling a new term."
            else:
                 message += f" Found {len(matching_terms_dicts)} relevant terms."
            
            return TaggingResult(
                element_id=element_id,
                element_name=name,
                element_description=description,
                matching_terms=matching_terms_dicts, 
                confidence_scores=confidence_scores, 
                modeling_required=modeling_required,
                message=message
            )
                
        except Exception as e:
            logger.error(f"Error tagging element '{name}' (ID: {element_id}): {e}", exc_info=True)
            return TaggingResult(
                element_id=element_id,
                element_name=name,
                element_description=description,
                matching_terms=[],
                confidence_scores=[],
                modeling_required=True,
                message=f"Error during tagging: {str(e)}. Modeling should be performed."
            )

    async def evaluate_tagging_with_reasoning(self, tagging_result: TaggingResult) -> Tuple[float, str]:
        """
        Evaluate the confidence in the tagging with detailed reasoning using the AI evaluation agent.
        """
        if not self.ai_evaluation_agent:
            logger.warning("AITaggingEvaluationAgent not available. Cannot provide AI-based evaluation.")
            if not tagging_result.matching_terms:
                return 0.0, "No terms to evaluate."
            avg_confidence = sum(tagging_result.confidence_scores) / len(tagging_result.confidence_scores) if tagging_result.confidence_scores else 0.0
            return avg_confidence, "AI evaluation agent not available. Confidence is based on similarity scores."

        try:
            if tagging_result.modeling_required and not tagging_result.matching_terms:
                return 0.0, "Modeling is required as no suitable matches were found."
            if not tagging_result.matching_terms:
                return 0.0, "No matching terms were found to evaluate."
            
            is_valid, overall_confidence, reasoning, _ = await self.ai_evaluation_agent.evaluate_tagging_result(tagging_result)
            return overall_confidence, reasoning
        
        except Exception as e:
            logger.error(f"Error evaluating tagging confidence with reasoning: {e}", exc_info=True)
            return 0.5, f"Error during AI evaluation of tagging: {e}"

    async def validate_tagging(self, tagging_result: TaggingResult) -> TaggingValidationResult:
        """Validate the tagging result, potentially using an AI agent."""
        if not self.ai_evaluation_agent:
            logger.warning("AITaggingEvaluationAgent not available. Basic validation will be applied.")
            is_valid_basic = bool(tagging_result.matching_terms) and not tagging_result.modeling_required
            feedback_basic = "Tagging seems plausible based on similarity scores." if is_valid_basic else "Tagging may require review or modeling."
            return TaggingValidationResult(
                is_valid=is_valid_basic,
                feedback=feedback_basic,
                suggested_alternatives=[]
            )
        try:
            is_valid, _, reasoning, _ = await self.ai_evaluation_agent.evaluate_tagging_result(tagging_result)
            return TaggingValidationResult(
                is_valid=is_valid,
                feedback=reasoning,
                suggested_alternatives=[] 
            )
        except Exception as e:
            logger.error(f"Error validating tagging: {e}", exc_info=True)
            return TaggingValidationResult(
                is_valid=False,
                feedback=f"Error during AI validation: {str(e)}",
                suggested_alternatives=[]
            )
            
    def get_all_terms(self) -> List[BusinessTerm]:
        """Get all business terms from the collection."""
        try:
            term_dicts = self.vector_store.get_all_terms() 
            return [BusinessTerm(**term_dict) for term_dict in term_dicts]
        except Exception as e:
            logger.error(f"Error retrieving all terms: {e}", exc_info=True)
            return []

    def get_term_by_id(self, term_id: str) -> Optional[BusinessTerm]:
        """Get a business term by its ID."""
        try:
            term_dict = self.vector_store.get_term_by_id(term_id)
            return BusinessTerm(**term_dict) if term_dict else None
        except Exception as e:
            logger.error(f"Error retrieving term by ID '{term_id}': {e}", exc_info=True)
            return None

    def get_term_count(self) -> int:
        """Get the total count of business terms."""
        try:
            if hasattr(self.vector_store, 'collection') and self.vector_store.collection: # type: ignore
                return self.vector_store.collection.count() # type: ignore
            return len(self.vector_store.get_all_terms())
        except Exception as e:
            logger.error(f"Error getting term count: {e}", exc_info=True)
            return 0

    def delete_term(self, term_id: str) -> bool:
        """Delete a business term by ID."""
        try:
            return self.vector_store.delete_term(term_id)
        except Exception as e:
            logger.error(f"Error deleting term ID '{term_id}': {e}", exc_info=True)
            return False

    def delete_all_terms(self) -> int:
        """Delete all business terms."""
        try:
            return self.vector_store.delete_all_terms()
        except Exception as e:
            logger.error(f"Error deleting all terms: {e}", exc_info=True)
            return 0

    def search_terms(self, query: str, limit: int = 20) -> List[BusinessTerm]:
        """Search for business terms by name or description (text search)."""
        try:
            term_dicts = self.vector_store.search_terms(query, limit)
            return [BusinessTerm(**term_dict) for term_dict in term_dicts]
        except Exception as e:
            logger.error(f"Error searching terms with query '{query}': {e}", exc_info=True)
            return []

    def compute_similarity(self, text1: str, text2: str) -> float:
        """Compute semantic similarity between two text strings."""
        try:
            doc1 = MyDocument(id="temp_sim_1", text=text1)
            doc2 = MyDocument(id="temp_sim_2", text=text2)
            
            doc1_embedded = self.embedding_client.generate_embeddings(doc1)
            doc2_embedded = self.embedding_client.generate_embeddings(doc2)

            if not doc1_embedded.embedding or not doc2_embedded.embedding:
                logger.warning("Could not generate embeddings for similarity computation.")
                return 0.0
            
            return self.vector_store.compute_cosine_similarity(
                doc1_embedded.embedding,
                doc2_embedded.embedding
            )
        except Exception as e:
            logger.error(f"Error computing similarity between texts: {e}", exc_info=True)
            return 0.0

    def get_vector_store_info(self) -> Dict[str, Any]:
        """Get information about the current vector store."""
        try:
            health = self.vector_store.health_check()
            info = {
                "type": self.vector_db_type, 
                "status": health.get("status", "unknown"),
                "term_count": health.get("term_count", self.get_term_count()), 
                "details": health.get("details", {})
            }
            return info
        except Exception as e:
            logger.error(f"Error getting vector store info: {e}", exc_info=True)
            return {"type": self.vector_db_type, "status": "error", "error": str(e)}
