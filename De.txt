import os
import sys
import uuid
import json
import logging
import chardet
import pandas as pd
import networkx as nx
import numpy as np
import csv
from typing import Optional, Any, Dict, List, Union
from pathlib import Path
from dotenv import dotenv_values
from azure.identity import DefaultAzureCredential, get_bearer_token_provider, ClientSecretCredential
from openai import AzureOpenAI
from pydantic import BaseModel
from langchain.chat_models import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain.docstore import Document as LC_DOCUMENT
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from collections import namedtuple
import re
from pydantic import BaseModel, ValidationError, field_validator

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

Triple = namedtuple("Triple", ["subject", "predicate", "object"])

## utility functions
def is_file_readable(filepath: str)->bool:
    """Check if a file is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str)->bool:
    """Convert a string to a boolean."""
    if s== 'True':
        return True
    elif s== 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean value: {s}")

## OSEnv class

class OSEnv:
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.bulk_set(config_file, True)
        self.bulk_set(creds_file, False)
        self.set_certificate_path(certificate_path)
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self.get_azure_token()
            self.credential = self._get_credential()
        else:
            self.token = None
            self.credential = self._get_credential()
        
    def _get_credential(self):
        if str_to_bool(self.get("USE_MANAGED_IDENTITY", "False")):
            return DefaultAzureCredential()
        else:
            return ClientSecretCredential(tenant_id=self.get("AZURE_TENANT_ID"), client_id=self.get("AZURE_CLIENT_ID"), client_secret=self.get("AZURE_CLIENT_SECRET"))
    
    def set_certificate_path(self, path: str):
        try:
            if not os.path.isabs(path):
                path = os.path.abspath(path)
            if not is_file_readable(path):
                raise FileNotFoundError(f"The file '{path}' does not exist or is not readable")
            
            self.set("REQUESTS_CA_BUNDLE", path)
            self.set("SSL_CERT_FILE", path)
            self.set("CURL_CA_BUNDLE", path)
        except Exception as e:
            logger.error(f"Error setting certificate path: {e}")
            raise
    
    def bulk_set(self, dotenvfile: str, print_val: bool = False)->None:
        try:
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
            if not is_file_readable(dotenvfile):
                raise FileNotFoundError(f"The file '{dotenvfile}' does not exist or is not readable")
            temp_dict = dotenv_values(dotenvfile)
            for key, value in temp_dict.items():
                self.set(key, value, print_val)
            del temp_dict
        except Exception as e:
            logger.error(f"Error loading environment variables from {dotenvfile}: {e}")
            raise
    
    def set(self, key: str, value: str, print_val: bool = False)->None:
        try:
            os.environ[key] = value
            if key not in self.var_list:
                self.var_list.append(key)
            if print_val:
                logger.info(f"{key}: {value}")
        except Exception as e:
            logger.error(f"Error setting environment variable {key}: {e}")
            raise
    
    def get(self, key: str, default: Optional[str] = None)->str:
        try:
            return os.environ.get(key, default)
        except Exception as e:
            logger.error(f"Error getting environment variable {key}: {e}")
            raise
    
    def set_proxy(self) -> None:
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            if not all([ad_username, ad_password, proxy_domain]):
                raise ValueError("Proxy settings are incomplete")
            proxy_url = f"https://{ad_username}:{ad_password}@{proxy_domain}"
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains), print_val=False)
        except Exception as e:
            logger.error(f"Error setting proxy: {e}")
            raise
    
    def get_azure_token(self) -> str:
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token set")
            return token.token
        except Exception as e:
            logger.error(f"Error retrieving Azure token: {e}")
            return None
    
    def list_env_vars(self)->None:
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [REDACTED]")
            else:
                logger.info(f"{var}: {os.getenv(var)}")


## embedding class + Document class

class MyDocument(BaseModel):
    id: str = ""
    text: str = ""
    embedding: List[float] = []
    metadata: Dict[str, Any] = {}

class EmbeddingClient:
    def __init__(self, azure_api_version: str = "2023-05-15", embeddings_model: str = "text-embedding-3-large"):
        self.azure_api_version = azure_api_version
        self.embeddings_model = embeddings_model
        self.direct_azure_client = self._get_direct_azure_client()
    
    def _get_direct_azure_client(self):
        token_provider = get_bearer_token_provider(
            DefaultAzureCredential(),
            "https://cognitiveservices.azure.com/.default"
        )
        return AzureOpenAI(token_provider, self.azure_api_version)
    
    def generate_embeddings(self, doc: MyDocument)->MyDocument:
        try:
            response = self.direct_azure_client.embeddings.create(
                model=self.embeddings_model,
                input=doc.text
            ).data[0].embedding
            doc.embedding = response
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            return doc

## LangChain components
## AzureChatbot components

class AzureChatbot:
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
    
    def _setup_chat_model(self):
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            temperature = float(self.env.get("TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2023-05-15")
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            azure_ad_token_provider = token_provider
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token_provider=azure_ad_token_provider
            )
        except Exception as e:
            logger.error(f"Error setting up chatbot: {e}")
            raise

## Regex Generator Components

class RegexPattern(BaseModel):
    """Pydantic model for regex patterns."""
    name: str
    pattern: str
    description: str = ""
    examples: List[str] = []
    metadata: Dict[str, Any] = {}

class RegexGenerator:
    """Generate regex patterns using prompt engineering."""
    
    def __init__(self, llm_client, csv_file_path: str):
        self.llm_client = llm_client
        self.csv_file_path = csv_file_path
        self.data = self._load_csv_data()
        self.patterns = []
    
    def _load_csv_data(self) -> pd.DataFrame:
        """Load and preprocess CSV data."""
        try:
            # Detect encoding
            with open(self.csv_file_path, 'rb') as f:
                result = chardet.detect(f.read())
                encoding = result['encoding']
            
            # Read CSV with detected encoding
            df = pd.read_csv(self.csv_file_path, encoding=encoding)
            
            # Clean column names - strip whitespace and convert to lowercase
            df.columns = [col.strip().lower() for col in df.columns]
            
            # Ensure required columns exist
            required_cols = ['name', 'definition', 'related_term_name', 
                           'related_term_definition', 'related_term_example']
            
            # Map column names if they don't match exactly
            col_mapping = {}
            for req_col in required_cols:
                for col in df.columns:
                    # Check for exact match or similar column names
                    if req_col == col or req_col.replace('_', ' ') == col:
                        col_mapping[col] = req_col
                        break
            
            # Rename columns based on mapping
            if col_mapping:
                df = df.rename(columns=col_mapping)
            
            # Fill missing values with empty strings
            df = df.fillna('')
            
            return df
        except Exception as e:
            logger.error(f"Error loading CSV data: {e}")
            raise
    
    def generate_patterns(self) -> List[RegexPattern]:
        """Generate regex patterns for all terms using prompt engineering."""
        
        patterns = []
        
        for _, row in self.data.iterrows():
            name = row.get('name', '')
            definition = row.get('definition', '')
            related_term = row.get('related_term_name', '')
            related_def = row.get('related_term_definition', '')
            example = row.get('related_term_example', '')
            
            if not name:
                continue
            
            try:
                # Create prompt for regex generation
                prompt = self._create_prompt(name, definition, related_term, related_def, example)
                
                # Generate regex using LLM
                pattern = self._generate_regex_with_llm(prompt)
                
                # Validate the pattern
                self._validate_regex(pattern)
                
                # Create RegexPattern object
                regex_pattern = RegexPattern(
                    name=name,
                    pattern=pattern,
                    description=definition,
                    examples=[example] if example else [],
                    metadata={
                        "related_term": related_term,
                        "related_definition": related_def
                    }
                )
                
                patterns.append(regex_pattern)
                
            except Exception as e:
                logger.error(f"Error generating pattern for '{name}': {e}")
                # Create a fallback pattern
                fallback_pattern = f"\\b{re.escape(name)}\\b"
                patterns.append(RegexPattern(
                    name=name,
                    pattern=fallback_pattern,
                    description=f"Fallback pattern for {name}",
                    examples=[],
                    metadata={"fallback": True}
                ))
        
        self.patterns = patterns
        return patterns
    
    def _create_prompt(self, name: str, definition: str, 
                      related_term: str, related_def: str, example: str) -> str:
        """Create a prompt for regex generation using all available information."""
        
        prompt = f"""
        Generate a regex pattern for data classification of the following term:
        
        Term Name: {name}
        Definition: {definition}
        
        Additional Information:
        Related Term: {related_term}
        Related Definition: {related_def}
        Example: {example}
        
        Requirements for the regex pattern:
        1. The pattern should be generic but precise enough to identify the concept
        2. Include common variations of the term
        3. Use word boundaries where appropriate
        4. Make the pattern case-insensitive
        5. The pattern should not be overly descriptive or specific
        6. Focus on key identifying elements of the term
        
        Only return the regex pattern, nothing else. Do not include explanations or any other text.
        """
        
        return prompt
    
    def _generate_regex_with_llm(self, prompt: str) -> str:
        """Generate regex pattern using LLM."""
        try:
            # Get response from LLM
            response = self.llm_client.completions.create(
                model="gpt-4o-mini",  # Use the model specified in your environment
                prompt=prompt,
                max_tokens=150,
                temperature=0.2
            )
            
            # Extract pattern from response
            pattern = response.choices[0].text.strip()
            
            # Clean up the pattern (remove quotes, etc.)
            pattern = pattern.strip('"\'')
            
            return pattern
            
        except Exception as e:
            logger.error(f"Error generating regex with LLM: {e}")
            raise
    
    def _validate_regex(self, pattern: str) -> bool:
        """Validate if the generated regex pattern is valid."""
        try:
            re.compile(pattern)
            return True
        except re.error as e:
            logger.error(f"Invalid regex pattern: {pattern}. Error: {e}")
            raise ValueError(f"Invalid regex pattern: {e}")
    
    def export_to_csv(self, output_file: str) -> None:
        """Export patterns to CSV instead of JSON."""
        try:
            with open(output_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                
                # Write header
                writer.writerow(['name', 'pattern', 'description', 'examples', 'metadata'])
                
                # Write data rows
                for pattern in self.patterns:
                    writer.writerow([
                        pattern.name,
                        pattern.pattern,
                        pattern.description,
                        '|'.join(pattern.examples),
                        json.dumps(pattern.metadata)  # Serialize metadata as JSON string
                    ])
                
            logger.info(f"Successfully exported {len(self.patterns)} patterns to {output_file}")
            
        except Exception as e:
            logger.error(f"Error exporting patterns to CSV: {e}")
            raise

## Main application

class RegexApp:
    """Main application for regex pattern generation."""
    
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.llm_client = self._setup_llm_client()
    
    def _setup_llm_client(self):
        """Set up the LLM client for regex generation."""
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            
            # Initialize Azure OpenAI client
            client = AzureOpenAI(
                azure_endpoint=self.env.get("AZURE_ENDPOINT", ""),
                api_version=self.env.get("API_VERSION", "2023-05-15"),
                azure_ad_token_provider=token_provider
            )
            
            return client
            
        except Exception as e:
            logger.error(f"Error setting up LLM client: {e}")
            raise
    
    def generate_patterns(self, input_csv: str, output_csv: str) -> None:
        """Generate regex patterns from input CSV and export to output CSV."""
        try:
            # Initialize regex generator
            generator = RegexGenerator(self.llm_client, input_csv)
            
            # Generate patterns
            patterns = generator.generate_patterns()
            
            # Export to CSV
            generator.export_to_csv(output_csv)
            
            logger.info(f"Generated {len(patterns)} regex patterns and saved to {output_csv}")
            
        except Exception as e:
            logger.error(f"Error in generate_patterns: {e}")
            raise

def main():
    """Main function to run the application."""
    try:
        # Parse command-line arguments
        input_file = sys.argv[1] if len(sys.argv) > 1 else "input.csv"
        output_file = sys.argv[2] if len(sys.argv) > 2 else "regex_patterns.csv"
        
        # Initialize app
        app = RegexApp()
        
        # Generate patterns
        app.generate_patterns(input_file, output_file)
        
    except Exception as e:
        logger.error(f"Error in main function: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
