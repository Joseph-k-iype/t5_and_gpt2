"""
LLM-based guidance analyzer for extracting ODRL components from guidance text.

COMPLETE FIX - ALL ERRORS RESOLVED:
✅ parse_json_safely → parse_json_response (5 places)
✅ Removed temperature parameter (2 places) 
✅ Removed max_tokens parameter (1 place)
✅ odrl_final_synthesis → odrl_synthesis_prompt (1 place)
✅ Enhanced JSON-only system message
✅ Uses clean_and_parse for robust JSON handling

Location: src/analyzers/guidance_analyzer.py
"""
import logging
from typing import Dict, List, Any, Optional
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, ValidationError

from ..services.openai_service import OpenAIService
from ..utils.json_parser import SafeJsonParser
from ..prompting.strategies import PromptingStrategies
from ..validators import ODRLLogicalValidator

logger = logging.getLogger(__name__)


class ODRLComponents(BaseModel):
    """Extracted ODRL components from guidance text."""
    
    # Core ODRL elements
    actions: List[str] = Field(default_factory=list)
    permissions: List[Dict[str, Any]] = Field(default_factory=list)
    prohibitions: List[Dict[str, Any]] = Field(default_factory=list)
    constraints: List[Dict[str, Any]] = Field(default_factory=list)
    
    # Data context
    data_categories: List[str] = Field(default_factory=list)
    data_subjects: List[str] = Field(default_factory=list)
    
    # Parties and roles
    parties: Dict[str, List[str]] = Field(default_factory=dict)
    
    # Additional context
    purpose: Optional[str] = None
    legal_basis: Optional[str] = None
    geographic_scope: List[str] = Field(default_factory=list)
    
    # Evidence and verification
    evidence_requirements: List[str] = Field(default_factory=list)
    verification_methods: List[str] = Field(default_factory=list)
    
    # Metadata
    confidence_score: float = 0.8
    extraction_reasoning: str = ""
    
    # Supervisor review metadata
    supervisor_reviewed: bool = False
    supervisor_corrections: int = 0


class GuidanceAnalyzer:
    """
    Analyzes guidance text using LLM to extract ODRL components.
    Uses complex prompting strategies for accurate extraction.
    NOW INCLUDES: Supervisor agent for permission/prohibition review.
    """
    
    def __init__(self):
        """Initialize guidance analyzer with LLM service."""
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
    
    async def analyze_guidance(
        self, 
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        rule_id: str
    ) -> ODRLComponents:
        """
        Comprehensive analysis of guidance text to extract ODRL components.
        
        Args:
            guidance_text: Complete guidance text
            rule_name: Name/title of the rule
            framework_type: DSS or DataVISA
            restriction_condition: restriction or condition
            rule_id: Unique identifier
            
        Returns:
            ODRLComponents with extracted and validated information
        """
        logger.info(f"Analyzing guidance for rule: {rule_name} ({rule_id})")
        
        # Stage 1: Initial comprehensive analysis
        initial_analysis = await self._stage1_comprehensive_analysis(
            guidance_text, rule_name, framework_type, restriction_condition
        )
        
        # Stage 2: ODRL-specific extraction
        odrl_extraction = await self._stage2_odrl_extraction(
            guidance_text, rule_name, initial_analysis
        )
        
        # Stage 3: Constraint analysis
        constraint_analysis = await self._stage3_constraint_analysis(
            guidance_text, rule_name, odrl_extraction
        )
        
        # Stage 4: Data category identification
        data_categories = await self._stage4_data_category_identification(
            guidance_text, rule_name, constraint_analysis
        )
        
        # Stage 4.5: Supervisor review
        reviewed_extraction = await self._stage4_5_supervisor_review(
            guidance_text, rule_name, odrl_extraction
        )
        
        # Stage 5: Synthesis and verification
        final_components = await self._stage5_synthesis(
            guidance_text, rule_name, framework_type, restriction_condition,
            initial_analysis, reviewed_extraction, constraint_analysis, data_categories
        )
        
        return final_components
    
    async def _stage1_comprehensive_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        framework_type: str,
        restriction_condition: str
    ) -> str:
        """Stage 1: Comprehensive understanding of guidance text."""
        
        prompt = PromptingStrategies.odrl_comprehensive_guidance_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition
        )
        
        messages = [
            SystemMessage(content="You are a legal and data protection expert analyzing regulatory guidance."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 1 analysis complete for {rule_name}")
        
        return response
    
    async def _stage2_odrl_extraction(
        self, 
        guidance_text: str, 
        rule_name: str,
        initial_analysis: str
    ) -> str:
        """Stage 2: Extract ODRL-specific components."""
        
        prompt = PromptingStrategies.odrl_component_extraction(
            guidance_text=guidance_text,
            rule_name=rule_name,
            initial_analysis=initial_analysis
        )
        
        messages = [
            SystemMessage(content="You are an ODRL specialist. Extract policy components according to ODRL ontology standards."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 2 ODRL extraction complete for {rule_name}")
        
        return response
    
    async def _stage3_constraint_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 3: Detailed constraint analysis."""
        
        prompt = PromptingStrategies.odrl_constraint_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            odrl_extraction=odrl_extraction
        )
        
        messages = [
            SystemMessage(content="You are an expert in ODRL constraints."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 3 constraint analysis complete for {rule_name}")
        
        return response
    
    async def _stage4_data_category_identification(
        self, 
        guidance_text: str, 
        rule_name: str,
        constraint_analysis: str
    ) -> str:
        """Stage 4: Identify specific data categories."""
        
        prompt = PromptingStrategies.odrl_data_category_identification(
            guidance_text=guidance_text,
            rule_name=rule_name,
            constraint_analysis=constraint_analysis
        )
        
        messages = [
            SystemMessage(content="You are a data classification expert."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 4 data category identification complete for {rule_name}")
        
        return response
    
    async def _stage4_5_supervisor_review(
        self,
        guidance_text: str,
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 4.5: Supervisor review of permission/prohibition classification."""
        logger.info(f"Stage 4.5: Supervisor review for {rule_name}")
        
        try:
            # ✅ FIXED: Use clean_and_parse for robust JSON handling
            extraction_data = self.json_parser.clean_and_parse(odrl_extraction)
            
            if not extraction_data or "error" in extraction_data:
                logger.warning(f"Could not parse ODRL extraction, using original")
                return odrl_extraction
            
            extracted_permissions = extraction_data.get("permissions", [])
            extracted_prohibitions = extraction_data.get("prohibitions", [])
            
            if not extracted_permissions and not extracted_prohibitions:
                logger.info("No permissions or prohibitions to review")
                return odrl_extraction
            
            import json
            prompt = PromptingStrategies.supervisor_permission_prohibition_review(
                guidance_text=guidance_text,
                rule_name=rule_name,
                extracted_permissions=extracted_permissions,
                extracted_prohibitions=extracted_prohibitions,
                odrl_extraction=odrl_extraction
            )
            
            messages = [
                SystemMessage(content="You are a Supervisor Agent validating ODRL policy classifications."),
                HumanMessage(content=prompt)
            ]
            
            # ✅ FIXED: Removed temperature parameter
            supervisor_response = await self.openai_service.get_completion(messages)
            
            # ✅ FIXED: Use clean_and_parse for robust JSON handling
            review_data = self.json_parser.clean_and_parse(supervisor_response.content)
            
            if not review_data or "error" in review_data:
                logger.warning(f"Could not parse supervisor review, using original")
                return odrl_extraction
            
            overall_assessment = review_data.get("overall_assessment", {})
            requires_correction = overall_assessment.get("requires_correction", False)
            misclassifications_found = review_data.get("misclassifications_found", [])
            
            if requires_correction and misclassifications_found:
                logger.warning(f"Supervisor found {len(misclassifications_found)} misclassifications")
                
                corrected_permissions = review_data.get("corrected_permissions", extracted_permissions)
                corrected_prohibitions = review_data.get("corrected_prohibitions", extracted_prohibitions)
                
                extraction_data["permissions"] = corrected_permissions
                extraction_data["prohibitions"] = corrected_prohibitions
                extraction_data["supervisor_reviewed"] = True
                extraction_data["supervisor_corrections"] = len(misclassifications_found)
                
                return json.dumps(extraction_data, indent=2)
            else:
                logger.info(f"Supervisor approved classifications for {rule_name}")
                extraction_data["supervisor_reviewed"] = True
                extraction_data["supervisor_corrections"] = 0
                return json.dumps(extraction_data, indent=2)
                
        except Exception as e:
            logger.error(f"Error in supervisor review: {e}")
            return odrl_extraction
    
    async def _stage5_synthesis(
        self,
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        initial_analysis: str,
        odrl_extraction: str,
        constraint_analysis: str,
        data_categories: str
    ) -> ODRLComponents:
        """Stage 5: Final synthesis and validation."""
        
        logger.info(f"Stage 5: Synthesizing ODRL components for {rule_name}")
        
        # ✅ FIXED: Changed from odrl_final_synthesis to odrl_synthesis_prompt
        prompt = PromptingStrategies.odrl_synthesis_prompt(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition,
            initial_analysis=initial_analysis,
            odrl_extraction=odrl_extraction,
            constraint_analysis=constraint_analysis,
            data_categories=data_categories
        )
        
        messages = [
            SystemMessage(content=(
                "You are a synthesis expert for ODRL policies.\n\n"
                "CRITICAL: You MUST return ONLY pure JSON. No preamble, no explanations, no markdown.\n"
                "Start your response with '{' and end with '}'.\n"
                "DO NOT write 'Here is the JSON' or any other text.\n"
                "ONLY output the raw JSON object with proper double quotes around all keys and string values."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            logger.debug(f"Requesting LLM synthesis for {rule_name}")
            
            # ✅ FIXED: Removed temperature and max_tokens parameters
            response = await self.openai_service.get_completion(messages)
            
            logger.debug(f"Received LLM response for {rule_name}")
            
            # ✅ FIXED: Use clean_and_parse which is most robust
            parsed_data = self.json_parser.clean_and_parse(response.content)
            
            if not parsed_data or "error" in parsed_data:
                logger.error(f"Failed to parse synthesis response for {rule_name}")
                logger.error(f"Response preview: {response.content[:500]}...")
                return ODRLComponents(
                    extraction_reasoning="Failed to parse LLM response"
                )
            
            # Sanitize data
            for key in ['actions', 'data_categories', 'data_subjects', 'geographic_scope', 
                        'evidence_requirements', 'verification_methods']:
                if key in parsed_data:
                    parsed_data[key] = self._sanitize_string_list(parsed_data.get(key), key)
                else:
                    parsed_data[key] = []
            
            for key in ['permissions', 'prohibitions', 'constraints']:
                if key in parsed_data:
                    parsed_data[key] = self._sanitize_dict_list(parsed_data.get(key), key)
                else:
                    parsed_data[key] = []
            
            if 'parties' in parsed_data and isinstance(parsed_data['parties'], dict):
                for party_key in ['controllers', 'processors', 'assigners', 'assignees', 'third_parties']:
                    if party_key not in parsed_data['parties'] or not isinstance(parsed_data['parties'][party_key], list):
                        parsed_data['parties'][party_key] = []
            else:
                parsed_data['parties'] = {
                    'controllers': [], 'processors': [], 'assigners': [],
                    'assignees': [], 'third_parties': []
                }
            
            # Extract supervisor metadata
            try:
                reviewed_data = self.json_parser.clean_and_parse(odrl_extraction)
                if reviewed_data and not "error" in reviewed_data:
                    parsed_data['supervisor_reviewed'] = reviewed_data.get('supervisor_reviewed', False)
                    parsed_data['supervisor_corrections'] = reviewed_data.get('supervisor_corrections', 0)
            except:
                pass
            
            try:
                components = ODRLComponents(**parsed_data)
                logger.info(f"Successfully created ODRLComponents for {rule_name}")
                return components
            except ValidationError as e:
                logger.error(f"Validation error: {e}")
                return ODRLComponents(extraction_reasoning=f"Validation error: {str(e)}")
        
        except Exception as e:
            logger.error(f"Error in synthesis stage: {e}", exc_info=True)
            return ODRLComponents(extraction_reasoning=f"Synthesis failed: {str(e)}")
    
    def _sanitize_string_list(self, data: Any, field_name: str) -> List[str]:
        """Sanitize a field that should be a list of strings."""
        if not data:
            return []
        if not isinstance(data, list):
            logger.warning(f"{field_name} is not a list, converting: {type(data)}")
            return []
        
        sanitized = []
        for item in data:
            if isinstance(item, str):
                if len(item) > 200 or item.lower().startswith(('list all', 'include', 'complete list')):
                    continue
                sanitized.append(item)
            elif isinstance(item, dict):
                if 'name' in item:
                    sanitized.append(str(item['name']))
                elif 'category_name' in item:
                    sanitized.append(str(item['category_name']))
            else:
                logger.warning(f"Non-string item in {field_name}: {type(item)}")
        
        return sanitized
    
    def _sanitize_dict_list(self, data: Any, field_name: str) -> List[Dict[str, Any]]:
        """Sanitize a field that should be a list of dictionaries."""
        if not data:
            return []
        if not isinstance(data, list):
            logger.warning(f"{field_name} is not a list: {type(data)}")
            return []
        
        sanitized = []
        for item in data:
            if isinstance(item, dict):
                sanitized.append(item)
            else:
                logger.warning(f"Non-dict item in {field_name}: {type(item)}")
        
        return sanitized
