#!/usr/bin/env python
"""
Business Terms Import Script

This script imports business terms from a CSV file into the vector database (ChromaDB).
It expects a CSV with columns like 'id' (optional), 'PBT_NAME', 'PBT_DESCRIPTION', and 'CDM'.
Embeddings are generated using the configured text-embedding-3-large model.
The BusinessTermManager now handles large files by streaming and batching internally.
"""

import os
import sys
import logging
import argparse
import time
from typing import Optional, Tuple

# Add parent directory to path to import app modules
# This ensures that 'app.core' etc. can be imported
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from app.core.business_terms import BusinessTermManager
    from app.config.environment import get_os_env # To initialize environment settings
    from app.config.settings import get_vector_store # To ensure vector store is initialized
except ImportError as e:
    print(f"Error importing application modules: {e}")
    print("Please ensure the script is run from the project root or the PYTHONPATH is set correctly.")
    sys.exit(1)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [%(name)s:%(lineno)d] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

def detect_file_encoding(file_path: str) -> str:
    """
    Detect the encoding of a file using chardet.
    Falls back to utf-8 if chardet is not available or detection fails.
    """
    try:
        import chardet
        with open(file_path, 'rb') as f:
            # Read a larger sample for better detection with potentially mixed content or large files
            sample_size = min(100 * 1024, os.path.getsize(file_path)) # Read up to 100KB
            sample = f.read(sample_size)
            result = chardet.detect(sample)
            encoding = result['encoding']
            confidence = result['confidence']
            if encoding and confidence and confidence > 0.7: # Reasonably high confidence
                logger.info(f"Detected encoding: {encoding} with confidence {confidence:.2f}")
                return encoding
            elif encoding:
                 logger.warning(f"Detected encoding {encoding} with low confidence ({confidence:.2f}). Proceeding with it, but consider specifying encoding if issues arise.")
                 return encoding
            else:
                logger.warning(f"Could not detect encoding (confidence {confidence:.2f}). Using UTF-8 as fallback.")
                return 'utf-8'
    except ImportError:
        logger.warning("chardet library not found. Assuming UTF-8 encoding. For better auto-detection, run: pip install chardet")
        return 'utf-8'
    except Exception as e:
        logger.error(f"Error detecting encoding: {e}. Assuming UTF-8.")
        return 'utf-8'

def main():
    parser = argparse.ArgumentParser(
        description="Import Preferred Business Terms (PBTs) from a CSV file into ChromaDB.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("csv_file", help="Path to the CSV file containing PBTs. Expected headers: id (optional), PBT_NAME, PBT_DESCRIPTION, CDM (optional).")
    parser.add_argument("--batch-size", type=int, default=100, help="Number of terms to process (read from CSV, embed, store) in each internal batch within BusinessTermManager.")
    parser.add_argument("--encoding", type=str, default="auto", help="Encoding of the CSV file (e.g., 'utf-8', 'latin1'). Use 'auto' for auto-detection.")
    
    parser.add_argument("--chroma-dir", help="Override ChromaDB persistent directory (CHROMA_PERSIST_DIR).")
    parser.add_argument("--chroma-collection", help="Override ChromaDB collection name (CHROMA_COLLECTION).")
    parser.add_argument("--embedding-model", help="Override OpenAI embedding model (EMBEDDING_MODEL), e.g., 'text-embedding-3-large'.")

    args = parser.parse_args()

    if args.chroma_dir:
        os.environ["CHROMA_PERSIST_DIR"] = args.chroma_dir
    if args.chroma_collection:
        os.environ["CHROMA_COLLECTION"] = args.chroma_collection
    if args.embedding_model:
        os.environ["EMBEDDING_MODEL"] = args.embedding_model
    else:
        os.environ.setdefault("EMBEDDING_MODEL", "text-embedding-3-large")

    try:
        get_os_env() 
    except Exception as e:
        logger.error(f"Failed to initialize OS environment: {e}. Ensure .env files are correctly set up if needed.")

    file_encoding = args.encoding
    if args.encoding.lower() == 'auto':
        logger.info("Attempting to auto-detect CSV file encoding...")
        file_encoding = detect_file_encoding(args.csv_file)
    
    logger.info(f"--- CSV Import Configuration ---")
    logger.info(f"CSV File: {args.csv_file}")
    logger.info(f"Target Encoding: {file_encoding}")
    logger.info(f"Internal Batch Size: {args.batch_size}")
    logger.info(f"Chroma Directory: {os.environ.get('CHROMA_PERSIST_DIR')}")
    logger.info(f"Chroma Collection: {os.environ.get('CHROMA_COLLECTION')}")
    logger.info(f"Embedding Model: {os.environ.get('EMBEDDING_MODEL')}")
    logger.info(f"---------------------------------")

    try:
        logger.info("Initializing Business Term Manager...")
        term_manager = BusinessTermManager()
        
        initial_term_count = term_manager.get_term_count()
        logger.info(f"Initial terms in ChromaDB collection '{term_manager.vector_store.collection_name}': {initial_term_count}") # type: ignore

        logger.info("Starting CSV import process (BusinessTermManager will handle streaming and batching)...")
        start_time = time.time()
        
        # BusinessTermManager.import_terms_from_csv now handles large files by streaming internally
        added_count = term_manager.import_terms_from_csv(
            csv_path=args.csv_file,
            encoding=file_encoding,
            batch_size=args.batch_size # This batch_size is used by the manager for its internal processing chunks
        )
        
        total_time = time.time() - start_time
        final_term_count = term_manager.get_term_count()
        
        logger.info(f"Import completed in {total_time:.2f} seconds.")
        logger.info(f"Terms added/updated by BusinessTermManager: {added_count}")
        logger.info(f"Total terms now in ChromaDB collection '{term_manager.vector_store.collection_name}': {final_term_count}") # type: ignore
        
        if added_count > 0:
            logger.info("Import successful.")
        elif initial_term_count == final_term_count and initial_term_count > 0 :
             logger.info("No new terms were added. Existing terms may have been updated if their content changed (upsert behavior).")
        else:
            logger.info("No terms were added or updated by the manager. Check CSV content and logs for details.")

    except FileNotFoundError:
        logger.error(f"Error: The CSV file was not found at '{args.csv_file}'. Please check the path.")
        sys.exit(1)
    except ValueError as ve: # Catch specific errors from BusinessTermManager
        logger.error(f"Error during import: {ve}")
        sys.exit(1)
    except Exception as e:
        logger.error(f"An unexpected error occurred during the import script execution: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
