// src/contexts/ChatContext.jsx - Fixed to sync with research panel
import React, { createContext, useContext, useReducer, useCallback } from 'react';
import { chatService } from '../services/chatService';
import { useSession } from './SessionContext';
import { useResearch } from './ResearchContext'; // Import research context
import toast from 'react-hot-toast';

// Create Chat Context
export const ChatContext = createContext();

// Chat reducer
const chatReducer = (state, action) => {
  switch (action.type) {
    case 'ADD_MESSAGE':
      return {
        ...state,
        messages: [...state.messages, action.payload],
      };
    case 'SET_MESSAGES':
      return {
        ...state,
        messages: action.payload,
      };
    case 'SET_TYPING':
      return {
        ...state,
        isTyping: action.payload,
      };
    case 'SET_LOADING':
      return {
        ...state,
        isLoading: action.payload,
      };
    case 'SET_PROCESSING':
      return {
        ...state,
        isProcessing: action.payload,
      };
    case 'SET_ERROR':
      return {
        ...state,
        error: action.payload,
        isLoading: false,
        isTyping: false,
        isProcessing: false,
      };
    case 'CLEAR_MESSAGES':
      return {
        ...state,
        messages: [],
        error: null,
      };
    case 'SET_LAST_RESEARCH_QUERY':
      return {
        ...state,
        lastResearchQuery: action.payload,
      };
    default:
      return state;
  }
};

// Initial state
const initialState = {
  messages: [],
  isTyping: false,
  isLoading: false,
  isProcessing: false,
  error: null,
  lastResearchQuery: null, // Track the last query that triggered research
};

export const ChatProvider = ({ children }) => {
  const [state, dispatch] = useReducer(chatReducer, initialState);
  const { sessionId, userId, updateSessionStats } = useSession();
  
  // Get research context functions - this is the key integration!
  const { updateFromChatResearch, notifyChatResearchStarted } = useResearch();

  const addMessage = useCallback((message) => {
    dispatch({ type: 'ADD_MESSAGE', payload: message });
  }, []);

  // Helper function to detect if a query is likely to trigger research
  const isResearchQuery = useCallback((query) => {
    const researchIndicators = [
      'analysis', 'comprehensive', 'compare', 'explain', 'requirements',
      'implementation', 'compliance', 'framework', 'regulation', 'law',
      'gdpr', 'ccpa', 'privacy', 'data protection', 'how to', 'what are',
      'differences between', 'best practices', 'guidelines'
    ];
    
    const queryLower = query.toLowerCase();
    const wordCount = query.split(' ').length;
    const hasIndicators = researchIndicators.some(indicator => queryLower.includes(indicator));
    
    // Research likely if: long query (>5 words) OR contains research indicators
    return wordCount > 5 || hasIndicators;
  }, []);

  // Helper function to detect if a response is a research result
  const isResearchResponse = useCallback((response) => {
    return !!(
      response.metadata?.real_ai && 
      (response.approach?.includes('REAL_AI') || 
       response.approach?.includes('enhanced') ||
       response.metadata?.approach?.includes('enhanced') ||
       response.answer?.length > 500) // Long responses are likely research
    );
  }, []);

  const sendMessage = useCallback(async (content) => {
    if (!sessionId || !content.trim()) return;

    const trimmedContent = content.trim();
    const isLikelyResearch = isResearchQuery(trimmedContent);

    try {
      // Add user message immediately
      const userMessage = {
        id: `user_${Date.now()}`,
        role: 'user',
        content: trimmedContent,
        timestamp: new Date().toISOString(),
      };
      
      addMessage(userMessage);
      dispatch({ type: 'SET_LOADING', payload: true });
      dispatch({ type: 'SET_TYPING', payload: true });

      // If this looks like a research query, notify research context
      if (isLikelyResearch) {
        console.log('🔬 Detected research query, notifying research panel...');
        dispatch({ type: 'SET_LAST_RESEARCH_QUERY', payload: trimmedContent });
        notifyChatResearchStarted(trimmedContent);
      }

      // Show processing message for longer operations
      const processingTimeout = setTimeout(() => {
        dispatch({ type: 'SET_PROCESSING', payload: true });
        
        // Add processing message
        const processingMessage = {
          id: `processing_${Date.now()}`,
          role: 'assistant',
          content: isLikelyResearch 
            ? '🧠 Conducting deep AI research analysis... This may take 1-3 minutes for comprehensive insights. The system is analyzing multiple sources and generating detailed findings.'
            : '🧠 AI processing your request... Please wait while I analyze and generate a response.',
          timestamp: new Date().toISOString(),
          metadata: {
            confidence: 'high',
            approach: 'processing_indicator',
            isTemporary: true,
          },
        };
        addMessage(processingMessage);
      }, 8000); // Show after 8 seconds

      try {
        // Send to API
        console.log('📤 Sending message to backend for processing...');
        const response = await chatService.sendQuickMessage({
          message: trimmedContent,
          session_id: sessionId,
          user_id: userId,
        });

        // Clear processing timeout
        clearTimeout(processingTimeout);
        dispatch({ type: 'SET_PROCESSING', payload: false });

        console.log('✅ Received response from backend');
        console.log('Response metadata:', response.metadata);

        // Add AI response to chat
        const aiMessage = {
          id: `ai_${Date.now()}`,
          role: 'assistant',
          content: response.answer,
          timestamp: response.timestamp,
          metadata: {
            confidence: response.confidence,
            approach: response.approach,
            real_ai: response.metadata?.real_ai || false,
            ...response.metadata,
          },
        };
        
        addMessage(aiMessage);

        // 🎯 KEY FIX: If this is a research response, update the research panel!
        if (isResearchResponse(response)) {
          console.log('🎯 Research response detected! Updating research panel...');
          
          // Update research panel with the results
          updateFromChatResearch(response, state.lastResearchQuery || trimmedContent);
          
          // Show success notification
          toast.success('🎉 AI research completed! Check the Research panel for detailed analysis.');
        } else {
          console.log('💬 Regular chat response (not research)');
        }
        
        // Update session stats
        updateSessionStats({
          messageCount: state.messages.length + 2,
        });

      } catch (error) {
        clearTimeout(processingTimeout);
        dispatch({ type: 'SET_PROCESSING', payload: false });
        
        console.error('Failed to send message:', error);
        
        // Better error handling
        let errorMessage = 'I apologize, but I encountered an error processing your message.';
        let shouldShowToast = true;
        
        if (error.isResearchTimeout) {
          errorMessage = '⏰ The AI research is taking longer than expected, but it\'s still processing. The system is conducting comprehensive analysis - please be patient.';
          shouldShowToast = false;
        } else if (!error.response) {
          errorMessage = 'Unable to connect to the AI research system. Please check if the backend is running on port 8000.';
          toast.error('Connection failed - is the backend running?');
        } else if (error.response?.status >= 500) {
          errorMessage = 'The AI research system encountered an error. Please try again in a moment.';
          toast.error('Server error - please try again');
        } else if (shouldShowToast) {
          toast.error('Failed to process message');
        }
        
        dispatch({ type: 'SET_ERROR', payload: error.message });
        
        // Add error message
        const errorMessageObj = {
          id: `error_${Date.now()}`,
          role: 'assistant',
          content: errorMessage,
          timestamp: new Date().toISOString(),
          metadata: {
            confidence: 'low',
            approach: 'error',
            isError: true,
          },
        };
        
        addMessage(errorMessageObj);
      }

    } catch (outerError) {
      console.error('Outer error in sendMessage:', outerError);
      dispatch({ type: 'SET_ERROR', payload: outerError.message });
      
    } finally {
      dispatch({ type: 'SET_LOADING', payload: false });
      dispatch({ type: 'SET_TYPING', payload: false });
      dispatch({ type: 'SET_PROCESSING', payload: false });
    }
  }, [sessionId, userId, addMessage, state.messages.length, state.lastResearchQuery, updateSessionStats, isResearchQuery, isResearchResponse, notifyChatResearchStarted, updateFromChatResearch]);

  const startDeepResearch = useCallback(async (topic) => {
    if (!sessionId || !topic.trim()) return;

    try {
      // Add user message
      const userMessage = {
        id: `research_user_${Date.now()}`,
        role: 'user',
        content: topic.trim(),
        timestamp: new Date().toISOString(),
        metadata: {
          type: 'research_request',
        },
      };
      
      addMessage(userMessage);
      dispatch({ type: 'SET_LOADING', payload: true });
      dispatch({ type: 'SET_PROCESSING', payload: true });
      dispatch({ type: 'SET_LAST_RESEARCH_QUERY', payload: topic.trim() });

      // Notify research context
      notifyChatResearchStarted(topic.trim());

      // Start research message
      const researchMessage = {
        id: `research_start_${Date.now()}`,
        role: 'assistant',
        content: `🔬 Starting comprehensive deep research on: "${topic.trim()}"\n\n🤖 Initializing multi-agent AI research system...\n⏳ This process typically takes 2-5 minutes for thorough analysis.\n\n📊 The system will:\n• Analyze multiple data sources\n• Apply specialized research agents\n• Generate comprehensive insights\n• Synthesize findings into a detailed report\n\nPlease wait while the research is conducted...`,
        timestamp: new Date().toISOString(),
        metadata: {
          confidence: 'high',
          approach: 'deep_research_initiated',
          type: 'research_start',
        },
      };
      
      addMessage(researchMessage);

    } catch (error) {
      console.error('Failed to start research:', error);
      dispatch({ type: 'SET_ERROR', payload: error.message });
      toast.error('Failed to start research. Please try again.');
      
    } finally {
      dispatch({ type: 'SET_LOADING', payload: false });
    }
  }, [sessionId, addMessage, notifyChatResearchStarted]);

  const loadConversationHistory = useCallback(async () => {
    if (!sessionId) return;

    try {
      const history = await chatService.getConversationHistory(sessionId);
      dispatch({ type: 'SET_MESSAGES', payload: history.messages });
      
    } catch (error) {
      console.error('Failed to load conversation history:', error);
    }
  }, [sessionId]);

  const clearMessages = useCallback(() => {
    dispatch({ type: 'CLEAR_MESSAGES' });
  }, []);

  const value = {
    ...state,
    sendMessage,
    startDeepResearch,
    addMessage,
    loadConversationHistory,
    clearMessages,
  };

  return (
    <ChatContext.Provider value={value}>
      {children}
    </ChatContext.Provider>
  );
};

// Standalone hook for backward compatibility
export const useChat = () => {
  const context = useContext(ChatContext);
  if (!context) {
    throw new error('useChat must be used within a ChatProvider');
  }
  return context;
};
