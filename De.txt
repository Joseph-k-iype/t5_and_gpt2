import asyncio
import json
import logging
import os
from typing import Dict, List, Optional, Any, Union
from enum import Enum
from datetime import datetime

# Core dependencies
import openai
from openai import OpenAI
from pydantic import BaseModel, Field, validator
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===============================
# GLOBAL CONFIGURATION
# ===============================

class Config:
    """Global configuration for the legislation rules converter."""
    BASE_URL = "https://api.openai.com/v1"
    API_KEY = os.getenv("OPENAI_API_KEY")
    CHAT_MODEL = "o3-mini-2025-01-31"
    EMBEDDING_MODEL = "text-embedding-3-large"
    
    # Paths
    RULES_OUTPUT_PATH = "./extracted_rules/"
    EMBEDDINGS_PATH = "./embeddings/"
    LOGS_PATH = "./logs/"

# Validate API key
if not Config.API_KEY:
    raise ValueError("OPENAI_API_KEY environment variable is required")

# ===============================
# PYDANTIC MODELS
# ===============================

class DataDomain(str, Enum):
    """Data domains as per privacy regulations."""
    DATA_TRANSFER = "data_transfer"
    DATA_USAGE = "data_usage" 
    DATA_STORAGE = "data_storage"

class DataRole(str, Enum):
    """Roles in data processing."""
    CONTROLLER = "controller"
    PROCESSOR = "processor"
    JOINT_CONTROLLER = "joint_controller"

class ConditionOperator(str, Enum):
    """Operators for rule conditions."""
    EQUAL = "equal"
    NOT_EQUAL = "notEqual"
    GREATER_THAN = "greaterThan"
    LESS_THAN = "lessThan"
    GREATER_THAN_EQUAL = "greaterThanInclusive"
    LESS_THAN_EQUAL = "lessThanInclusive"
    CONTAINS = "contains"
    NOT_CONTAINS = "doesNotContain"
    IN = "in"
    NOT_IN = "notIn"

class RuleCondition(BaseModel):
    """Individual condition within a rule."""
    fact: str = Field(..., description="The fact/data point to evaluate")
    operator: ConditionOperator = Field(..., description="Comparison operator")
    value: Union[str, int, float, bool, List[Any]] = Field(..., description="Value to compare against")
    path: Optional[str] = Field(None, description="JSONPath to navigate nested objects")
    description: str = Field(..., description="Human-readable description of this condition")
    data_domain: List[DataDomain] = Field(..., description="Applicable data domains")
    role: DataRole = Field(..., description="Role this condition applies to")
    reasoning: str = Field(..., description="LLM reasoning for why this condition was extracted")

class RuleEvent(BaseModel):
    """Event triggered when rule conditions are met."""
    type: str = Field(..., description="Type of event/action")
    params: Dict[str, Any] = Field(default_factory=dict, description="Event parameters")

class LegislationRule(BaseModel):
    """Complete rule structure aligned with json-rules-engine format."""
    id: str = Field(..., description="Unique rule identifier")
    name: str = Field(..., description="Rule name")
    description: str = Field(..., description="Human-readable rule description")
    source_article: str = Field(..., description="Source legislation article/section")
    
    conditions: Dict[str, List[RuleCondition]] = Field(
        ..., 
        description="Rule conditions with 'all', 'any', or 'not' logic"
    )
    event: RuleEvent = Field(..., description="Event triggered when conditions are met")
    priority: int = Field(default=1, description="Rule priority (1-10)")
    
    # Metadata
    extracted_at: datetime = Field(default_factory=datetime.utcnow)
    extraction_method: str = Field(default="llm_analysis")
    confidence_score: float = Field(..., ge=0.0, le=1.0, description="Extraction confidence")
    
    @validator('conditions')
    def validate_conditions_structure(cls, v):
        """Ensure conditions follow json-rules-engine format."""
        valid_keys = {'all', 'any', 'not'}
        if not isinstance(v, dict) or not any(key in valid_keys for key in v.keys()):
            raise ValueError("Conditions must contain 'all', 'any', or 'not' keys")
        return v

class ExtractionResult(BaseModel):
    """Complete result of legislation analysis."""
    rules: List[LegislationRule] = Field(..., description="Extracted rules")
    summary: str = Field(..., description="Summary of extraction")
    total_rules: int = Field(..., description="Total number of rules extracted")
    processing_time: float = Field(..., description="Processing time in seconds")
    embeddings: Optional[List[List[float]]] = Field(None, description="Rule embeddings")

# ===============================
# ADVANCED PROMPTING STRATEGIES
# ===============================

class PromptingStrategies:
    """Advanced prompting strategies for rule extraction."""
    
    @staticmethod
    def chain_of_thought_prompt(legislation_text: str) -> str:
        """Chain of Thought prompting for step-by-step reasoning."""
        return f"""
        You are an expert legal analyst specializing in converting legislation into machine-readable rules.
        
        Analyze the following legislation text step by step:
        
        LEGISLATION TEXT:
        {legislation_text}
        
        CHAIN OF THOUGHT ANALYSIS:
        
        Step 1: Identify Key Legal Obligations
        - What are the main obligations stated in this text?
        - Who has these obligations (controller, processor, joint_controller)?
        
        Step 2: Extract Conditional Logic
        - What conditions trigger these obligations?
        - Are there any "if-then" relationships?
        - What are the specific criteria that must be met?
        
        Step 3: Determine Data Domains
        - Does this relate to data_transfer, data_usage, or data_storage?
        - Which specific data activities are covered?
        
        Step 4: Identify Roles and Responsibilities
        - Who are the key actors (controller, processor, joint_controller)?
        - What are their specific roles in each obligation?
        
        Step 5: Structure as Machine-Readable Rules
        - Convert each obligation into a conditional rule
        - Define clear facts, operators, and values
        - Ensure alignment with json-rules-engine format
        
        Let's work through this step by step...
        """
    
    @staticmethod
    def mixture_of_experts_prompt(legislation_text: str) -> str:
        """Mixture of Experts prompting with specialized perspectives."""
        return f"""
        We need to analyze legislation from multiple expert perspectives. Each expert will contribute their specialized knowledge.
        
        LEGISLATION TEXT:
        {legislation_text}
        
        === EXPERT PANEL ANALYSIS ===
        
        EXPERT 1 - PRIVACY LAW SPECIALIST:
        As a privacy law expert, I will focus on:
        - Data protection obligations and rights
        - Cross-border transfer requirements
        - Consent and lawful basis considerations
        - Individual rights and freedoms
        
        EXPERT 2 - TECHNICAL COMPLIANCE SPECIALIST:
        As a technical expert, I will focus on:
        - Technical and organizational measures
        - Security requirements and safeguards
        - Data processing procedures and controls
        - Risk assessment and mitigation
        
        EXPERT 3 - REGULATORY INTERPRETATION SPECIALIST:
        As a regulatory expert, I will focus on:
        - Supervisory authority requirements
        - Penalty and enforcement mechanisms
        - Compliance documentation needs
        - Audit and accountability measures
        
        Each expert will identify different aspects of the legislation and contribute to a comprehensive rule extraction.
        
        Now, let each expert analyze the text and provide their perspective...
        """
    
    @staticmethod
    def mixture_of_thought_prompt(legislation_text: str) -> str:
        """Mixture of Thought prompting for diverse reasoning approaches."""
        return f"""
        Apply multiple thinking approaches to analyze this legislation comprehensively.
        
        LEGISLATION TEXT:
        {legislation_text}
        
        === MULTIPLE THINKING APPROACHES ===
        
        ANALYTICAL THINKING:
        - Break down the text into component obligations
        - Identify logical relationships and dependencies
        - Create systematic categorization of requirements
        
        CREATIVE THINKING:
        - Consider edge cases and alternative interpretations
        - Think about practical implementation scenarios
        - Explore different ways obligations could be triggered
        
        CRITICAL THINKING:
        - Question assumptions and implicit requirements
        - Evaluate the necessity and sufficiency of conditions
        - Consider potential conflicts or ambiguities
        
        PRACTICAL THINKING:
        - Focus on real-world application and compliance
        - Consider operational feasibility and implementation
        - Think about monitoring and enforcement mechanisms
        
        SYSTEMATIC THINKING:
        - Consider the broader regulatory framework
        - Understand interconnections with other provisions
        - Map relationships between different roles and responsibilities
        
        Apply each thinking approach to extract comprehensive, actionable rules...
        """
    
    @staticmethod
    def mixture_of_reasoning_prompt(legislation_text: str) -> str:
        """Mixture of Reasoning prompting for comprehensive analysis."""
        return f"""
        Use multiple reasoning strategies to thoroughly analyze this legislation.
        
        LEGISLATION TEXT:
        {legislation_text}
        
        === REASONING STRATEGIES ===
        
        DEDUCTIVE REASONING:
        - Start with general legal principles
        - Apply them to specific provisions
        - Derive specific obligations and requirements
        
        INDUCTIVE REASONING:
        - Examine specific examples and cases mentioned
        - Identify patterns and common elements
        - Generalize to broader rules and principles
        
        ABDUCTIVE REASONING:
        - Observe the intended outcomes and goals
        - Infer the most likely requirements to achieve them
        - Hypothesize necessary conditions and controls
        
        ANALOGICAL REASONING:
        - Compare to similar regulations and provisions
        - Draw parallels from established legal frameworks
        - Apply proven compliance patterns
        
        CAUSAL REASONING:
        - Identify cause-and-effect relationships
        - Map triggers to required actions
        - Understand consequences of non-compliance
        
        Apply each reasoning strategy to extract precise, enforceable rules...
        """

# ===============================
# OPENAI CLIENT AND EMBEDDINGS
# ===============================

class OpenAIService:
    """Service for OpenAI API interactions."""
    
    def __init__(self):
        self.client = OpenAI(api_key=Config.API_KEY)
    
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings using OpenAI's text-embedding-3-large model."""
        try:
            response = self.client.embeddings.create(
                model=Config.EMBEDDING_MODEL,
                input=texts,
                encoding_format="float"
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise
    
    async def chat_completion(self, messages: List[Union[Dict[str, str], SystemMessage, HumanMessage, AIMessage]]) -> str:
        """Generate chat completion using OpenAI's API."""
        try:
            # Convert LangChain messages to dict format for OpenAI API
            formatted_messages = []
            for msg in messages:
                if isinstance(msg, (SystemMessage, HumanMessage, AIMessage)):
                    if isinstance(msg, SystemMessage):
                        formatted_messages.append({"role": "system", "content": msg.content})
                    elif isinstance(msg, HumanMessage):
                        formatted_messages.append({"role": "user", "content": msg.content})
                    elif isinstance(msg, AIMessage):
                        formatted_messages.append({"role": "assistant", "content": msg.content})
                elif isinstance(msg, dict):
                    formatted_messages.append(msg)
                else:
                    formatted_messages.append({"role": "user", "content": str(msg)})
            
            response = self.client.chat.completions.create(
                model=Config.CHAT_MODEL,
                messages=formatted_messages
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error in chat completion: {e}")
            raise

# ===============================
# SAFE JSON PARSING
# ===============================

class SafeJsonParser:
    """Safe JSON parsing with error handling and validation."""
    
    @staticmethod
    def parse_json_response(response: str) -> Dict[str, Any]:
        """Safely parse JSON response from LLM."""
        try:
            # Clean the response
            cleaned = response.strip()
            
            # Handle code blocks
            if "```json" in cleaned:
                start = cleaned.find("```json") + 7
                end = cleaned.find("```", start)
                if end != -1:
                    cleaned = cleaned[start:end].strip()
            elif "```" in cleaned:
                start = cleaned.find("```") + 3
                end = cleaned.find("```", start)
                if end != -1:
                    cleaned = cleaned[start:end].strip()
            
            # Try to parse JSON
            parsed = json.loads(cleaned)
            return parsed
            
        except json.JSONDecodeError as e:
            logger.warning(f"JSON decode error: {e}. Attempting to fix...")
            
            # Try to fix common JSON issues
            try:
                # Remove trailing commas
                import re
                fixed = re.sub(r',(\s*[}\]])', r'\1', cleaned)
                parsed = json.loads(fixed)
                return parsed
            except Exception:
                logger.error(f"Could not parse JSON response: {cleaned[:200]}...")
                return {"error": "Failed to parse JSON", "raw_response": cleaned}
    
    @staticmethod
    def validate_rule_structure(data: Dict[str, Any]) -> bool:
        """Validate that parsed data follows expected rule structure."""
        required_fields = ['id', 'name', 'description', 'conditions', 'event']
        return all(field in data for field in required_fields)

# ===============================
# LANGGRAPH TOOLS
# ===============================

@tool
def extract_rule_conditions(legislation_text: str, focus_area: str) -> str:
    """Extract specific rule conditions from legislation text."""
    openai_service = OpenAIService()
    
    prompt = f"""
    Extract specific rule conditions from the following legislation text, focusing on {focus_area}.
    
    Return a JSON object with conditions in json-rules-engine format.
    
    Text: {legislation_text}
    
    Focus on identifying:
    - Specific facts that can be evaluated
    - Comparison operators (equal, greaterThan, contains, etc.)
    - Values to compare against
    - Data domains (data_transfer, data_usage, data_storage) and roles (controller, processor, joint_controller)
    
    Return valid JSON only.
    """
    
    try:
        # This is a synchronous tool, so we use the sync version
        response = openai_service.client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error extracting conditions: {str(e)}"

@tool
def analyze_data_domains(legislation_text: str) -> str:
    """Analyze and identify relevant data domains in legislation."""
    openai_service = OpenAIService()
    
    prompt = f"""
    Analyze the following legislation text and identify which data domains are relevant:
    - data_transfer
    - data_usage
    - data_storage
    
    Text: {legislation_text}
    
    Return a JSON object mapping each identified domain to its relevance and reasoning.
    """
    
    try:
        response = openai_service.client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error analyzing domains: {str(e)}"

@tool
def identify_roles_responsibilities(legislation_text: str) -> str:
    """Identify roles and responsibilities in legislation."""
    openai_service = OpenAIService()
    
    prompt = f"""
    Identify the roles and responsibilities mentioned in this legislation:
    - controller
    - processor 
    - joint_controller
    
    Text: {legislation_text}
    
    For each role, identify their specific obligations and responsibilities.
    Return a JSON object with role mappings.
    """
    
    try:
        response = openai_service.client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error identifying roles: {str(e)}"

# ===============================
# MAIN LEGISLATION ANALYZER
# ===============================

class LegislationAnalyzer:
    """Main analyzer for converting legislation to machine-readable rules."""
    
    def __init__(self):
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
        
        # Initialize LangChain model
        self.llm = ChatOpenAI(
            model=Config.CHAT_MODEL,
            openai_api_key=Config.API_KEY
        )
        
        # Create react agent with tools
        self.tools = [
            extract_rule_conditions,
            analyze_data_domains, 
            identify_roles_responsibilities
        ]
        
        # Memory for conversation state
        self.memory = MemorySaver()
        
        # Create react agent
        self.agent = create_react_agent(
            self.llm,
            self.tools,
            checkpointer=self.memory
        )
    
    async def analyze_legislation(self, legislation_text: str, article_reference: str = "") -> ExtractionResult:
        """Analyze legislation text and extract machine-readable rules."""
        start_time = datetime.utcnow()
        
        try:
            logger.info(f"Starting analysis of legislation: {article_reference}")
            
            # Step 1: Apply advanced prompting strategies
            cot_analysis = await self._apply_chain_of_thought(legislation_text)
            moe_analysis = await self._apply_mixture_of_experts(legislation_text)
            mot_analysis = await self._apply_mixture_of_thought(legislation_text)
            mor_analysis = await self._apply_mixture_of_reasoning(legislation_text)
            
            # Step 2: Use react agent for comprehensive analysis
            agent_analysis = await self._run_react_agent(legislation_text, article_reference)
            
            # Step 3: Synthesize all analyses into structured rules
            rules = await self._synthesize_rules(
                legislation_text, 
                article_reference,
                cot_analysis,
                moe_analysis, 
                mot_analysis,
                mor_analysis,
                agent_analysis
            )
            
            # Step 4: Generate embeddings for rules
            if rules:
                rule_texts = [f"{rule.description} {rule.source_article}" for rule in rules]
                embeddings = await self.openai_service.get_embeddings(rule_texts)
            else:
                embeddings = []
            
            # Step 5: Calculate processing time
            end_time = datetime.utcnow()
            processing_time = (end_time - start_time).total_seconds()
            
            # Create result
            result = ExtractionResult(
                rules=rules,
                summary=f"Extracted {len(rules)} rules from {article_reference}",
                total_rules=len(rules),
                processing_time=processing_time,
                embeddings=embeddings
            )
            
            logger.info(f"Analysis completed: {len(rules)} rules extracted in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing legislation: {e}")
            raise
    
    async def _apply_chain_of_thought(self, legislation_text: str) -> str:
        """Apply Chain of Thought prompting strategy."""
        prompt = PromptingStrategies.chain_of_thought_prompt(legislation_text)
        
        messages = [
            SystemMessage(content="You are an expert legal analyst. Use step-by-step reasoning."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _apply_mixture_of_experts(self, legislation_text: str) -> str:
        """Apply Mixture of Experts prompting strategy."""
        prompt = PromptingStrategies.mixture_of_experts_prompt(legislation_text)
        
        messages = [
            SystemMessage(content="You are a panel of legal experts with different specializations."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _apply_mixture_of_thought(self, legislation_text: str) -> str:
        """Apply Mixture of Thought prompting strategy."""
        prompt = PromptingStrategies.mixture_of_thought_prompt(legislation_text)
        
        messages = [
            SystemMessage(content="Apply diverse thinking approaches to comprehensive analysis."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _apply_mixture_of_reasoning(self, legislation_text: str) -> str:
        """Apply Mixture of Reasoning prompting strategy.""" 
        prompt = PromptingStrategies.mixture_of_reasoning_prompt(legislation_text)
        
        messages = [
            SystemMessage(content="Use multiple reasoning strategies for thorough analysis."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _run_react_agent(self, legislation_text: str, article_reference: str) -> str:
        """Run the react agent for comprehensive analysis."""
        try:
            config = {"configurable": {"thread_id": f"analysis_{datetime.utcnow().timestamp()}"}}
            
            message = f"""
            Analyze the following legislation and use all available tools to extract comprehensive information:
            
            Article: {article_reference}
            Text: {legislation_text}
            
            Use the tools to:
            1. Extract specific rule conditions
            2. Analyze data domains
            3. Identify roles and responsibilities
            
            Provide a comprehensive analysis that can be used to create machine-readable rules.
            """
            
            result = self.agent.invoke(
                {"messages": [HumanMessage(content=message)]},
                config
            )
            
            # Extract the final message content
            if result and "messages" in result:
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content'):
                    return last_message.content
                elif isinstance(last_message, dict) and 'content' in last_message:
                    return last_message['content']
            
            return "Agent analysis completed but no content returned"
            
        except Exception as e:
            logger.error(f"Error running react agent: {e}")
            return f"Error in agent analysis: {str(e)}"
    
    async def _synthesize_rules(
        self, 
        legislation_text: str,
        article_reference: str,
        cot_analysis: str,
        moe_analysis: str, 
        mot_analysis: str,
        mor_analysis: str,
        agent_analysis: str
    ) -> List[LegislationRule]:
        """Synthesize all analyses into structured rules."""
        
        synthesis_prompt = f"""
        Based on the comprehensive analyses below, create machine-readable rules in JSON format that align with json-rules-engine structure.
        
        ORIGINAL LEGISLATION:
        Article: {article_reference}
        Text: {legislation_text}
        
        ANALYSIS RESULTS:
        
        Chain of Thought Analysis:
        {cot_analysis}
        
        Mixture of Experts Analysis:
        {moe_analysis}
        
        Mixture of Thought Analysis:
        {mot_analysis}
        
        Mixture of Reasoning Analysis:
        {mor_analysis}
        
        Agent Tool Analysis:
        {agent_analysis}
        
        REQUIREMENTS:
        1. Create rules in json-rules-engine format with conditions containing 'all', 'any', or 'not' keys
        2. Each condition must have: fact, operator, value, description, data_domain, role, reasoning
        3. Infer appropriate data domains from: data_transfer, data_usage, data_storage
        4. Assign roles from: controller, processor, joint_controller
        5. Use LLM reasoning capabilities to infer domains and roles not explicitly stated
        6. Provide confidence scores (0.0-1.0) for each rule
        
        Return a JSON array of rules. Each rule must follow this exact structure:
        {{
            "id": "unique_id",
            "name": "rule_name", 
            "description": "human_readable_description",
            "source_article": "{article_reference}",
            "conditions": {{
                "all": [
                    {{
                        "fact": "fact_name",
                        "operator": "equal",
                        "value": "comparison_value",
                        "path": "$.optional.json.path",
                        "description": "condition_description",
                        "data_domain": ["data_transfer"],
                        "role": "controller",
                        "reasoning": "why_this_condition_was_extracted"
                    }}
                ]
            }},
            "event": {{
                "type": "compliance_required",
                "params": {{
                    "action": "specific_action_required"
                }}
            }},
            "priority": 1,
            "confidence_score": 0.85
        }}
        
        Return ONLY valid JSON array, no other text.
        """
        
        messages = [
            SystemMessage(content="You are a legal-tech expert. Return only valid JSON."),
            HumanMessage(content=synthesis_prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        
        # Parse JSON response safely
        parsed_data = self.json_parser.parse_json_response(response)
        
        if "error" in parsed_data:
            logger.error(f"Failed to parse rules JSON: {parsed_data}")
            return []
        
        # Convert to Pydantic models
        rules = []
        try:
            if isinstance(parsed_data, list):
                rule_data_list = parsed_data
            elif isinstance(parsed_data, dict) and "rules" in parsed_data:
                rule_data_list = parsed_data["rules"]
            else:
                rule_data_list = [parsed_data]
            
            for rule_data in rule_data_list:
                try:
                    # Ensure required fields have defaults
                    rule_data.setdefault("priority", 1)
                    rule_data.setdefault("confidence_score", 0.8)
                    rule_data.setdefault("source_article", article_reference)
                    
                    # Create rule
                    rule = LegislationRule(**rule_data)
                    rules.append(rule)
                    
                except Exception as e:
                    logger.warning(f"Skipping invalid rule: {e}")
                    continue
                    
        except Exception as e:
            logger.error(f"Error creating rule objects: {e}")
            
        return rules

# ===============================
# MAIN EXECUTION FUNCTION
# ===============================

async def main():
    """Main execution function demonstrating the system."""
    
    # Example: GDPR Article 28 text
    gdpr_article_28 = """
    Article 28 - Processor
    
    1. Where processing is to be carried out on behalf of a controller, the controller shall use only processors providing sufficient guarantees to implement appropriate technical and organisational measures in such a manner that processing will meet the requirements of this Regulation and ensure the protection of the rights of the data subject.
    
    2. The processor shall not engage another processor without prior specific or general written authorisation of the controller. In the case of general written authorisation, the processor shall inform the controller of any intended changes concerning the addition or replacement of other processors, thereby giving the controller the opportunity to object to such changes.
    
    3. Processing by a processor shall be governed by a contract or other legal act under Union or Member State law, that is binding on the processor with regard to the controller and that sets out the subject-matter and duration of the processing, the nature and purpose of the processing, the type of personal data and categories of data subjects and the obligations and rights of the controller.
    """
    
    # Initialize analyzer
    analyzer = LegislationAnalyzer()
    
    try:
        # Analyze the legislation
        result = await analyzer.analyze_legislation(
            legislation_text=gdpr_article_28,
            article_reference="GDPR Article 28"
        )
        
        # Print results
        print(f"\n=== EXTRACTION RESULTS ===")
        print(f"Summary: {result.summary}")
        print(f"Total Rules: {result.total_rules}")
        print(f"Processing Time: {result.processing_time:.2f} seconds")
        
        print(f"\n=== EXTRACTED RULES ===")
        for i, rule in enumerate(result.rules, 1):
            print(f"\nRule {i}: {rule.name}")
            print(f"Description: {rule.description}")
            print(f"Confidence: {rule.confidence_score}")
            print(f"Priority: {rule.priority}")
            
            print(f"Conditions:")
            for logic_type, conditions in rule.conditions.items():
                print(f"  {logic_type.upper()}:")
                for condition in conditions:
                    print(f"    - {condition.description}")
                    print(f"      Fact: {condition.fact}")
                    print(f"      Operator: {condition.operator}")
                    print(f"      Value: {condition.value}")
                    print(f"      Role: {condition.role}")
                    print(f"      Domains: {condition.data_domain}")
            
            print(f"Event: {rule.event.type}")
            print("-" * 50)
        
        # Save results
        os.makedirs(Config.RULES_OUTPUT_PATH, exist_ok=True)
        output_file = os.path.join(Config.RULES_OUTPUT_PATH, "gdpr_article_28_rules.json")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(
                [rule.model_dump() for rule in result.rules], 
                f, 
                indent=2, 
                default=str,
                ensure_ascii=False
            )
        
        print(f"\nRules saved to: {output_file}")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}")
        raise

if __name__ == "__main__":
    # Run the main function
    asyncio.run(main())
