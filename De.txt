import os
import json
import logging
import requests
from dotenv import load_dotenv
from azure.identity import DefaultAzureCredential

# ------------------------------
# Load Environment Variables
# ------------------------------
load_dotenv("config/dev")         # General settings
load_dotenv("config/dev.creds")    # Credential settings

# Get endpoints and deployment names from environment variables
chat_endpoint = os.getenv("AZURE_OPENAI_CHAT_ENDPOINT")
embedding_endpoint = os.getenv("AZURE_OPENAI_EMBEDDINGS_ENDPOINT")
chat_deployment = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT", "gpt-4o-mini")
embedding_deployment = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "text-embedding-3-large")
embedding_api_key = os.getenv("AZURE_OPENAI_EMBEDDINGS_API_KEY")
openai_api_version = os.getenv("OPENAI_API_VERSION", "2023-05-15")

if not chat_endpoint or not embedding_endpoint:
    raise ValueError("Please set both AZURE_OPENAI_CHAT_ENDPOINT and AZURE_OPENAI_EMBEDDINGS_ENDPOINT.")

# Ensure endpoints include "/openai" as required by Azure OpenAI
if "/openai" not in chat_endpoint:
    chat_endpoint = chat_endpoint.rstrip("/") + "/openai"
if "/openai" not in embedding_endpoint:
    embedding_endpoint = embedding_endpoint.rstrip("/") + "/openai"

# ------------------------------
# Setup Logging
# ------------------------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ------------------------------
# Token Provider (if not using API key)
# ------------------------------
def get_bearer_token():
    credential = DefaultAzureCredential()
    token = credential.get_token("https://cognitiveservices.azure.com/.default")
    return token.token

# ------------------------------
# Function to Get Embedding for a Text
# ------------------------------
def get_embedding_for_text(text, endpoint, deployment, api_version):
    payload = {"input": [text]}
    # Choose authentication method: API key if provided; else, use bearer token.
    if embedding_api_key:
        headers = {
            'api-key': embedding_api_key,
            'Content-Type': 'application/json'
        }
    else:
        token = get_bearer_token()
        headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json'
        }
    
    # Construct the API URL for embeddings
    api_url = f"{endpoint}/deployments/{deployment}/embeddings?api-version={api_version}"
    logger.info(f"Requesting embedding from URL: {api_url}")
    
    try:
        response = requests.post(api_url, headers=headers, json=payload)
        if response.status_code == 200:
            data = response.json()
            # Assuming response structure: { "data": [ { "embedding": [...] } ] }
            embedding = data.get("data", [{}])[0].get("embedding")
            if embedding:
                return embedding
            else:
                logger.error("No embedding found in response.")
                logger.error(json.dumps(data, indent=2))
        else:
            logger.error(f"Embedding API call failed with status {response.status_code}: {response.text}")
    except Exception as e:
        logger.error(f"Error during embedding API call: {str(e)}")
    return None

# ------------------------------
# Main Execution
# ------------------------------
if __name__ == "__main__":
    test_text = "Hello, world!"
    embedding = get_embedding_for_text(test_text, embedding_endpoint, embedding_deployment, openai_api_version)
    if embedding:
        print(f"Test embedding dimension: {len(embedding)}")
    else:
        print("Failed to retrieve test embedding.")
