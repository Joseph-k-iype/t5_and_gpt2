import streamlit as st
import pandas as pd
import duckdb
import plotly.express as px
from typing import List, Optional
from pydantic import BaseModel, Field
from io import BytesIO
import numpy as np
from datetime import datetime
import statsmodels.api as sm
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest, RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import (mean_squared_error, r2_score, accuracy_score, 
                           classification_report, confusion_matrix)
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
from reportlab.lib import colors
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
from reportlab.lib.styles import getSampleStyleSheet
import json
from datetime import datetime, timedelta
import schedule
import time
import nltk
from nltk.sentiment import SentimentIntensityAnalyzer

class DatasetConfig(BaseModel):
    name: str
    columns: List[str]
    date_columns: List[str] = Field(default_factory=list)
    numeric_columns: List[str] = Field(default_factory=list)
    categorical_columns: List[str] = Field(default_factory=list)

class DataCleaner:
    @staticmethod
    def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
        return df.drop_duplicates()
    
    @staticmethod
    def handle_missing_values(df: pd.DataFrame, numeric_fill: str = 'mean', 
                            categorical_fill: str = 'mode') -> pd.DataFrame:
        df = df.copy()
        
        for col in df.columns:
            if df[col].dtype in ['int64', 'float64']:
                if numeric_fill == 'mean':
                    df[col].fillna(df[col].mean(), inplace=True)
                elif numeric_fill == 'median':
                    df[col].fillna(df[col].median(), inplace=True)
                elif numeric_fill == 'zero':
                    df[col].fillna(0, inplace=True)
            else:
                if categorical_fill == 'mode':
                    df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else 'Unknown', 
                                 inplace=True)
                elif categorical_fill == 'unknown':
                    df[col].fillna('Unknown', inplace=True)
        
        return df
    
    @staticmethod
    def standardize_dates(df: pd.DataFrame, date_columns: List[str]) -> pd.DataFrame:
        df = df.copy()
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')
        return df

class PivotAnalyzer:
    @staticmethod
    def create_pivot_table(df: pd.DataFrame, 
                          index_cols: List[str],
                          value_cols: List[str],
                          agg_func: str = 'sum',
                          pivot_col: Optional[str] =         elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))) -> pd.DataFrame:
        if pivot_col:
            return pd.pivot_table(
                df,
                values=value_cols,
                index=index_cols,
                columns=[pivot_col],
                aggfunc=agg_func,
                fill_value=0
            )
        else:
            return pd.pivot_table(
                df,
                values=value_cols,
                index=index_cols,
                aggfunc=agg_func,
                fill_value=0
            )
    
    @staticmethod
    def get_available_agg_functions() -> List[str]:
        return ['sum', 'mean', 'count', 'min', 'max', 'median', 'std']

class TimeSeriesAnalyzer:
    @staticmethod
    def decompose_series(data: pd.Series) -> dict:
        decomposition = sm.tsa.seasonal_decompose(data, period=12)
        return {
            'trend': decomposition.trend,
            'seasonal': decomposition.seasonal,
            'residual': decomposition.resid
        }
    
    @staticmethod
    def forecast_prophet(df: pd.DataFrame, date_col: str, value_col: str, 
                        periods: int = 12) -> pd.DataFrame:
        model = Prophet(yearly_seasonality=True, weekly_seasonality=True)
        prophet_df = df[[date_col, value_col]].copy()
        prophet_df.columns = ['ds', 'y']
        model.fit(prophet_df)
        future = model.make_future_dataframe(periods=periods)
        forecast = model.predict(future)
        return forecast

class StatisticalAnalyzer:
    @staticmethod
    def run_hypothesis_test(data1: pd.Series, data2: pd.Series, 
                          test_type: str) -> dict:
        if test_type == 't_test':
            stat, pvalue = stats.ttest_ind(data1, data2)
            return {'statistic': stat, 'p_value': pvalue, 'test': 't_test'}
        elif test_type == 'chi_square':
            stat, pvalue = stats.chi2_contingency(pd.crosstab(data1, data2))[:2]
            return {'statistic': stat, 'p_value': pvalue, 'test': 'chi_square'}
        elif test_type == 'anova':
            stat, pvalue = stats.f_oneway(data1, data2)
            return {'statistic': stat, 'p_value': pvalue, 'test': 'anova'}
    
    @staticmethod
    def calculate_confidence_interval(data: pd.Series, 
                                   confidence: float = 0.95) -> dict:
        mean = data.mean()
        ci = stats.t.interval(confidence, len(data)-1, loc=mean, 
                            scale=stats.sem(data))
        return {'mean': mean, 'ci_lower': ci[0], 'ci_upper': ci[1]}

class MLAnalyzer:
    def __init__(self):
        self.model =         elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
    
    def perform_clustering(self, df: pd.DataFrame, n_clusters: int = 3) -> dict:
        scaled_data = self.scaler.fit_transform(df)
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        clusters = kmeans.fit_predict(scaled_data)
        
        # Calculate silhouette score
        from sklearn.metrics import silhouette_score
        silhouette_avg = silhouette_score(scaled_data, clusters)
        
        return {
            'clusters': clusters,
            'centroids': kmeans.cluster_centers_,
            'inertia': kmeans.inertia_,
            'silhouette_score': silhouette_avg
        }
    
    def detect_anomalies(self, df: pd.DataFrame, contamination: float = 0.1) -> dict:
        scaled_data = self.scaler.fit_transform(df)
        iso_forest = IsolationForest(contamination=contamination, random_state=42)
        anomalies = iso_forest.fit_predict(scaled_data)
        
        anomaly_scores = iso_forest.score_samples(scaled_data)
        
        return {
            'anomalies': anomalies,
            'scores': anomaly_scores,
            'normal_samples': (anomalies == 1).sum(),
            'anomaly_samples': (anomalies == -1).sum()
        }
    
    def train_predictor(self, X: pd.DataFrame, y: pd.Series, 
                       problem_type: str = 'regression') -> dict:
        # Split data
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Scale features
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        if problem_type == 'regression':
            self.model = RandomForestRegressor(n_estimators=100, random_state=42)
            self.model.fit(X_train_scaled, y_train)
            
            # Make predictions
            y_pred = self.model.predict(X_test_scaled)
            
            # Calculate metrics
            mse = mean_squared_error(y_test, y_pred)
            r2 = r2_score(y_test, y_pred)
            
            return {
                'mse': mse,
                'r2': r2,
                'feature_importance': dict(zip(X.columns, self.model.feature_importances_))
            }
        else:
            self.model = RandomForestClassifier(n_estimators=100, random_state=42)
            y_encoded = self.label_encoder.fit_transform(y)
            y_train_encoded = self.label_encoder.transform(y_train)
            y_test_encoded = self.label_encoder.transform(y_test)
            
            self.model.fit(X_train_scaled, y_train_encoded)
            y_pred = self.model.predict(X_test_scaled)
            
            return {
                'accuracy': accuracy_score(y_test_encoded, y_pred),
                'classification_report': classification_report(y_test_encoded, y_pred),
                'feature_importance': dict(zip(X.columns, self.model.feature_importances_))
            }
    
    def analyze_text(self, text_series: pd.Series) -> dict:
        # Initialize sentiment analyzer
        sia = SentimentIntensityAnalyzer()
        
        # Get sentiment scores
        sentiments = text_series.apply(lambda x: sia.polarity_scores(str(x)))
        
        # Extract key metrics
        sentiment_df = pd.DataFrame(sentiments.tolist())
        
        # Get most common words
        vectorizer = TfidfVectorizer(max_features=10, stop_words='english')
        tfidf_matrix = vectorizer.fit_transform(text_series.astype(str))
        
        return {
            'average_sentiment': sentiment_df.mean().to_dict(),
            'sentiment_distribution': sentiment_df.compound.value_counts().to_dict(),
            'top_terms': dict(zip(vectorizer.get_feature_names_out(), 
                                tfidf_matrix.sum(axis=0).A1))
        }

class ReportGenerator:
    @staticmethod
    def create_pdf_report(data: dict, filename: str):
        doc = SimpleDocTemplate(filename, pagesize=letter)
        styles = getSampleStyleSheet()
        elements = []
        
        # Add title
        elements.append(Paragraph(f"Analysis Report - {datetime.now().strftime('%Y-%m-%d')}", 
                                styles['Title']))
        
        # Add sections based on data
        for section, content in data.items():
            elements.append(Paragraph(section, styles['Heading1']))
            
            if isinstance(content, pd.DataFrame):
                # Convert DataFrame to table
                table_data = [content.columns.tolist()] + content.values.tolist()
                t = Table(table_data)
                t.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, 0), 14),
                    ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                    ('TEXTCOLOR', (0, 1), (-1, -1), colors.black),
                    ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
                    ('FONTSIZE', (0, 1), (-1, -1), 12),
                    ('GRID', (0, 0), (-1, -1), 1, colors.black)
                ]))
                elements.append(t)
            else:
                elements.append(Paragraph(str(content), styles['Normal']))
        
        doc.build(elements)

class AnalysisTemplate(BaseModel):
    name: str
    description: str
    analysis_steps: List[dict] = Field(default_factory=list)
    visualization_config: dict = Field(default_factory=dict)
    scheduling: Optional[dict] =         elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))

class CollaborationManager:
    def __init__(self):
        self.shared_analyses = {}
        self.comments = {}
        self.user_permissions = {}
    
    def share_analysis(self, analysis_id: str, users: List[str], 
                      permissions: List[str]):
        self.shared_analyses[analysis_id] = {
            'shared_with': users,
            'permissions': permissions,
            'shared_at': datetime.now()
        }
    
    def add_comment(self, analysis_id: str, user: str, comment: str):
        if analysis_id not in self.comments:
            self.comments[analysis_id] = []
        
        self.comments[analysis_id].append({
            'user': user,
            'comment': comment,
            'timestamp': datetime.now()
        })
    
    def get_analysis_history(self, analysis_id: str) -> List[dict]:
        return self.comments.get(analysis_id, [])

class InsightGenerator:
    @staticmethod
    def generate_statistical_insights(df: pd.DataFrame) -> List[str]:
        insights = []
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_cols:
            stats_dict = {
                'mean': df[col].mean(),
                'median': df[col].median(),
                'std': df[col].std(),
                'skew': df[col].skew()
            }
            
            insights.append(f"Column {col}:")
            insights.append(f"- Average value: {stats_dict['mean']:.2f}")
            insights.append(f"- Median value: {stats_dict['median']:.2f}")
            
            if abs(stats_dict['skew']) > 1:
                insights.append(
                    f"- Distribution is {'positively' if stats_dict['skew'] > 0 else 'negatively'} skewed"
                )
            
            # Detect outliers using IQR method
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = df[col][(df[col] < (Q1 - 1.5 * IQR)) | 
                              (df[col] > (Q3 + 1.5 * IQR))]
            if len(outliers) > 0:
                insights.append(
                    f"- Found {len(outliers)} potential outliers ({(len(outliers)/len(df)*100):.1f}% of data)"
                )
        
        return insights
    
    @staticmethod
    def generate_trend_insights(df: pd.DataFrame, 
                              date_col: str, 
                              value_col: str) -> List[str]:
        insights = []
        df = df.sort_values(date_col)
        
        # Overall trend
        start_value = df[value_col].iloc[0]
        end_value = df[value_col].iloc[-1]
        change_pct = ((end_value - start_value) / start_value) * 100
        
        insights.append(f"Overall trend analysis for {value_col}:")
        insights.append(
            f"- {'Increased' if change_pct > 0 else 'Decreased'} by {abs(change_pct):.1f}% "
            f"from {start_value:.2f} to {end_value:.2f}"
        )
        
        # Seasonality check using autocorrelation
        autocorr = pd.Series(df[value_col]).autocorr()
        if abs(autocorr) > 0.7:
            insights.append("- Strong seasonal pattern detected")
        elif abs(autocorr) > 0.3:
            insights.append("- Moderate seasonal pattern detected")
        
        return insights

class AdvancedPivotAnalyzer:
    def __init__(self):
        self.filters = {}
        self.groups = {}
        self.calculated_fields = {}
    
    def apply_filters(self, df: pd.DataFrame, filters: dict) -> pd.DataFrame:
        filtered_df = df.copy()
        for col, filter_values in filters.items():
            if filter_values.get('values'):
                filtered_df = filtered_df[filtered_df[col].isin(filter_values['values'])]
            if filter_values.get('range'):
                min_val, max_val = filter_values['range']
                filtered_df = filtered_df[
                    (filtered_df[col] >= min_val) & (filtered_df[col] <= max_val)
                ]
        return filtered_df
    
    def create_groups(self, df: pd.DataFrame, group_config: dict) -> pd.DataFrame:
        df = df.copy()
        for col, config in group_config.items():
            if config['type'] == 'numeric_bins':
                df[f"{col}_group"] = pd.qcut(
                    df[col], 
                    q=config['bins'], 
                    labels=config.get('labels')
                )
            elif config['type'] == 'date':
                df[f"{col}_group"] = df[col].dt.to_period(config['freq'])
            elif config['type'] == 'custom':
                mapping = config['mapping']
                df[f"{col}_group"] = df[col].map(mapping)
        return df
    
    def calculate_field(self, df: pd.DataFrame, calc_config: dict) -> pd.Series:
        if calc_config['type'] == 'simple_math':
            expression = calc_config['expression']
            for col in df.columns:
                expression = expression.replace(col, f"df['{col}']")
            return eval(expression)
        elif calc_config['type'] == 'rolling':
            return df[calc_config['column']].rolling(
                window=calc_config['window']
            ).agg(calc_config['function'])
        elif calc_config['type'] == 'percentage':
            return (df[calc_config['column']] / 
                   df[calc_config['column']].sum() * 100)
        return pd.Series()
    
    def create_pivot(self, df: pd.DataFrame, config: dict) -> dict:
        # Apply filters
        if config.get('filters'):
            df = self.apply_filters(df, config['filters'])
        
        # Create groups
        if config.get('groups'):
            df = self.create_groups(df, config['groups'])
        
        # Calculate custom fields
        for field_name, calc_config in config.get('calculated_fields', {}).items():
            df[field_name] = self.calculate_field(df, calc_config)
        
        # Create pivot table
        pivot_df = pd.pivot_table(
            df,
            values=config['values'],
            index=config['rows'],
            columns=config.get('columns'),
            aggfunc=config['aggregations'],
            fill_value=0,
            margins=config.get('show_totals', False)
        )
        
        # Sort if specified
        if config.get('sort'):
            sort_col = config['sort']['column']
            ascending = config['sort'].get('ascending', True)
            pivot_df = pivot_df.sort_values(sort_col, ascending=ascending)
        
        # Calculate subtotals if specified
        subtotals = {}
        if config.get('subtotals'):
            for level in range(len(config['rows'])):
                subtotal = df.groupby(
                    config['rows'][:level+1]
                )[config['values']].agg(config['aggregations'])
                subtotals[level] = subtotal
        
        return {
            'pivot': pivot_df,
            'subtotals': subtotals,
            'filtered_records': len(df)
        }

    def get_drill_down(self, df: pd.DataFrame, config: dict, 
                      filters: dict) -> pd.DataFrame:
        # Apply filters from pivot selection
        filtered_df = self.apply_filters(df, filters)
        
        # Select columns for drill-down
        if config.get('drill_down_columns'):
            return filtered_df[config['drill_down_columns']]
        return filtered_df

class DuckDBAnalyzer:
    def __init__(self):
        self.con = duckdb.connect(database=':memory:', read_only=False)
    
    def load_dataframe(self, df: pd.DataFrame, table_name: str):
        self.con.register(table_name, df)
    
    def run_query(self, query: str) -> pd.DataFrame:
        return self.con.execute(query).df()
    
    def get_summary_stats(self, table_name: str, numeric_columns: List[str]) -> pd.DataFrame:
        if not numeric_columns:
            return pd.DataFrame()
        
        stats_query = f"""
        SELECT 
            {', '.join([f'MIN({col}) as {col}_min, 
                         MAX({col}) as {col}_max, 
                         AVG({col}) as {col}_avg, 
                         STDDEV({col}) as {col}_std' 
                       for col in numeric_columns])}
        FROM {table_name}
        """
        return self.run_query(stats_query)
    
    def get_correlation_matrix(self, table_name: str, numeric_columns: List[str]) -> pd.DataFrame:
        if len(numeric_columns) < 2:
            return pd.DataFrame()
        
        correlations = []
        for col1 in numeric_columns:
            for col2 in numeric_columns:
                query = f"""
                SELECT CORR({col1}, {col2}) as correlation
                FROM {table_name}
                """
                corr = self.run_query(query).iloc[0,0]
                correlations.append({'column1': col1, 'column2': col2, 'correlation': corr})
        
        return pd.DataFrame(correlations)

def main():
    st.set_page_config(page_title="Advanced Data Analysis Tool", layout="wide")
    st.title("Advanced Data Analysis Tool")
    
    # Initialize session state
    if 'datasets' not in st.session_state:
        st.session_state.datasets = {}
        st.session_state.merged_data =         elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))
        st.session_state.analyzer = DuckDBAnalyzer()
    
    # File Upload Section
    st.header("1. Data Upload")
    uploaded_files = st.file_uploader("Upload Excel Files", type=['xlsx', 'xls'], 
                                    accept_multiple_files=True)
    
    if uploaded_files:
        for file in uploaded_files:
            if file.name not in st.session_state.datasets:
                df = pd.read_excel(file)
                config = DatasetConfig(
                    name=file.name,
                    columns=df.columns.tolist(),
                    numeric_columns=df.select_dtypes(include=[np.number]).columns.tolist(),
                    categorical_columns=df.select_dtypes(include=['object']).columns.tolist()
                )
                st.session_state.datasets[file.name] = {'df': df, 'config': config}
    
    # Data Cleaning Section
    if st.session_state.datasets:
        st.header("2. Data Cleaning")
        
        selected_dataset = st.selectbox("Select Dataset to Clean", 
                                      options=list(st.session_state.datasets.keys()))
        
        if selected_dataset:
            df = st.session_state.datasets[selected_dataset]['df']
            config = st.session_state.datasets[selected_dataset]['config']
            
            st.subheader("Cleaning Options")
            col1, col2 = st.columns(2)
            
            with col1:
                remove_duplicates = st.checkbox("Remove Duplicate Rows", value=True)
                numeric_fill = st.selectbox("Handle Missing Numeric Values", 
                                          ['mean', 'median', 'zero'])
            
            with col2:
                categorical_fill = st.selectbox("Handle Missing Categorical Values", 
                                              ['mode', 'unknown'])
                date_columns = st.multiselect("Select Date Columns", 
                                            options=config.columns)
            
            if st.button("Apply Cleaning"):
                # Apply cleaning operations
                if remove_duplicates:
                    df = DataCleaner.remove_duplicates(df)
                
                df = DataCleaner.handle_missing_values(df, numeric_fill, categorical_fill)
                df = DataCleaner.standardize_dates(df, date_columns)
                
                # Update the dataset
                config.date_columns = date_columns
                st.session_state.datasets[selected_dataset]['df'] = df
                st.session_state.datasets[selected_dataset]['config'] = config
                
                st.success("Data cleaning completed!")
    
    # Data Merging Section
    if len(st.session_state.datasets) > 1:
        st.header("3. Data Merging")
        
        merge_cols = {}
        datasets_to_merge = st.multiselect("Select Datasets to Merge", 
                                         options=list(st.session_state.datasets.keys()))
        
        if len(datasets_to_merge) >= 2:
            for dataset in datasets_to_merge:
                merge_cols[dataset] = st.selectbox(
                    f"Select Merge Column for {dataset}",
                    options=st.session_state.datasets[dataset]['config'].columns
                )
            
            if st.button("Merge Datasets"):
                merged_df = st.session_state.datasets[datasets_to_merge[0]]['df']
                
                for dataset in datasets_to_merge[1:]:
                    merged_df = merged_df.merge(
                        st.session_state.datasets[dataset]['df'],
                        left_on=merge_cols[datasets_to_merge[0]],
                        right_on=merge_cols[dataset],
                        how='inner'
                    )
                
                st.session_state.merged_data = merged_df
                st.session_state.analyzer.load_dataframe(merged_df, 'merged_data')
                st.success("Datasets merged successfully!")
    
    # Analysis Section
    if st.session_state.merged_data is not         elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    )):
        st.header("4. Data Analysis")
        
        analysis_type = st.selectbox(
            "Select Analysis Type",
            ["Summary Statistics", "Correlation Analysis", "Custom Query", "Visualization", 
             "Basic Pivot Table", "Advanced Pivot Table", "Machine Learning",
             "Text Analysis", "Report Generation", "Templates", "Collaboration", "Dashboard"]
        )
        
        if analysis_type == "Summary Statistics":
            numeric_cols = st.session_state.merged_data.select_dtypes(
                include=[np.number]).columns.tolist()
            stats_df = st.session_state.analyzer.get_summary_stats('merged_data', numeric_cols)
            st.write(stats_df)
        
        elif analysis_type == "Correlation Analysis":
            numeric_cols = st.session_state.merged_data.select_dtypes(
                include=[np.number]).columns.tolist()
            corr_df = st.session_state.analyzer.get_correlation_matrix('merged_data', numeric_cols)
            
            # Create correlation heatmap
            if not corr_df.empty:
                corr_matrix = pd.pivot_table(
                    corr_df, 
                    values='correlation', 
                    index='column1', 
                    columns='column2'
                )
                fig = px.imshow(
                    corr_matrix,
                    labels=dict(color="Correlation"),
                    color_continuous_scale="RdBu"
                )
                st.plotly_chart(fig)
            
        elif analysis_type == "Basic Pivot Table":
            st.subheader("Basic Pivot Table Analysis")
            
            # Select columns for pivot table
            col1, col2 = st.columns(2)
            with col1:
                index_cols = st.multiselect(
                    "Select Row Headers (Index)",
                    options=st.session_state.merged_data.columns,
                    help="Select columns to group by rows"
                )
            with col2:
                value_cols = st.multiselect(
                    "Select Values to Aggregate",
                    options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns,
                    help="Select numeric columns to analyze"
                )
            
            agg_func = st.selectbox(
                "Select Aggregation Function",
                options=PivotAnalyzer.get_available_agg_functions(),
                help="Choose how to aggregate the values"
            )
            
            if index_cols and value_cols:
                try:
                    pivot_df = PivotAnalyzer.create_pivot_table(
                        st.session_state.merged_data,
                        index_cols=index_cols,
                        value_cols=value_cols,
                        agg_func=agg_func
                    )
                    st.write(pivot_df)
                    
                    # Download button for pivot table
                    if st.button("Download Pivot Table"):
                        buffer = BytesIO()
                        pivot_df.to_excel(buffer, index=True)
                        buffer.seek(0)
                        st.download_button(
                            label="Download Excel file",
                            data=buffer,
                            file_name=f"pivot_table_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.ms-excel"
                        )
                except Exception as e:
                    st.error(f"Error creating pivot table: {str(e)}")
        
        elif analysis_type == "Advanced Pivot Table":
            st.subheader("Advanced Pivot Table Analysis")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                index_cols = st.multiselect(
                    "Select Row Headers (Index)",
                    options=st.session_state.merged_data.columns,
                    help="Select columns to group by rows"
                )
            with col2:
                value_cols = st.multiselect(
                    "Select Values to Aggregate",
                    options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns,
                    help="Select numeric columns to analyze"
                )
            with col3:
                pivot_col = st.selectbox(
                    "Select Column Header (Optional)",
                    options=['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))'] + list(st.session_state.merged_data.columns),
                    help="Select column to pivot (create column headers)"
                )
            
            # Advanced options
            st.subheader("Advanced Options")
            col1, col2 = st.columns(2)
            with col1:
                agg_func = st.selectbox(
                    "Select Aggregation Function",
                    options=PivotAnalyzer.get_available_agg_functions(),
                    help="Choose how to aggregate the values"
                )
                show_subtotals = st.checkbox("Show Subtotals", value=False)
            
            with col2:
                sort_values = st.selectbox(
                    "Sort Values By",
                    options=['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))'] + value_cols if value_cols else ['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))']
                )
                ascending = st.checkbox("Sort Ascending", value=True)
            
            if index_cols and value_cols:
                try:
                    pivot_df = PivotAnalyzer.create_pivot_table(
                        st.session_state.merged_data,
                        index_cols=index_cols,
                        value_cols=value_cols,
                        agg_func=agg_func,
                        pivot_col=        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    )) if pivot_col == '        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))' else pivot_col
                    )
                    
                    # Apply sorting if selected
                    if sort_values != '        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))':
                        pivot_df = pivot_df.sort_values(by=sort_values, ascending=ascending)
                    
                    # Add subtotals if selected
                    if show_subtotals and len(index_cols) > 1:
                        for i in range(len(index_cols)):
                            subtotal_df = pivot_df.groupby(index_cols[:i+1]).sum()
                            pivot_df = pd.concat([pivot_df, subtotal_df])
                        pivot_df = pivot_df.sort_index()
                    
                    st.write(pivot_df)
                    
                    # Visualization options
                    st.subheader("Pivot Table Visualization")
                    chart_type = st.selectbox(
                        "Select Chart Type",
                        options=["Bar Chart", "Line Chart", "Heatmap"]
                    )
                    
                    if chart_type == "Bar Chart":
                        fig = px.bar(pivot_df.reset_index(), x=index_cols[0], y=value_cols)
                    elif chart_type == "Line Chart":
                        fig = px.line(pivot_df.reset_index(), x=index_cols[0], y=value_cols)
                    else:  # Heatmap
                        fig = px.imshow(pivot_df,
                                      labels=dict(color="Value"),
                                      aspect="auto")
                    st.plotly_chart(fig)
                    
                    # Download options
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("Download Pivot Table"):
                            buffer = BytesIO()
                            pivot_df.to_excel(buffer, index=True)
                            buffer.seek(0)
                            st.download_button(
                                label="Download Excel file",
                                data=buffer,
                                file_name=f"advanced_pivot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.ms-excel"
                            )
                    with col2:
                        if st.button("Save to Dashboard"):
                            if 'dashboard_items' not in st.session_state:
                                st.session_state.dashboard_items = []
                            
                            dashboard_item = {
                                'type': 'pivot_table',
                                'config': {
                                    'index_cols': index_cols,
                                    'value_cols': value_cols,
                                    'pivot_col': pivot_col,
                                    'agg_func': agg_func,
                                    'chart_type': chart_type
                                },
                                'title': f"Pivot Analysis - {', '.join(value_cols)}"
                            }
                            st.session_state.dashboard_items.append(dashboard_item)
                            st.success("Added to dashboard!")
                            
                except Exception as e:
                    st.error(f"Error creating advanced pivot table: {str(e)}")
        
        elif analysis_type == "Dashboard":
            st.subheader("Dashboard")
            
            if 'dashboard_items' not in st.session_state:
                st.session_state.dashboard_items = []
            
            if not st.session_state.dashboard_items:
                st.info("Add items to your dashboard from the Analysis sections above!")
            else:
                # Dashboard layout
                for idx, item in enumerate(st.session_state.dashboard_items):
                    with st.expander(f"{item['title']}", expanded=True):
                        if item['type'] == 'pivot_table':
                            config = item['config']
                            pivot_df = PivotAnalyzer.create_pivot_table(
                                st.session_state.merged_data,
                                index_cols=config['index_cols'],
                                value_cols=config['value_cols'],
                                agg_func=config['agg_func'],
                                pivot_col=config['pivot_col']
                            )
                            
                            # Show table
                            st.write(pivot_df)
                            
                            # Show visualization
                            if config['chart_type'] == "Bar Chart":
                                fig = px.bar(pivot_df.reset_index(), 
                                           x=config['index_cols'][0], 
                                           y=config['value_cols'])
                            elif config['chart_type'] == "Line Chart":
                                fig = px.line(pivot_df.reset_index(), 
                                            x=config['index_cols'][0], 
                                            y=config['value_cols'])
                            else:  # Heatmap
                                fig = px.imshow(pivot_df,
                                              labels=dict(color="Value"),
                                              aspect="auto")
                            st.plotly_chart(fig)
                            
                        if st.button(f"Remove from Dashboard", key=f"remove_{idx}"):
                            st.session_state.dashboard_items.pop(idx)
                            st.experimental_rerun()
                
                # Dashboard export
                if st.button("Export Dashboard"):
                    buffer = BytesIO()
                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                        for idx, item in enumerate(st.session_state.dashboard_items):
                            if item['type'] == 'pivot_table':
                                config = item['config']
                                pivot_df = PivotAnalyzer.create_pivot_table(
                                    st.session_state.merged_data,
                                    index_cols=config['index_cols'],
                                    value_cols=config['value_cols'],
                                    agg_func=config['agg_func'],
                                    pivot_col=config['pivot_col']
                                )
                                pivot_df.to_excel(writer, 
                                                sheet_name=f"Pivot_{idx+1}",
                                                index=True)
                    
                    buffer.seek(0)
                    st.download_button(
                        label="Download Dashboard",
                        data=buffer,
                        file_name=f"dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                                    mime="application/vnd.ms-excel"
                    )
        
        elif analysis_type == "Time Series Analysis":
            st.subheader("Time Series Analysis")
            
            # Select columns for analysis
            date_col = st.selectbox(
                "Select Date Column",
                options=[col for col in st.session_state.merged_data.columns 
                        if st.session_state.merged_data[col].dtype in ['datetime64[ns]', 'object']]
            )
            value_col = st.selectbox(
                "Select Value Column",
                options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns
            )
            
            analysis_type = st.selectbox(
                "Select Analysis Type",
                ["Decomposition", "Forecasting"]
            )
            
            if date_col and value_col:
                # Ensure date column is datetime
                df = st.session_state.merged_data.copy()
                df[date_col] = pd.to_datetime(df[date_col])
                df = df.sort_values(date_col)
                
                if analysis_type == "Decomposition":
                    try:
                        decomposition = TimeSeriesAnalyzer.decompose_series(
                            df.set_index(date_col)[value_col]
                        )
                        
                        # Plot components
                        fig = px.line(title="Time Series Decomposition")
                        fig.add_trace(px.line(y=decomposition['trend'], 
                                            title="Trend").data[0])
                        fig.add_trace(px.line(y=decomposition['seasonal'], 
                                            title="Seasonal").data[0])
                        fig.add_trace(px.line(y=decomposition['residual'], 
                                            title="Residual").data[0])
                        st.plotly_chart(fig)
                        
                    except Exception as e:
                        st.error(f"Error in decomposition: {str(e)}")
                
                else:  # Forecasting
                    forecast_periods = st.slider(
                        "Select number of periods to forecast",
                        min_value=1,
                        max_value=24,
                        value=12
                    )
                    
                    try:
                        forecast = TimeSeriesAnalyzer.forecast_prophet(
                            df,
                            date_col=date_col,
                            value_col=value_col,
                            periods=forecast_periods
                        )
                        
                        # Plot forecast
                        fig = px.line()
                        fig.add_trace(px.line(
                            x=df[date_col], 
                            y=df[value_col],
                            title="Historical Data"
                        ).data[0])
                        fig.add_trace(px.line(
                            x=forecast['ds'],
                            y=forecast['yhat'],
                            title="Forecast"
                        ).data[0])
                        fig.add_scatter(
                            x=forecast['ds'],
                            y=forecast['yhat_upper'],
                            fill=        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    )),
                            mode='lines',
                            line_color='rgba(0,100,80,0.2)',
                            name='Upper Bound'
                        )
                        fig.add_scatter(
                            x=forecast['ds'],
                            y=forecast['yhat_lower'],
                            fill='tonexty',
                            mode='lines',
                            line_color='rgba(0,100,80,0.2)',
                            name='Lower Bound'
                        )
                        st.plotly_chart(fig)
                        
                        # Show forecast statistics
                        st.write("Forecast Statistics:")
                        forecast_stats = forecast[['ds', 'yhat', 'yhat_lower', 
                                                 'yhat_upper']].tail(forecast_periods)
                        forecast_stats.columns = ['Date', 'Forecast', 'Lower Bound', 
                                                'Upper Bound']
                        st.write(forecast_stats)
                        
                    except Exception as e:
                        st.error(f"Error in forecasting: {str(e)}")
        
        elif analysis_type == "Statistical Tests":
            st.subheader("Statistical Tests")
            
            test_type = st.selectbox(
                "Select Test Type",
                ["T-Test", "Chi-Square Test", "ANOVA", "Confidence Interval"]
            )
            
            if test_type in ["T-Test", "ANOVA"]:
                col1, col2 = st.columns(2)
                with col1:
                    group1_col = st.selectbox(
                        "Select First Group",
                        options=st.session_state.merged_data.select_dtypes(
                            include=[np.number]).columns
                    )
                with col2:
                    group2_col = st.selectbox(
                        "Select Second Group",
                        options=st.session_state.merged_data.select_dtypes(
                            include=[np.number]).columns
                    )
                
                if st.button("Run Test"):
                    result = StatisticalAnalyzer.run_hypothesis_test(
                        st.session_state.merged_data[group1_col],
                        st.session_state.merged_data[group2_col],
                        test_type.lower().replace('-', '_')
                    )
                    
                    st.write(f"Test Statistic: {result['statistic']:.4f}")
                    st.write(f"P-value: {result['p_value']:.4f}")
                    
                    # Interpretation
                    if result['p_value'] < 0.05:
                        st.success("Statistically significant difference found (p < 0.05)")
                    else:
                        st.info("No statistically significant difference found (p >= 0.05)")
            
            elif test_type == "Chi-Square Test":
                col1, col2 = st.columns(2)
                with col1:
                    cat1_col = st.selectbox(
                        "Select First Categorical Variable",
                        options=st.session_state.merged_data.select_dtypes(
                            include=['object']).columns
                    )
                with col2:
                    cat2_col = st.selectbox(
                        "Select Second Categorical Variable",
                        options=st.session_state.merged_data.select_dtypes(
                            include=['object']).columns
                    )
                
                if st.button("Run Test"):
                    result = StatisticalAnalyzer.run_hypothesis_test(
                        st.session_state.merged_data[cat1_col],
                        st.session_state.merged_data[cat2_col],
                        'chi_square'
                    
        
        elif analysis_type == "Custom Query":
            query = st.text_area("Enter your SQL query:", 
                               "SELECT * FROM merged_data LIMIT 5")
            if st.button("Run Query"):
                try:
                    result = st.session_state.analyzer.run_query(query)
                    st.write(result)
                except Exception as e:
                    st.error(f"Error executing query: {str(e)}")
        
        elif analysis_type == "Visualization":
            chart_type = st.selectbox("Select Chart Type", 
                                    ["Line Chart", "Bar Chart", "Scatter Plot"])
            
            col1, col2 = st.columns(2)
            with col1:
                x_col = st.selectbox("Select X-axis column", 
                                   options=st.session_state.merged_data.columns)
            with col2:
                y_col = st.selectbox("Select Y-axis column", 
                                   options=st.session_state.merged_data.columns)
            
            if chart_type == "Line Chart":
                fig = px.line(st.session_state.merged_data, x=x_col, y=y_col)
            elif chart_type == "Bar Chart":
                fig = px.bar(st.session_state.merged_data, x=x_col, y=y_col)
            else:  # Scatter Plot
                fig = px.scatter(st.session_state.merged_data, x=x_col, y=y_col)
            
            st.plotly_chart(fig)
            
        elif analysis_type == "Basic Pivot Table":
            st.subheader("Basic Pivot Table Analysis")
            
            # Select columns for pivot table
            col1, col2 = st.columns(2)
            with col1:
                index_cols = st.multiselect(
                    "Select Row Headers (Index)",
                    options=st.session_state.merged_data.columns,
                    help="Select columns to group by rows"
                )
            with col2:
                value_cols = st.multiselect(
                    "Select Values to Aggregate",
                    options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns,
                    help="Select numeric columns to analyze"
                )
            
            agg_func = st.selectbox(
                "Select Aggregation Function",
                options=PivotAnalyzer.get_available_agg_functions(),
                help="Choose how to aggregate the values"
            )
            
            if index_cols and value_cols:
                try:
                    pivot_df = PivotAnalyzer.create_pivot_table(
                        st.session_state.merged_data,
                        index_cols=index_cols,
                        value_cols=value_cols,
                        agg_func=agg_func
                    )
                    st.write(pivot_df)
                    
                    # Download button for pivot table
                    if st.button("Download Pivot Table"):
                        buffer = BytesIO()
                        pivot_df.to_excel(buffer, index=True)
                        buffer.seek(0)
                        st.download_button(
                            label="Download Excel file",
                            data=buffer,
                            file_name=f"pivot_table_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.ms-excel"
                        )
                except Exception as e:
                    st.error(f"Error creating pivot table: {str(e)}")
        
        elif analysis_type == "Advanced Pivot Table":
            st.subheader("Advanced Pivot Table Analysis")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                index_cols = st.multiselect(
                    "Select Row Headers (Index)",
                    options=st.session_state.merged_data.columns,
                    help="Select columns to group by rows"
                )
            with col2:
                value_cols = st.multiselect(
                    "Select Values to Aggregate",
                    options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns,
                    help="Select numeric columns to analyze"
                )
            with col3:
                pivot_col = st.selectbox(
                    "Select Column Header (Optional)",
                    options=['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))'] + list(st.session_state.merged_data.columns),
                    help="Select column to pivot (create column headers)"
                )
            
            # Advanced options
            st.subheader("Advanced Options")
            col1, col2 = st.columns(2)
            with col1:
                agg_func = st.selectbox(
                    "Select Aggregation Function",
                    options=PivotAnalyzer.get_available_agg_functions(),
                    help="Choose how to aggregate the values"
                )
                show_subtotals = st.checkbox("Show Subtotals", value=False)
            
            with col2:
                sort_values = st.selectbox(
                    "Sort Values By",
                    options=['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))'] + value_cols if value_cols else ['        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))']
                )
                ascending = st.checkbox("Sort Ascending", value=True)
            
            if index_cols and value_cols:
                try:
                    pivot_df = PivotAnalyzer.create_pivot_table(
                        st.session_state.merged_data,
                        index_cols=index_cols,
                        value_cols=value_cols,
                        agg_func=agg_func,
                        pivot_col=        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    )) if pivot_col == '        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))' else pivot_col
                    )
                    
                    # Apply sorting if selected
                    if sort_values != '        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    ))':
                        pivot_df = pivot_df.sort_values(by=sort_values, ascending=ascending)
                    
                    # Add subtotals if selected
                    if show_subtotals and len(index_cols) > 1:
                        for i in range(len(index_cols)):
                            subtotal_df = pivot_df.groupby(index_cols[:i+1]).sum()
                            pivot_df = pd.concat([pivot_df, subtotal_df])
                        pivot_df = pivot_df.sort_index()
                    
                    st.write(pivot_df)
                    
                    # Visualization options
                    st.subheader("Pivot Table Visualization")
                    chart_type = st.selectbox(
                        "Select Chart Type",
                        options=["Bar Chart", "Line Chart", "Heatmap"]
                    )
                    
                    if chart_type == "Bar Chart":
                        fig = px.bar(pivot_df.reset_index(), x=index_cols[0], y=value_cols)
                    elif chart_type == "Line Chart":
                        fig = px.line(pivot_df.reset_index(), x=index_cols[0], y=value_cols)
                    else:  # Heatmap
                        fig = px.imshow(pivot_df,
                                      labels=dict(color="Value"),
                                      aspect="auto")
                    st.plotly_chart(fig)
                    
                    # Download options
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("Download Pivot Table"):
                            buffer = BytesIO()
                            pivot_df.to_excel(buffer, index=True)
                            buffer.seek(0)
                            st.download_button(
                                label="Download Excel file",
                                data=buffer,
                                file_name=f"advanced_pivot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                mime="application/vnd.ms-excel"
                            )
                    with col2:
                        if st.button("Save to Dashboard"):
                            if 'dashboard_items' not in st.session_state:
                                st.session_state.dashboard_items = []
                            
                            dashboard_item = {
                                'type': 'pivot_table',
                                'config': {
                                    'index_cols': index_cols,
                                    'value_cols': value_cols,
                                    'pivot_col': pivot_col,
                                    'agg_func': agg_func,
                                    'chart_type': chart_type
                                },
                                'title': f"Pivot Analysis - {', '.join(value_cols)}"
                            }
                            st.session_state.dashboard_items.append(dashboard_item)
                            st.success("Added to dashboard!")
                            
                except Exception as e:
                    st.error(f"Error creating advanced pivot table: {str(e)}")
        
        elif analysis_type == "Dashboard":
            st.subheader("Dashboard")
            
            if 'dashboard_items' not in st.session_state:
                st.session_state.dashboard_items = []
            
            if not st.session_state.dashboard_items:
                st.info("Add items to your dashboard from the Analysis sections above!")
            else:
                # Dashboard layout
                for idx, item in enumerate(st.session_state.dashboard_items):
                    with st.expander(f"{item['title']}", expanded=True):
                        if item['type'] == 'pivot_table':
                            config = item['config']
                            pivot_df = PivotAnalyzer.create_pivot_table(
                                st.session_state.merged_data,
                                index_cols=config['index_cols'],
                                value_cols=config['value_cols'],
                                agg_func=config['agg_func'],
                                pivot_col=config['pivot_col']
                            )
                            
                            # Show table
                            st.write(pivot_df)
                            
                            # Show visualization
                            if config['chart_type'] == "Bar Chart":
                                fig = px.bar(pivot_df.reset_index(), 
                                           x=config['index_cols'][0], 
                                           y=config['value_cols'])
                            elif config['chart_type'] == "Line Chart":
                                fig = px.line(pivot_df.reset_index(), 
                                            x=config['index_cols'][0], 
                                            y=config['value_cols'])
                            else:  # Heatmap
                                fig = px.imshow(pivot_df,
                                              labels=dict(color="Value"),
                                              aspect="auto")
                            st.plotly_chart(fig)
                            
                        if st.button(f"Remove from Dashboard", key=f"remove_{idx}"):
                            st.session_state.dashboard_items.pop(idx)
                            st.experimental_rerun()
                
                # Dashboard export
                if st.button("Export Dashboard"):
                    buffer = BytesIO()
                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                        for idx, item in enumerate(st.session_state.dashboard_items):
                            if item['type'] == 'pivot_table':
                                config = item['config']
                                pivot_df = PivotAnalyzer.create_pivot_table(
                                    st.session_state.merged_data,
                                    index_cols=config['index_cols'],
                                    value_cols=config['value_cols'],
                                    agg_func=config['agg_func'],
                                    pivot_col=config['pivot_col']
                                )
                                pivot_df.to_excel(writer, 
                                                sheet_name=f"Pivot_{idx+1}",
                                                index=True)
                    
                    buffer.seek(0)
                    st.download_button(
                        label="Download Dashboard",
                        data=buffer,
                        file_name=f"dashboard_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                                    mime="application/vnd.ms-excel"
                    )
        
        elif analysis_type == "Time Series Analysis":
            st.subheader("Time Series Analysis")
            
            # Select columns for analysis
            date_col = st.selectbox(
                "Select Date Column",
                options=[col for col in st.session_state.merged_data.columns 
                        if st.session_state.merged_data[col].dtype in ['datetime64[ns]', 'object']]
            )
            value_col = st.selectbox(
                "Select Value Column",
                options=st.session_state.merged_data.select_dtypes(include=[np.number]).columns
            )
            
            analysis_type = st.selectbox(
                "Select Analysis Type",
                ["Decomposition", "Forecasting"]
            )
            
            if date_col and value_col:
                # Ensure date column is datetime
                df = st.session_state.merged_data.copy()
                df[date_col] = pd.to_datetime(df[date_col])
                df = df.sort_values(date_col)
                
                if analysis_type == "Decomposition":
                    try:
                        decomposition = TimeSeriesAnalyzer.decompose_series(
                            df.set_index(date_col)[value_col]
                        )
                        
                        # Plot components
                        fig = px.line(title="Time Series Decomposition")
                        fig.add_trace(px.line(y=decomposition['trend'], 
                                            title="Trend").data[0])
                        fig.add_trace(px.line(y=decomposition['seasonal'], 
                                            title="Seasonal").data[0])
                        fig.add_trace(px.line(y=decomposition['residual'], 
                                            title="Residual").data[0])
                        st.plotly_chart(fig)
                        
                    except Exception as e:
                        st.error(f"Error in decomposition: {str(e)}")
                
                else:  # Forecasting
                    forecast_periods = st.slider(
                        "Select number of periods to forecast",
                        min_value=1,
                        max_value=24,
                        value=12
                    )
                    
                    try:
                        forecast = TimeSeriesAnalyzer.forecast_prophet(
                            df,
                            date_col=date_col,
                            value_col=value_col,
                            periods=forecast_periods
                        )
                        
                        # Plot forecast
                        fig = px.line()
                        fig.add_trace(px.line(
                            x=df[date_col], 
                            y=df[value_col],
                            title="Historical Data"
                        ).data[0])
                        fig.add_trace(px.line(
                            x=forecast['ds'],
                            y=forecast['yhat'],
                            title="Forecast"
                        ).data[0])
                        fig.add_scatter(
                            x=forecast['ds'],
                            y=forecast['yhat_upper'],
                            fill=        elif analysis_type == "Machine Learning":
            st.subheader("Machine Learning Analysis")
            
            ml_type = st.selectbox(
                "Select Machine Learning Task",
                ["Clustering", "Anomaly Detection", "Predictive Modeling"]
            )
            
            if ml_type == "Clustering":
                # Select features for clustering
                features = st.multiselect(
                    "Select Features for Clustering",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                n_clusters = st.slider(
                    "Number of Clusters",
                    min_value=2,
                    max_value=10,
                    value=3
                )
                
                if features and st.button("Perform Clustering"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.perform_clustering(
                        st.session_state.merged_data[features],
                        n_clusters=n_clusters
                    )
                    
                    # Add cluster labels to data
                    clustered_data = st.session_state.merged_data.copy()
                    clustered_data['Cluster'] = result['clusters']
                    
                    # Show clustering results
                    st.write("Clustering Results:")
                    st.write(f"Silhouette Score: {result['silhouette_score']:.3f}")
                    
                    # Visualize clusters
                    if len(features) >= 2:
                        fig = px.scatter(
                            clustered_data,
                            x=features[0],
                            y=features[1],
                            color='Cluster',
                            title="Cluster Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show cluster statistics
                    st.write("Cluster Statistics:")
                    cluster_stats = clustered_data.groupby('Cluster')[features].mean()
                    st.write(cluster_stats)
            
            elif ml_type == "Anomaly Detection":
                features = st.multiselect(
                    "Select Features for Anomaly Detection",
                    options=st.session_state.merged_data.select_dtypes(
                        include=[np.number]).columns
                )
                
                contamination = st.slider(
                    "Contamination Factor",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    help="Expected proportion of outliers in the data"
                )
                
                if features and st.button("Detect Anomalies"):
                    ml_analyzer = MLAnalyzer()
                    result = ml_analyzer.detect_anomalies(
                        st.session_state.merged_data[features],
                        contamination=contamination
                    )
                    
                    # Add anomaly labels to data
                    anomaly_data = st.session_state.merged_data.copy()
                    anomaly_data['Is_Anomaly'] = result['anomalies'] == -1
                    anomaly_data['Anomaly_Score'] = result['scores']
                    
                    # Show results
                    st.write(f"Found {result['anomaly_samples']} anomalies "
                            f"({result['anomaly_samples']/len(anomaly_data)*100:.1f}% of data)")
                    
                    # Visualize anomalies
                    if len(features) >= 2:
                        fig = px.scatter(
                            anomaly_data,
                            x=features[0],
                            y=features[1],
                            color='Is_Anomaly',
                            title="Anomaly Detection Visualization"
                        )
                        st.plotly_chart(fig)
                    
                    # Show anomaly details
                    st.write("Top Anomalies:")
                    st.write(anomaly_data[anomaly_data['Is_Anomaly']].sort_values(
                        'Anomaly_Score'
                    )),
                            mode='lines',
                            line_color='rgba(0,100,80,0.2)',
                            name='Upper Bound'
                        )
                        fig.add_scatter(
                            x=forecast['ds'],
                            y=forecast['yhat_lower'],
                            fill='tonexty',
                            mode='lines',
                            line_color='rgba(0,100,80,0.2)',
                            name='Lower Bound'
                        )
                        st.plotly_chart(fig)
                        
                        # Show forecast statistics
                        st.write("Forecast Statistics:")
                        forecast_stats = forecast[['ds', 'yhat', 'yhat_lower', 
                                                 'yhat_upper']].tail(forecast_periods)
                        forecast_stats.columns = ['Date', 'Forecast', 'Lower Bound', 
                                                'Upper Bound']
                        st.write(forecast_stats)
                        
                    except Exception as e:
                        st.error(f"Error in forecasting: {str(e)}")
        
        elif analysis_type == "Statistical Tests":
            st.subheader("Statistical Tests")
            
            test_type = st.selectbox(
                "Select Test Type",
                ["T-Test", "Chi-Square Test", "ANOVA", "Confidence Interval"]
            )
            
            if test_type in ["T-Test", "ANOVA"]:
                col1, col2 = st.columns(2)
                with col1:
                    group1_col = st.selectbox(
                        "Select First Group",
                        options=st.session_state.merged_data.select_dtypes(
                            include=[np.number]).columns
                    )
                with col2:
                    group2_col = st.selectbox(
                        "Select Second Group",
                        options=st.session_state.merged_data.select_dtypes(
                            include=[np.number]).columns
                    )
                
                if st.button("Run Test"):
                    result = StatisticalAnalyzer.run_hypothesis_test(
                        st.session_state.merged_data[group1_col],
                        st.session_state.merged_data[group2_col],
                        test_type.lower().replace('-', '_')
                    )
                    
                    st.write(f"Test Statistic: {result['statistic']:.4f}")
                    st.write(f"P-value: {result['p_value']:.4f}")
                    
                    # Interpretation
                    if result['p_value'] < 0.05:
                        st.success("Statistically significant difference found (p < 0.05)")
                    else:
                        st.info("No statistically significant difference found (p >= 0.05)")
            
            elif test_type == "Chi-Square Test":
                col1, col2 = st.columns(2)
                with col1:
                    cat1_col = st.selectbox(
                        "Select First Categorical Variable",
                        options=st.session_state.merged_data.select_dtypes(
                            include=['object']).columns
                    )
                with col2:
                    cat2_col = st.selectbox(
                        "Select Second Categorical Variable",
                        options=st.session_state.merged_data.select_dtypes(
                            include=['object']).columns
                    )
                
                if st.button("Run Test"):
                    result = StatisticalAnalyzer.run_hypothesis_test(
                        st.session_state.merged_data[cat1_col],
                        st.session_state.merged_data[cat2_col],
                        'chi_square'
                    

if __name__ == "__main__":
    main()
