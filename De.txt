import os
import logging
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Tuple
from dotenv import dotenv_values
from azure.identity import ClientSecretCredential
from langchain_openai import AzureOpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OSEnv:
    """Enhanced environment manager with security features"""
    
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.token = None
        
        # Load configuration
        self._load_env_file(config_file, True)
        self._load_env_file(creds_file, False)
        
        # Security setup
        self._set_certificate_path(certificate_path)
        
        if self.str_to_bool(self.get("PROXY_ENABLED", "False")):
            self._configure_proxy()
            
        if self.str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self._get_azure_token()

    def _load_env_file(self, file_path: str, log_values: bool) -> None:
        """Load environment variables from .env file"""
        try:
            abs_path = Path(file_path).resolve()
            if not abs_path.exists():
                raise FileNotFoundError(f"Env file not found: {abs_path}")
                
            config = dotenv_values(abs_path)
            for k, v in config.items():
                self.set(k, v, log_values)
                
        except Exception as e:
            logger.error(f"Failed to load {file_path}: {str(e)}")
            raise

    def _set_certificate_path(self, cert_path: str) -> None:
        """Configure SSL certificate settings"""
        cert_path = Path(cert_path).resolve()
        if not cert_path.exists():
            raise FileNotFoundError(f"Certificate not found: {cert_path}")
            
        self.set("REQUESTS_CA_BUNDLE", str(cert_path))
        self.set("SSL_CERT_FILE", str(cert_path))
        self.set("CURL_CA_BUNDLE", str(cert_path))

    def _configure_proxy(self) -> None:
        """Set up authenticated proxy configuration"""
        proxy_url = (
            f"http://{self.get('AD_USERNAME')}:{self.get('AD_USER_PW')}"
            f"@{self.get('HTTPS_PROXY_DOMAIN')}"
        )
        self.set("HTTP_PROXY", proxy_url, False)
        self.set("HTTPS_PROXY", proxy_url, False)

    def _get_azure_token(self) -> str:
        """Acquire Azure AD token"""
        credential = ClientSecretCredential(
            tenant_id=self.get("AZURE_TENANT_ID"),
            client_id=self.get("AZURE_CLIENT_ID"),
            client_secret=self.get("AZURE_CLIENT_SECRET")
        )
        return credential.get_token("https://cognitiveservices.azure.com/.default").token

    def set(self, var_name: str, value: str, log: bool = True) -> None:
        """Set environment variable securely"""
        os.environ[var_name] = value
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if log:
            logger.info(f"Set {var_name}")

    def get(self, var_name: str, default: Any = None) -> Any:
        """Get environment variable safely"""
        return os.environ.get(var_name, default)

    @staticmethod
    def str_to_bool(s: str) -> bool:
        """Convert string to boolean safely"""
        return s.lower() in ['true', '1', 't', 'y', 'yes']

class ChromaVectorStore:
    """ChromaDB vector store manager with Azure OpenAI integration"""
    
    def __init__(self, env: OSEnv):
        self.env = env
        self.embeddings = self._init_embeddings()
        self.vector_store = None
        self.collection_name = None

    def _init_embeddings(self) -> AzureOpenAIEmbeddings:
        """Initialize Azure OpenAI embeddings with security"""
        return AzureOpenAIEmbeddings(
            deployment=self.env.get("AZURE_EMBEDDING_DEPLOYMENT"),
            model=self.env.get("AZURE_EMBEDDING_MODEL"),
            api_version=self.env.get("AZURE_API_VERSION"),
            azure_endpoint=self.env.get("AZURE_OPENAI_ENDPOINT"),
            azure_ad_token=self.env.token,
            openai_api_key="placeholder"  # Required by SDK but not used with AD token
        )

    def create_collection(self, csv_path: Path, text_column: str) -> None:
        """Create Chroma collection from CSV"""
        try:
            df = pd.read_csv(csv_path)
            if text_column not in df.columns:
                raise ValueError(f"Text column '{text_column}' not found")
                
            documents, metadatas = self._process_csv(df, text_column)
            self.collection_name = csv_path.stem.lower()
            
            self.vector_store = Chroma.from_documents(
                documents=documents,
                embedding=self.embeddings,
                collection_name=self.collection_name,
                ids=[str(i) for i in range(len(documents))],
                metadatas=metadatas,
                persist_directory=self.env.get("CHROMA_PERSIST_DIR", "./chroma_db")
            )
            
            logger.info(f"Created collection '{self.collection_name}' with {len(documents)} documents")
            
        except Exception as e:
            logger.error(f"Collection creation failed: {str(e)}")
            raise

    def _process_csv(self, df: pd.DataFrame, text_column: str) -> Tuple[List[Document], List[Dict]]:
        """Convert CSV data to Chroma documents and metadata"""
        documents = []
        metadatas = []
        
        for _, row in df.iterrows():
            metadata = {col: str(row[col]) for col in df.columns if col != text_column}
            documents.append(Document(page_content=row[text_column], metadata=metadata))
            metadatas.append(metadata)
            
        return documents, metadatas

    def search(self, query: str, k: int = 5) -> List[Tuple[str, float, Dict]]:
        """Perform similarity search with metadata"""
        try:
            results = self.vector_store.similarity_search_with_score(query, k=k)
            return [
                (result[0].page_content, 1 - result[1], result[0].metadata)
                for result in results
            ]
        except Exception as e:
            logger.error(f"Search failed: {str(e)}")
            raise

    def close(self):
        """Persist data and clean up resources"""
        if self.vector_store:
            self.vector_store.persist()
        logger.info("ChromaDB resources persisted")

def main():
    """Main application workflow"""
    try:
        # Initialize environment
        env_dir = Path(__file__).parent.parent / "env"
        env = OSEnv(
            config_file=env_dir / "config.env",
            creds_file=env_dir / "credentials.env",
            certificate_path=env_dir / "cacert.pem"
        )
        
        # Initialize vector store
        chroma_db = ChromaVectorStore(env)
        
        # CSV processing
        csv_path = Path(input("Enter CSV file path: ").strip()).resolve()
        df = pd.read_csv(csv_path)
        
        print("Available columns:")
        for idx, col in enumerate(df.columns):
            print(f"{idx+1}. {col}")
            
        text_col = df.columns[int(input("Enter text column number: "))-1]
        
        chroma_db.create_collection(csv_path, text_col)
        
        # Interactive search
        while True:
            query = input("\nEnter search query (or 'exit'): ").strip()
            if query.lower() == "exit":
                break
                
            try:
                k = int(input("Number of results (default 5): ") or 5)
            except ValueError:
                k = 5
                
            results = chroma_db.search(query, k)
            
            print(f"\nTop {k} results for '{query}':")
            for i, (text, score, metadata) in enumerate(results, 1):
                print(f"\n{i}. Similarity: {score:.4f}")
                print(f"Text: {text}")
                print("Metadata:")
                for k, v in metadata.items():
                    print(f"  - {k}: {v}")
                    
    except Exception as e:
        logger.error(f"Application error: {str(e)}")
    finally:
        chroma_db.close()
        logger.info("Application shutdown complete")

if __name__ == "__main__":
    main()
