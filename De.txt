"""
Feature to Capability Mapper with Domain-Aware AI Agents
Maps features to capability model using OpenCypher and graph-aware agents
"""
import csv
import logging
import asyncio
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from falkordb import FalkorDB

from src.services.openai_service import OpenAIService
from src.config import Config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Feature:
    """Represents a feature to be mapped"""
    name: str
    description: str


@dataclass
class CapabilityMatch:
    """Represents a capability match"""
    feature_name: str
    feature_description: str
    l0: Optional[str] = None
    l1: Optional[str] = None
    l2: Optional[str] = None
    l3: Optional[str] = None
    confidence: float = 0.0
    reasoning: str = ""
    status: str = "Unmapped"  # Mapped, Gap, Proposed
    similarity_score: float = 0.0
    matched_level: str = ""


class FeatureCapabilityMapper:
    """Maps features to capabilities using domain-aware AI agents"""
    
    def __init__(
        self,
        graph_name: str = "hsbc_capabilities",
        host: str = None,
        port: int = None
    ):
        """
        Initialize the feature mapper
        
        Args:
            graph_name: Name of the capability graph
            host: FalkorDB host
            port: FalkorDB port
        """
        self.graph_name = graph_name
        self.host = host or Config.FALKORDB_HOST
        self.port = port or Config.FALKORDB_PORT
        
        # Connect to FalkorDB
        logger.info(f"Connecting to FalkorDB at {self.host}:{self.port}")
        self.db = FalkorDB(host=self.host, port=self.port)
        self.graph = self.db.select_graph(self.graph_name)
        
        # Initialize OpenAI service with o3-mini
        logger.info("Initializing OpenAI service with o3-mini...")
        self.openai_service = OpenAIService()
        
        # Override to use o3-mini
        self.reasoning_model = "o3-mini"
        
        # Load graph structure into memory for agents
        self.graph_context = None
        
        logger.info("✓ Feature capability mapper initialized")
    
    def load_graph_context(self) -> Dict:
        """
        Load the entire graph structure for agent memory using OpenCypher
        
        Returns:
            Dictionary with graph structure and statistics
        """
        logger.info("Loading graph structure into agent memory...")
        
        # OpenCypher query to get graph statistics
        stats_query = """
        MATCH (c:Capability)
        RETURN 
            c.level AS level,
            count(c) AS count
        ORDER BY level
        """
        
        stats_result = self.graph.query(stats_query)
        level_counts = {record[0]: record[1] for record in stats_result.result_set}
        
        # OpenCypher query to get all capabilities with hierarchy
        hierarchy_query = """
        MATCH (c:Capability)
        OPTIONAL MATCH path = (root:Capability)-[:HAS_SUBCAPABILITY*0..]->(c)
        WHERE NOT EXISTS((parent)-[:HAS_SUBCAPABILITY]->(root))
        WITH c, nodes(path) AS hierarchy_nodes
        RETURN 
            c.name AS name,
            c.description AS description,
            c.level AS level,
            c.guid AS guid,
            [node IN hierarchy_nodes WHERE node.level = 0 | node.name][0] AS l0,
            [node IN hierarchy_nodes WHERE node.level = 1 | node.name][0] AS l1,
            [node IN hierarchy_nodes WHERE node.level = 2 | node.name][0] AS l2,
            [node IN hierarchy_nodes WHERE node.level = 3 | node.name][0] AS l3
        ORDER BY c.level, c.name
        """
        
        hierarchy_result = self.graph.query(hierarchy_query)
        
        capabilities_by_level = {0: [], 1: [], 2: [], 3: []}
        all_capabilities = []
        
        for record in hierarchy_result.result_set:
            cap = {
                'name': record[0],
                'description': record[1],
                'level': record[2],
                'guid': record[3],
                'l0': record[4],
                'l1': record[5],
                'l2': record[6],
                'l3': record[7]
            }
            capabilities_by_level[record[2]].append(cap)
            all_capabilities.append(cap)
        
        # Get relationship structure using OpenCypher
        relationships_query = """
        MATCH (parent:Capability)-[:HAS_SUBCAPABILITY]->(child:Capability)
        RETURN 
            parent.name AS parent_name,
            parent.level AS parent_level,
            child.name AS child_name,
            child.level AS child_level
        ORDER BY parent_level, parent_name
        """
        
        rel_result = self.graph.query(relationships_query)
        relationships = [
            {
                'parent': record[0],
                'parent_level': record[1],
                'child': record[2],
                'child_level': record[3]
            }
            for record in rel_result.result_set
        ]
        
        context = {
            'total_capabilities': len(all_capabilities),
            'level_counts': level_counts,
            'capabilities_by_level': capabilities_by_level,
            'all_capabilities': all_capabilities,
            'relationships': relationships
        }
        
        logger.info(f"✓ Loaded graph context:")
        logger.info(f"  Total capabilities: {context['total_capabilities']}")
        for level, count in sorted(level_counts.items()):
            logger.info(f"  Level {level}: {count} capabilities")
        logger.info(f"  Relationships: {len(relationships)}")
        
        self.graph_context = context
        return context
    
    def get_graph_context_summary(self) -> str:
        """
        Get a formatted summary of graph context for agent prompts
        
        Returns:
            Formatted string with graph structure
        """
        if not self.graph_context:
            self.load_graph_context()
        
        ctx = self.graph_context
        
        # Create hierarchical view
        summary = f"""CAPABILITY MODEL STRUCTURE:
Total Capabilities: {ctx['total_capabilities']}

HIERARCHY OVERVIEW:
"""
        
        for level in [0, 1, 2, 3]:
            count = ctx['level_counts'].get(level, 0)
            summary += f"\nLevel {level}: {count} capabilities\n"
            
            # Show sample capabilities at each level
            samples = ctx['capabilities_by_level'][level][:5]
            for cap in samples:
                indent = "  " * (level + 1)
                summary += f"{indent}• {cap['name']}\n"
            
            if len(ctx['capabilities_by_level'][level]) > 5:
                summary += f"{indent}... and {len(ctx['capabilities_by_level'][level]) - 5} more\n"
        
        return summary
    
    def read_features_csv(self, csv_path: str) -> List[Feature]:
        """
        Read features from CSV file
        
        Args:
            csv_path: Path to CSV file
            
        Returns:
            List of Feature objects
        """
        logger.info(f"Reading features from {csv_path}")
        features = []
        
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                features.append(Feature(
                    name=row['Features'].strip(),
                    description=row['Description'].strip()
                ))
        
        logger.info(f"✓ Read {len(features)} features")
        return features
    
    async def find_similar_capabilities_by_level(
        self,
        query_text: str,
        level: int,
        top_k: int = 5
    ) -> List[Dict]:
        """
        Find capabilities at a specific level using OpenCypher
        
        Args:
            query_text: Text to search for
            level: Capability level (0, 1, 2, or 3)
            top_k: Number of results
            
        Returns:
            List of similar capabilities
        """
        # Generate embedding
        embeddings = await self.openai_service.get_embeddings([query_text])
        query_embedding = embeddings[0]
        
        # OpenCypher query with vector search at specific level
        search_query = f"""
        CALL db.idx.vector.queryNodes(
            'Capability',
            'embedding',
            100,
            vecf32({query_embedding})
        )
        YIELD node, score
        WHERE node.level = {level}
        RETURN 
            node.name AS name,
            node.description AS description,
            node.level AS level,
            node.guid AS guid,
            score
        ORDER BY score DESC
        LIMIT {top_k}
        """
        
        result = self.graph.query(search_query)
        
        capabilities = []
        for record in result.result_set:
            capabilities.append({
                'name': record[0],
                'description': record[1],
                'level': record[2],
                'guid': record[3],
                'similarity_score': record[4]
            })
        
        return capabilities
    
    def get_capability_full_hierarchy(self, capability_name: str) -> Dict:
        """
        Get the full hierarchy for a capability using OpenCypher
        
        Args:
            capability_name: Name of the capability
            
        Returns:
            Dictionary with L0, L1, L2, L3 paths
        """
        name_escaped = capability_name.replace("'", "\\'")
        
        # OpenCypher query for hierarchy traversal
        query = f"""
        MATCH (c:Capability {{name: '{name_escaped}'}})
        OPTIONAL MATCH path = (root:Capability)-[:HAS_SUBCAPABILITY*0..]->(c)
        WHERE NOT EXISTS((()-[:HAS_SUBCAPABILITY]->(root)))
        WITH nodes(path) AS hierarchy_nodes
        RETURN 
            [node IN hierarchy_nodes WHERE node.level = 0 | node.name][0] AS l0,
            [node IN hierarchy_nodes WHERE node.level = 1 | node.name][0] AS l1,
            [node IN hierarchy_nodes WHERE node.level = 2 | node.name][0] AS l2,
            [node IN hierarchy_nodes WHERE node.level = 3 | node.name][0] AS l3
        LIMIT 1
        """
        
        result = self.graph.query(query)
        
        if result.result_set:
            record = result.result_set[0]
            return {
                'l0': record[0],
                'l1': record[1],
                'l2': record[2],
                'l3': record[3]
            }
        
        return {'l0': None, 'l1': None, 'l2': None, 'l3': None}
    
    def get_contextual_capabilities(self, candidates: List[Dict]) -> str:
        """
        Get contextual information about candidate capabilities from graph
        
        Args:
            candidates: List of candidate capabilities
            
        Returns:
            Formatted context string
        """
        context = "CANDIDATE CAPABILITIES WITH FULL CONTEXT:\n\n"
        
        for i, cap in enumerate(candidates[:10], 1):
            # Get hierarchy for this capability
            hierarchy = self.get_capability_full_hierarchy(cap['name'])
            
            # Get siblings and children using OpenCypher
            name_escaped = cap['name'].replace("'", "\\'")
            
            siblings_query = f"""
            MATCH (target:Capability {{name: '{name_escaped}'}})
            MATCH (parent:Capability)-[:HAS_SUBCAPABILITY]->(target)
            MATCH (parent)-[:HAS_SUBCAPABILITY]->(sibling:Capability)
            WHERE sibling.name <> target.name
            RETURN sibling.name AS sibling_name
            LIMIT 5
            """
            
            children_query = f"""
            MATCH (target:Capability {{name: '{name_escaped}'}})
            MATCH (target)-[:HAS_SUBCAPABILITY]->(child:Capability)
            RETURN child.name AS child_name
            LIMIT 5
            """
            
            siblings_result = self.graph.query(siblings_query)
            siblings = [record[0] for record in siblings_result.result_set]
            
            children_result = self.graph.query(children_query)
            children = [record[0] for record in children_result.result_set]
            
            # Build context
            context += f"{i}. {cap['name']} (L{cap['level']}) [Similarity: {cap['similarity_score']:.3f}]\n"
            context += f"   Description: {cap['description']}\n"
            
            # Hierarchy path
            path_parts = []
            for level_key in ['l0', 'l1', 'l2', 'l3']:
                if hierarchy.get(level_key):
                    path_parts.append(hierarchy[level_key])
            context += f"   Hierarchy: {' → '.join(path_parts)}\n"
            
            if siblings:
                context += f"   Siblings: {', '.join(siblings)}\n"
            if children:
                context += f"   Children: {', '.join(children)}\n"
            context += "\n"
        
        return context
    
    async def analyze_with_chain_of_thought(
        self,
        feature: Feature,
        candidate_capabilities: List[Dict]
    ) -> Dict:
        """
        Use chain of thought reasoning with graph context
        
        Args:
            feature: Feature to map
            candidate_capabilities: List of candidate capabilities
            
        Returns:
            Analysis result with reasoning
        """
        # Get rich contextual information about candidates
        candidates_context = self.get_contextual_capabilities(candidate_capabilities)
        
        # Get graph structure summary
        graph_summary = self.get_graph_context_summary()
        
        prompt = f"""You are a domain expert business analyst with deep knowledge of the enterprise capability model.

CAPABILITY MODEL YOU ARE WORKING WITH:
{graph_summary}

TASK: Map the following feature to the most appropriate capability in the model.

FEATURE TO MAP:
Name: {feature.name}
Description: {feature.description}

{candidates_context}

As a domain expert with full knowledge of the capability model, use chain-of-thought reasoning:

1. DOMAIN UNDERSTANDING: Given your knowledge of the capability model structure, what domain does this feature belong to?
2. SEMANTIC ANALYSIS: Which candidate capabilities have semantic alignment with the feature?
3. HIERARCHICAL PLACEMENT: At what level (L3→L2→L1→L0) does this feature operate?
4. CONTEXTUAL FIT: Considering siblings and children of candidates, which context best fits this feature?
5. FUNCTIONAL ALIGNMENT: Which capability's function and scope best aligns with this feature?
6. CONFIDENCE ASSESSMENT: How confident are you in this mapping (0-100)?

Provide your analysis in this exact JSON format:
{{
    "reasoning_steps": {{
        "domain_understanding": "...",
        "semantic_analysis": "...",
        "hierarchical_placement": "...",
        "contextual_fit": "...",
        "functional_alignment": "..."
    }},
    "best_match": "capability name or null",
    "confidence": 0-100,
    "summary_reasoning": "concise explanation referencing the graph structure"
}}

If no capability is a good match (confidence < 60), set best_match to null."""

        try:
            response = await self.openai_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                model=self.reasoning_model,
                temperature=0.3
            )
            
            # Extract JSON from response
            import json
            import re
            
            # Try to find JSON in response
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                return analysis
            else:
                logger.warning(f"Could not parse JSON from response for {feature.name}")
                return {
                    "reasoning_steps": {},
                    "best_match": None,
                    "confidence": 0,
                    "summary_reasoning": "Failed to analyze"
                }
                
        except Exception as e:
            logger.error(f"Error in chain of thought analysis: {e}")
            return {
                "reasoning_steps": {},
                "best_match": None,
                "confidence": 0,
                "summary_reasoning": f"Error: {str(e)}"
            }
    
    async def mixture_of_experts_validation(
        self,
        feature: Feature,
        proposed_match: str,
        candidates: List[Dict]
    ) -> Dict:
        """
        Use mixture of domain experts with graph memory
        
        Args:
            feature: Feature being mapped
            proposed_match: Proposed capability match
            candidates: List of candidate capabilities
            
        Returns:
            Expert consensus analysis
        """
        # Get rich context for the proposed match
        candidates_context = self.get_contextual_capabilities(candidates)
        
        # Get specific context for proposed match
        hierarchy = self.get_capability_full_hierarchy(proposed_match)
        path_parts = [hierarchy.get(k) for k in ['l0', 'l1', 'l2', 'l3'] if hierarchy.get(k)]
        hierarchy_path = ' → '.join(path_parts)
        
        # Get graph summary
        graph_summary = self.get_graph_context_summary()
        
        prompt = f"""You are a panel of three domain expert consultants, each with complete knowledge of the capability model.

CAPABILITY MODEL STRUCTURE:
{graph_summary}

FEATURE TO MAP:
{feature.name}: {feature.description}

PROPOSED MAPPING:
{proposed_match}
Hierarchy: {hierarchy_path}

CONTEXT OF OTHER CANDIDATES:
{candidates_context}

Each domain expert evaluates the proposed mapping:

EXPERT 1 - Enterprise Architect (knows full capability model):
- Does this mapping fit within the established capability structure?
- Are there better alternatives in the model?
- Does it align with the hierarchy?

EXPERT 2 - Business Domain Expert (knows capability relationships):
- Does this make business sense given sibling and child capabilities?
- Is the scope and level appropriate?
- Does it fit the domain context?

EXPERT 3 - Solution Architect (knows implementation implications):
- Is this technically coherent?
- Does the placement make sense for implementation?
- Are there overlaps with other capabilities?

Provide response in this JSON format:
{{
    "expert_opinions": {{
        "enterprise_architect": {{
            "agrees": true/false, 
            "reasoning": "...",
            "alternative_suggestion": "capability name or null"
        }},
        "business_domain_expert": {{
            "agrees": true/false, 
            "reasoning": "...",
            "alternative_suggestion": "capability name or null"
        }},
        "solution_architect": {{
            "agrees": true/false, 
            "reasoning": "...",
            "alternative_suggestion": "capability name or null"
        }}
    }},
    "consensus": true/false,
    "consensus_confidence": 0-100,
    "recommendation": "approve/reject/reconsider",
    "alternative_match": "capability name or null",
    "summary": "summary referencing graph context"
}}"""

        try:
            response = await self.openai_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                model=self.reasoning_model,
                temperature=0.4
            )
            
            import json
            import re
            
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {
                    "consensus": False,
                    "consensus_confidence": 0,
                    "recommendation": "reconsider",
                    "summary": "Could not parse expert opinions"
                }
                
        except Exception as e:
            logger.error(f"Error in mixture of experts: {e}")
            return {
                "consensus": False,
                "consensus_confidence": 0,
                "recommendation": "reconsider",
                "summary": f"Error: {str(e)}"
            }
    
    async def map_feature_hierarchically(
        self,
        feature: Feature
    ) -> CapabilityMatch:
        """
        Map a feature to capabilities using hierarchical search with graph context
        
        Args:
            feature: Feature to map
            
        Returns:
            CapabilityMatch with results
        """
        logger.info(f"\nMapping feature: {feature.name}")
        
        query_text = f"{feature.name}: {feature.description}"
        
        # Try each level from L3 to L0
        for level in [3, 2, 1, 0]:
            logger.info(f"  Searching at L{level}...")
            
            candidates = await self.find_similar_capabilities_by_level(
                query_text,
                level,
                top_k=10
            )
            
            if not candidates:
                logger.info(f"    No candidates at L{level}")
                continue
            
            logger.info(f"    Found {len(candidates)} candidates at L{level}")
            
            # Use chain of thought with graph context to analyze
            cot_analysis = await self.analyze_with_chain_of_thought(
                feature,
                candidates
            )
            
            if cot_analysis['best_match'] and cot_analysis['confidence'] >= 60:
                logger.info(f"    Chain of thought suggests: {cot_analysis['best_match']} (confidence: {cot_analysis['confidence']})")
                
                # Validate with mixture of domain experts
                expert_validation = await self.mixture_of_experts_validation(
                    feature,
                    cot_analysis['best_match'],
                    candidates
                )
                
                # Check if experts suggest an alternative
                if expert_validation.get('alternative_match') and expert_validation['recommendation'] == 'reconsider':
                    logger.info(f"    Experts suggest alternative: {expert_validation['alternative_match']}")
                    final_match = expert_validation['alternative_match']
                elif expert_validation['consensus'] and expert_validation['recommendation'] == 'approve':
                    logger.info(f"    ✓ Experts approve mapping")
                    final_match = cot_analysis['best_match']
                else:
                    logger.info(f"    Experts reject mapping - continuing search")
                    continue
                
                # Get full hierarchy for final match
                hierarchy = self.get_capability_full_hierarchy(final_match)
                
                # Find the matching candidate for similarity score
                matched_candidate = next(
                    (c for c in candidates if c['name'] == final_match),
                    candidates[0]
                )
                
                return CapabilityMatch(
                    feature_name=feature.name,
                    feature_description=feature.description,
                    l0=hierarchy['l0'],
                    l1=hierarchy['l1'],
                    l2=hierarchy['l2'],
                    l3=hierarchy['l3'],
                    confidence=expert_validation['consensus_confidence'] / 100.0,
                    reasoning=f"CoT: {cot_analysis['summary_reasoning']} | Experts: {expert_validation['summary']}",
                    status="Mapped",
                    similarity_score=matched_candidate['similarity_score'],
                    matched_level=f"L{level}"
                )
        
        # No good match found at any level
        logger.info(f"    No suitable mapping found - marking as gap")
        
        return CapabilityMatch(
            feature_name=feature.name,
            feature_description=feature.description,
            confidence=0.0,
            reasoning="No suitable capability found at any level after domain expert analysis",
            status="Gap"
        )
    
    async def propose_new_capabilities(
        self,
        unmapped_features: List[CapabilityMatch]
    ) -> List[Dict]:
        """
        Analyze unmapped features and propose new capabilities with graph context
        
        Args:
            unmapped_features: List of unmapped features
            
        Returns:
            List of proposed capabilities with grouped features
        """
        if not unmapped_features:
            return []
        
        logger.info(f"\nAnalyzing {len(unmapped_features)} unmapped features with graph context...")
        
        features_text = "\n".join([
            f"- {f.feature_name}: {f.feature_description}"
            for f in unmapped_features
        ])
        
        # Get graph context for proposal
        graph_summary = self.get_graph_context_summary()
        
        prompt = f"""You are a domain expert enterprise architect with complete knowledge of the existing capability model.

EXISTING CAPABILITY MODEL:
{graph_summary}

UNMAPPED FEATURES (gaps in current model):
{features_text}

TASK: As a domain expert who knows the entire capability structure, analyze these gaps and propose new capabilities.

Your analysis should:
1. Consider where these features would fit in the existing hierarchy
2. Group similar/related features together
3. Propose capability names that align with existing naming conventions
4. Suggest appropriate parent capabilities from the existing model
5. Explain why these are genuine gaps vs. poor initial matching

Provide response in this JSON format:
{{
    "proposed_capabilities": [
        {{
            "capability_name": "...",
            "capability_description": "...",
            "suggested_level": "L0/L1/L2/L3",
            "suggested_parent": "existing parent capability name or null for L0",
            "grouped_features": ["feature1", "feature2"],
            "rationale": "why these features form this capability and where it fits in the model",
            "alternative_consideration": "could these have been mapped to existing capabilities? if so, which ones and why were they rejected?"
        }}
    ],
    "model_gaps_summary": "overall assessment of gaps in the current model"
}}"""

        try:
            response = await self.openai_service.chat_completion(
                messages=[{"role": "user", "content": prompt}],
                model=self.reasoning_model,
                temperature=0.5
            )
            
            import json
            import re
            
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result.get('proposed_capabilities', [])
            
        except Exception as e:
            logger.error(f"Error proposing capabilities: {e}")
        
        return []
    
    async def map_all_features(
        self,
        features_csv_path: str,
        output_csv_path: str = "./feature_capability_mapping.csv"
    ):
        """
        Map all features and generate report
        
        Args:
            features_csv_path: Path to features CSV
            output_csv_path: Path for output CSV
        """
        # Load graph structure into agent memory
        self.load_graph_context()
        
        # Read features
        features = self.read_features_csv(features_csv_path)
        
        # Map each feature
        all_matches = []
        for i, feature in enumerate(features, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"Processing {i}/{len(features)}: {feature.name}")
            logger.info(f"{'='*60}")
            
            match = await self.map_feature_hierarchically(feature)
            all_matches.append(match)
            
            # Small delay to avoid rate limiting
            await asyncio.sleep(1)
        
        # Separate mapped and unmapped
        mapped = [m for m in all_matches if m.status == "Mapped"]
        gaps = [m for m in all_matches if m.status == "Gap"]
        
        logger.info(f"\n{'='*60}")
        logger.info(f"MAPPING SUMMARY")
        logger.info(f"{'='*60}")
        logger.info(f"Total features: {len(features)}")
        logger.info(f"Successfully mapped: {len(mapped)}")
        logger.info(f"Gaps identified: {len(gaps)}")
        
        # Propose new capabilities for gaps using graph context
        proposed = []
        if gaps:
            logger.info(f"\nProposing new capabilities for gaps with graph context...")
            proposals = await self.propose_new_capabilities(gaps)
            
            # Create proposed matches
            for proposal in proposals:
                for feature_name in proposal['grouped_features']:
                    gap_match = next(
                        (g for g in gaps if g.feature_name == feature_name),
                        None
                    )
                    if gap_match:
                        gap_match.status = "Proposed"
                        gap_match.reasoning = f"Proposed: {proposal['capability_name']} ({proposal['suggested_level']}) under '{proposal.get('suggested_parent', 'root')}' - {proposal['rationale']}"
                        proposed.append(gap_match)
        
        # Write to CSV
        self._write_mapping_report(all_matches, output_csv_path)
        
        # Write proposals separately
        if proposals:
            self._write_proposals_report(proposals, output_csv_path.replace('.csv', '_proposals.csv'))
        
        logger.info(f"\n✓ Mapping complete! Report saved to {output_csv_path}")
    
    def _write_mapping_report(
        self,
        matches: List[CapabilityMatch],
        output_path: str
    ):
        """Write mapping report to CSV"""
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # Headers
            writer.writerow([
                'Feature Name',
                'Feature Description',
                'Status',
                'Capability L0',
                'Capability L1',
                'Capability L2',
                'Capability L3',
                'Matched Level',
                'Similarity Score',
                'Confidence',
                'Reasoning'
            ])
            
            # Data
            for match in matches:
                writer.writerow([
                    match.feature_name,
                    match.feature_description,
                    match.status,
                    match.l0 or '',
                    match.l1 or '',
                    match.l2 or '',
                    match.l3 or '',
                    match.matched_level,
                    f"{match.similarity_score:.4f}" if match.similarity_score else '',
                    f"{match.confidence:.2%}" if match.confidence else '',
                    match.reasoning
                ])
        
        logger.info(f"✓ Written mapping report to {output_path}")
    
    def _write_proposals_report(
        self,
        proposals: List[Dict],
        output_path: str
    ):
        """Write capability proposals to CSV"""
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            
            # Headers
            writer.writerow([
                'Proposed Capability Name',
                'Description',
                'Suggested Level',
                'Suggested Parent',
                'Grouped Features',
                'Rationale',
                'Alternative Consideration'
            ])
            
            # Data
            for proposal in proposals:
                writer.writerow([
                    proposal['capability_name'],
                    proposal['capability_description'],
                    proposal['suggested_level'],
                    proposal.get('suggested_parent', ''),
                    ', '.join(proposal['grouped_features']),
                    proposal['rationale'],
                    proposal.get('alternative_consideration', '')
                ])
        
        logger.info(f"✓ Written proposals report to {output_path}")


async def main():
    """Main execution"""
    
    # Initialize mapper
    mapper = FeatureCapabilityMapper(graph_name="hsbc_capabilities")
    
    # Map features
    features_csv = "./features.csv"  # Update with your path
    output_csv = "./feature_capability_mapping.csv"
    
    await mapper.map_all_features(features_csv, output_csv)
    
    logger.info("\n" + "="*60)
    logger.info("COMPLETE!")
    logger.info("="*60)
    logger.info(f"Main report: {output_csv}")
    logger.info(f"Proposals: {output_csv.replace('.csv', '_proposals.csv')}")


if __name__ == "__main__":
    asyncio.run(main())
