"""
Example usage of HSBC-authenticated OpenAI service
Works with LangChain, LangGraph, and direct OpenAI calls
"""
import asyncio
import logging
from langchain_core.messages import HumanMessage, SystemMessage

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Import your services
from src.services.openai_service import OpenAIService
from src.config import Config

# For LangChain/LangGraph compatibility
from langchain_openai import ChatOpenAI


async def example_direct_openai_service():
    """Example using OpenAIService directly"""
    print("\n=== Example 1: Direct OpenAI Service ===")
    
    # Initialize service (automatically uses HSBC auth if configured)
    service = OpenAIService()
    
    # Chat completion
    messages = [
        SystemMessage(content="You are a helpful assistant."),
        HumanMessage(content="What is LLM?")
    ]
    
    response = await service.chat_completion(messages)
    print(f"Response: {response}")


async def example_with_langchain():
    """Example using LangChain with HSBC authentication"""
    print("\n=== Example 2: LangChain Integration ===")
    
    # Initialize service to get client
    service = OpenAIService()
    
    # Create LangChain ChatOpenAI with the HSBC client
    # Note: LangChain will use the client's base_url and api_key
    chat = ChatOpenAI(
        model=Config.CHAT_MODEL,
        openai_api_key=service.api_key,
        openai_api_base=service.base_url,
        http_client=service.client._client  # Use the underlying HTTP client
    )
    
    # Use LangChain
    messages = [
        SystemMessage(content="You are a helpful assistant."),
        HumanMessage(content="Explain data privacy in one sentence.")
    ]
    
    response = await chat.ainvoke(messages)
    print(f"Response: {response.content}")


async def example_embeddings():
    """Example generating embeddings with HSBC auth"""
    print("\n=== Example 3: Embeddings ===")
    
    service = OpenAIService()
    
    texts = [
        "Data privacy regulation",
        "GDPR compliance requirements",
        "Personal data processing"
    ]
    
    embeddings = await service.get_embeddings(texts)
    print(f"Generated {len(embeddings)} embeddings")
    print(f"Embedding dimension: {len(embeddings[0])}")


async def example_raw_openai_client():
    """Example using raw OpenAI client directly"""
    print("\n=== Example 4: Raw OpenAI Client ===")
    
    # Initialize service and get client
    service = OpenAIService()
    client = service.get_client()
    
    # Use client directly (sync)
    response = client.chat.completions.create(
        model=Config.CHAT_MODEL,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is a knowledge graph?"}
        ]
    )
    
    print(f"Response: {response.choices[0].message.content}")


async def example_token_refresh():
    """Example demonstrating automatic token refresh"""
    print("\n=== Example 5: Token Refresh (simulated auth error) ===")
    
    service = OpenAIService()
    
    # First call - uses initial token
    print("Making first call...")
    response1 = await service.chat_completion([
        {"role": "user", "content": "Hello"}
    ])
    print(f"First response: {response1[:50]}...")
    
    # Simulate token expiry by invalidating it
    if service.use_hsbc_auth:
        print("Invalidating token to simulate expiry...")
        service.client.token_service.invalidate_token()
    
    # Second call - should automatically refresh token
    print("Making second call (token will be refreshed)...")
    response2 = await service.chat_completion([
        {"role": "user", "content": "How are you?"}
    ])
    print(f"Second response: {response2[:50]}...")
    print("Token was automatically refreshed!")


async def example_multiple_requests():
    """Example making multiple requests efficiently"""
    print("\n=== Example 6: Multiple Requests ===")
    
    service = OpenAIService()
    
    questions = [
        "What is GDPR?",
        "What is CCPA?",
        "What is data sovereignty?"
    ]
    
    for i, question in enumerate(questions, 1):
        print(f"\nQuestion {i}: {question}")
        response = await service.chat_completion([
            {"role": "user", "content": question}
        ])
        print(f"Answer: {response[:100]}...")


async def main():
    """Run all examples"""
    print("Starting HSBC OpenAI Service Examples")
    print("=" * 60)
    
    # Check configuration
    print(f"\nConfiguration:")
    print(f"  HSBC Auth Enabled: {Config.USE_HSBC_AUTH}")
    print(f"  Base URL: {Config.BASE_URL}")
    print(f"  Chat Model: {Config.CHAT_MODEL}")
    
    if Config.USE_HSBC_AUTH:
        print(f"  HSBC Username: {Config.HSBC_USERNAME}")
        print(f"  HSBC User ID: {Config.HSBC_USER_ID}")
        if not Config.HSBC_PASSWORD:
            print("\n⚠️  WARNING: HSBC_PASSWORD not set!")
            print("   Set it using: export HSBC_PASSWORD='your-password'")
            return
    else:
        if not Config.API_KEY:
            print("\n⚠️  WARNING: OPENAI_API_KEY not set!")
            print("   Set it using: export OPENAI_API_KEY='your-key'")
            return
    
    try:
        # Run examples
        await example_direct_openai_service()
        await example_embeddings()
        await example_raw_openai_client()
        
        # Only test LangChain if available
        try:
            await example_with_langchain()
        except ImportError:
            print("\nSkipping LangChain example (langchain_openai not installed)")
        
        # Token refresh example
        if Config.USE_HSBC_AUTH:
            await example_token_refresh()
        
        await example_multiple_requests()
        
        print("\n" + "=" * 60)
        print("All examples completed successfully! ✓")
        
    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
