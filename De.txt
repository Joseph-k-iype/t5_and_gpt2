"""
Script to load and index data from a CSV file.
"""

import os
import sys
import asyncio
import argparse
import pandas as pd
import logging
from app.services.azure_openai import AzureOpenAIService
from app.services.elasticsearch_service import ElasticsearchService
from app.services.vector_service import VectorService
from app.core.environment import get_os_env

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

async def load_data(csv_path: str, force_recreate: bool = False):
    """
    Load and index data from a CSV file.
    
    Args:
        csv_path: Path to the CSV file
        force_recreate: Whether to force recreate the index
    """
    # Initialize services to None
    azure_service = None
    es_service = None
    vector_service = None
    
    try:
        logger.info(f"Loading data from {csv_path}")
        
        # Create Azure OpenAI service
        logger.info("Initializing Azure OpenAI service...")
        azure_service = AzureOpenAIService()
        
        # Create Elasticsearch service
        logger.info("Initializing Elasticsearch service...")
        es_service = ElasticsearchService()
        
        # Connect to Elasticsearch
        logger.info("Connecting to Elasticsearch...")
        await es_service.connect()
        
        # Create index
        logger.info("Creating/checking Elasticsearch index...")
        await es_service.create_index(force=force_recreate)
        
        # Create vector service
        logger.info("Initializing Vector service...")
        vector_service = VectorService(azure_service, es_service)
        
        # Check if CSV file exists and is readable
        if not os.path.isfile(csv_path):
            raise FileNotFoundError(f"CSV file not found: {csv_path}")
        
        if not os.access(csv_path, os.R_OK):
            raise PermissionError(f"Cannot read CSV file: {csv_path}")
        
        # Index data
        logger.info(f"Indexing data from CSV: {csv_path}")
        await vector_service.index_data_from_csv(csv_path)
        
        logger.info("Data loading completed successfully")
    except FileNotFoundError as e:
        logger.error(f"File error: {e}")
        raise
    except PermissionError as e:
        logger.error(f"Permission error: {e}")
        raise
    except Exception as e:
        logger.error(f"Error loading data: {e}")
        raise
    finally:
        # Close Elasticsearch connection if it was initialized and connected
        if es_service and hasattr(es_service, 'client') and es_service.client:
            try:
                await es_service.close()
                logger.info("Elasticsearch connection closed")
            except Exception as close_error:
                logger.error(f"Error closing Elasticsearch connection: {close_error}")

def main():
    """Main function to run the script."""
    parser = argparse.ArgumentParser(description="Load and index data from a CSV file")
    parser.add_argument("--csv", type=str, required=True, help="Path to the CSV file")
    parser.add_argument("--force", action="store_true", help="Force recreate the Elasticsearch index")
    args = parser.parse_args()
    
    # Check if CSV file exists before proceeding
    if not os.path.isfile(args.csv):
        logger.error(f"CSV file not found: {args.csv}")
        sys.exit(1)
    
    # Load environment variables
    env = get_os_env()
    
    # Run the async function
    try:
        asyncio.run(load_data(args.csv, args.force))
    except KeyboardInterrupt:
        logger.info("Process interrupted by user")
        sys.exit(0)
    except Exception as e:
        logger.error(f"Process failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
