"""
ISO 11179 Data Enrichment with Intelligent Context Usage
========================================================
FIXED:
- Intelligent context usage (not ignoring, but using wisely)
- No redundancy (partyModelID ‚Üí Party Model Identifier, not Customer Party Model Identifier)
- Context when needed (alternateNameType ‚Üí Customer Alternate Name Type)
- Multi-stage supervisor validation with modelling as last resort
"""

import json
import os
import pandas as pd
from typing import TypedDict, Annotated, List, Dict, Any, Literal, Sequence, Tuple
import numpy as np
from openai import OpenAI
import time
from datetime import datetime
from collections import defaultdict
import networkx as nx
from difflib import SequenceMatcher
import pickle

# LangChain and LangGraph imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.embeddings import Embeddings
from langchain_community.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
OPENAI_BASE_URL = "https://api.openai.com/v1"
OPENAI_REASONING_MODEL = "o3-mini"
OPENAI_EMBEDDING_MODEL = "text-embedding-3-large"

openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

INPUT_JSON_PATH = "cib_long_json.json"
EXCEL_PATH = "pbt.xlsx"
ACRONYM_CSV_PATH = "acronyms.csv"
OUTPUT_CSV_PATH = "enriched_mapped_output.csv"
CACHE_JSON_PATH = "mapping_cache.json"
PROCEDURAL_MEMORY_PATH = "procedural_memory.json"
EPISODIC_MEMORY_PATH = "episodic_memory.json"
KNOWLEDGE_GRAPH_PATH = "semantic_knowledge_graph.gpickle"

# Global stores
MAPPING_CACHE = {}
PROCEDURAL_MEMORY = {}
EPISODIC_MEMORY = []
SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()


# ============================================================================
# KNOWLEDGE GRAPH (Simplified)
# ============================================================================

def initialize_knowledge_graph():
    global SEMANTIC_KNOWLEDGE_GRAPH
    if os.path.exists(KNOWLEDGE_GRAPH_PATH):
        try:
            with open(KNOWLEDGE_GRAPH_PATH, 'rb') as f:
                SEMANTIC_KNOWLEDGE_GRAPH = pickle.load(f)
            print(f"   ‚Üí KG: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
        except:
            SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()
    else:
        SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()

def save_knowledge_graph():
    try:
        with open(KNOWLEDGE_GRAPH_PATH, 'wb') as f:
            pickle.dump(SEMANTIC_KNOWLEDGE_GRAPH, f, protocol=pickle.HIGHEST_PROTOCOL)
    except Exception as e:
        print(f"   ‚ö† KG save failed: {e}")

def add_field_to_graph(field_name, enriched_name, object_name, property_name, confidence, pii_category, application, eim_id):
    field_node = f"field:{field_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(field_node, type='field', original_name=field_name, enriched_name=enriched_name)
    enriched_node = f"concept:{enriched_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(enriched_node, type='concept', name=enriched_name)
    object_node = f"object:{object_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(object_node, type='object', name=object_name)
    property_node = f"property:{property_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(property_node, type='property', name=property_name)
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(field_node, enriched_node, relationship='enriched_to')
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(enriched_node, object_node, relationship='mapped_to_object')
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(enriched_node, property_node, relationship='mapped_to_property')


# ============================================================================
# LEXICAL + SEMANTIC MATCHING
# ============================================================================

def calculate_lexical_similarity(str1: str, str2: str) -> float:
    str1 = str1.lower()
    str2 = str2.lower()
    seq_similarity = SequenceMatcher(None, str1, str2).ratio()
    words1 = set(str1.split('_') + str1.split())
    words2 = set(str2.split('_') + str2.split())
    jaccard = len(words1 & words2) / len(words1 | words2) if words1 or words2 else 0
    return (0.5 * seq_similarity + 0.5 * jaccard)


def hybrid_similarity_search(query: str, vector_store: Any, all_items: List[str], top_k: int = 5) -> List[Tuple[str, float, Dict[str, float]]]:
    semantic_results = vector_store.similarity_search_with_score(query, k=top_k * 2)
    semantic_dict = {}
    for doc, score in semantic_results:
        item = doc.metadata.get('object') or doc.metadata.get('property') or doc.page_content
        semantic_dict[item] = float(score)
    
    lexical_scores = {item: calculate_lexical_similarity(query, item) for item in all_items}
    
    all_items_set = set(semantic_dict.keys()) | set(lexical_scores.keys())
    combined_results = []
    
    for item in all_items_set:
        semantic_score = semantic_dict.get(item, 0)
        lexical_score = lexical_scores.get(item, 0)
        semantic_score_norm = 1 / (1 + semantic_score) if semantic_score > 0 else 0
        combined_score = (0.3 * lexical_score) + (0.7 * semantic_score_norm)
        combined_results.append((item, combined_score, {'lexical': lexical_score, 'semantic': semantic_score_norm, 'combined': combined_score}))
    
    combined_results.sort(key=lambda x: x[1], reverse=True)
    return combined_results[:top_k]


# ============================================================================
# MEMORY FUNCTIONS
# ============================================================================

def load_all_memory():
    global MAPPING_CACHE, PROCEDURAL_MEMORY, EPISODIC_MEMORY
    if os.path.exists(CACHE_JSON_PATH):
        with open(CACHE_JSON_PATH, 'r') as f:
            MAPPING_CACHE = json.load(f)
        print(f"   ‚Üí Cache: {len(MAPPING_CACHE)} entries")
    if os.path.exists(PROCEDURAL_MEMORY_PATH):
        with open(PROCEDURAL_MEMORY_PATH, 'r') as f:
            PROCEDURAL_MEMORY = json.load(f)
    else:
        PROCEDURAL_MEMORY = {"prefix_patterns": {}, "suffix_patterns": {}}
    if os.path.exists(EPISODIC_MEMORY_PATH):
        with open(EPISODIC_MEMORY_PATH, 'r') as f:
            EPISODIC_MEMORY = json.load(f)
    initialize_knowledge_graph()

def save_all_memory():
    with open(CACHE_JSON_PATH, 'w') as f:
        json.dump(MAPPING_CACHE, f, indent=2)
    with open(PROCEDURAL_MEMORY_PATH, 'w') as f:
        json.dump(PROCEDURAL_MEMORY, f, indent=2)
    with open(EPISODIC_MEMORY_PATH, 'w') as f:
        json.dump(EPISODIC_MEMORY, f, indent=2)
    save_knowledge_graph()

def update_all_memory(field_name, enriched_name, obj, prop, strategy, confidence, pii, obj_mod, prop_mod, application, eim_id):
    cache_key = f"{enriched_name.lower()}|{field_name.lower()[:100]}"
    MAPPING_CACHE[cache_key] = {'object': obj, 'property': prop, 'confidence': confidence, 'object_was_modelled': obj_mod, 'property_was_modelled': prop_mod}
    EPISODIC_MEMORY.append({"timestamp": datetime.now().isoformat(), "field": field_name, "enriched": enriched_name, "mapping": {"object": obj, "property": prop}, "confidence": confidence, "pii": pii})
    if len(EPISODIC_MEMORY) > 1000:
        EPISODIC_MEMORY[:] = EPISODIC_MEMORY[-1000:]
    add_field_to_graph(field_name, enriched_name, obj, prop, confidence, pii, application, eim_id)


# ============================================================================
# EMBEDDINGS
# ============================================================================

class OpenAIEmbeddings(Embeddings):
    def __init__(self, model: str = OPENAI_EMBEDDING_MODEL):
        self.model = model
        self.client = openai_client
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for idx, text in enumerate(texts, 1):
            print(f"      üìä Embedding {idx}/{len(texts)}")
            embeddings.append(self.embed_query(text))
            time.sleep(0.1)
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        response = self.client.embeddings.create(model=self.model, input=[text[:8000]])
        return response.data[0].embedding


def call_openai_with_retry(messages: List[Dict], max_retries: int = 10) -> str:
    for attempt in range(max_retries):
        try:
            response = openai_client.chat.completions.create(model=OPENAI_REASONING_MODEL, messages=messages)
            return response.choices[0].message.content
        except Exception as e:
            print(f"      ‚ö† Attempt {attempt + 1} failed: {e}")
            time.sleep(2 ** attempt)
    raise Exception(f"Failed after {max_retries} attempts")


# ============================================================================
# AGENT STATE
# ============================================================================

class EnrichmentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    current_field: Dict[str, Any]
    enriched_name: str
    enriched_description: str
    object_name: str
    property_name: str
    object_was_modelled: bool
    property_was_modelled: bool
    pii_classification: Dict[str, Any]
    enrichment_rationale: str
    mapping_rationale: str
    enrichment_confidence: Dict[str, Any]
    mapping_confidence: Dict[str, Any]
    pii_confidence: Dict[str, Any]
    intersection_vector_store: Any
    object_vector_store: Any
    property_vector_store: Any
    all_objects: List[str]
    all_properties: List[str]
    objects_dict: Dict[str, List[str]]
    acronym_dict: Dict[str, str]
    mapping_strategy: str


# ============================================================================
# ENRICHMENT COORDINATOR WITH INTELLIGENT CONTEXT USAGE
# ============================================================================

def enrichment_coordinator_node(state: EnrichmentState) -> EnrichmentState:
    """Coordinator with intelligent context usage and multi-stage validation."""
    
    field_name = state['current_field'].get('Field Name', '')
    app_name = state['current_field'].get('Application Name', '')
    app_desc = state['current_field'].get('Application Description', '')
    
    print(f"\n{'='*80}")
    print(f"PROCESSING: {field_name}")
    print(f"APPLICATION: {app_name}")
    print(f"{'='*80}")
    
    # ========================================================================
    # STEP 1: INTELLIGENT ENRICHMENT WITH SMART CONTEXT USAGE
    # ========================================================================
    print("\n[STEP 1] ISO 11179 Name Enrichment (Intelligent Context)...")
    
    # Format acronym list for prompt
    acronym_dict = state.get('acronym_dict', {})
    if acronym_dict:
        acronym_list = "ACRONYM REFERENCE (expand these when found):\n"
        for acr, exp in sorted(acronym_dict.items()):
            acronym_list += f"  - {acr} = {exp}\n"
    else:
        acronym_list = "ACRONYM REFERENCE: (None provided)\n"
    
    enrichment_prompt = f"""You are an ISO 11179 naming expert. Create a clear, logical, human-readable name.

FIELD NAME: {field_name}
APPLICATION CONTEXT: {app_name}
(Use context intelligently - only when it adds clarity without redundancy)

{acronym_list}

INTELLIGENT CONTEXT USAGE RULES:

1. CHECK IF FIELD HAS ITS OWN ENTITY REFERENCE:
   Look for entity words in the field name itself:
   - party, customer, account, transaction, product, employee, user, invoice, payment, order
   
   If field contains these, DON'T add context entity:
   ‚úì "partyModelID" ‚Üí "Party Model Identifier" (NOT "Customer Party Model Identifier")
   ‚úì "accountBalance" ‚Üí "Account Balance" (NOT "Customer Account Balance")
   ‚úì "transactionAmount" ‚Üí "Transaction Amount" (NOT "Customer Transaction Amount")
   ‚úì "partyReference" ‚Üí "Party Reference" (NOT "Customer Party Reference")
   ‚úì "productCode" ‚Üí "Product Code" (NOT "Customer Product Code")

2. USE CONTEXT ONLY FOR GENERIC FIELDS:
   If field is generic (no entity reference), use application context:
   ‚úì "alternateNameType" in Customer app ‚Üí "Customer Alternate Name Type"
   ‚úì "statusCode" in Customer app ‚Üí "Customer Status Code"
   ‚úì "identifier" in Customer app ‚Üí "Customer Identifier"
   ‚úì "referenceNumber" in Customer app ‚Üí "Customer Reference Number"

3. AVOID REDUNDANCY:
   Never create redundant names like:
   ‚ùå "Customer Party Identifier" (redundant - party IS the entity)
   ‚ùå "Customer Account Balance" (account is already the entity)
   ‚ùå "Customer Transaction Amount" (transaction is already the entity)

4. EXPAND ABBREVIATIONS LOGICALLY:
   - ID, Id ‚Üí Identifier
   - Num, No ‚Üí Number
   - Addr ‚Üí Address
   - Ref ‚Üí Reference
   - Amt ‚Üí Amount
   - Cd ‚Üí Code
   - Dt ‚Üí Date
   - Type ‚Üí Type (keep as is)
   - Model ‚Üí Model (keep as is)

5. FORMAT:
   - Title Case with proper spacing
   - Clear and concise (max 5 words)
   - Readable by non-technical people

EXAMPLES:

Field: "partyModelID" in Customer app
‚úì CORRECT: "Party Model Identifier" (expanded ID ‚Üí Identifier)
‚ùå WRONG: "Customer Party Model Identifier" (redundant)

Field: "alternateNameType" in Customer app
‚úì CORRECT: "Customer Alternate Name Type"
‚ùå WRONG: "Alternate Name Type" (loses context)

Field: "accountBalance" in Customer app
‚úì CORRECT: "Account Balance"
‚ùå WRONG: "Customer Account Balance" (redundant)

Field: "custStatusCd" in Customer app (assume CUST=Customer in acronym list)
‚úì CORRECT: "Customer Status Code" (expanded CUST ‚Üí Customer, Cd ‚Üí Code)
‚ùå WRONG: "Cust Status Code" (didn't expand acronym)

Field: "txnAmtRef" in Customer app (assume TXN=Transaction in acronym list)
‚úì CORRECT: "Transaction Amount Reference" (expanded TXN ‚Üí Transaction, Amt ‚Üí Amount, Ref ‚Üí Reference)
‚ùå WRONG: "Customer Transaction Amount Reference" (redundant, txn already specifies entity)

Field: "acctNum" in Customer app (assume ACCT=Account in acronym list)
‚úì CORRECT: "Account Number" (expanded ACCT ‚Üí Account, Num ‚Üí Number)
‚ùå WRONG: "Customer Account Number" (redundant)

Field: "statusCode" in Customer app
‚úì CORRECT: "Customer Status Code" (generic field, needs context)
‚ùå WRONG: "Status Code" (loses context)

Field: "transactionRef" in Customer app
‚úì CORRECT: "Transaction Reference"
‚ùå WRONG: "Customer Transaction Reference" (redundant)

Field: "partyIdentifier" in Customer app
‚úì CORRECT: "Party Identifier"
‚ùå WRONG: "Customer Party Identifier" (redundant)

Field: "referenceNumber" in Customer app
‚úì CORRECT: "Customer Reference Number" (generic, needs context)
‚ùå WRONG: "Reference Number" (loses context)

Field: "empID" in Customer app (assume EMP=Employee in acronym list)
‚úì CORRECT: "Employee Identifier" (expanded EMP ‚Üí Employee, ID ‚Üí Identifier)
‚ùå WRONG: "Customer Employee Identifier" (redundant)

THINK STEP BY STEP:
1. Does the field name contain an entity word (party, account, transaction, product, etc.)?
2. If YES ‚Üí Use that entity, don't add application context
3. If NO ‚Üí Field is generic, add application context for clarity
4. Check acronym reference list for any matching acronyms (exact or substring match)
5. Expand all acronyms and abbreviations properly
6. Ensure result is logical, human-readable, and non-redundant

Now enrich this field name following these rules.
OUTPUT: ONLY the enriched name, nothing else."""

    try:
        enriched_name = call_openai_with_retry([{"role": "user", "content": enrichment_prompt}]).strip()
        enriched_name = enriched_name.split('\n')[0].strip().strip('"').strip("'")
        state['enriched_name'] = enriched_name
        print(f"   ‚úì Enriched: {enriched_name}")
    except:
        state['enriched_name'] = field_name
        print(f"   ‚ùå Using original: {field_name}")
    
    # ========================================================================
    # STEP 2: DEFINITION
    # ========================================================================
    print("\n[STEP 2] Definition...")
    try:
        definition = call_openai_with_retry([{"role": "user", "content": f"Create a precise, 2-sentence ISO 11179 definition for: {state['enriched_name']}. Be clear and concise."}]).strip()
        state['enriched_description'] = definition
        print(f"   ‚úì Definition: {definition[:80]}...")
    except:
        state['enriched_description'] = f"A data element representing {state['enriched_name'].lower()}."
    
    # ========================================================================
    # STEP 3: INTERSECTION MATCHING
    # ========================================================================
    print("\n[STEP 3] Intersection Matching (Object.Property combos)...")
    
    query = f"{state['enriched_name']} {state['enriched_description']}"
    intersection_results = state['intersection_vector_store'].similarity_search_with_score(query, k=5)
    
    top_matches = []
    for doc, score in intersection_results:
        obj = doc.metadata.get('object', '')
        prop = doc.metadata.get('property', '')
        top_matches.append({'object': obj, 'property': prop, 'score': float(score)})
    
    print(f"   ‚Üí Top 3 intersection matches:")
    for i, match in enumerate(top_matches[:3], 1):
        print(f"      {i}. {match['object']}.{match['property']} (score: {match['score']:.4f})")
    
    # ========================================================================
    # STEP 4: SUPERVISOR VALIDATION - INTERSECTION
    # ========================================================================
    print("\n[STEP 4] Supervisor Validates Intersection Match...")
    
    supervisor_intersection_prompt = f"""You are a SUPERVISOR validating semantic mapping.

ENRICHED FIELD: {state['enriched_name']}
DEFINITION: {state['enriched_description']}

TOP INTERSECTION MATCH: {top_matches[0]['object']}.{top_matches[0]['property']}
MATCH SCORE: {top_matches[0]['score']:.4f}

VALIDATION: Does this object.property combination make SEMANTIC SENSE?

Be STRICT. Only approve if:
1. Object accurately represents the entity
2. Property accurately represents the characteristic
3. Combination is logically sound
4. A human would agree this is correct

OUTPUT (JSON only):
{{
    "approved": <true/false>,
    "rationale": "<detailed explanation>",
    "semantic_correctness_score": <0-100>
}}"""

    try:
        supervisor_response = call_openai_with_retry([{"role": "user", "content": supervisor_intersection_prompt}])
        if '```json' in supervisor_response:
            supervisor_response = supervisor_response.split('```json')[1].split('```')[0]
        supervisor_data = json.loads(supervisor_response.strip())
        
        intersection_approved = supervisor_data.get('approved', False)
        intersection_rationale = supervisor_data.get('rationale', '')
        intersection_score = supervisor_data.get('semantic_correctness_score', 0)
        
        print(f"   ‚Üí Supervisor: {'‚úì APPROVED' if intersection_approved else '‚úó REJECTED'}")
        print(f"   ‚Üí Score: {intersection_score}/100")
        print(f"   ‚Üí Rationale: {intersection_rationale[:150]}...")
        
        if intersection_approved:
            # USE INTERSECTION MATCH
            state['object_name'] = top_matches[0]['object']
            state['property_name'] = top_matches[0]['property']
            state['object_was_modelled'] = False
            state['property_was_modelled'] = False
            state['mapping_strategy'] = 'intersection_approved'
            state['mapping_rationale'] = f"INTERSECTION MATCH APPROVED: {intersection_rationale}"
            print(f"   ‚úì USING: {state['object_name']}.{state['property_name']}")
            
        else:
            print(f"   ‚Üí Intersection rejected. Trying separate search...")
            
            # ================================================================
            # STEP 5-6: SEPARATE OBJECT & PROPERTY SEARCH
            # ================================================================
            print("\n[STEP 5] Separate Object Search...")
            object_results = hybrid_similarity_search(query, state['object_vector_store'], state['all_objects'], top_k=5)
            print(f"   ‚Üí Top 3 objects:")
            for i, (obj, score, breakdown) in enumerate(object_results[:3], 1):
                print(f"      {i}. {obj} (score: {score:.3f})")
            
            print("\n[STEP 6] Separate Property Search...")
            property_results = hybrid_similarity_search(query, state['property_vector_store'], state['all_properties'], top_k=5)
            print(f"   ‚Üí Top 3 properties:")
            for i, (prop, score, breakdown) in enumerate(property_results[:3], 1):
                print(f"      {i}. {prop} (score: {score:.3f})")
            
            # ================================================================
            # STEP 7: SUPERVISOR VALIDATES SEPARATE MATCH
            # ================================================================
            print("\n[STEP 7] Supervisor Validates Separate Combo...")
            
            proposed_object = object_results[0][0]
            proposed_property = property_results[0][0]
            
            supervisor_separate_prompt = f"""You are a SUPERVISOR validating semantic mapping.

ENRICHED FIELD: {state['enriched_name']}
DEFINITION: {state['enriched_description']}

PROPOSED: {proposed_object}.{proposed_property}
(From separate object and property searches)

VALIDATION: Does this make SEMANTIC SENSE?

Be VERY critical. Only approve if semantically sound.

OUTPUT (JSON only):
{{
    "approved": <true/false>,
    "object_ok": <true/false>,
    "property_ok": <true/false>,
    "rationale": "<detailed explanation>",
    "semantic_correctness_score": <0-100>
}}"""

            try:
                supervisor_response2 = call_openai_with_retry([{"role": "user", "content": supervisor_separate_prompt}])
                if '```json' in supervisor_response2:
                    supervisor_response2 = supervisor_response2.split('```json')[1].split('```')[0]
                supervisor_data2 = json.loads(supervisor_response2.strip())
                
                separate_approved = supervisor_data2.get('approved', False)
                object_ok = supervisor_data2.get('object_ok', False)
                property_ok = supervisor_data2.get('property_ok', False)
                separate_rationale = supervisor_data2.get('rationale', '')
                separate_score = supervisor_data2.get('semantic_correctness_score', 0)
                
                print(f"   ‚Üí Supervisor: {'‚úì APPROVED' if separate_approved else '‚úó REJECTED'}")
                print(f"   ‚Üí Object OK: {object_ok}, Property OK: {property_ok}")
                print(f"   ‚Üí Score: {separate_score}/100")
                
                if separate_approved:
                    # USE SEPARATE MATCH
                    state['object_name'] = proposed_object
                    state['property_name'] = proposed_property
                    state['object_was_modelled'] = False
                    state['property_was_modelled'] = False
                    state['mapping_strategy'] = 'separate_search_approved'
                    state['mapping_rationale'] = f"SEPARATE SEARCH APPROVED: {separate_rationale}"
                    print(f"   ‚úì USING: {state['object_name']}.{state['property_name']}")
                    
                else:
                    # ========================================================
                    # STEP 8: MODEL WHAT DOESN'T WORK (LAST RESORT)
                    # ========================================================
                    print("\n[STEP 8] MODELLING (Last Resort)...")
                    
                    if object_ok and not property_ok:
                        print(f"   ‚Üí MODELLING: Property only")
                        model_prompt = f"""Model a property for: {state['enriched_name']}
Object: {proposed_object} (approved)
Follow ISO 11179/BIAN/FIBO. Be concise, Title Case.
OUTPUT: ONLY the property name."""
                        
                        modelled_property = call_openai_with_retry([{"role": "user", "content": model_prompt}]).strip().split('\n')[0].strip('"').strip("'")
                        
                        state['object_name'] = proposed_object
                        state['property_name'] = modelled_property
                        state['object_was_modelled'] = False
                        state['property_was_modelled'] = True
                        state['mapping_strategy'] = 'property_modelled'
                        state['mapping_rationale'] = f"PROPERTY MODELLED: {separate_rationale}. Modelled '{modelled_property}' as no suitable PBT property exists."
                        print(f"   ‚úì {state['object_name']}.{state['property_name']} (property modelled)")
                        
                    elif property_ok and not object_ok:
                        print(f"   ‚Üí MODELLING: Object only")
                        model_prompt = f"""Model an object for: {state['enriched_name']}
Property: {proposed_property} (approved)
Follow ISO 11179/BIAN/FIBO. Be concise, Title Case.
OUTPUT: ONLY the object name."""
                        
                        modelled_object = call_openai_with_retry([{"role": "user", "content": model_prompt}]).strip().split('\n')[0].strip('"').strip("'")
                        
                        state['object_name'] = modelled_object
                        state['property_name'] = proposed_property
                        state['object_was_modelled'] = True
                        state['property_was_modelled'] = False
                        state['mapping_strategy'] = 'object_modelled'
                        state['mapping_rationale'] = f"OBJECT MODELLED: {separate_rationale}. Modelled '{modelled_object}' as no suitable PBT object exists."
                        print(f"   ‚úì {state['object_name']}.{state['property_name']} (object modelled)")
                        
                    else:
                        print(f"   ‚Üí MODELLING: Both")
                        model_prompt = f"""Model object and property for: {state['enriched_name']}
Definition: {state['enriched_description']}
Follow ISO 11179/BIAN/FIBO. Be concise, Title Case.
OUTPUT (JSON): {{"object": "<name>", "property": "<name>"}}"""
                        
                        model_response = call_openai_with_retry([{"role": "user", "content": model_prompt}])
                        if '```json' in model_response:
                            model_response = model_response.split('```json')[1].split('```')[0]
                        model_data = json.loads(model_response.strip())
                        
                        state['object_name'] = model_data['object']
                        state['property_name'] = model_data['property']
                        state['object_was_modelled'] = True
                        state['property_was_modelled'] = True
                        state['mapping_strategy'] = 'both_modelled'
                        state['mapping_rationale'] = f"BOTH MODELLED: {separate_rationale}. No suitable PBT terms exist."
                        print(f"   ‚úì {state['object_name']}.{state['property_name']} (both modelled)")
                
            except Exception as e:
                print(f"   ‚ùå Error: {e}")
                state['object_name'] = proposed_object
                state['property_name'] = proposed_property
                state['object_was_modelled'] = False
                state['property_was_modelled'] = False
                state['mapping_strategy'] = 'fallback'
                state['mapping_rationale'] = f"Fallback: {str(e)}"
    
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        state['object_name'] = top_matches[0]['object'] if top_matches else 'Unknown'
        state['property_name'] = top_matches[0]['property'] if top_matches else 'Unknown'
        state['object_was_modelled'] = False
        state['property_was_modelled'] = False
        state['mapping_strategy'] = 'error'
        state['mapping_rationale'] = f"Error: {str(e)}"
    
    # ========================================================================
    # STEP 9: PII CLASSIFICATION
    # ========================================================================
    print("\n[STEP 9] PII Classification...")
    try:
        pii_prompt = f"""Classify PII: {state['enriched_name']}
CATEGORIES: NON PERSONAL DATA, PERSONAL DATA, SENSITIVE PERSONAL DATA
OUTPUT (JSON): {{"pii_category": "<category>", "is_pii": <bool>, "regulatory_considerations": ["<regs>"], "detailed_rationale": "<why>"}}"""
        
        pii_response = call_openai_with_retry([{"role": "user", "content": pii_prompt}])
        if '```json' in pii_response:
            pii_response = pii_response.split('```json')[1].split('```')[0]
        pii_data = json.loads(pii_response.strip())
        state['pii_classification'] = pii_data
        print(f"   ‚úì PII: {pii_data.get('pii_category', 'UNKNOWN')}")
    except:
        state['pii_classification'] = {"pii_category": "NON PERSONAL DATA", "is_pii": False, "regulatory_considerations": [], "detailed_rationale": "Failed"}
    
    # ========================================================================
    # STEP 10: FINAL CONFIDENCE SCORING
    # ========================================================================
    print("\n[STEP 10] Final Confidence Scoring...")
    
    final_prompt = f"""Final SUPERVISOR confidence scoring.

RESULTS:
- Enriched: {state['enriched_name']}
- Mapping: {state['object_name']}.{state['property_name']}
- Strategy: {state['mapping_strategy']}
- Mapping Rationale: {state.get('mapping_rationale', '')}

Provide confidence scores.

OUTPUT (JSON):
{{
    "enrichment_rationale": "<validation>",
    "enrichment_confidence": {{
        "supporting_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "contradictory_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "confidence_score": <0-100>,
        "confidence_rationale": "<explanation>"
    }},
    "mapping_confidence": {{
        "supporting_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "contradictory_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "confidence_score": <0-100>,
        "confidence_rationale": "<explanation>"
    }},
    "pii_confidence": {{
        "supporting_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "contradictory_reasons": [{{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}, {{"reason": "<specific>", "weight": <0.0-1.0>}}],
        "confidence_score": <0-100>,
        "confidence_rationale": "<explanation>"
    }}
}}"""

    try:
        final_response = call_openai_with_retry([{"role": "user", "content": final_prompt}])
        if '```json' in final_response:
            final_response = final_response.split('```json')[1].split('```')[0]
        final_data = json.loads(final_response.strip())
        
        state['enrichment_rationale'] = final_data.get('enrichment_rationale', '')
        state['enrichment_confidence'] = final_data.get('enrichment_confidence', {})
        state['mapping_confidence'] = final_data.get('mapping_confidence', {})
        state['pii_confidence'] = final_data.get('pii_confidence', {})
        
        print(f"   ‚úì Confidence: E={state['enrichment_confidence'].get('confidence_score', 0)}, M={state['mapping_confidence'].get('confidence_score', 0)}, P={state['pii_confidence'].get('confidence_score', 0)}")
    except Exception as e:
        print(f"   ‚ö† Scoring failed: {e}")
        state['enrichment_rationale'] = 'Failed'
        state['enrichment_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
        state['mapping_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
        state['pii_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
    
    # UPDATE MEMORY
    print("\n[STEP 11] Updating Memory...")
    try:
        update_all_memory(field_name, state['enriched_name'], state['object_name'], state['property_name'], state['mapping_strategy'], state['mapping_confidence'].get('confidence_score', 0), state['pii_classification'].get('pii_category', 'NON PERSONAL DATA'), state.get('object_was_modelled', False), state.get('property_was_modelled', False), app_name, state['current_field'].get('EIM ID', ''))
    except Exception as e:
        print(f"   ‚ö† Memory update failed: {e}")
    
    print(f"{'='*80}\n")
    return state


def should_continue(state: EnrichmentState) -> Literal["end"]:
    return "end"


def create_enrichment_graph():
    workflow = StateGraph(EnrichmentState)
    workflow.add_node("enrichment_coordinator", enrichment_coordinator_node)
    workflow.set_entry_point("enrichment_coordinator")
    workflow.add_conditional_edges("enrichment_coordinator", should_continue, {"end": END})
    return workflow.compile()


# ============================================================================
# MAIN PROCESSING
# ============================================================================

def process_data_enrichment_and_mapping():
    print("="*80)
    print("ISO 11179 WITH INTELLIGENT CONTEXT USAGE")
    print("="*80)
    
    print("\n[1] Loading Memory...")
    load_all_memory()
    
    print("\n[2] Loading Input...")
    with open(INPUT_JSON_PATH, 'r') as f:
        input_data = json.load(f)
    print(f"   ‚Üí {len(input_data)} records")
    
    # Load acronyms
    print("\n[2.5] Loading Acronym Reference...")
    acronym_dict = {}
    if os.path.exists(ACRONYM_CSV_PATH):
        try:
            acronym_df = pd.read_csv(ACRONYM_CSV_PATH)
            # Expected columns: 'acronym' and 'expansion'
            for _, row in acronym_df.iterrows():
                acronym = str(row['acronym']).strip().upper()
                expansion = str(row['expansion']).strip()
                acronym_dict[acronym] = expansion
            print(f"   ‚Üí Loaded {len(acronym_dict)} acronyms")
            # Show sample
            if acronym_dict:
                sample = list(acronym_dict.items())[:5]
                for acr, exp in sample:
                    print(f"      ‚Ä¢ {acr} = {exp}")
                if len(acronym_dict) > 5:
                    print(f"      ‚Ä¢ ... and {len(acronym_dict) - 5} more")
        except Exception as e:
            print(f"   ‚ö† Error loading acronyms: {e}")
            print(f"   ‚Üí Expected CSV format: columns 'acronym' and 'expansion'")
            acronym_dict = {}
    else:
        print(f"   ‚Üí Acronym file not found: {ACRONYM_CSV_PATH}")
        print(f"   ‚Üí Continuing without acronym reference")
    
    print("\n[3] Creating Vector Stores...")
    excel_df = pd.read_excel(EXCEL_PATH)
    
    objects_dict = {}
    all_objects = []
    all_properties = []
    
    for _, row in excel_df.iterrows():
        obj = str(row['Object name']).strip()
        prop = str(row['Property name']).strip()
        
        if obj not in objects_dict:
            objects_dict[obj] = []
            all_objects.append(obj)
        if prop not in objects_dict[obj]:
            objects_dict[obj].append(prop)
        if prop not in all_properties:
            all_properties.append(prop)
    
    print(f"   ‚Üí {len(all_objects)} objects, {len(all_properties)} properties")
    
    embeddings = OpenAIEmbeddings()
    
    intersection_docs = [Document(page_content=f"{obj} {prop}", metadata={"object": obj, "property": prop}) for obj in all_objects for prop in objects_dict[obj]]
    intersection_store = InMemoryVectorStore.from_documents(intersection_docs, embeddings)
    
    object_docs = [Document(page_content=obj, metadata={"object": obj}) for obj in all_objects]
    object_store = InMemoryVectorStore.from_documents(object_docs, embeddings)
    
    property_docs = [Document(page_content=prop, metadata={"property": prop}) for prop in all_properties]
    property_store = InMemoryVectorStore.from_documents(property_docs, embeddings)
    
    print(f"   ‚úì Created 3 vector stores")
    
    print("\n[4] Initializing Workflow...")
    app = create_enrichment_graph()
    
    print(f"\n[5] Processing Records...")
    
    successful = 0
    failed = 0
    modelled_obj = 0
    modelled_prop = 0
    
    for idx, record in enumerate(input_data):
        eim_id = record.get("EIM ID", "")
        
        try:
            initial_state = {
                "messages": [], "current_field": record, "enriched_name": "", "enriched_description": "",
                "object_name": "", "property_name": "", "object_was_modelled": False, "property_was_modelled": False,
                "pii_classification": {}, "enrichment_rationale": "", "mapping_rationale": "",
                "enrichment_confidence": {}, "mapping_confidence": {}, "pii_confidence": {},
                "intersection_vector_store": intersection_store, "object_vector_store": object_store,
                "property_vector_store": property_store, "all_objects": all_objects, "all_properties": all_properties,
                "objects_dict": objects_dict, "acronym_dict": acronym_dict, "mapping_strategy": "unknown"
            }
            
            final_state = app.invoke(initial_state)
            
            def fmt_reasons(reasons):
                if not reasons:
                    return ""
                return " | ".join([f"{i+1}. {r.get('reason', 'N/A')} (w:{r.get('weight', 0.0):.2f})" for i, r in enumerate(reasons)])
            
            pii = final_state['pii_classification']
            ec = final_state.get('enrichment_confidence', {})
            mc = final_state.get('mapping_confidence', {})
            pc = final_state.get('pii_confidence', {})
            
            result = {
                "EIM ID": eim_id,
                "Application Name": record.get("Application Name", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": final_state['enriched_name'],
                "Enriched Description": final_state['enriched_description'],
                "Mapped Object": final_state['object_name'],
                "Mapped Property": final_state['property_name'],
                "Mapping Strategy": final_state.get('mapping_strategy', 'unknown'),
                "Object Was Modelled": final_state.get('object_was_modelled', False),
                "Property Was Modelled": final_state.get('property_was_modelled', False),
                "PII Category": pii.get('pii_category', ''),
                "Is PII": pii.get('is_pii', False),
                "Regulatory Considerations": ", ".join(pii.get('regulatory_considerations', [])),
                "PII Rationale": pii.get('detailed_rationale', ''),
                "Enrichment Rationale": final_state.get('enrichment_rationale', ''),
                "Mapping Rationale": final_state.get('mapping_rationale', ''),
                "Enrichment Confidence Score": ec.get('confidence_score', 0),
                "Enrichment Supporting Reasons": fmt_reasons(ec.get('supporting_reasons', [])),
                "Enrichment Contradictory Reasons": fmt_reasons(ec.get('contradictory_reasons', [])),
                "Enrichment Confidence Rationale": ec.get('confidence_rationale', ''),
                "Mapping Confidence Score": mc.get('confidence_score', 0),
                "Mapping Supporting Reasons": fmt_reasons(mc.get('supporting_reasons', [])),
                "Mapping Contradictory Reasons": fmt_reasons(mc.get('contradictory_reasons', [])),
                "Mapping Confidence Rationale": mc.get('confidence_rationale', ''),
                "PII Confidence Score": pc.get('confidence_score', 0),
                "PII Supporting Reasons": fmt_reasons(pc.get('supporting_reasons', [])),
                "PII Contradictory Reasons": fmt_reasons(pc.get('contradictory_reasons', [])),
                "PII Confidence Rationale": pc.get('confidence_rationale', ''),
                "Status": "SUCCESS"
            }
            
            successful += 1
            if result["Object Was Modelled"]:
                modelled_obj += 1
            if result["Property Was Modelled"]:
                modelled_prop += 1
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
            
            result = {
                "EIM ID": eim_id, "Application Name": record.get("Application Name", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": record.get("Field Name", ""),
                "Enriched Description": f"Error: {str(e)[:200]}",
                "Mapped Object": "Unknown", "Mapped Property": "Unknown",
                "Mapping Strategy": "error", "Object Was Modelled": False, "Property Was Modelled": False,
                "PII Category": "NON PERSONAL DATA", "Is PII": False,
                "Regulatory Considerations": "", "PII Rationale": "",
                "Enrichment Rationale": "Error", "Mapping Rationale": "Error",
                "Enrichment Confidence Score": 0, "Enrichment Supporting Reasons": "",
                "Enrichment Contradictory Reasons": "", "Enrichment Confidence Rationale": "",
                "Mapping Confidence Score": 0, "Mapping Supporting Reasons": "",
                "Mapping Contradictory Reasons": "", "Mapping Confidence Rationale": "",
                "PII Confidence Score": 0, "PII Supporting Reasons": "",
                "PII Contradictory Reasons": "", "PII Confidence Rationale": "",
                "Status": "FAILED"
            }
            failed += 1
        
        # Write incrementally
        pd.DataFrame([result]).to_csv(OUTPUT_CSV_PATH, mode='a', header=(successful+failed==1), index=False)
    
    print("\n[6] Saving Memory...")
    save_all_memory()
    
    print(f"\n{'='*80}")
    print("COMPLETE!")
    print(f"{'='*80}")
    print(f"Success: {successful}, Failed: {failed}")
    print(f"Modelled: Objects={modelled_obj}, Properties={modelled_prop}")
    print(f"Output: {OUTPUT_CSV_PATH}")


if __name__ == "__main__":
    process_data_enrichment_and_mapping()
