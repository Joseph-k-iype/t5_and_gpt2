"""
Embedding service for generating and managing embeddings for the AI Tagging Service.
"""

import logging
import uuid
from typing import List, Dict, Any, Optional, Tuple
from pydantic import BaseModel, Field
from azure.identity import get_bearer_token_provider
from openai import AzureOpenAI
from langchain_openai import AzureChatOpenAI
from app.config.settings import get_settings
from app.config.environment import get_os_env
from app.core.auth.auth_helper import get_azure_token_cached, refresh_token_if_needed

logger = logging.getLogger(__name__)

class Document(BaseModel):
    """Document model for embedding generation."""
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    text: str
    embedding: List[float] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    synonyms: List[str] = Field(default_factory=list)


class EmbeddingService:
    """Service for generating embeddings using Azure OpenAI."""
    
    _instance = None
    
    def __new__(cls):
        """Implement singleton pattern."""
        if cls._instance is None:
            cls._instance = super(EmbeddingService, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the embedding service."""
        if self._initialized:
            return
            
        self._initialized = True
        self.settings = get_settings()
        self.env = get_os_env()
        
        # Initialize Azure OpenAI client for embeddings
        self.client = self._init_client()
        
        # Initialize the LLM for generating synonyms
        self.llm = self._init_llm()
        
        logger.info("Embedding service initialized")
    
    def _init_client(self) -> AzureOpenAI:
        """Initialize the Azure OpenAI client."""
        try:
            # Get Azure token
            token = get_azure_token_cached(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default"
            )
            
            if not token:
                logger.error("Failed to get Azure token for embedding service")
                raise ValueError("Failed to get Azure token")
            
            # Create token provider function
            token_provider = lambda: get_azure_token_cached(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default"
            ) or token
            
            # Initialize Azure OpenAI client
            client = AzureOpenAI(
                azure_endpoint=self.settings.azure.azure_endpoint,
                api_version=self.settings.azure.api_version,
                azure_ad_token_provider=token_provider
            )
            
            return client
        
        except Exception as e:
            logger.error(f"Error initializing Azure OpenAI client: {e}")
            raise
    
    def _init_llm(self) -> AzureChatOpenAI:
        """Initialize the LLM for generating synonyms."""
        try:
            # Get Azure token
            token = get_azure_token_cached(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default"
            )
            
            if not token:
                logger.error("Failed to get Azure token for LLM service")
                raise ValueError("Failed to get Azure token")
            
            # Create token provider function that refreshes on each call
            token_provider = lambda: get_azure_token_cached(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default"
            ) or token
            
            # Initialize Azure OpenAI client for LLM
            llm = AzureChatOpenAI(
                model_name=self.settings.azure.openai_model_name,  # Use the renamed field
                temperature=0.5,  # Good for creativity in synonyms
                max_tokens=300,
                api_version=self.settings.azure.api_version,
                azure_endpoint=self.settings.azure.azure_endpoint,
                azure_ad_token_provider=token_provider
            )
            
            return llm
        
        except Exception as e:
            logger.error(f"Error initializing LLM: {e}")
            return None
    
    def generate_embedding(self, document: Document) -> Document:
        """
        Generate an embedding for a document.
        
        Args:
            document: Document to generate embedding for
            
        Returns:
            Document with embedding
        """
        try:
            # Make sure we have a valid token
            refresh_token_if_needed(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default",
                min_validity_seconds=600  # 10 minutes
            )
            
            # Retry mechanism with backoff
            max_retries = 3
            retry_delay = 2  # seconds
            
            for attempt in range(max_retries):
                try:
                    response = self.client.embeddings.create(
                        model=self.settings.azure.embedding_deployment_name,
                        input=document.text,
                        encoding_format="float"
                    ).data[0].embedding
                    
                    document.embedding = response
                    logger.debug(f"Generated embedding for document {document.id}")
                    return document
                except Exception as retry_error:
                    if attempt < max_retries - 1:
                        logger.warning(f"Embedding generation attempt {attempt+1} failed, retrying in {retry_delay} seconds: {retry_error}")
                        import time
                        time.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                        
                        # Re-initialize client on failure
                        self.client = self._init_client()
                    else:
                        raise  # Re-raise on last attempt
        
        except Exception as e:
            logger.error(f"Error generating embedding: {e}")
            # Return document without embedding rather than failing completely
            logger.warning(f"Returning document {document.id} without embedding")
            return document
    
    def batch_generate_embeddings(self, documents: List[Document]) -> List[Document]:
        """
        Generate embeddings for a batch of documents.
        
        Args:
            documents: Documents to generate embeddings for
            
        Returns:
            Documents with embeddings
        """
        try:
            # Make sure we have a valid token
            refresh_token_if_needed(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default",
                min_validity_seconds=600  # 10 minutes
            )
            
            # Process in batches to avoid Azure API limits
            batch_size = 16
            processed_documents = []
            
            for i in range(0, len(documents), batch_size):
                batch = documents[i:i+batch_size]
                texts = [doc.text for doc in batch]
                
                max_retries = 3
                retry_delay = 2  # seconds
                
                for attempt in range(max_retries):
                    try:
                        response = self.client.embeddings.create(
                            model=self.settings.azure.embedding_deployment_name,
                            input=texts,
                            encoding_format="float"
                        )
                        
                        # Update documents with embeddings
                        for j, embedding_data in enumerate(response.data):
                            batch[j].embedding = embedding_data.embedding
                        
                        break  # Success, exit retry loop
                    except Exception as retry_error:
                        if attempt < max_retries - 1:
                            logger.warning(f"Batch embedding generation attempt {attempt+1} failed, retrying in {retry_delay} seconds: {retry_error}")
                            import time
                            time.sleep(retry_delay)
                            retry_delay *= 2  # Exponential backoff
                            
                            # Re-initialize client on failure
                            self.client = self._init_client()
                        else:
                            logger.error(f"Failed to generate embeddings for batch after {max_retries} attempts")
                            # Leave embeddings empty rather than failing completely
                
                processed_documents.extend(batch)
                logger.info(f"Generated embeddings for batch {i//batch_size + 1} of {(len(documents) - 1)//batch_size + 1}")
            
            return processed_documents
        
        except Exception as e:
            logger.error(f"Error generating batch embeddings: {e}")
            return documents  # Return documents without embeddings rather than failing
    
    def generate_synonyms(self, term_name: str, term_definition: str, max_synonyms: int = 10) -> List[str]:
        """
        Generate synonyms for a business term using the LLM.
        
        Args:
            term_name: Business term name
            term_definition: Business term definition
            max_synonyms: Maximum number of synonyms to generate
            
        Returns:
            List of synonyms
        """
        if not self.llm:
            logger.warning("LLM not initialized, cannot generate synonyms")
            return []
        
        try:
            # Make sure we have a valid token
            refresh_token_if_needed(
                tenant_id=self.settings.azure.tenant_id,
                client_id=self.settings.azure.client_id,
                client_secret=self.settings.azure.client_secret,
                scope="https://cognitiveservices.azure.com/.default",
                min_validity_seconds=600  # 10 minutes
            )
            
            # Re-initialize LLM if needed
            self.llm = self._init_llm()
            
            prompt = f"""
            Generate {max_synonyms} alternative terms, phrases or synonyms that business users might use when referring to this business term:
            
            Term: {term_name}
            Definition: {term_definition}
            
            Provide ONLY a comma-separated list of alternative terms or phrases that a user might use when referring to this concept.
            These should be different ways to express the same concept, including industry jargon, abbreviations, and common variations.
            DO NOT provide explanations - ONLY the comma-separated list of terms.
            """
            
            max_retries = 3
            retry_delay = 2  # seconds
            
            for attempt in range(max_retries):
                try:
                    response = self.llm.invoke(prompt)
                    
                    # Parse the response to extract the list of synonyms
                    synonyms_text = response.content.strip()
                    
                    # Split by comma and clean up each synonym
                    synonyms = [syn.strip() for syn in synonyms_text.split(',')]
                    
                    # Remove duplicates and empty strings
                    synonyms = list(set([syn for syn in synonyms if syn]))
                    
                    logger.info(f"Generated {len(synonyms)} synonyms for '{term_name}'")
                    return synonyms
                    
                except Exception as retry_error:
                    if attempt < max_retries - 1:
                        logger.warning(f"Synonym generation attempt {attempt+1} failed, retrying in {retry_delay} seconds: {retry_error}")
                        import time
                        time.sleep(retry_delay)
                        retry_delay *= 2  # Exponential backoff
                        
                        # Re-initialize LLM on failure
                        self.llm = self._init_llm()
                    else:
                        logger.error(f"Failed to generate synonyms after {max_retries} attempts")
                        return []  # Return empty list on failure
            
        except Exception as e:
            logger.error(f"Error generating synonyms for '{term_name}': {e}")
            return []
    
    def get_langchain_compatible_embeddings(self):
        """
        Get a Langchain-compatible embeddings object for use with vector stores.
        
        Returns:
            A Langchain-compatible embeddings object
        """
        # Define a class that implements the Langchain embeddings interface
        class AzureEmbeddings:
            def __init__(self, service):
                self.service = service
            
            def embed_documents(self, texts):
                docs = [Document(id=str(i), text=text) for i, text in enumerate(texts)]
                embedded_docs = self.service.batch_generate_embeddings(docs)
                return [doc.embedding for doc in embedded_docs]
            
            def embed_query(self, text):
                doc = Document(id="query", text=text)
                embedded_doc = self.service.generate_embedding(doc)
                return embedded_doc.embedding
        
        return AzureEmbeddings(self)


# Get the embedding service instance
def get_embedding_service(force_refresh: bool = False) -> EmbeddingService:
    """
    Get the embedding service instance.
    
    Args:
        force_refresh: Force refresh of tokens and service initialization
    
    Returns:
        EmbeddingService: Embedding service instance
    """
    instance = EmbeddingService()
    
    if force_refresh:
        # Reinitialize the clients with fresh tokens
        instance._initialized = False
        instance.__init__()
        logger.info("Embedding service reinitialized with fresh tokens")
    
    return instance
