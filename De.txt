import os
import sys
import uuid
import json
import logging
import chardet
import pandas as pd
import networkx as nx
from typing import Optional, Dict, Any, List
from pathlib import Path

from dotenv import dotenv_values
from azure.identity import ClientSecretCredential, DefaultAzureCredential, get_bearer_token_provider
from openai import AzureOpenAI
from pydantic import BaseModel

# LangChain
from langchain.chat_models import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.docstore.document import Document as LC_Document
from langchain.embeddings.base import Embeddings
from langchain.vectorstores import Chroma
from chromadb.config import Settings

# Logging setup
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

###############################################################################
# GLOBAL CONSTANTS
###############################################################################
ENV_DIR = "../env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"
CSV_PATH = "knowledgebase.csv"  # Must have columns: name, definition, [id]

###############################################################################
# Utility
###############################################################################
def str_to_bool(s: str) -> bool:
    s_lower = s.lower()
    if s_lower == "true":
        return True
    elif s_lower == "false":
        return False
    else:
        raise ValueError(f"Invalid boolean string: {s}")

###############################################################################
# OSEnv class
###############################################################################
class OSEnv:
    """
    Loads environment variables from config/creds files,
    sets up proxies, cert paths, and fetches Azure AD token if needed.
    """
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self._bulk_set(config_file, print_val=True)
        logger.info(f"Loaded main configuration from {config_file}")

        self._bulk_set(creds_file, print_val=False)
        logger.info(f"Loaded credentials from {creds_file}")

        self._set_certificate_path(certificate_path)
        logger.info("Certificate path configured")

        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self._set_proxy()
            logger.info("Proxy configured")

        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            logger.info("Securing endpoints")
            self.token = self._get_azure_token()
        else:
            self.token = None

    def _bulk_set(self, dotenvfile: str, print_val: bool):
        if not os.path.isabs(dotenvfile):
            dotenvfile = os.path.abspath(dotenvfile)
        if not os.path.isfile(dotenvfile):
            logger.warning(f"No such env file: {dotenvfile}")
            return

        logger.info(f"Loading environment from {dotenvfile}")
        temp_dict = dotenv_values(dotenvfile)
        for k, v in temp_dict.items():
            self.set(k, v, print_val=print_val)

    def set(self, var_name: str, val: str, print_val: bool = True):
        os.environ[var_name] = val
        if var_name not in self.var_list:
            self.var_list.append(var_name)
        if print_val:
            logger.info(f"Set {var_name}={val}")

    def get(self, var_name: str, default: Optional[str] = None) -> Optional[str]:
        return os.environ.get(var_name, default)

    def _set_certificate_path(self, certificate_path: str):
        if not os.path.isabs(certificate_path):
            certificate_path = os.path.abspath(certificate_path)
        if not os.path.isfile(certificate_path):
            logger.warning(f"Certificate file missing: {certificate_path}")
            return
        self.set("REQUESTS_CA_BUNDLE", certificate_path)
        self.set("SSL_CERT_FILE", certificate_path)
        self.set("CURL_CA_BUNDLE", certificate_path)

    def _set_proxy(self):
        ad_username = self.get("AD_USERNAME")
        ad_password = self.get("AD_USER_PW")
        proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
        if not all([ad_username, ad_password, proxy_domain]):
            logger.warning("Missing proxy credentials, skipping proxy setup.")
            return
        proxy_url = f"http://{ad_username}:{ad_password}@{proxy_domain}"
        self.set("HTTP_PROXY", proxy_url, print_val=False)
        self.set("HTTPS_PROXY", proxy_url, print_val=False)
        no_proxy_domains = [
            "cognitiveservices.azure.com",
            "search.windows.net",
            "openai.azure.com",
            "core.windows.net",
            "azurewebsites.net"
        ]
        self.set("NO_PROXY", ",".join(no_proxy_domains))

    def _get_azure_token(self) -> str:
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID", ""),
                client_id=self.get("AZURE_CLIENT_ID", ""),
                client_secret=self.get("AZURE_CLIENT_SECRET", "")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token acquired successfully")
            return token.token
        except Exception as e:
            logger.error(f"Failed to get Azure token: {str(e)}")
            return ""

    def list_env_vars(self):
        for var in self.var_list:
            if var in {"AZURE_TOKEN", "AD_USER_PW", "AZURE_CLIENT_SECRET"}:
                logger.info(f"{var}: [HIDDEN]")
            else:
                logger.info(f"{var}: {os.environ.get(var, '')}")

###############################################################################
# Documents + Embeddings
###############################################################################
class MyDocument(BaseModel):
    text: str = ""
    embedding: List[float] = []
    metadata: Dict[str, Any] = {}
    id: str = ""

class EmbeddingClient:
    """
    Real embedding logic using AzureOpenAI embeddings with a token provider.
    """
    def __init__(self, azure_api_version: str = "2023-05-15", embeddings_model: str = "text-embedding-3-large"):
        self.azure_api_version = azure_api_version
        self.embeddings_model = embeddings_model
        self.direct_azure_client = self._get_direct_azure_client()

    def _get_direct_azure_client(self):
        from azure.identity import DefaultAzureCredential, get_bearer_token_provider
        token_provider = get_bearer_token_provider(
            DefaultAzureCredential(),
            "https://cognitiveservices.azure.com/.default"
        )
        return AzureOpenAI(
            api_version=self.azure_api_version,
            azure_ad_token_provider=token_provider
        )

    def generate_embeddings(self, doc: MyDocument) -> MyDocument:
        try:
            response = self.direct_azure_client.embeddings.create(
                model=self.embeddings_model,
                input=doc.text
            ).data[0].embedding
            doc.embedding = response
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings for doc {doc.id}: {str(e)}")
            return doc

###############################################################################
# KnowledgeBase: read CSV (encoding with chardet) + build graph
###############################################################################
class KnowledgeBase:
    def __init__(self, csv_path: str):
        """
        We'll auto-detect encoding with chardet, fallback to 'utf-8'.
        We'll store docs for Chroma ingestion and build a networkx graph.
        """
        self.csv_path = csv_path
        self.docs: List[LC_Document] = []
        self.graph = nx.MultiDiGraph()
        self._read_csv_and_build()

    def _read_csv_and_build(self):
        if not os.path.isfile(self.csv_path):
            raise FileNotFoundError(f"CSV not found: {self.csv_path}")

        # 1) chardet detect
        with open(self.csv_path, "rb") as f:
            rawdata = f.read(100000)
        import chardet
        result = chardet.detect(rawdata)
        detected_encoding = result["encoding"]
        logger.info(f"chardet detected encoding: {detected_encoding}")
        if not detected_encoding:
            logger.warning("chardet failed, fallback to utf-8")
            detected_encoding = "utf-8"

        # 2) read CSV with pandas
        import pandas as pd
        df = pd.read_csv(self.csv_path, encoding=detected_encoding, keep_default_na=False)
        if "name" not in df.columns or "definition" not in df.columns:
            raise ValueError("CSV must have 'name' and 'definition' columns")

        if "id" not in df.columns:
            df["id"] = [str(uuid.uuid4()) for _ in range(len(df))]

        # 3) build docs for ingestion in Chroma
        for _, row in df.iterrows():
            name_val = str(row["name"])
            def_val = str(row["definition"])
            id_val = str(row["id"])
            doc = LC_Document(
                page_content=def_val,
                metadata={"name": name_val, "id": id_val}
            )
            self.docs.append(doc)

        # 4) build a networkx graph
        for _, row in df.iterrows():
            subj = str(row["name"])
            obj = str(row["definition"])
            row_id = str(row["id"])

            # subject node
            self.graph.add_node(subj, node_id=row_id, node_type="subject")
            # object node
            self.graph.add_node(obj, node_type="definition")
            # edge
            self.graph.add_edge(subj, obj, label="is defined by")

        logger.info(f"Built graph with {self.graph.number_of_nodes()} nodes and {self.graph.number_of_edges()} edges")

###############################################################################
# AzureOpenAIEmbeddings => Chroma
###############################################################################
class AzureOpenAIEmbeddings(Embeddings):
    def __init__(self, azure_api_version="2023-05-15", embeddings_model="text-embedding-3-large"):
        self.client = EmbeddingClient(azure_api_version, embeddings_model)

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for txt in texts:
            doc = MyDocument(text=txt, id="doc-embed")
            updated_doc = self.client.generate_embeddings(doc)
            embeddings.append(updated_doc.embedding)
        return embeddings

    def embed_query(self, text: str) -> List[float]:
        doc = MyDocument(text=text, id="query-embed")
        updated_doc = self.client.generate_embeddings(doc)
        return updated_doc.embedding

###############################################################################
# AzureChatbot => normal chat + vector store + naive graph search
###############################################################################
class AzureChatbot:
    def __init__(self, config_file: str, creds_file: str, cert_file: str, csv_path: str):
        logger.info("Initializing AzureChatbot with chardet + networkx approach.")
        self.env = OSEnv(config_file, creds_file, cert_file)

        # 1) Chat model
        self._setup_chat_model()

        # 2) Normal conversation chain
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)

        # 3) Build knowledge base => docs + graph
        self.kb = KnowledgeBase(csv_path)
        self.graph = self.kb.graph

        # 4) Create vector store from docs
        self._setup_vectorstore()

        logger.info("AzureChatbot is ready.")

    def _setup_chat_model(self):
        try:
            model_name = self.env.get("MODEL_NAME", "gpt-4o-mini")
            temperature = float(self.env.get("MODEL_TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2023-05-15")
            azure_endpoint = self.env.get("AZURE_OPENAI_ENDPOINT", "")
            azure_ad_token = self.env.token

            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                openai_api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token=azure_ad_token
            )
            logger.info("Chat model initialized successfully.")
        except Exception as e:
            logger.error(f"Failed to initialize chat model: {str(e)}")
            raise

    def _setup_vectorstore(self):
        try:
            azure_embeddings_model = self.env.get("EMBEDDINGS_MODEL", "text-embedding-3-large")
            azure_api_version = self.env.get("EMBEDDINGS_API_VERSION", "2023-05-15")

            embedding = AzureOpenAIEmbeddings(
                azure_api_version=azure_api_version,
                embeddings_model=azure_embeddings_model
            )
            chroma_settings = Settings(anonymized_telemetry=False, persist_directory="chromadb-data")
            self.vs = Chroma.from_documents(
                documents=self.kb.docs,
                embedding=embedding,
                collection_name="kb_collection",
                client_settings=chroma_settings
            )
            logger.info("Chroma vector store created successfully.")
        except Exception as e:
            logger.error(f"Failed to set up vector store: {str(e)}")
            raise

    def chat(self, message: str) -> str:
        """Normal conversation with memory (no RAG)."""
        if not message.strip():
            return "Please provide a non-empty message."
        try:
            return self.conversation.predict(input=message)
        except Exception as e:
            logger.error(f"Error in chat: {str(e)}")
            return f"An error occurred: {str(e)}"

    def rag_query(self, query: str, k: int = 3) -> str:
        """
        Vector store search for top matches, returning confidence + rating.
        """
        try:
            results = self.vs.similarity_search_with_score(query, k=k)
            if not results:
                return "No relevant matches found."

            lines = []
            for idx, (doc, score) in enumerate(results, start=1):
                confidence = max(0.0, min(1.0, 1.0 - score))
                rating = "Green" if confidence >= 0.8 else ("Amber" if confidence >= 0.5 else "Red")
                reason = f"Confidence={confidence:.2f}, rating={rating}, definition={doc.page_content}"
                lines.append(
                    f"Match #{idx}\n"
                    f"Name: {doc.metadata.get('name','Unknown')}\n"
                    f"ID: {doc.metadata.get('id','No ID')}\n"
                    f"Confidence: {confidence:.2f}\n"
                    f"Rating: {rating}\n"
                    f"Reason: {reason}\n"
                )
            return "\n".join(lines)
        except Exception as e:
            logger.error(f"Error in rag_query: {str(e)}")
            return f"An error occurred: {str(e)}"

    def graph_search(self, query: str) -> str:
        """
        Naive substring search in the graph's nodes for 'query'.
        """
        results = []
        q_lower = query.lower()

        # check node data for a match
        for node, data in self.graph.nodes(data=True):
            if q_lower in str(node).lower():
                # gather info
                node_info = f"Node: {node}, node_type={data.get('node_type','')}, node_id={data.get('node_id','')}"
                results.append(node_info)

        if not results:
            return "No matching nodes found in the graph."

        return "\n".join(results)

    def list_env(self):
        self.env.list_env_vars()

###############################################################################
# main
###############################################################################
def main():
    try:
        # check for missing files
        required_files = {
            "config.env": CONFIG_PATH,
            "credentials.env": CREDS_PATH,
            "cacert.pem": CERT_PATH,
            "knowledgebase.csv": CSV_PATH
        }
        missing = []
        for name, path in required_files.items():
            if not os.path.exists(path):
                missing.append(name)
        if missing:
            print(f"Missing required files: {', '.join(missing)}")
            sys.exit(1)

        print("Initializing AzureChatbot with chardet + networkx approach...")
        chatbot = AzureChatbot(
            config_file=CONFIG_PATH,
            creds_file=CREDS_PATH,
            cert_file=CERT_PATH,
            csv_path=CSV_PATH
        )
        print("AzureChatbot is ready!")

        # user loop
        print("\nCommands:\n"
              "- 'quit'/'exit'/'bye': end\n"
              "- 'env': show environment\n"
              "- 'rag <query>': vector store search\n"
              "- 'graph <query>': naive graph search\n"
              "anything else => normal chat\n")

        while True:
            user_input = input("\nYou: ").strip()
            if user_input.lower() in ["quit", "exit", "bye"]:
                print("Goodbye!")
                break

            if user_input.lower() == "env":
                chatbot.list_env()
                continue

            if user_input.lower().startswith("rag "):
                query = user_input[4:].strip()
                result = chatbot.rag_query(query)
                print(f"\nRAG => {result}")
                continue

            if user_input.lower().startswith("graph "):
                query = user_input[6:].strip()
                result = chatbot.graph_search(query)
                print(f"\nGraph => {result}")
                continue

            # normal chat
            result = chatbot.chat(user_input)
            print(f"\nBot => {result}")

    except Exception as e:
        print(f"Unexpected error: {str(e)}")
        logger.exception("Unexpected error occurred")


if __name__ == "__main__":
    main()
