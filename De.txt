# main.py - Fixed to use REAL enhanced chatbot API

import sys
import os
import asyncio
import logging
from datetime import datetime
import uuid
from typing import Dict, Any

# Add current directory to Python path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

print("üöÄ Starting Deep Research Chatbot API with REAL functionality...")

# Basic FastAPI imports (required)
try:
    from fastapi import FastAPI, HTTPException
    from fastapi.middleware.cors import CORSMiddleware  
    from pydantic import BaseModel
    print("‚úÖ FastAPI imports successful")
except ImportError as e:
    print(f"‚ùå FastAPI import failed: {e}")
    print("Install with: pip install fastapi uvicorn[standard] pydantic")
    sys.exit(1)

# Try to import the enhanced chatbot
ENHANCED_CHATBOT_AVAILABLE = False
chatbot_interface = None

print("üîç Attempting to import enhanced chatbot...")

try:
    # Try importing the enhanced chatbot
    from enhanced_chatbot import EnhancedChatbotInterface
    ENHANCED_CHATBOT_AVAILABLE = True
    print("‚úÖ Enhanced chatbot imported successfully!")
except ImportError as e:
    print(f"‚ö†Ô∏è Enhanced chatbot import failed: {e}")
    print("Will attempt to continue with minimal dependencies...")
    
    # Try to import with error handling for specific missing packages
    missing_packages = []
    
    # Check what's missing
    try:
        import openai
    except ImportError:
        missing_packages.append("openai")
    
    try:
        import elasticsearch
    except ImportError:
        missing_packages.append("elasticsearch")
        
    try:
        import tiktoken
    except ImportError:
        missing_packages.append("tiktoken")
    
    try:
        from langchain_core.documents import Document
    except ImportError:
        missing_packages.append("langchain-core")
    
    if missing_packages:
        print(f"üì¶ Missing packages for full functionality: {', '.join(missing_packages)}")
        print("To enable full AI research:")
        print(f"pip install {' '.join(missing_packages)}")
        print("For now, running with limited functionality...")

# Create FastAPI app
app = FastAPI(
    title="Deep Research Chatbot API",
    description="Advanced AI-powered research assistant",
    version="1.0.0",
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Models
class QuickChatRequest(BaseModel):
    message: str
    session_id: str = None
    user_id: str = None

class QuickChatResponse(BaseModel):
    answer: str
    confidence: str
    approach: str
    session_id: str
    user_id: str
    timestamp: str
    metadata: Dict[str, Any] = {}

class DeepResearchRequest(BaseModel):
    topic: str
    session_id: str = None
    user_id: str = None

# Initialize the enhanced chatbot on startup
@app.on_event("startup")
async def startup_event():
    global chatbot_interface, ENHANCED_CHATBOT_AVAILABLE
    
    if ENHANCED_CHATBOT_AVAILABLE:
        try:
            print("ü§ñ Initializing Enhanced Chatbot Interface...")
            chatbot_interface = EnhancedChatbotInterface()
            
            # Initialize the chatbot - this may take a moment
            print("‚è≥ This may take 30-60 seconds for first-time setup...")
            
            # Run initialization in thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            success = await loop.run_in_executor(
                None, 
                lambda: asyncio.run(chatbot_interface.initialize())
            )
            
            if success:
                print("üéâ Enhanced Chatbot initialized successfully!")
                print("‚úÖ REAL AI research functionality is now available!")
            else:
                print("‚ùå Enhanced Chatbot initialization failed")
                chatbot_interface = None
                ENHANCED_CHATBOT_AVAILABLE = False
                
        except Exception as e:
            print(f"‚ùå Error initializing Enhanced Chatbot: {e}")
            print(f"Error details: {type(e).__name__}: {str(e)}")
            chatbot_interface = None
            ENHANCED_CHATBOT_AVAILABLE = False
    
    if not ENHANCED_CHATBOT_AVAILABLE:
        print("‚ö†Ô∏è Running in LIMITED MODE - install missing dependencies for full functionality")

# Mock storage for sessions
sessions = {}

@app.get("/")
async def root():
    return {
        "message": "Deep Research Chatbot API",
        "status": "running",
        "enhanced_chatbot": ENHANCED_CHATBOT_AVAILABLE,
        "mode": "FULL AI RESEARCH" if ENHANCED_CHATBOT_AVAILABLE else "LIMITED MODE",
        "timestamp": datetime.utcnow().isoformat()
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "enhanced_chatbot": ENHANCED_CHATBOT_AVAILABLE,
        "chatbot_ready": chatbot_interface is not None,
        "timestamp": datetime.utcnow().isoformat()
    }

@app.post("/api/v1/chat/quick", response_model=QuickChatResponse)
async def quick_chat(request: QuickChatRequest):
    print(f"üì® Received message: {request.message}")
    print(f"ü§ñ Enhanced chatbot available: {ENHANCED_CHATBOT_AVAILABLE}")
    print(f"üîó Chatbot interface ready: {chatbot_interface is not None}")
    
    try:
        # Handle session initialization
        if request.message == "__session_init__":
            session_id = str(uuid.uuid4())
            user_id = request.user_id or f"user_{uuid.uuid4().hex[:8]}"
            
            sessions[session_id] = {
                "user_id": user_id,
                "created_at": datetime.utcnow().isoformat(),
                "messages": []
            }
            
            return QuickChatResponse(
                answer="Session initialized - Enhanced AI research ready!" if ENHANCED_CHATBOT_AVAILABLE else "Session initialized - Limited mode active",
                confidence="high",
                approach="session_init",
                session_id=session_id,
                user_id=user_id,
                timestamp=datetime.utcnow().isoformat(),
                metadata={"enhanced_mode": ENHANCED_CHATBOT_AVAILABLE}
            )
        
        # Get or create session
        session_id = request.session_id or str(uuid.uuid4())
        user_id = request.user_id or f"user_{uuid.uuid4().hex[:8]}"
        
        # USE REAL ENHANCED CHATBOT IF AVAILABLE
        if ENHANCED_CHATBOT_AVAILABLE and chatbot_interface:
            print("üß† Using REAL Enhanced Chatbot...")
            
            try:
                # Run the actual chatbot in thread pool
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: asyncio.run(
                        chatbot_interface.ask_question(
                            request.message,
                            user_id=user_id,
                            thread_id=session_id
                        )
                    )
                )
                
                print(f"‚úÖ Real chatbot response received")
                print(f"Confidence: {result.get('confidence')}, Approach: {result.get('approach')}")
                
                return QuickChatResponse(
                    answer=result.get("answer", "No response generated"),
                    confidence=result.get("confidence", "medium"),
                    approach=f"REAL_AI_{result.get('approach', 'enhanced')}",
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=datetime.utcnow().isoformat(),
                    metadata={
                        **result.get("metadata", {}),
                        "enhanced_mode": True,
                        "real_ai": True
                    }
                )
                
            except Exception as e:
                print(f"‚ùå Error with real chatbot: {e}")
                # Fall back to error response
                return QuickChatResponse(
                    answer=f"I encountered a technical issue processing your question: '{request.message}'. The AI research system is experiencing difficulties. Please try again.",
                    confidence="low", 
                    approach="error_fallback",
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=datetime.utcnow().isoformat(),
                    metadata={"error": str(e), "enhanced_mode": True}
                )
        
        # FALLBACK MODE - Limited functionality
        else:
            print("‚ö†Ô∏è Using limited mode response...")
            
            return QuickChatResponse(
                answer=f"[LIMITED MODE] Your question '{request.message}' was received. To enable full AI research capabilities, please install missing dependencies. Currently running with basic functionality only.",
                confidence="low",
                approach="limited_mode",
                session_id=session_id,
                user_id=user_id,
                timestamp=datetime.utcnow().isoformat(),
                metadata={"enhanced_mode": False, "reason": "Missing dependencies"}
            )
            
    except Exception as e:
        print(f"‚ùå Error in quick_chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/research/deep")
async def deep_research(request: DeepResearchRequest):
    print(f"üî¨ Received research request: {request.topic}")
    print(f"ü§ñ Enhanced chatbot available: {ENHANCED_CHATBOT_AVAILABLE}")
    
    try:
        session_id = request.session_id or str(uuid.uuid4())
        user_id = request.user_id or f"user_{uuid.uuid4().hex[:8]}"
        
        # USE REAL ENHANCED CHATBOT FOR RESEARCH
        if ENHANCED_CHATBOT_AVAILABLE and chatbot_interface:
            print("üî¨ Starting REAL deep research...")
            
            try:
                # Run the actual deep research
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: asyncio.run(
                        chatbot_interface.conduct_deep_research(
                            request.topic,
                            user_id=user_id
                        )
                    )
                )
                
                print(f"‚úÖ Real deep research completed!")
                print(f"Confidence: {result.get('overall_confidence')}")
                
                return {
                    "final_synthesis": result.get("final_synthesis", "Research completed"),
                    "overall_confidence": result.get("overall_confidence", 0.8),
                    "session_id": session_id,
                    "user_id": user_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "agents_used": result.get("agents_used", []),
                    "iterations_completed": result.get("iterations_completed", 0),
                    "processing_time": "real_ai_research",
                    "metadata": {
                        **result.get("metadata", {}),
                        "real_ai": True,
                        "enhanced_mode": True
                    }
                }
                
            except Exception as e:
                print(f"‚ùå Error in real deep research: {e}")
                return {
                    "final_synthesis": f"Deep research on '{request.topic}' encountered technical difficulties. Error: {str(e)}",
                    "overall_confidence": 0.1,
                    "session_id": session_id,
                    "user_id": user_id,
                    "timestamp": datetime.utcnow().isoformat(),
                    "agents_used": [],
                    "iterations_completed": 0,
                    "processing_time": "error",
                    "metadata": {"error": str(e), "enhanced_mode": True}
                }
        
        # FALLBACK - Limited mode
        else:
            print("‚ö†Ô∏è Research request in limited mode...")
            return {
                "final_synthesis": f"[LIMITED MODE] Research topic: '{request.topic}'\n\nThe full AI research system is not available. To enable comprehensive multi-agent research, please install the required dependencies (openai, elasticsearch, tiktoken, langchain-core).",
                "overall_confidence": 0.2,
                "session_id": session_id,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat(),
                "agents_used": [],
                "iterations_completed": 0,
                "processing_time": "limited_mode",
                "metadata": {"enhanced_mode": False}
            }
            
    except Exception as e:
        print(f"‚ùå Error in deep_research: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/knowledge-graph/generate")
async def generate_knowledge_graph(request: dict):
    if ENHANCED_CHATBOT_AVAILABLE:
        return {
            "nodes": [],
            "edges": [],
            "metadata": {"message": "Knowledge graph generation available but not yet implemented in this endpoint"}
        }
    else:
        return {
            "nodes": [],
            "edges": [],
            "metadata": {"message": "Knowledge graph requires enhanced chatbot dependencies"}
        }

# Fixed uvicorn run
if __name__ == "__main__":
    print("üöÄ Starting server...")
    
    try:
        import uvicorn
        uvicorn.run(
            "main:app",  # Import string format
            host="0.0.0.0", 
            port=8000, 
            reload=True,
            log_level="info"
        )
    except Exception as e:
        print(f"‚ùå Failed to start server: {e}")
        sys.exit(1)
