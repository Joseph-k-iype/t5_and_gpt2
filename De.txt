#!/usr/bin/env python
"""
Business Terms Import Script

This script imports business terms from a CSV file into the vector database (ChromaDB).
It expects a CSV with columns like 'id' (optional), 'PBT_NAME', 'PBT_DESCRIPTION', and 'CDM'.
Embeddings are generated using the configured text-embedding-3-large model.
"""

import os
import sys
import logging
import argparse
import time
from typing import Optional, Tuple

# Add parent directory to path to import app modules
# This ensures that 'app.core' etc. can be imported
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

try:
    from app.core.business_terms import BusinessTermManager
    from app.config.environment import get_os_env # To initialize environment settings
    from app.config.settings import get_vector_store # To ensure vector store is initialized
except ImportError as e:
    print(f"Error importing application modules: {e}")
    print("Please ensure the script is run from the project root or the PYTHONPATH is set correctly.")
    sys.exit(1)

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [%(name)s:%(lineno)d] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

def detect_file_encoding(file_path: str) -> str:
    """
    Detect the encoding of a file using chardet.
    Falls back to utf-8 if chardet is not available or detection fails.
    """
    try:
        import chardet
        with open(file_path, 'rb') as f:
            sample = f.read(10000)  # Read a sample for detection
            result = chardet.detect(sample)
            encoding = result['encoding']
            confidence = result['confidence']
            if encoding and confidence and confidence > 0.7:
                logger.info(f"Detected encoding: {encoding} with confidence {confidence:.2f}")
                return encoding
            else:
                logger.warning(f"Low confidence in detected encoding ({encoding}, {confidence:.2f}). Using UTF-8.")
                return 'utf-8'
    except ImportError:
        logger.warning("chardet library not found. Assuming UTF-8 encoding. For better auto-detection, run: pip install chardet")
        return 'utf-8'
    except Exception as e:
        logger.error(f"Error detecting encoding: {e}. Assuming UTF-8.")
        return 'utf-8'

def main():
    parser = argparse.ArgumentParser(
        description="Import Preferred Business Terms (PBTs) from a CSV file into ChromaDB.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument("csv_file", help="Path to the CSV file containing PBTs. Expected headers: id (optional), PBT_NAME, PBT_DESCRIPTION, CDM (optional).")
    parser.add_argument("--batch-size", type=int, default=100, help="Number of terms to process and embed in each batch.")
    parser.add_argument("--encoding", type=str, default="auto", help="Encoding of the CSV file (e.g., 'utf-8', 'latin1'). Use 'auto' for auto-detection.")
    
    # Arguments to override environment settings if needed for the script
    parser.add_argument("--chroma-dir", help="Override ChromaDB persistent directory (CHROMA_PERSIST_DIR).")
    parser.add_argument("--chroma-collection", help="Override ChromaDB collection name (CHROMA_COLLECTION).")
    parser.add_argument("--embedding-model", help="Override OpenAI embedding model (EMBEDDING_MODEL), e.g., 'text-embedding-3-large'.")

    args = parser.parse_args()

    # Override environment variables if command-line arguments are provided
    if args.chroma_dir:
        os.environ["CHROMA_PERSIST_DIR"] = args.chroma_dir
        logger.info(f"Using ChromaDB directory (from arg): {args.chroma_dir}")
    if args.chroma_collection:
        os.environ["CHROMA_COLLECTION"] = args.chroma_collection
        logger.info(f"Using ChromaDB collection (from arg): {args.chroma_collection}")
    if args.embedding_model:
        os.environ["EMBEDDING_MODEL"] = args.embedding_model
        logger.info(f"Using embedding model (from arg): {args.embedding_model}")
    else:
        # Ensure text-embedding-3-large is default if not specified
        os.environ.setdefault("EMBEDDING_MODEL", "text-embedding-3-large")
        logger.info(f"Using embedding model (default/env): {os.environ['EMBEDDING_MODEL']}")


    # Initialize environment (reads .env files, sets up proxy if configured)
    # This is important for the EmbeddingClient to get Azure credentials etc.
    try:
        get_os_env() 
    except Exception as e:
        logger.error(f"Failed to initialize OS environment: {e}. Ensure .env files are correctly set up if needed.")
        # Continue, but embedding might fail if it relies on env vars for auth.

    # Determine encoding
    file_encoding = args.encoding
    if args.encoding.lower() == 'auto':
        logger.info("Attempting to auto-detect CSV file encoding...")
        file_encoding = detect_file_encoding(args.csv_file)
    
    logger.info(f"Using CSV file: {args.csv_file}")
    logger.info(f"Processing with encoding: {file_encoding}")
    logger.info(f"Batch size: {args.batch_size}")

    try:
        # Initialize BusinessTermManager. This will also initialize the
        # EmbeddingClient (using EMBEDDING_MODEL from env) and the VectorStore (ChromaDB).
        logger.info("Initializing Business Term Manager...")
        term_manager = BusinessTermManager()
        
        initial_term_count = term_manager.get_term_count()
        logger.info(f"Initial number of terms in ChromaDB collection '{term_manager.vector_store.collection_name}': {initial_term_count}") # type: ignore

        logger.info("Starting CSV import process...")
        start_time = time.time()
        
        added_count = term_manager.import_terms_from_csv(
            csv_path=args.csv_file,
            encoding=file_encoding,
            batch_size=args.batch_size
        )
        
        total_time = time.time() - start_time
        final_term_count = term_manager.get_term_count()
        
        logger.info(f"Import completed in {total_time:.2f} seconds.")
        logger.info(f"Terms added/updated during this import: {added_count}")
        logger.info(f"Total terms now in ChromaDB collection '{term_manager.vector_store.collection_name}': {final_term_count}") # type: ignore
        
        if added_count > 0:
            logger.info("Import successful.")
        elif initial_term_count == final_term_count and initial_term_count > 0 :
             logger.info("No new terms were added. Existing terms may have been updated if their content changed.")
        else:
            logger.info("No terms were added or updated. Check CSV content and logs for details.")

    except FileNotFoundError:
        logger.error(f"Error: The CSV file was not found at '{args.csv_file}'. Please check the path.")
        sys.exit(1)
    except ValueError as ve:
        logger.error(f"Error during import: {ve}")
        logger.error("This might be due to missing columns in the CSV or an empty CSV file. "
                     "Expected headers: id (optional), PBT_NAME (or NAME), PBT_DESCRIPTION (or DESCRIPTION), CDM (optional).")
        sys.exit(1)
    except Exception as e:
        logger.error(f"An unexpected error occurred during the import process: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    main()
