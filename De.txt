import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Union, Optional
import io
import numpy as np
from datetime import datetime

# Set page configuration
st.set_page_config(
    page_title="Excel Analyzer",
    page_icon="ðŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply custom CSS
st.markdown("""
    <style>
    .stButton>button {
        width: 100%;
    }
    .reportview-container {
        background: #FAFAFA;
    }
    .main {
        padding: 2rem;
    }
    </style>
""", unsafe_allow_html=True)

def load_excel_file(uploaded_file) -> Optional[pd.DataFrame]:
    """
    Load an Excel file and return as DataFrame with error handling and type conversion.
    """
    try:
        # Read Excel file
        df = pd.read_excel(uploaded_file)
        
        # Process each column
        for col in df.columns:
            # Handle datetime columns
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = pd.to_datetime(df[col])
            # Try to convert numeric strings to numbers
            elif df[col].dtype == 'object':
                try:
                    numeric_conversion = pd.to_numeric(df[col], errors='coerce')
                    # Only convert if at least 80% of values are numeric
                    if numeric_conversion.notna().mean() >= 0.8:
                        df[col] = numeric_conversion
                except:
                    pass
        
        return df
    except Exception as e:
        st.error(f"Error loading {uploaded_file.name}: {str(e)}")
        return None

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    Clean the DataFrame by handling common issues.
    """
    # Remove completely empty rows and columns
    df = df.dropna(how='all').dropna(axis=1, how='all')
    
    # Strip whitespace from string columns
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].str.strip() if df[col].dtype == 'object' else df[col]
    
    return df

def merge_dataframes(dataframes: List[pd.DataFrame], keys: List[str], how: str = 'left') -> pd.DataFrame:
    """
    Merge multiple DataFrames based on selected keys.
    """
    try:
        if not dataframes:
            return pd.DataFrame()
        
        # Start with the first DataFrame
        result = dataframes[0]
        
        # Merge with subsequent DataFrames
        for i, df in enumerate(dataframes[1:], 1):
            result = result.merge(df, on=keys, how=how, suffixes=(f'_{i-1}', f'_{i}'))
            
            # Log merge results
            st.write(f"Merge {i} complete - Shape: {result.shape}")
        
        return result
    except Exception as e:
        st.error(f"Error in merge operation: {str(e)}")
        return pd.DataFrame()

def calculate_aggregation(df: pd.DataFrame, 
                       group_cols: List[str], 
                       agg_cols: List[str], 
                       agg_funcs: List[str],
                       filters: Dict = None) -> pd.DataFrame:
    """
    Calculate aggregations with proper handling of different data types and column names.
    """
    try:
        # Apply filters
        filtered_df = df.copy()
        if filters:
            for col, values in filters.items():
                if values:
                    # Convert column and filter values to same type
                    col_type = filtered_df[col].dtype
                    if pd.api.types.is_numeric_dtype(col_type):
                        values = [pd.to_numeric(v) if pd.notna(v) else v for v in values]
                    elif pd.api.types.is_datetime64_any_dtype(col_type):
                        values = [pd.to_datetime(v) if pd.notna(v) else v for v in values]
                    filtered_df = filtered_df[filtered_df[col].isin(values)]

        # Initialize list to store individual aggregations
        agg_results = []

        # Process each column and aggregation separately
        for col in agg_cols:
            # Determine column type and appropriate aggregations
            is_numeric = pd.api.types.is_numeric_dtype(filtered_df[col].dtype)
            is_datetime = pd.api.types.is_datetime64_any_dtype(filtered_df[col].dtype)
            
            for func in agg_funcs:
                # Handle different aggregation types based on data type
                if func in ['count', 'distinct_count']:
                    # These operations work on any data type
                    if func == 'distinct_count':
                        agg_name = f"{col} (Unique Count)"
                        agg_func = lambda x: len(x.unique())
                    else:
                        agg_name = f"{col} (Count)"
                        agg_func = 'count'
                elif is_numeric and func in ['sum', 'mean', 'max', 'min']:
                    # Numeric operations only for numeric data
                    agg_name = f"{col} ({func.capitalize()})"
                    agg_func = func
                elif is_datetime and func in ['max', 'min']:
                    # Date operations for datetime data
                    agg_name = f"{col} ({func.capitalize()})"
                    agg_func = func
                else:
                    # Skip invalid combinations
                    continue
                
                # Calculate aggregation
                try:
                    agg = filtered_df.groupby(group_cols)[col].agg(agg_func)
                    agg = pd.DataFrame(agg)
                    agg.columns = [agg_name]
                    agg_results.append(agg)
                except Exception as e:
                    st.warning(f"Couldn't calculate {func} for {col}: {str(e)}")
                    continue

        if not agg_results:
            return pd.DataFrame()

        # Combine all aggregations
        result = pd.concat(agg_results, axis=1)

        # Add total row
        try:
            totals = pd.DataFrame(index=['Total'])
            for col in result.columns:
                if 'Count' in col:
                    # Sum for count columns
                    totals[col] = result[col].sum()
                elif 'Sum' in col or 'Mean' in col:
                    # Sum for numeric columns
                    totals[col] = result[col].sum()
                elif 'Max' in col:
                    # Max for max columns
                    totals[col] = result[col].max()
                elif 'Min' in col:
                    # Min for min columns
                    totals[col] = result[col].min()
            result = pd.concat([result, totals])
        except Exception as e:
            st.warning(f"Couldn't calculate totals: {str(e)}")

        return result.round(2)

    except Exception as e:
        st.error(f"Error in aggregation calculation: {str(e)}")
        return pd.DataFrame()

def create_visualization(df: pd.DataFrame, 
                       chart_type: str, 
                       x_col: str, 
                       y_col: str) -> Optional[go.Figure]:
    """
    Create a visualization based on the data and selected chart type.
    """
    try:
        # Remove total row for visualization
        plot_df = df[df.index != 'Total'].copy()
        
        if chart_type == 'Bar':
            fig = px.bar(plot_df, x=plot_df.index, y=y_col, 
                        title=f'{y_col} by {x_col}')
        elif chart_type == 'Line':
            fig = px.line(plot_df, x=plot_df.index, y=y_col,
                         title=f'{y_col} over {x_col}')
        elif chart_type == 'Scatter':
            fig = px.scatter(plot_df, x=plot_df.index, y=y_col,
                           title=f'{y_col} vs {x_col}')
        else:
            return None

        # Update layout
        fig.update_layout(
            xaxis_title=x_col,
            yaxis_title=y_col,
            showlegend=True,
            template='plotly_white'
        )

        return fig
    except Exception as e:
        st.error(f"Error creating visualization: {str(e)}")
        return None

def save_to_excel(result_df: pd.DataFrame, 
                 merged_df: pd.DataFrame, 
                 filename: str = "analysis_results.xlsx") -> Optional[bytes]:
    """
    Save results to Excel file with proper formatting.
    """
    try:
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # Write results sheet
            result_df.to_excel(writer, sheet_name='Analysis Results')
            
            # Write merged data sheet
            merged_df.to_excel(writer, sheet_name='Merged Data', index=False)
            
            # Get workbook and add formats
            workbook = writer.book
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#D3D3D3',
                'border': 1
            })
            
            # Format Analysis Results sheet
            worksheet = writer.sheets['Analysis Results']
            for col_num, value in enumerate(result_df.columns.values):
                worksheet.write(0, col_num + 1, value, header_format)
            
            # Format Merged Data sheet
            worksheet = writer.sheets['Merged Data']
            for col_num, value in enumerate(merged_df.columns.values):
                worksheet.write(0, col_num, value, header_format)
        
        return output.getvalue()
    except Exception as e:
        st.error(f"Error saving to Excel: {str(e)}")
        return None

def main():
    st.title("ðŸ“Š Excel File Analyzer and Dashboard")
    st.write("Upload multiple Excel files, merge them, and create dynamic analyses")

    # File upload section
    with st.sidebar:
        st.header("ðŸ“ File Upload")
        uploaded_files = st.file_uploader("Choose Excel files",
                                        type=['xlsx', 'xls'],
                                        accept_multiple_files=True,
                                        help="Upload one or more Excel files")

    if not uploaded_files:
        st.info("ðŸ‘† Please upload Excel files using the sidebar to begin.")
        return

    # Load and process files
    st.header("ðŸ“‘ Uploaded Files")
    dataframes = []
    
    # Create columns for file display
    cols = st.columns(len(uploaded_files))
    for idx, file in enumerate(uploaded_files):
        with cols[idx]:
            st.subheader(f"File {idx + 1}")
            df = load_excel_file(file)
            if df is not None:
                df = clean_dataframe(df)
                dataframes.append(df)
                st.success(f"âœ“ {file.name}")
                st.dataframe(df.head(3), height=150)
                st.write(f"Shape: {df.shape}")
            else:
                st.error(f"Ã— Failed to load {file.name}")

    if not dataframes:
        st.error("âŒ No valid data loaded. Please check your files.")
        return

    # Get common columns
    common_columns = list(set.intersection(*[set(df.columns) for df in dataframes]))
    if not common_columns:
        st.error("âŒ No common columns found between files!")
        for idx, df in enumerate(dataframes):
            st.write(f"File {idx + 1} columns: {list(df.columns)}")
        return

    # Merge settings
    st.header("ðŸ”„ Merge Settings")
    col1, col2 = st.columns(2)
    
    with col1:
        merge_keys = st.multiselect("Select merge columns:",
                                  common_columns,
                                  help="Select columns to use as merge keys")
    
    with col2:
        merge_type = st.selectbox("Select merge type:",
                                ['left', 'right', 'inner', 'outer'],
                                help="Choose how to merge the files")

    if not merge_keys:
        st.warning("âš ï¸ Please select at least one column to merge on.")
        return

    # Perform merge
    merged_df = merge_dataframes(dataframes, merge_keys, merge_type)
    if merged_df.empty:
        st.error("âŒ Merge resulted in empty data. Please check your merge settings.")
        return

    st.success("âœ… Files merged successfully!")
    
    # Show merged data preview
    with st.expander("ðŸ‘€ Preview Merged Data"):
        st.dataframe(merged_df.head(), height=200)
        st.write(f"Total rows: {len(merged_df)}, Total columns: {len(merged_df.columns)}")

    # Analysis section
    st.header("ðŸ“Š Create Analysis")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        group_cols = st.multiselect("Select Grouping Columns:",
                                  merged_df.columns,
                                  help="Select columns to group by")
    
    with col2:
        agg_cols = st.multiselect("Select Columns to Analyze:",
                                merged_df.columns,
                                help="Select columns to analyze")
    
    with col3:
        agg_functions = st.multiselect("Select Analysis Functions:",
                                     ['sum', 'mean', 'count', 'distinct_count', 'max', 'min'],
                                     help="Select functions to apply")

    # Filters
    if group_cols:
        st.subheader("ðŸ” Filters")
        filter_containers = st.columns(min(len(group_cols), 4))
        filters = {}
        
        for idx, col in enumerate(group_cols):
            with filter_containers[idx % 4]:
                unique_values = sorted(merged_df[col].unique())
                selected_values = st.multiselect(f"Filter {col}:",
                                               unique_values,
                                               help=f"Select values to include for {col}")
                if selected_values:
                    filters[col] = selected_values

        # Calculate results
        if agg_cols and agg_functions:
            result_df = calculate_aggregation(merged_df,
                                          group_cols,
                                          agg_cols,
                                          agg_functions,
                                          filters)
            
            if not result_df.empty:
                st.header("ðŸ“ˆ Analysis Results")
                st.dataframe(result_df, height=400)
                
                # Visualizations
                if len(result_df) > 1:
                    st.subheader("ðŸ“Š Visualization")
                    
                    viz_col1, viz_col2 = st.columns(2)
                    
                    with viz_col1:
                        chart_type = st.selectbox("Chart Type:",
                                                ['Bar', 'Line', 'Scatter'])
                    
                    with viz_col2:
                        if len(result_df.columns) > 1:
                            y_column = st.selectbox("Value to Plot:",
                                                  result_df.columns)
                        else:
                            y_column = result_df.columns[0]
                    
                    fig = create_visualization(result_df,
                                            chart_type,
                                            group_cols[0],
                                            y_column)
                    
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)

                # Download results
                st.subheader("ðŸ’¾ Download Results")
                excel_data = save_to_excel(result_df, merged_df)
                
                if excel_data:
                    st.download_button(
                        label="ðŸ“¥ Download Excel file",
                        data=excel_data,
                        file_name=f"analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )

if __name__ == "__main__":
    main()
