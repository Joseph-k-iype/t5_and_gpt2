"""
ISO/IEC 11179-1:2023 Data Enrichment System
Multi-Agent Architecture with LangGraph ReAct Agents
Uses LangChain InMemoryVectorStore and OpenAI Embeddings
"""

import json
import pandas as pd
from typing import List, Dict, Any, Annotated, Sequence, TypedDict
from openai import OpenAI
import operator

# LangChain and LangGraph imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_core.embeddings.base import Embeddings
from langchain_openai import ChatOpenAI

from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import create_react_agent, ToolNode
from langgraph.checkpoint.memory import MemorySaver

# Global API Configuration
OPENAI_API_KEY = "your-api-key-here"
OPENAI_BASE_URL = "https://api.openai.com/v1"
O3_MINI_MODEL = "o3-mini"
EMBEDDING_MODEL = "text-embedding-3-large"


# ==========================
# Custom OpenAI Embeddings Class
# ==========================

class DirectOpenAIEmbeddings(Embeddings):
    """Custom embeddings using OpenAI API directly (no tiktoken)"""
    
    def __init__(self, api_key: str, model: str = EMBEDDING_MODEL):
        self.client = OpenAI(api_key=api_key, base_url=OPENAI_BASE_URL)
        self.model = model
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed a list of documents"""
        embeddings = []
        for text in texts:
            response = self.client.embeddings.create(
                model=self.model,
                input=text
            )
            embeddings.append(response.data[0].embedding)
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        """Embed a single query"""
        response = self.client.embeddings.create(
            model=self.model,
            input=text
        )
        return response.data[0].embedding


# ==========================
# ISO/IEC 11179-1:2023 Standards
# ==========================

ISO_11179_FRAMEWORK = """
ISO/IEC 11179-1:2023 Metadata Registry Framework

Core Principles:
1. Data Element: A unit of data for which definition, identification, representation, 
   and permissible values are specified by means of a set of attributes.

2. Object Class: A set of ideas, abstractions, or things in the real world that can be 
   identified with explicit boundaries and meaning (e.g., Person, Product, Transaction).

3. Property: A characteristic common to all members of an object class (e.g., name, date, amount).

4. Representation: The form in which the data is presented (e.g., Text, Code, Date, Number).

Naming Convention (ISO/IEC 11179-5):
Format: [Object Class] [Qualifier*] [Property] [Representation]
- Use complete words, no abbreviations
- Singular nouns for object classes
- Proper spacing (no camelCase or snake_case)
- Business-friendly terminology

Examples:
- Customer Birth Date
- Product Available Quantity Number
- Transaction Authorization Status Code

Definition Guidelines (ISO/IEC 11179-4):
- State WHAT the concept is (not what it is NOT)
- Be precise, unambiguous, and complete
- Do not repeat the name in the definition
- Include context and valid values
- Use complete, grammatically correct sentences
"""


# ==========================
# State Definition
# ==========================

class AgentState(TypedDict):
    """State shared across all agents in the workflow"""
    messages: Annotated[Sequence[BaseMessage], operator.add]
    current_field: Dict[str, Any]
    enriched_name: str
    enriched_description: str
    mapped_object: str
    mapped_property: str
    enrichment_rationale: str
    mapping_rationale: str
    next_agent: str


# ==========================
# Tool Definitions
# ==========================

# Global vector store (initialized later)
vector_store: InMemoryVectorStore = None


@tool
def enrich_field_name(field_name: str, application_context: str) -> str:
    """
    Enrich a field name according to ISO/IEC 11179-1:2023 naming standards.
    
    Args:
        field_name: Original field name to enrich
        application_context: Context about the application and field usage
    
    Returns:
        JSON string with enriched name and reasoning
    """
    # This tool will be called by the naming agent
    # The actual enrichment logic is in the agent's prompt
    return json.dumps({
        "status": "ready_for_enrichment",
        "field": field_name,
        "context": application_context
    })


@tool
def generate_iso_definition(enriched_name: str, context: str) -> str:
    """
    Generate an ISO/IEC 11179-1:2023 compliant definition.
    
    Args:
        enriched_name: The ISO 11179 compliant field name
        context: Application and business context
    
    Returns:
        JSON string with definition and reasoning
    """
    return json.dumps({
        "status": "ready_for_definition",
        "enriched_name": enriched_name,
        "context": context
    })


@tool
def search_similar_mappings(field_description: str, top_k: int = 5) -> str:
    """
    Search for similar Object-Property mappings using vector similarity.
    
    Args:
        field_description: Description of the field to map
        top_k: Number of similar mappings to return
    
    Returns:
        JSON string with similar mappings and scores
    """
    if vector_store is None:
        return json.dumps({"error": "Vector store not initialized"})
    
    # Search for similar documents
    results = vector_store.similarity_search_with_score(field_description, k=top_k)
    
    mappings = []
    for doc, score in results:
        mappings.append({
            "object": doc.metadata.get("object_name"),
            "property": doc.metadata.get("property_name"),
            "similarity": float(score)
        })
    
    return json.dumps({
        "similar_mappings": mappings,
        "query": field_description
    })


@tool
def validate_enrichment(
    enriched_name: str,
    description: str,
    mapped_object: str,
    mapped_property: str
) -> str:
    """
    Validate the enrichment against ISO/IEC 11179-1:2023 standards.
    
    Args:
        enriched_name: The enriched field name
        description: The field definition
        mapped_object: Selected object name
        mapped_property: Selected property name
    
    Returns:
        JSON string with validation results
    """
    return json.dumps({
        "ready_for_validation": True,
        "enriched_name": enriched_name,
        "description": description,
        "mapping": f"{mapped_object} -> {mapped_property}"
    })


# ==========================
# Create Specialized ReAct Agents
# ==========================

def create_naming_agent(llm: ChatOpenAI) -> Any:
    """Create the naming expert ReAct agent"""
    
    system_prompt = f"""You are an ISO/IEC 11179-1:2023 Naming Standards Expert.

{ISO_11179_FRAMEWORK}

Your task is to enrich field names according to ISO/IEC 11179-1:2023 standards.

Process:
1. Analyze the original field name and application context
2. Identify the Object Class (business entity)
3. Identify the Property (characteristic)
4. Identify any Qualifiers (specificity)
5. Identify the Representation (data type)
6. Construct the ISO-compliant name with proper spacing

Always provide:
- The enriched name
- Step-by-step reasoning
- ISO compliance justification

Return your response as a valid JSON object:
{{
    "enriched_name": "Complete ISO 11179 name",
    "object_class": "The business entity",
    "property": "The characteristic",
    "qualifiers": ["Any qualifiers"],
    "representation": "The data type",
    "reasoning": "Your detailed analysis"
}}"""
    
    tools = [enrich_field_name]
    
    return create_react_agent(
        llm,
        tools=tools,
        state_modifier=system_prompt
    )


def create_description_agent(llm: ChatOpenAI) -> Any:
    """Create the description expert ReAct agent"""
    
    system_prompt = f"""You are an ISO/IEC 11179-1:2023 Definition Standards Expert.

{ISO_11179_FRAMEWORK}

Your task is to create precise ISO/IEC 11179-1:2023 compliant definitions.

Process:
1. Analyze the enriched name and context
2. Define WHAT the concept is (not what it's NOT)
3. Include business purpose and usage
4. Specify constraints or valid values
5. Use complete, grammatically correct sentences

Definition must:
- NOT repeat the name
- Be precise and unambiguous
- Include business context
- Specify representation format

Return your response as a valid JSON object:
{{
    "definition": "The ISO 11179 compliant definition",
    "reasoning": "Your analysis of how this meets standards"
}}"""
    
    tools = [generate_iso_definition]
    
    return create_react_agent(
        llm,
        tools=tools,
        state_modifier=system_prompt
    )


def create_mapping_agent(llm: ChatOpenAI) -> Any:
    """Create the semantic mapping expert ReAct agent"""
    
    system_prompt = """You are a Semantic Data Mapping Expert.

Your task is to map enriched fields to the best Object-Property combination using semantic similarity.

Process:
1. Use the search_similar_mappings tool to find candidates
2. Analyze the enriched name and description
3. Compare with similar mappings
4. Select the most appropriate Object and Property
5. Justify your selection with confidence level

Return your response as a valid JSON object:
{
    "selected_object": "The chosen object name",
    "selected_property": "The chosen property name",
    "confidence": "high/medium/low",
    "reasoning": "Why this mapping is correct"
}"""
    
    tools = [search_similar_mappings]
    
    return create_react_agent(
        llm,
        tools=tools,
        state_modifier=system_prompt
    )


def create_validation_agent(llm: ChatOpenAI) -> Any:
    """Create the validation expert ReAct agent"""
    
    system_prompt = f"""You are an ISO/IEC 11179-1:2023 Quality Validation Expert.

{ISO_11179_FRAMEWORK}

Your task is to validate the complete enrichment against ISO/IEC 11179-1:2023 standards.

Check:
1. Name follows ISO 11179 format
2. Definition is clear and compliant
3. Mapping is logical and semantically correct
4. Overall quality meets standards

Return your response as a valid JSON object:
{{
    "valid": true/false,
    "iso_compliant": true/false,
    "issues": ["list any issues"],
    "overall_assessment": "Brief summary"
}}"""
    
    tools = [validate_enrichment]
    
    return create_react_agent(
        llm,
        tools=tools,
        state_modifier=system_prompt
    )


# ==========================
# Supervisor Agent
# ==========================

def create_supervisor_chain(llm: ChatOpenAI):
    """Create the supervisor agent that routes to specialized agents"""
    
    agents = ["naming_agent", "description_agent", "mapping_agent", "validation_agent", "FINISH"]
    
    system_prompt = f"""You are a supervisor managing a team of specialized agents for ISO/IEC 11179-1:2023 data enrichment.

Available agents:
- naming_agent: Enriches field names to ISO 11179 standards
- description_agent: Creates ISO 11179 compliant definitions  
- mapping_agent: Maps fields to Object-Property pairs
- validation_agent: Validates the complete enrichment
- FINISH: Complete the workflow

Workflow:
1. Start with naming_agent to enrich the field name
2. Then description_agent to create the definition
3. Then mapping_agent to find Object-Property mapping
4. Then validation_agent to ensure quality
5. FINISH when all steps are complete

Based on the current state and conversation, select the next agent.
Respond with only the agent name."""
    
    function_def = {
        "name": "route",
        "description": "Select the next agent",
        "parameters": {
            "type": "object",
            "properties": {
                "next": {
                    "type": "string",
                    "enum": agents,
                    "description": "Next agent to call"
                }
            },
            "required": ["next"]
        }
    }
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        MessagesPlaceholder(variable_name="messages"),
        ("human", "Based on the above, who should act next? Select: {agents}")
    ])
    
    chain = prompt | llm.bind_functions([function_def], function_call="route")
    
    return chain


# ==========================
# LangGraph Workflow
# ==========================

def create_workflow(llm: ChatOpenAI) -> StateGraph:
    """Create the complete LangGraph workflow with supervisor pattern"""
    
    # Create specialized agents
    naming_agent = create_naming_agent(llm)
    description_agent = create_description_agent(llm)
    mapping_agent = create_mapping_agent(llm)
    validation_agent = create_validation_agent(llm)
    supervisor_chain = create_supervisor_chain(llm)
    
    # Define agent nodes
    def naming_node(state: AgentState):
        field_data = state["current_field"]
        context = f"Application: {field_data['application_name']}. Description: {field_data['application_description']}. Field: {field_data['field_name']}. Classification: {field_data.get('isr_classification', 'N/A')}"
        
        messages = [HumanMessage(content=f"Enrich this field name according to ISO/IEC 11179-1:2023: {field_data['field_name']}. Context: {context}")]
        result = naming_agent.invoke({"messages": messages})
        
        # Extract enriched name from result
        last_message = result["messages"][-1]
        try:
            response_data = json.loads(last_message.content)
            return {
                "enriched_name": response_data.get("enriched_name", ""),
                "enrichment_rationale": response_data.get("reasoning", ""),
                "messages": [AIMessage(content=f"Naming complete: {response_data.get('enriched_name', '')}")]
            }
        except:
            return {
                "enriched_name": field_data['field_name'],
                "enrichment_rationale": last_message.content,
                "messages": [AIMessage(content="Naming complete")]
            }
    
    def description_node(state: AgentState):
        enriched_name = state["enriched_name"]
        field_data = state["current_field"]
        context = f"Application: {field_data['application_name']}. Enriched name: {enriched_name}"
        
        messages = [HumanMessage(content=f"Generate ISO/IEC 11179-1:2023 compliant definition for: {enriched_name}. Context: {context}")]
        result = description_agent.invoke({"messages": messages})
        
        last_message = result["messages"][-1]
        try:
            response_data = json.loads(last_message.content)
            return {
                "enriched_description": response_data.get("definition", ""),
                "messages": [AIMessage(content="Description generated")]
            }
        except:
            return {
                "enriched_description": last_message.content,
                "messages": [AIMessage(content="Description generated")]
            }
    
    def mapping_node(state: AgentState):
        enriched_name = state["enriched_name"]
        description = state["enriched_description"]
        field_text = f"{enriched_name}: {description}"
        
        messages = [HumanMessage(content=f"Map this field to Object-Property: {field_text}")]
        result = mapping_agent.invoke({"messages": messages})
        
        last_message = result["messages"][-1]
        try:
            response_data = json.loads(last_message.content)
            return {
                "mapped_object": response_data.get("selected_object", ""),
                "mapped_property": response_data.get("selected_property", ""),
                "mapping_rationale": response_data.get("reasoning", ""),
                "messages": [AIMessage(content="Mapping complete")]
            }
        except:
            return {
                "mapped_object": "Unknown",
                "mapped_property": "Unknown",
                "mapping_rationale": last_message.content,
                "messages": [AIMessage(content="Mapping complete")]
            }
    
    def validation_node(state: AgentState):
        messages = [HumanMessage(content=f"Validate: Name={state['enriched_name']}, Desc={state['enriched_description']}, Mapping={state['mapped_object']}->{state['mapped_property']}")]
        result = validation_agent.invoke({"messages": messages})
        
        return {
            "messages": [AIMessage(content="Validation complete")]
        }
    
    def supervisor_node(state: AgentState):
        result = supervisor_chain.invoke({
            "messages": state["messages"],
            "agents": ", ".join(["naming_agent", "description_agent", "mapping_agent", "validation_agent", "FINISH"])
        })
        
        if hasattr(result, 'additional_kwargs') and 'function_call' in result.additional_kwargs:
            next_agent = json.loads(result.additional_kwargs['function_call']['arguments'])["next"]
        else:
            # Sequential fallback
            messages = state["messages"]
            if not state.get("enriched_name"):
                next_agent = "naming_agent"
            elif not state.get("enriched_description"):
                next_agent = "description_agent"
            elif not state.get("mapped_object"):
                next_agent = "mapping_agent"
            elif len([m for m in messages if "Validation complete" in m.content]) == 0:
                next_agent = "validation_agent"
            else:
                next_agent = "FINISH"
        
        return {"next_agent": next_agent}
    
    # Create the workflow graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("naming_agent", naming_node)
    workflow.add_node("description_agent", description_node)
    workflow.add_node("mapping_agent", mapping_node)
    workflow.add_node("validation_agent", validation_node)
    
    # Add edges
    workflow.add_edge(START, "supervisor")
    workflow.add_edge("naming_agent", "supervisor")
    workflow.add_edge("description_agent", "supervisor")
    workflow.add_edge("mapping_agent", "supervisor")
    workflow.add_edge("validation_agent", "supervisor")
    
    # Conditional edges from supervisor
    def route_supervisor(state: AgentState):
        next_agent = state.get("next_agent", "FINISH")
        if next_agent == "FINISH":
            return END
        return next_agent
    
    workflow.add_conditional_edges(
        "supervisor",
        route_supervisor,
        {
            "naming_agent": "naming_agent",
            "description_agent": "description_agent",
            "mapping_agent": "mapping_agent",
            "validation_agent": "validation_agent",
            END: END
        }
    )
    
    return workflow


# ==========================
# Main Processing Pipeline
# ==========================

def initialize_vector_store(excel_path: str, embeddings: DirectOpenAIEmbeddings) -> InMemoryVectorStore:
    """Initialize LangChain InMemoryVectorStore with Object-Property mappings"""
    
    print("\n[System] Loading Excel mappings...")
    df = pd.read_excel(excel_path)
    
    documents = []
    for _, row in df.iterrows():
        obj_name = row['Object name']
        prop_name = row['Property name']
        
        doc = Document(
            page_content=f"{obj_name} {prop_name}",
            metadata={
                "object_name": obj_name,
                "property_name": prop_name
            }
        )
        documents.append(doc)
    
    print(f"  Creating InMemoryVectorStore with {len(documents)} mappings...")
    store = InMemoryVectorStore.from_documents(documents, embeddings)
    print("  ✓ Vector store initialized")
    
    return store


def process_data(json_path: str, excel_path: str, output_csv: str = "enriched_output.csv"):
    """Main processing pipeline using LangGraph"""
    
    global vector_store
    
    print("\n" + "="*70)
    print("ISO/IEC 11179-1:2023 Data Enrichment System")
    print("LangGraph Multi-Agent with ReAct Architecture")
    print("="*70)
    
    # Initialize components
    print("\n[System] Initializing components...")
    embeddings = DirectOpenAIEmbeddings(api_key=OPENAI_API_KEY)
    llm = ChatOpenAI(
        model=O3_MINI_MODEL,
        api_key=OPENAI_API_KEY,
        base_url=OPENAI_BASE_URL
    )
    
    # Initialize vector store
    vector_store = initialize_vector_store(excel_path, embeddings)
    
    # Load JSON data
    print("\n[System] Loading JSON data...")
    with open(json_path, 'r') as f:
        json_data = json.load(f)
    print(f"  Loaded {len(json_data)} fields")
    
    # Create workflow
    print("\n[System] Creating LangGraph workflow...")
    workflow = create_workflow(llm)
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    print("  ✓ Workflow compiled")
    
    # Process each field
    print("\n[System] Processing fields...")
    results = []
    
    for idx, field_data in enumerate(json_data):
        print(f"\n{'='*70}")
        print(f"Field {idx+1}/{len(json_data)}: {field_data['Field Name']}")
        print(f"{'='*70}")
        
        # Initial state
        initial_state = {
            "messages": [HumanMessage(content=f"Process field: {field_data['Field Name']}")],
            "current_field": field_data,
            "enriched_name": "",
            "enriched_description": "",
            "mapped_object": "",
            "mapped_property": "",
            "enrichment_rationale": "",
            "mapping_rationale": "",
            "next_agent": ""
        }
        
        # Run workflow
        config = {"configurable": {"thread_id": f"field_{idx}"}}
        final_state = app.invoke(initial_state, config)
        
        # Collect results
        result = {
            "EIM ID": field_data.get("EIM ID"),
            "Application Name": field_data.get("Application Name"),
            "Original Field Name": field_data.get("Field Name"),
            "Enriched Field Name": final_state.get("enriched_name", ""),
            "Enriched Description": final_state.get("enriched_description", ""),
            "Mapped Object": final_state.get("mapped_object", ""),
            "Mapped Property": final_state.get("mapped_property", ""),
            "Enrichment Rationale": final_state.get("enrichment_rationale", ""),
            "Mapping Rationale": final_state.get("mapping_rationale", ""),
            "ISR Classification": field_data.get("ISR Classification", "")
        }
        results.append(result)
        
        print(f"\n✓ Enriched: {result['Enriched Field Name']}")
        print(f"✓ Mapped: {result['Mapped Object']} -> {result['Mapped Property']}")
    
    # Save results
    print("\n[System] Saving results...")
    df = pd.DataFrame(results)
    df.to_csv(output_csv, index=False)
    
    print(f"\n{'='*70}")
    print(f"✓ Processing complete!")
    print(f"  Output: {output_csv}")
    print(f"  Fields processed: {len(results)}")
    print(f"{'='*70}\n")
    
    return df


# ==========================
# Entry Point
# ==========================

if __name__ == "__main__":
    import sys
    
    # Check if API key is provided
    if len(sys.argv) > 1:
        OPENAI_API_KEY = sys.argv[1]
    else:
        OPENAI_API_KEY = input("Enter your OpenAI API key: ")
    
    # File paths
    json_path = "input_data.json"
    excel_path = "object_property_mappings.xlsx"
    output_csv = "enriched_output.csv"
    
    # Run the pipeline
    result_df = process_data(json_path, excel_path, output_csv)
    
    print("\nSample Results:")
    print(result_df.head())
