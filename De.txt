import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from typing import List, Dict, Optional, Union, Any
import io
from datetime import datetime
import warnings

# Suppress warnings
warnings.filterwarnings('ignore')

# Configure Streamlit page
st.set_page_config(
    page_title="Excel Analyzer",
    page_icon="📊",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add custom CSS
st.markdown("""
    <style>
    .stButton > button {
        width: 100%;
    }
    .streamlit-expanderHeader {
        font-size: 1.2em;
    }
    .stProgress .st-bo {
        background-color: #00cc00;
    }
    </style>
""", unsafe_allow_html=True)

@st.cache_data
def convert_df_to_excel(df: pd.DataFrame) -> bytes:
    """Convert DataFrame to Excel bytes."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Sheet1', index=False)
    return output.getvalue()

def load_and_process_excel(file) -> Optional[pd.DataFrame]:
    """
    Load and process Excel file with comprehensive error handling and data cleaning.
    """
    try:
        # Read the Excel file
        df = pd.read_excel(file, engine='openpyxl')
        
        # Clean column names
        df.columns = df.columns.str.strip().str.replace(' ', '_')
        
        # Process each column
        for col in df.columns:
            # Clean string data
            if df[col].dtype == 'object':
                df[col] = df[col].astype(str).str.strip()
                
                # Try converting to numeric if possible
                try:
                    numeric_series = pd.to_numeric(df[col], errors='coerce')
                    # If more than 70% are numeric, convert the column
                    if numeric_series.notna().mean() > 0.7:
                        df[col] = numeric_series
                except:
                    pass
                    
            # Handle datetime
            elif pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = pd.to_datetime(df[col], errors='coerce')
                
        # Remove any completely empty rows or columns
        df = df.dropna(how='all').dropna(axis=1, how='all')
        
        return df
    except Exception as e:
        st.error(f"Error loading file: {str(e)}")
        return None

def merge_dataframes(dfs: List[pd.DataFrame], merge_keys: List[str], merge_type: str = 'left') -> Optional[pd.DataFrame]:
    """
    Merge multiple DataFrames with error handling and validation.
    """
    try:
        if not dfs:
            return None
            
        result = dfs[0]
        for idx, df in enumerate(dfs[1:], 1):
            # Validate merge keys exist in both DataFrames
            if not all(key in df.columns for key in merge_keys) or \
               not all(key in result.columns for key in merge_keys):
                st.error(f"Merge keys not found in all DataFrames at merge step {idx}")
                return None
                
            # Handle duplicate columns
            suffix_a = f"_1_{idx}" if idx > 1 else ""
            suffix_b = f"_2_{idx}"
            
            # Perform merge
            result = result.merge(
                df,
                on=merge_keys,
                how=merge_type,
                suffixes=(suffix_a, suffix_b)
            )
            
            # Log merge results
            st.info(f"Merge {idx} complete: {len(result)} rows")
            
        return result
    except Exception as e:
        st.error(f"Error during merge: {str(e)}")
        return None

def safe_aggregate(series: pd.Series, func: str) -> Any:
    """
    Safely apply aggregation function to a series with type checking.
    """
    try:
        if func == 'count':
            return len(series.dropna())
        elif func == 'distinct_count':
            return len(series.dropna().unique())
        elif pd.api.types.is_numeric_dtype(series):
            if func == 'sum':
                return series.sum()
            elif func == 'mean':
                return series.mean()
            elif func == 'min':
                return series.min()
            elif func == 'max':
                return series.max()
        return None
    except Exception:
        return None

def create_pivot(df: pd.DataFrame, 
                index_cols: List[str], 
                value_cols: List[str],
                agg_funcs: List[str],
                filters: Dict = None) -> Optional[pd.DataFrame]:
    """
    Create pivot table with multiple aggregations and mixed type handling.
    """
    try:
        # Convert groupby columns to string for consistency
        temp_df = df.copy()
        for col in index_cols:
            temp_df[col] = temp_df[col].astype(str)

        # Apply filters
        if filters:
            for col, values in filters.items():
                if values:
                    temp_df = temp_df[temp_df[col].astype(str).isin([str(v) for v in values])]
        
        # Initialize results list
        agg_results = []
        
        # Create base groupby object
        grouped = temp_df.groupby(index_cols, observed=True)
        
        # Process each value column and aggregation
        for col in value_cols:
            for func in agg_funcs:
                # Define aggregation function based on column type and requested function
                if func == 'distinct_count':
                    agg_result = grouped[col].agg(lambda x: len(pd.Series(x).unique()))
                    display_name = 'Unique Count'
                elif func == 'count':
                    agg_result = grouped[col].count()
                    display_name = 'Count'
                elif pd.api.types.is_numeric_dtype(df[col]):
                    if func in ['sum', 'mean', 'min', 'max']:
                        agg_result = grouped[col].agg(func)
                        display_name = func.capitalize()
                    else:
                        continue
                else:
                    # For string columns, only allow count and distinct_count
                    if func not in ['count', 'distinct_count']:
                        continue
                    elif func == 'distinct_count':
                        agg_result = grouped[col].agg(lambda x: len(pd.Series(x).unique()))
                        display_name = 'Unique Count'
                    else:
                        agg_result = grouped[col].count()
                        display_name = 'Count'
                
                # Convert to DataFrame and set column name
                agg_df = pd.DataFrame(agg_result)
                agg_df.columns = [f"{col} ({display_name})"]
                agg_results.append(agg_df)
        
        if not agg_results:
            return None
            
        # Combine results
        result = pd.concat(agg_results, axis=1)
        
        # Add totals
        totals = pd.DataFrame(index=['Total'])
        for col in result.columns:
            try:
                if 'Count' in col or 'Sum' in col:
                    totals[col] = result[col].astype(float).sum()
                elif 'Mean' in col:
                    totals[col] = result[col].astype(float).mean()
                elif 'Max' in col:
                    totals[col] = result[col].astype(float).max()
                elif 'Min' in col:
                    totals[col] = result[col].astype(float).min()
            except:
                totals[col] = None
        
        result = pd.concat([result, totals])
        
        return result
        
    except Exception as e:
        st.error(f"Error creating pivot: {str(e)}")
        st.write("Debug information:")
        st.write(f"Index columns: {index_cols}")
        st.write(f"Value columns: {value_cols}")
        st.write(f"Aggregation functions: {agg_funcs}")
        for col in index_cols + value_cols:
            st.write(f"Column '{col}' type: {df[col].dtype}")
        return None

def create_plot(df: pd.DataFrame, 
               plot_type: str,
               x_col: str,
               y_col: str,
               title: str = "") -> Optional[px.Figure]:
    """
    Create plotly visualization with error handling.
    """
    try:
        # Remove total row for plotting
        plot_df = df[df.index != 'Total'].copy()
        
        if plot_type == 'Bar':
            fig = px.bar(plot_df, x=plot_df.index, y=y_col, title=title)
        elif plot_type == 'Line':
            fig = px.line(plot_df, x=plot_df.index, y=y_col, title=title)
        elif plot_type == 'Scatter':
            fig = px.scatter(plot_df, x=plot_df.index, y=y_col, title=title)
        else:
            return None
            
        # Update layout
        fig.update_layout(
            xaxis_title=x_col,
            yaxis_title=y_col,
            showlegend=True,
            template='plotly_white'
        )
        
        return fig
        
    except Exception as e:
        st.error(f"Error creating plot: {str(e)}")
        return None

def export_to_excel(results_df: pd.DataFrame, 
                   data_df: pd.DataFrame,
                   filename: str = "analysis_results.xlsx") -> Optional[bytes]:
    """
    Export results and data to formatted Excel file.
    """
    try:
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            # Write results sheet
            results_df.to_excel(writer, sheet_name='Analysis')
            
            # Write data sheet
            data_df.to_excel(writer, sheet_name='Data', index=False)
            
            # Get workbook and add formats
            workbook = writer.book
            header_format = workbook.add_format({
                'bold': True,
                'bg_color': '#D3D3D3',
                'border': 1
            })
            
            # Format Analysis sheet
            worksheet = writer.sheets['Analysis']
            for col_num, value in enumerate(results_df.columns.values):
                worksheet.write(0, col_num + 1, value, header_format)
            
            # Format Data sheet
            worksheet = writer.sheets['Data']
            for col_num, value in enumerate(data_df.columns.values):
                worksheet.write(0, col_num, value, header_format)
                
        return output.getvalue()
        
    except Exception as e:
        st.error(f"Error exporting to Excel: {str(e)}")
        return None

def main():
    st.title("📊 Excel Analysis Dashboard")
    st.write("Upload Excel files, merge them, and create dynamic analyses")
    
    # File Upload Section
    with st.sidebar:
        st.header("📁 File Upload")
        uploaded_files = st.file_uploader(
            "Choose Excel files",
            type=['xlsx', 'xls'],
            accept_multiple_files=True,
            help="Upload one or more Excel files"
        )
    
    if not uploaded_files:
        st.info("👆 Please upload Excel files using the sidebar to begin.")
        return
    
    # Load and Display Files
    st.header("📑 Uploaded Files")
    dataframes = []
    
    cols = st.columns(len(uploaded_files))
    for idx, file in enumerate(uploaded_files):
        with cols[idx]:
            st.subheader(f"File {idx + 1}")
            df = load_and_process_excel(file)
            if df is not None:
                dataframes.append(df)
                st.success(f"✓ {file.name}")
                st.dataframe(df.head(3))
                st.write(f"Rows: {len(df)}, Columns: {len(df.columns)}")
            else:
                st.error(f"× Failed to load {file.name}")
    
    if not dataframes:
        st.error("❌ No valid data loaded.")
        return
    
    # Get Common Columns
    common_columns = list(set.intersection(*[set(df.columns) for df in dataframes]))
    if not common_columns:
        st.error("❌ No common columns found between files!")
        return
    
    # Merge Settings
    st.header("🔄 Merge Settings")
    
    merge_keys = st.multiselect(
        "Select merge columns:",
        common_columns,
        help="Select columns to merge on"
    )
    
    merge_type = st.selectbox(
        "Select merge type:",
        ['left', 'right', 'inner', 'outer'],
        help="Choose how to merge the files"
    )
    
    if not merge_keys:
        st.warning("⚠️ Please select merge columns.")
        return
    
    # Perform Merge
    merged_df = merge_dataframes(dataframes, merge_keys, merge_type)
    if merged_df is None or merged_df.empty:
        st.error("❌ Merge resulted in empty data.")
        return
    
    st.success("✅ Files merged successfully!")
    
    # Show Merged Data Preview
    with st.expander("👀 Preview Merged Data"):
        st.dataframe(merged_df.head())
        st.write(f"Total rows: {len(merged_df)}, Total columns: {len(merged_df.columns)}")
    
    # Analysis Settings
    st.header("📊 Analysis Settings")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        index_cols = st.multiselect(
            "Group by:",
            merged_df.columns,
            help="Select columns to group by"
        )
    
    with col2:
        value_cols = st.multiselect(
            "Select columns to analyze:",
            merged_df.columns,
            help="Select columns to aggregate"
        )
    
    with col3:
        agg_funcs = st.multiselect(
            "Select functions:",
            ['sum', 'mean', 'count', 'distinct_count', 'max', 'min'],
            help="Choose analysis functions"
        )
    
    # Filters
    if index_cols:
        st.subheader("🔍 Filters")
        filters = {}
        filter_cols = st.columns(min(len(index_cols), 4))
        
        for idx, col in enumerate(index_cols):
            with filter_cols[idx % 4]:
                unique_vals = sorted(merged_df[col].unique())
                selected = st.multiselect(
                    f"Filter {col}:",
                    unique_vals,
                    help=f"Select values to include for {col}"
                )
                if selected:
                    filters[col] = selected
        
        # Calculate Results
        if value_cols and agg_funcs:
            results = create_pivot(
                merged_df,
                index_cols,
                value_cols,
                agg_funcs,
                filters
            )
            
            if results is not None and not results.empty:
                st.header("📈 Results")
                st.dataframe(results)
                
                # Visualization
                if len(results) > 1:
                    st.subheader("📊 Visualization")
                    
                    viz_col1, viz_col2 = st.columns(2)
                    
                    with viz_col1:
                        chart_type = st.selectbox(
                            "Chart Type:",
                            ['Bar', 'Line', 'Scatter']
                        )
                    
                    with viz_col2:
                        y_column = st.selectbox(
                            "Value to Plot:",
                            results.columns
                        ) if len(results.columns) > 1 else results.columns[0]
                    
                    fig = create_plot(
                        results,
                        chart_type,
                        index_cols[0],
                        y_column,
                        f"{y_column} by {index_cols[0]}"
                    )
                    
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                
                # Download Results
                st.subheader("💾 Download Results")
                
                excel_data = export_to_excel(results, merged_df)
                if excel_data:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    st.download_button(
                        label="📥 Download Excel file",
                        data=excel_data,
                        file_name=f"analysis_results_{timestamp}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        help="Download the results and merged data as an Excel file"
                    )

if __name__ == "__main__":
    main()
