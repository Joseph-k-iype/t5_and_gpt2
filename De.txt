"""
Advanced Prompting Strategies for Legal Document Analysis
ABSOLUTELY COMPLETE VERSION - ALL METHODS INCLUDED
NO TRUNCATION WHATSOEVER
Location: src/prompting/advanced_strategies.py
"""
from typing import Optional, List, Dict, Any
from enum import Enum


class ExpertRole(str, Enum):
    """Expert roles for Mixture of Experts prompting"""
    LEGAL_EXPERT = "legal_expert"
    COMPLIANCE_OFFICER = "compliance_officer"
    DATA_PRIVACY_SPECIALIST = "data_privacy_specialist"
    REGULATORY_ANALYST = "regulatory_analyst"
    TECHNICAL_ARCHITECT = "technical_architect"
    BUSINESS_ANALYST = "business_analyst"


class ReasoningMode(str, Enum):
    """Reasoning modes for different analysis approaches"""
    CHAIN_OF_THOUGHT = "chain_of_thought"
    MIXTURE_OF_EXPERTS = "mixture_of_experts"
    TREE_OF_THOUGHT = "tree_of_thought"
    REFLECTION = "reflection"
    REACT = "react"


class AdvancedPromptingStrategies:
    """
    Advanced prompting strategies optimized for citation tracking,
    evidence collection, and simplified taxonomy.
    NOTE: Watermarks are filtered by DocumentChunker before text reaches these prompts
    """
    
    def __init__(self, rule_name: str, jurisdiction: str):
        self.rule_name = rule_name
        self.jurisdiction = jurisdiction
    
    def _get_level_description(self, level: int) -> str:
        """Get description of document level"""
        descriptions = {
            1: "PRIMARY LEGISLATION - Base legal requirements from laws and regulations",
            2: "REGULATORY GUIDANCE - Detailed interpretation and implementation guidance",
            3: "ENTERPRISE POLICIES - Organization-specific implementation and internal requirements"
        }
        return descriptions.get(level, "Unknown level")
    
    # ============================================================================
    # PRIMARY EXTRACTION PROMPT - MOST IMPORTANT METHOD
    # ============================================================================
    
    def get_complete_extraction_prompt(
        self,
        chunk_text: str,
        chunk_id: int,
        level: int,
        enterprise_context: Optional[Dict[str, Any]]
    ) -> str:
        """
        COMPLETE extraction prompt with ALL requirements
        This is the main prompt used by legal_document_analyzer.py
        """
        
        level_desc = self._get_level_description(level)
        chunk_context = f"Chunk ID: {chunk_id}"
        
        enterprise_section = ""
        if enterprise_context:
            org = enterprise_context.get("organization", "")
            tools = enterprise_context.get("internal_tools", [])
            if org or tools:
                enterprise_section = f"\n\nENTERPRISE CONTEXT (Level 3 Enterprise Policies):\n- Organization: {org}\n- Internal Tools: {', '.join(tools)}\n- IMPORTANT: Look for organization-specific policies!"
        
        return f"""You are analyzing legal/regulatory text for: {self.rule_name} in {self.jurisdiction}

DOCUMENT LEVEL: {level_desc}
{chunk_context}{enterprise_section}

CRITICAL ANTI-HALLUCINATION RULES:
1. Extract ONLY what is explicitly stated in the text below
2. Every citation must be VERBATIM text from the chunk (word-for-word quote)
3. Every claim must have a corresponding citation
4. DO NOT infer, assume, or make up information
5. If something is not clearly stated, do not extract it
6. Use simple, clear English - NO references to "the document", "section 2", "the guidance", etc.

===== FULL CHUNK TEXT (WATERMARKS ALREADY FILTERED) =====
{chunk_text}
===== END OF CHUNK TEXT =====

MANDATORY EXTRACTION REQUIREMENTS:

1. RULE DESCRIPTION (MANDATORY):
   - Comprehensive summary in simple English (minimum 100 characters)
   - Explain WHO must do WHAT under WHICH conditions
   - NO document references
   - Example: "Organizations must implement appropriate technical measures to ensure data security, including encryption and access controls, when processing personal data"

2. CITATIONS (MINIMUM 3 REQUIRED):
   - EXACT VERBATIM quotes from text above
   - Between 20-200 characters each
   - Include reasoning for each
   - Format: {{"text": "EXACT QUOTE", "reasoning": "how this supports the claim"}}

3. DATA ACTIONS:
   - Type: ONLY "data_sharing_and_access" | "data_storage_and_hosting" | "data_usage"
   - Description: Complete in simple English (minimum 30 chars)
   - Citations: At least ONE
   - Thought_process: Detailed reasoning (minimum 50 chars)

4. CONSTRAINTS:
   - Type: temporal|geographic|purpose|technical|procedural
   - Description: Complete (minimum 40 chars)
   - Left_operand: What is constrained
   - Operator: eq|neq|lt|gt|lte|gte|in|contains|isPartOf
   - Right_operand: Value
   - Scope: general|permission|prohibition|duty
   - Citations: At least ONE
   - Thought_process: Detailed reasoning (minimum 50 chars)

5. USER EVIDENCE (what users must/can/cannot do):
   - Description: Complete (minimum 40 chars)
   - Citations: At least ONE
   - Thought_process: Detailed reasoning (minimum 50 chars)

6. SYSTEM EVIDENCE (what systems must implement):
   - Description: Complete (minimum 40 chars)
   - Citations: At least ONE
   - Thought_process: Detailed reasoning (minimum 50 chars)

7. ENTERPRISE POLICIES (ONLY for Level 3):
   - Policy_name: Name (minimum 10 chars)
   - Description: Complete (minimum 50 chars)
   - Organization: Org name
   - Applies_to: List
   - Internal_tools: List
   - Citations: At least ONE
   - Thought_process: Detailed reasoning (minimum 50 chars)

8. CLASSIFICATION (MANDATORY):
   - "condition" OR "restriction"
   - Classification_reasoning: Explanation (minimum 50 chars)

QUALITY REQUIREMENTS:
✓ EVERY item has citations with VERBATIM text
✓ EVERY item has thought_process (minimum 50 chars)
✓ Descriptions are COMPLETE sentences
✓ Rule description minimum 100 chars
✓ NO hallucination
✓ NO document references
✓ Use simple, clear English

Return valid JSON:
{{
  "description": "...",
  "citations": [{{"text": "...", "reasoning": "...", "level": {level}}}],
  "data_actions": [{{"type": "...", "description": "...", "citations": [...], "thought_process": "..."}}],
  "constraints": [{{"type": "...", "description": "...", "left_operand": "...", "operator": "...", "right_operand": "...", "scope": "...", "citations": [...], "thought_process": "..."}}],
  "user_evidence": [{{"description": "...", "citations": [...], "thought_process": "..."}}],
  "system_evidence": [{{"description": "...", "citations": [...], "thought_process": "..."}}],
  "enterprise_policies": [{{"policy_name": "...", "description": "...", "organization": "...", "applies_to": [...], "internal_tools": [...], "citations": [...], "thought_process": "..."}}],
  "classification": "condition|restriction",
  "classification_reasoning": "..."
}}"""
    
    # ============================================================================
    # REACT AGENT PROMPTS
    # ============================================================================
    
    def get_react_agent_system_prompt(self) -> str:
        """ReAct agent system prompt"""
        return f"""You are a legal document analyzer using ReAct methodology.

Rule: {self.rule_name}
Jurisdiction: {self.jurisdiction}

REQUIREMENTS:
1. CITATIONS: Exact text excerpts (max 200 chars) with reasoning
2. EVIDENCE: Separate user (what users do) from system (what systems implement)
3. ACTION TAXONOMY: data_sharing_and_access | data_storage_and_hosting | data_usage
4. CLASSIFICATION: condition OR restriction
5. NO DOCUMENT REFERENCES

Extract with citations and reasoning."""
    
    # ============================================================================
    # CHAIN OF THOUGHT PROMPTS
    # ============================================================================
    
    def get_chain_of_thought_prompt(self, text: str) -> str:
        """Chain of Thought reasoning prompt"""
        text_truncated = text[:2000] + "..." if len(text) > 2000 else text
        
        return f"""Analyze step by step:

TEXT:
{text_truncated}

STEPS:
1. IDENTIFY KEY REQUIREMENTS
2. EXTRACT CONDITIONS
3. DETERMINE CLASSIFICATION
4. IDENTIFY EVIDENCE TYPES
5. MAP TO TAXONOMY
6. EXTRACT CITATIONS

Provide reasoning at each step, then final JSON."""
    
    # ============================================================================
    # MIXTURE OF EXPERTS PROMPTS
    # ============================================================================
    
    def get_mixture_of_experts_prompt(self, text: str, experts: List[ExpertRole]) -> str:
        """Mixture of Experts prompt"""
        text_truncated = text[:1500] + "..." if len(text) > 1500 else text
        
        expert_instructions = []
        for expert in experts:
            if expert == ExpertRole.LEGAL_EXPERT:
                expert_instructions.append("LEGAL EXPERT: Identify legal obligations")
            elif expert == ExpertRole.COMPLIANCE_OFFICER:
                expert_instructions.append("COMPLIANCE OFFICER: Identify compliance steps")
            elif expert == ExpertRole.DATA_PRIVACY_SPECIALIST:
                expert_instructions.append("DATA PRIVACY: Identify privacy safeguards")
            elif expert == ExpertRole.TECHNICAL_ARCHITECT:
                expert_instructions.append("TECHNICAL: Identify system requirements")
        
        expert_section = "\n".join(expert_instructions)
        
        return f"""Analyze from multiple perspectives:

TEXT:
{text_truncated}

EXPERTS:
{expert_section}

Each expert: analyze, provide citations, explain reasoning.
Synthesize into unified JSON."""
    
    # ============================================================================
    # REFLECTION AND VALIDATION
    # ============================================================================
    
    def get_reflection_prompt(self, analysis: Dict[str, Any]) -> str:
        """Reflection prompt for validation"""
        summary = f"""Analysis:
Classification: {analysis.get('classification', 'N/A')}
Description: {analysis.get('description', '')[:200]}...
Actions: {len(analysis.get('data_actions', []))}
Citations: {len(analysis.get('citations', []))}"""
        
        return f"""Validate this analysis:

{summary}

CHECKLIST:
1. Citations: All claims cited with exact text?
2. Taxonomy: Actions mapped to 3 categories?
3. Evidence: User/system separation clear?
4. Classification: Correct?
5. Completeness: Anything missing?
6. No Hallucination: Everything based on source?

Provide JSON with validation results."""
    
    def get_validation_prompt(self, analysis: Dict[str, Any]) -> str:
        """Validation prompt"""
        summary = f"""Classification: {analysis.get('classification', 'N/A')}
Actions: {len(analysis.get('data_actions', []))}
Evidence: {len(analysis.get('user_evidence', []))} user, {len(analysis.get('system_evidence', []))} system
Citations: {len(analysis.get('citations', []))}"""
        
        return f"""Validate:

{summary}

Check: Citations, Taxonomy, Evidence separation, Classification, Completeness, Accuracy

Provide JSON with issues and suggestions."""
    
    # ============================================================================
    # MERGE AND REFINEMENT
    # ============================================================================
    
    def get_merge_prompt(self, analyses: List[Dict[str, Any]]) -> str:
        """Merge multiple analyses"""
        summaries = []
        total_citations = 0
        
        for i, analysis in enumerate(analyses[:3]):
            desc = analysis.get('description', '')[:100]
            num_cites = len(analysis.get('citations', []))
            total_citations += num_cites
            summaries.append(f"Analysis {i+1}: {desc}... [{num_cites} citations]")
        
        if len(analyses) > 3:
            remaining = sum(len(a.get('citations', [])) for a in analyses[3:])
            total_citations += remaining
            summaries.append(f"... and {len(analyses) - 3} more [{remaining} citations]")
        
        summary_text = "\n".join(summaries)
        
        return f"""Merge analyses:

{summary_text}

Total citations: {total_citations}

Provide merged JSON with:
- Combined description
- ALL citations preserved
- All unique actions
- All evidence
- All constraints
- Unified classification

Deduplicate while preserving citations."""
    
    def get_refinement_prompt(self, analysis: Dict[str, Any], feedback: str) -> str:
        """Refinement based on feedback"""
        summary = f"""Analysis:
Classification: {analysis.get('classification', 'N/A')}
Description: {analysis.get('description', '')[:200]}...
Actions: {len(analysis.get('data_actions', []))}"""
        
        feedback_truncated = feedback[:300] + "..." if len(feedback) > 300 else feedback
        
        return f"""Refine based on feedback:

{summary}

FEEDBACK:
{feedback_truncated}

Apply improvements while preserving citations and maintaining quality."""
    
    # ============================================================================
    # ENTERPRISE CONTEXT
    # ============================================================================
    
    def get_enterprise_context_prompt(self, text: str, level: int) -> str:
        """Extract enterprise context"""
        text_truncated = text[:1000] + "..." if len(text) > 1000 else text
        
        level_note = ""
        if level == 3:
            level_note = "\n\nIMPORTANT: Level 3 - Look for organization-specific policies, internal tools, company requirements.\n"
        
        return f"""Identify enterprise context:
{level_note}
TEXT:
{text_truncated}

Extract:
- Organization name
- Internal tools/systems
- Company-specific processes
- Enterprise policies

Provide JSON."""
    
    # ============================================================================
    # CLASSIFICATION HELPERS
    # ============================================================================
    
    def get_classification_prompt(self, analysis_summary: str) -> str:
        """Classification prompt"""
        return f"""Classify as CONDITION or RESTRICTION:

{analysis_summary}

DEFINITIONS:
- CONDITION: Allowed under conditions
- RESTRICTION: Prohibited/restricted

Provide JSON with classification, reasoning, key indicators, confidence."""
    
    # ============================================================================
    # EVIDENCE SEPARATION
    # ============================================================================
    
    def get_evidence_separation_prompt(self, text: str) -> str:
        """Separate user and system evidence"""
        text_truncated = text[:1500] + "..." if len(text) > 1500 else text
        
        return f"""Separate into user and system:

TEXT:
{text_truncated}

USER PERSPECTIVE: Actions users take
SYSTEM PERSPECTIVE: Technical requirements

Provide JSON with user_evidence and system_evidence."""
    
    # ============================================================================
    # ACTION TAXONOMY
    # ============================================================================
    
    def get_action_taxonomy_mapping_prompt(self, actions_text: str) -> str:
        """Map actions to taxonomy"""
        return f"""Map to taxonomy:

ACTIONS:
{actions_text}

TAXONOMY:
1. data_sharing_and_access
2. data_storage_and_hosting
3. data_usage

Provide JSON with mapped actions."""
    
    def get_action_extraction_prompt(self, text: str) -> str:
        """Extract actions"""
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract actions:

{text_truncated}

Map to taxonomy: sharing/access, storage/hosting, usage

Provide JSON with user_actions and system_actions."""
    
    # ============================================================================
    # CONSTRAINT ANALYSIS
    # ============================================================================
    
    def get_constraint_analysis_prompt(self, text: str) -> str:
        """Extract constraints"""
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract constraints:

{text_truncated}

Provide JSON with constraints (type, description, citations)."""
    
    # ============================================================================
    # DUTY EXTRACTION
    # ============================================================================
    
    def get_duty_extraction_prompt(self, text: str) -> str:
        """Extract duties"""
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract duties:

{text_truncated}

Separate user and system perspectives.

Provide JSON with user_evidence and system_evidence."""
    
    # ============================================================================
    # DATA CATEGORIES AND ROLES
    # ============================================================================
    
    def get_data_category_prompt(self, text: str) -> str:
        """Identify data categories"""
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify data categories:

{text_truncated}

Common: personal data, sensitive data, financial data, health data, biometric data

Provide JSON with data_categories array."""
    
    def get_role_identification_prompt(self, text: str) -> str:
        """Identify roles"""
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify roles:

{text_truncated}

Common: data controller, processor, subject, third party, joint controller

Provide JSON with roles array."""
    
    # ============================================================================
    # DECISION INFERENCE
    # ============================================================================
    
    def get_decision_inference_prompt(self, rule_context: str) -> str:
        """Infer decisions"""
        context_truncated = rule_context[:600] + "..." if len(rule_context) > 600 else rule_context
        
        return f"""Identify decision scenarios:

{context_truncated}

For each: scenario, decision_type (yes/no/maybe), conditions, actions

Provide JSON."""
    
    # ============================================================================
    # LEVEL-SPECIFIC ANALYSIS
    # ============================================================================
    
    def get_level_specific_prompt(self, text: str, level: int) -> str:
        """Level-specific analysis"""
        level_instructions = {
            1: "Level 1 (Legislation): Legal requirements, statutory obligations",
            2: "Level 2 (Guidance): Regulatory interpretations, compliance guidance",
            3: "Level 3 (Enterprise): Organization-specific, internal tools, policies"
        }
        
        instruction = level_instructions.get(level, level_instructions[1])
        text_truncated = text[:1000] + "..." if len(text) > 1000 else text
        
        return f"""Analyze Level {level}:

{instruction}

TEXT:
{text_truncated}

Extract with level-appropriate focus."""
    
    def get_cross_level_validation_prompt(
        self,
        level_1_findings: str,
        level_2_findings: str,
        level_3_findings: str
    ) -> str:
        """Validate across levels"""
        return f"""Validate consistency:

LEVEL 1: {level_1_findings[:300]}
LEVEL 2: {level_2_findings[:300]}
LEVEL 3: {level_3_findings[:300]}

Check: Consistency, Progression, Gaps

Provide JSON with validation results."""
    
    # ============================================================================
    # MULTI-LEVEL SYNTHESIS
    # ============================================================================
    
    def get_multi_level_synthesis_prompt(
        self,
        level_1_analysis: str,
        level_2_analysis: str,
        level_3_analysis: str
    ) -> str:
        """Synthesize multi-level"""
        l1 = level_1_analysis[:400] + "..." if len(level_1_analysis) > 400 else level_1_analysis
        l2 = level_2_analysis[:400] + "..." if len(level_2_analysis) > 400 else level_2_analysis
        l3 = level_3_analysis[:400] + "..." if len(level_3_analysis) > 400 else level_3_analysis
        
        return f"""Synthesize 3 levels for "{self.rule_name}" in {self.jurisdiction}.

LEVEL 1 (Legislation): {l1}
LEVEL 2 (Guidance): {l2}
LEVEL 3 (Enterprise): {l3}

Provide comprehensive JSON integrating all levels."""
    
    # ============================================================================
    # CITATION EXTRACTION
    # ============================================================================
    
    def get_citation_extraction_prompt(self, text: str, claim: str) -> str:
        """Extract citations for claim"""
        text_truncated = text[:1500] + "..." if len(text) > 1500 else text
        
        return f"""Find citations for claim:

CLAIM: "{claim}"

TEXT:
{text_truncated}

Extract exact text excerpts (max 200 chars) supporting this claim.

Provide JSON with citations array."""
