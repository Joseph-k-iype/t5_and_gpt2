#!/usr/bin/env python3
"""
Advanced Hierarchical Multi-Level App Categorizer with Topic Modeling and Iterative Refinement
=============================================================================================

This system combines three sophisticated approaches:
1. Hierarchical Multi-Level Categorization (3 levels of taxonomy)
2. Topic Modeling Hybrid (semantic topic extraction + distribution analysis)  
3. Iterative Refinement (continuous improvement through multiple passes)

The system creates a comprehensive 3-level taxonomy:
- Level 1: Broad domains (Business, Technical, etc.)
- Level 2: Functional areas (CRM, Analytics, Security, etc.)
- Level 3: Specific capabilities (Lead Management, Threat Detection, etc.)

No fallback mechanisms - designed to always work with Phi4's reasoning capabilities.
"""

import pandas as pd
import openai
from openai import OpenAI
import json
import time
from collections import Counter, defaultdict
import logging
from typing import List, Dict, Tuple, Set
import itertools

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdvancedPhi4Categorizer:
    """
    Advanced multi-stage categorizer with hierarchical taxonomy, topic modeling, and iterative refinement
    """
    
    def __init__(self, api_key: str, base_url: str, model_name: str = "microsoft/phi-4"):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model_name = model_name
        self.topics_corpus = None
        self.hierarchical_taxonomy = None
        self.app_topic_distributions = None
        self.refinement_history = []
        
    def stage1_topic_discovery(self, descriptions: List[str]) -> Dict[str, any]:
        """
        Stage 1: Discover semantic topics across the entire corpus using Phi4
        """
        logger.info("Stage 1: Discovering semantic topics across corpus...")
        
        # Prepare corpus analysis
        corpus_sample = descriptions[:50] if len(descriptions) > 50 else descriptions
        corpus_text = "\n\n".join([f"App {i+1}: {desc}" for i, desc in enumerate(corpus_sample)])
        
        prompt = f"""
Analyze this corpus of {len(descriptions)} app/EUC descriptions and identify the underlying semantic topics that emerge across the entire dataset.

Sample descriptions:
{corpus_text}

Perform semantic topic modeling to discover:
1. Core functional domains that appear across multiple applications
2. Business areas that these applications serve
3. Technical patterns and architectural themes
4. Cross-cutting concerns and capabilities

Identify 15-25 distinct semantic topics that best represent the functional landscape of this application portfolio.

For each topic, provide:
- Topic name (concise, descriptive)
- Topic description (what this topic represents)
- Key semantic indicators (concepts/terms that signal this topic)

Respond with JSON:
{{
  "topics": [
    {{
      "name": "discovered_topic_name",
      "description": "what this topic represents based on the application descriptions",
      "indicators": ["list", "of", "semantic", "indicators", "found"]
    }}
  ]
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at semantic topic modeling and enterprise software analysis. Extract meaningful topics that represent functional domains."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        topics_data = json.loads(content)
        
        self.topics_corpus = topics_data
        logger.info(f"Discovered {len(topics_data['topics'])} semantic topics")
        return topics_data
    
    def stage2_hierarchical_taxonomy_creation(self, topics_data: Dict) -> Dict:
        """
        Stage 2: Create a 3-level hierarchical taxonomy from discovered topics
        """
        logger.info("Stage 2: Creating hierarchical multi-level taxonomy...")
        
        topics_list = "\n".join([
            f"- {topic['name']}: {topic['description']}" 
            for topic in topics_data['topics']
        ])
        
        prompt = f"""
Using these discovered semantic topics, create a comprehensive 3-level hierarchical taxonomy:

Discovered Topics:
{topics_list}

Create a hierarchy with exactly 3 levels:

LEVEL 1 (Domains): 4-6 broad organizational domains that emerge from the topics
LEVEL 2 (Areas): 3-5 functional areas within each domain that naturally group related topics
LEVEL 3 (Capabilities): 2-4 specific capabilities within each area that represent concrete functionalities

Design principles:
- Level 1: Identify the highest-level organizational domains that emerge from analyzing all topics
- Level 2: Within each domain, discover functional specializations that logically group related topics
- Level 3: Within each area, identify specific operational capabilities that represent concrete functionalities
- Map all discovered topics into this hierarchy based on their semantic relationships
- Ensure comprehensive coverage with no gaps
- Create logical parent-child relationships based purely on topic analysis
- Let the taxonomy emerge organically from the data without any preconceptions

Respond with JSON structure:
{{
  "level_1_domains": [
    {{
      "name": "discovered_domain_name",
      "description": "what this domain represents based on the topics",
      "level_2_areas": [
        {{
          "name": "discovered_area_name", 
          "description": "what this functional area represents",
          "level_3_capabilities": [
            {{
              "name": "discovered_capability_name",
              "description": "what this specific capability represents",
              "mapped_topics": ["list_of_topics_that_map_here"]
            }}
          ]
        }}
      ]
    }}
  ]
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at creating logical hierarchical taxonomies for enterprise systems. Create comprehensive, non-overlapping hierarchies."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        taxonomy = json.loads(content)
        
        self.hierarchical_taxonomy = taxonomy
        logger.info(f"Created hierarchical taxonomy with {len(taxonomy['level_1_domains'])} domains")
        return taxonomy
    
    def stage3_topic_distribution_analysis(self, descriptions: List[str], topics_data: Dict) -> List[Dict]:
        """
        Stage 3: Analyze topic distributions for each application
        """
        logger.info("Stage 3: Analyzing topic distributions per application...")
        
        app_distributions = []
        batch_size = 10
        
        for i in range(0, len(descriptions), batch_size):
            batch = descriptions[i:i+batch_size]
            batch_distributions = self._analyze_batch_topic_distributions(batch, topics_data)
            app_distributions.extend(batch_distributions)
            
            logger.info(f"Analyzed topic distributions for {min(i+batch_size, len(descriptions))}/{len(descriptions)} apps")
            time.sleep(1)
        
        self.app_topic_distributions = app_distributions
        return app_distributions
    
    def _analyze_batch_topic_distributions(self, descriptions: List[str], topics_data: Dict) -> List[Dict]:
        """
        Analyze topic distributions for a batch of applications
        """
        batch_text = ""
        for idx, desc in enumerate(descriptions, 1):
            batch_text += f"\nApp {idx}: {desc}\n"
        
        topics_list = "\n".join([
            f"- {topic['name']}: {topic['description']}"
            for topic in topics_data['topics']
        ])
        
        prompt = f"""
For each application description, analyze which semantic topics are present and their relative strength.

Available Topics:
{topics_list}

Application Descriptions:
{batch_text}

For each app, identify:
1. Primary topics (strongest relevance)
2. Secondary topics (moderate relevance) 
3. Tertiary topics (weak but present relevance)

Respond with JSON object where keys are app numbers and values contain topic analysis:
{{
  "1": {{
    "primary_topics": ["discovered_topic_1", "discovered_topic_2"],
    "secondary_topics": ["discovered_topic_3"],
    "tertiary_topics": ["discovered_topic_4"],
    "topic_reasoning": "explanation of why these topics were identified for this app"
  }}
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at analyzing application functionality and mapping it to semantic topics. Be precise and thorough."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        distributions = json.loads(content)
        
        # Convert to list format
        result = []
        for i in range(1, len(descriptions) + 1):
            if str(i) in distributions:
                result.append(distributions[str(i)])
            else:
                result.append({
                    "primary_topics": ["Uncategorized"],
                    "secondary_topics": [],
                    "tertiary_topics": [],
                    "topic_reasoning": "Could not analyze topic distribution"
                })
        
        return result
    
    def stage4_initial_hierarchical_mapping(self, app_distributions: List[Dict], taxonomy: Dict) -> List[Dict]:
        """
        Stage 4: Map applications to hierarchical taxonomy based on topic distributions
        """
        logger.info("Stage 4: Mapping applications to hierarchical taxonomy...")
        
        mappings = []
        batch_size = 15
        
        for i in range(0, len(app_distributions), batch_size):
            batch = app_distributions[i:i+batch_size]
            batch_mappings = self._map_batch_to_hierarchy(batch, taxonomy, i)
            mappings.extend(batch_mappings)
            
            logger.info(f"Mapped {min(i+batch_size, len(app_distributions))}/{len(app_distributions)} apps to hierarchy")
            time.sleep(1)
        
        return mappings
    
    def _map_batch_to_hierarchy(self, distributions_batch: List[Dict], taxonomy: Dict, batch_start_idx: int) -> List[Dict]:
        """
        Map a batch of applications to the hierarchical taxonomy
        """
        batch_info = ""
        for idx, dist in enumerate(distributions_batch, 1):
            batch_info += f"\nApp {idx}: Primary topics: {dist['primary_topics']}, Secondary: {dist['secondary_topics']}, Reasoning: {dist['topic_reasoning']}"
        
        # Flatten taxonomy for reference
        taxonomy_structure = self._flatten_taxonomy_for_prompt(taxonomy)
        
        prompt = f"""
Map each application to the most appropriate position in this hierarchical taxonomy based on their topic distributions.

Hierarchical Taxonomy:
{taxonomy_structure}

Applications to map:
{batch_info}

For each app, determine:
1. Level 1 Domain (primary organizational domain)
2. Level 2 Area (specific functional area)  
3. Level 3 Capability (most specific capability match)
4. Confidence level (High/Medium/Low)
5. Mapping reasoning

Respond with JSON:
{{
  "1": {{
    "level_1_domain": "discovered_domain_name",
    "level_2_area": "discovered_area_name",
    "level_3_capability": "discovered_capability_name",
    "confidence": "High/Medium/Low",
    "mapping_reasoning": "detailed explanation of why this app maps to this hierarchy position"
  }}
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at mapping applications to hierarchical taxonomies. Consider topic distributions and logical hierarchy placement."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        mappings = json.loads(content)
        
        # Convert to list format
        result = []
        for i in range(1, len(distributions_batch) + 1):
            if str(i) in mappings:
                result.append(mappings[str(i)])
            else:
                result.append({
                    "level_1_domain": "Unknown",
                    "level_2_area": "Unknown", 
                    "level_3_capability": "Unknown",
                    "confidence": "Low",
                    "mapping_reasoning": "Could not determine hierarchy placement"
                })
        
        return result
    
    def _flatten_taxonomy_for_prompt(self, taxonomy: Dict) -> str:
        """
        Flatten hierarchical taxonomy into a readable format for prompts
        """
        result = []
        for domain in taxonomy['level_1_domains']:
            result.append(f"\nDOMAIN: {domain['name']} - {domain['description']}")
            for area in domain['level_2_areas']:
                result.append(f"  AREA: {area['name']} - {area['description']}")
                for capability in area['level_3_capabilities']:
                    mapped_topics = ', '.join(capability.get('mapped_topics', []))
                    result.append(f"    CAPABILITY: {capability['name']} - {capability['description']} (Topics: {mapped_topics})")
        return '\n'.join(result)
    
    def stage5_consistency_analysis(self, mappings: List[Dict], app_distributions: List[Dict]) -> Dict:
        """
        Stage 5: Analyze consistency and identify refinement opportunities
        """
        logger.info("Stage 5: Analyzing consistency and identifying refinement opportunities...")
        
        # Gather mapping statistics
        confidence_dist = Counter([m['confidence'] for m in mappings])
        domain_dist = Counter([m['level_1_domain'] for m in mappings])
        area_dist = Counter([m['level_2_area'] for m in mappings])
        
        # Identify inconsistencies
        inconsistencies = []
        
        # Find low confidence mappings
        low_confidence = [i for i, m in enumerate(mappings) if m['confidence'] == 'Low']
        
        # Find similar topic distributions with different mappings
        similar_different_mappings = self._find_similar_topic_different_mappings(app_distributions, mappings)
        
        # Analyze for consistency improvement
        analysis_data = {
            'low_confidence_apps': low_confidence,
            'similar_different_mappings': similar_different_mappings,
            'confidence_distribution': dict(confidence_dist),
            'domain_distribution': dict(domain_dist),
            'area_distribution': dict(area_dist)
        }
        
        analysis_prompt = f"""
Analyze this categorization consistency data and identify specific improvements:

Confidence Distribution: {confidence_dist}
Low Confidence Apps: {len(low_confidence)} applications
Similar Topics, Different Mappings: {len(similar_different_mappings)} cases

Analysis Goals:
1. Identify taxonomy gaps or overlaps
2. Suggest specific hierarchy improvements
3. Recommend new categories if needed
4. Identify mapping rule refinements

Provide specific, actionable recommendations for taxonomy refinement.

Respond with JSON:
{{
  "issues_identified": [
    "specific issues discovered through consistency analysis"
  ],
  "taxonomy_improvements": [
    {{
      "type": "improvement_type",
      "domain": "affected_domain",
      "area": "affected_area", 
      "new_capability": "suggested_new_capability",
      "reasoning": "why this improvement is needed based on the data"
    }}
  ],
  "mapping_refinements": [
    "discovered rules for improving mapping accuracy based on the data patterns"
  ],
  "confidence_improvement_actions": [
    "specific actions to improve confidence based on the analysis"
  ]
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at analyzing categorization systems and identifying improvements. Provide specific, actionable recommendations."},
                {"role": "user", "content": analysis_prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        consistency_analysis = json.loads(content)
        
        consistency_analysis.update(analysis_data)
        return consistency_analysis
    
    def _find_similar_topic_different_mappings(self, distributions: List[Dict], mappings: List[Dict]) -> List[Tuple]:
        """
        Find applications with similar topic distributions but different hierarchy mappings
        """
        similar_pairs = []
        
        for i in range(len(distributions)):
            for j in range(i+1, len(distributions)):
                # Check topic similarity
                topics_i = set(distributions[i]['primary_topics'] + distributions[i]['secondary_topics'])
                topics_j = set(distributions[j]['primary_topics'] + distributions[j]['secondary_topics'])
                
                overlap = len(topics_i.intersection(topics_j))
                union = len(topics_i.union(topics_j))
                
                if union > 0 and (overlap / union) > 0.6:  # 60% topic similarity
                    # Check if mappings are different
                    mapping_i = f"{mappings[i]['level_1_domain']}-{mappings[i]['level_2_area']}"
                    mapping_j = f"{mappings[j]['level_1_domain']}-{mappings[j]['level_2_area']}"
                    
                    if mapping_i != mapping_j:
                        similar_pairs.append((i, j, overlap/union))
        
        return similar_pairs
    
    def stage6_taxonomy_refinement(self, consistency_analysis: Dict, current_taxonomy: Dict) -> Dict:
        """
        Stage 6: Refine taxonomy based on consistency analysis
        """
        logger.info("Stage 6: Refining taxonomy based on consistency analysis...")
        
        current_taxonomy_str = json.dumps(current_taxonomy, indent=2)
        improvements = json.dumps(consistency_analysis['taxonomy_improvements'], indent=2)
        
        prompt = f"""
Refine this hierarchical taxonomy based on the identified improvements:

Current Taxonomy:
{current_taxonomy_str}

Required Improvements:
{improvements}

Apply the improvements while maintaining:
1. Logical hierarchical structure
2. Comprehensive coverage 
3. Non-overlapping categories
4. Clear parent-child relationships

Return the refined taxonomy in the same JSON format, incorporating all suggested improvements.
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at refining taxonomies. Apply improvements while maintaining logical structure and comprehensive coverage."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        refined_taxonomy = json.loads(content)
        
        self.hierarchical_taxonomy = refined_taxonomy
        self.refinement_history.append({
            'iteration': len(self.refinement_history) + 1,
            'improvements_applied': consistency_analysis['taxonomy_improvements'],
            'issues_addressed': consistency_analysis['issues_identified']
        })
        
        logger.info("Taxonomy refinement completed")
        return refined_taxonomy
    
    def stage7_final_mapping(self, app_distributions: List[Dict], refined_taxonomy: Dict) -> List[Dict]:
        """
        Stage 7: Final mapping with refined taxonomy
        """
        logger.info("Stage 7: Final mapping with refined taxonomy...")
        
        final_mappings = []
        batch_size = 15
        
        for i in range(0, len(app_distributions), batch_size):
            batch = app_distributions[i:i+batch_size]
            batch_mappings = self._final_map_batch(batch, refined_taxonomy)
            final_mappings.extend(batch_mappings)
            
            logger.info(f"Final mapping: {min(i+batch_size, len(app_distributions))}/{len(app_distributions)} apps")
            time.sleep(1)
        
        return final_mappings
    
    def _final_map_batch(self, distributions_batch: List[Dict], taxonomy: Dict) -> List[Dict]:
        """
        Final mapping with refined taxonomy and improved accuracy
        """
        batch_info = ""
        for idx, dist in enumerate(distributions_batch, 1):
            all_topics = dist['primary_topics'] + dist['secondary_topics'] + dist['tertiary_topics']
            batch_info += f"\nApp {idx}: All topics: {all_topics}, Reasoning: {dist['topic_reasoning']}"
        
        taxonomy_structure = self._flatten_taxonomy_for_prompt(taxonomy)
        
        prompt = f"""
Perform final precise mapping of applications to the refined hierarchical taxonomy.

Refined Taxonomy:
{taxonomy_structure}

Applications:
{batch_info}

Use refined mapping rules:
1. Consider ALL topic levels (primary, secondary, tertiary)
2. Use topic reasoning for context
3. Choose most specific appropriate capability
4. Aim for High confidence whenever possible
5. Provide detailed reasoning for each mapping

Respond with JSON:
{{
  "1": {{
    "level_1_domain": "discovered_domain",
    "level_2_area": "discovered_area", 
    "level_3_capability": "discovered_capability",
    "confidence": "High/Medium/Low",
    "mapping_reasoning": "detailed reasoning for this specific mapping based on topic analysis",
    "supporting_topics": ["list", "of", "key", "supporting", "topics"],
    "hierarchy_path": "Domain > Area > Capability"
  }}
}}
"""

        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "You are an expert at precise application categorization. Use the refined taxonomy to create accurate, high-confidence mappings."},
                {"role": "user", "content": prompt}
            ]
        )
        
        content = response.choices[0].message.content.strip()
        content = content.replace('```json', '').replace('```', '').strip()
        mappings = json.loads(content)
        
        # Convert to list format with hierarchy path
        result = []
        for i in range(1, len(distributions_batch) + 1):
            if str(i) in mappings:
                mapping = mappings[str(i)]
                mapping['hierarchy_path'] = f"{mapping['level_1_domain']} > {mapping['level_2_area']} > {mapping['level_3_capability']}"
                result.append(mapping)
            else:
                result.append({
                    "level_1_domain": "Unknown",
                    "level_2_area": "Unknown",
                    "level_3_capability": "Unknown", 
                    "confidence": "Low",
                    "mapping_reasoning": "Final mapping failed",
                    "supporting_topics": [],
                    "hierarchy_path": "Unknown > Unknown > Unknown"
                })
        
        return result
    
    def process_csv(self, csv_file_path: str) -> Tuple[pd.DataFrame, Dict, Dict]:
        """
        Execute the complete advanced processing pipeline
        """
        logger.info("Starting advanced hierarchical processing pipeline...")
        
        # Read and validate CSV
        df = pd.read_csv(csv_file_path)
        if 'name' not in df.columns or 'description' not in df.columns:
            raise ValueError("CSV must contain 'name' and 'description' columns")
        
        descriptions = df['description'].fillna("").tolist()
        
        # Execute all stages
        topics_data = self.stage1_topic_discovery(descriptions)
        initial_taxonomy = self.stage2_hierarchical_taxonomy_creation(topics_data)
        app_distributions = self.stage3_topic_distribution_analysis(descriptions, topics_data)
        initial_mappings = self.stage4_initial_hierarchical_mapping(app_distributions, initial_taxonomy)
        consistency_analysis = self.stage5_consistency_analysis(initial_mappings, app_distributions)
        refined_taxonomy = self.stage6_taxonomy_refinement(consistency_analysis, initial_taxonomy)
        final_mappings = self.stage7_final_mapping(app_distributions, refined_taxonomy)
        
        # Add comprehensive results to dataframe
        df['primary_topics'] = [dist['primary_topics'] for dist in app_distributions]
        df['secondary_topics'] = [dist['secondary_topics'] for dist in app_distributions]
        df['tertiary_topics'] = [dist['tertiary_topics'] for dist in app_distributions]
        df['topic_reasoning'] = [dist['topic_reasoning'] for dist in app_distributions]
        
        df['level_1_domain'] = [mapping['level_1_domain'] for mapping in final_mappings]
        df['level_2_area'] = [mapping['level_2_area'] for mapping in final_mappings] 
        df['level_3_capability'] = [mapping['level_3_capability'] for mapping in final_mappings]
        df['hierarchy_path'] = [mapping['hierarchy_path'] for mapping in final_mappings]
        df['confidence'] = [mapping['confidence'] for mapping in final_mappings]
        df['mapping_reasoning'] = [mapping['mapping_reasoning'] for mapping in final_mappings]
        df['supporting_topics'] = [mapping['supporting_topics'] for mapping in final_mappings]
        
        # String representations for easy viewing
        df['all_topics'] = df.apply(lambda row: ', '.join(row['primary_topics'] + row['secondary_topics'] + row['tertiary_topics']), axis=1)
        
        analysis_results = {
            'topics_discovered': topics_data,
            'initial_taxonomy': initial_taxonomy,
            'refined_taxonomy': refined_taxonomy,
            'consistency_analysis': consistency_analysis,
            'refinement_history': self.refinement_history,
            'processing_metadata': {
                'total_apps': len(df),
                'topics_count': len(topics_data['topics']),
                'domains_count': len(refined_taxonomy['level_1_domains']),
                'final_confidence_distribution': Counter(df['confidence'])
            }
        }
        
        return df, refined_taxonomy, analysis_results
    
    def generate_comprehensive_report(self, df: pd.DataFrame, taxonomy: Dict, analysis: Dict) -> str:
        """
        Generate comprehensive analysis report
        """
        report = []
        report.append("=" * 80)
        report.append("ADVANCED HIERARCHICAL CATEGORIZATION REPORT")
        report.append("Multi-Level Taxonomy + Topic Modeling + Iterative Refinement")
        report.append("=" * 80)
        report.append("")
        
        # Executive Summary
        report.append("EXECUTIVE SUMMARY")
        report.append("-" * 30)
        metadata = analysis['processing_metadata']
        report.append(f"Applications Analyzed: {metadata['total_apps']}")
        report.append(f"Semantic Topics Discovered: {metadata['topics_count']}")
        report.append(f"Hierarchical Domains Created: {metadata['domains_count']}")
        report.append(f"Refinement Iterations: {len(analysis['refinement_history'])}")
        report.append(f"High Confidence Mappings: {metadata['final_confidence_distribution'].get('High', 0)}")
        report.append("")
        
        # Discovered Topics
        report.append("DISCOVERED SEMANTIC TOPICS")
        report.append("-" * 35)
        for topic in analysis['topics_discovered']['topics']:
            report.append(f"• {topic['name']}")
            report.append(f"  {topic['description']}")
            report.append(f"  Indicators: {', '.join(topic['indicators'])}")
            report.append("")
        
        # Hierarchical Taxonomy
        report.append("FINAL HIERARCHICAL TAXONOMY")
        report.append("-" * 40)
        for domain in taxonomy['level_1_domains']:
            report.append(f"\n📁 DOMAIN: {domain['name']}")
            report.append(f"   {domain['description']}")
            
            for area in domain['level_2_areas']:
                report.append(f"   └── 📂 AREA: {area['name']}")
                report.append(f"       {area['description']}")
                
                for capability in area['level_3_capabilities']:
                    app_count = len(df[df['level_3_capability'] == capability['name']])
                    report.append(f"       └── 📄 CAPABILITY: {capability['name']} ({app_count} apps)")
                    report.append(f"           {capability['description']}")
        report.append("")
        
        # Distribution Analysis
        report.append("DISTRIBUTION ANALYSIS")
        report.append("-" * 30)
        
        domain_counts = Counter(df['level_1_domain'])
        report.append("By Domain:")
        for domain, count in domain_counts.most_common():
            percentage = (count / len(df)) * 100
            report.append(f"  {domain:30} {count:3d} apps ({percentage:5.1f}%)")
        report.append("")
        
        confidence_counts = Counter(df['confidence'])
        report.append("Confidence Distribution:")
        for confidence, count in confidence_counts.most_common():
            percentage = (count / len(df)) * 100
            report.append(f"  {confidence:15} {count:3d} apps ({percentage:5.1f}%)")
        report.append("")
        
        # Refinement History
        if analysis['refinement_history']:
            report.append("ITERATIVE REFINEMENT HISTORY")
            report.append("-" * 35)
            for iteration in analysis['refinement_history']:
                report.append(f"Iteration {iteration['iteration']}:")
                report.append(f"  Issues Addressed: {len(iteration['issues_addressed'])}")
                report.append(f"  Improvements Applied: {len(iteration['improvements_applied'])}")
                for improvement in iteration['improvements_applied']:
                    report.append(f"    • {improvement.get('type', 'Unknown')}: {improvement.get('reasoning', 'No reasoning provided')}")
                report.append("")
        
        # Sample Applications by Domain
        report.append("SAMPLE APPLICATIONS BY DOMAIN")
        report.append("-" * 40)
        for domain in domain_counts.keys():
            domain_apps = df[df['level_1_domain'] == domain].head(3)
            report.append(f"\n{domain}:")
            for _, app in domain_apps.iterrows():
                report.append(f"  • {app['name']}")
                report.append(f"    Path: {app['hierarchy_path']}")
                report.append(f"    Topics: {', '.join(app['primary_topics'])}")
                report.append(f"    Confidence: {app['confidence']}")
        
        return "\n".join(report)

def main():
    """
    Execute advanced hierarchical categorization
    """
    
    # ================================
    # CONFIGURATION
    # ================================
    
    API_KEY = "your_phi4_api_key_here"
    BASE_URL = "https://api.deepinfra.com/v1/openai"
    MODEL_NAME = "microsoft/phi-4"
    
    INPUT_CSV = "apps_data.csv"
    OUTPUT_CSV = "apps_hierarchical_categorized.csv"
    TAXONOMY_FILE = "hierarchical_taxonomy.json"
    ANALYSIS_FILE = "complete_analysis.json"
    REPORT_FILE = "advanced_categorization_report.txt"
    
    # ================================
    # PROCESSING
    # ================================
    
    try:
        categorizer = AdvancedPhi4Categorizer(
            api_key=API_KEY,
            base_url=BASE_URL,
            model_name=MODEL_NAME
        )
        
        # Execute complete pipeline
        df_result, final_taxonomy, analysis_results = categorizer.process_csv(INPUT_CSV)
        
        # Generate comprehensive report
        report = categorizer.generate_comprehensive_report(df_result, final_taxonomy, analysis_results)
        
        # Save all results
        df_result.to_csv(OUTPUT_CSV, index=False)
        
        with open(TAXONOMY_FILE, 'w', encoding='utf-8') as f:
            json.dump(final_taxonomy, f, indent=2, ensure_ascii=False)
        
        with open(ANALYSIS_FILE, 'w', encoding='utf-8') as f:
            json.dump(analysis_results, f, indent=2, ensure_ascii=False, default=str)
        
        with open(REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(report)
        
        # Display results summary
        print("\n" + "="*80)
        print("ADVANCED HIERARCHICAL CATEGORIZATION COMPLETE!")
        print("="*80)
        metadata = analysis_results['processing_metadata']
        print(f"✓ Analyzed {metadata['total_apps']} applications")
        print(f"✓ Discovered {metadata['topics_count']} semantic topics")
        print(f"✓ Created {metadata['domains_count']}-domain hierarchical taxonomy")
        print(f"✓ Performed {len(analysis_results['refinement_history'])} refinement iterations")
        print(f"✓ Achieved {metadata['final_confidence_distribution'].get('High', 0)} high-confidence mappings")
        print(f"\n📁 Results saved:")
        print(f"   • Categorized data: {OUTPUT_CSV}")
        print(f"   • Hierarchical taxonomy: {TAXONOMY_FILE}")
        print(f"   • Complete analysis: {ANALYSIS_FILE}")
        print(f"   • Comprehensive report: {REPORT_FILE}")
        
        print(f"\n{report}")
        
    except Exception as e:
        logger.error(f"Advanced processing failed: {e}")
        raise

if __name__ == "__main__":
    main()
