mport pandas as pd
import requests
from time import sleep
from pandas import json_normalize

# Load the CSV file to get IDs
df_input = pd.read_csv('your_data.csv')

# API endpoint base URL
api_base_url = 'https://your-api-endpoint.com/path'

# Headers if needed
headers = {
    'Content-Type': 'application/json'
    # Add other headers if required
}

# List to store all results
results = []

# Counter for progress tracking
total_records = len(df_input)
successful_requests = 0

# Iterate through each ID in the DataFrame
for index, row in df_input.iterrows():
    # Get the ID
    record_id = row['id']
    
    # Construct the URL with ID as a parameter
    url = f"{api_base_url}?id={record_id}"
    
    print(f"Processing {index+1}/{total_records}: ID {record_id}")
    
    try:
        # Make GET request
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        
        # Parse the JSON response
        data = response.json()
        
        # Add the data to our results list
        results.append(data)
        successful_requests += 1
        
    except requests.exceptions.RequestException as e:
        print(f"Error fetching ID {record_id}: {str(e)}")
        print(f"Response content: {response.text if 'response' in locals() else 'No response'}")
    
    # Optional: Add delay between requests to avoid rate limiting
    sleep(0.2)

print(f"Completed: {successful_requests} successful out of {total_records} attempts")

# Convert results to DataFrame with proper structure
if results:
    try:
        # Try to normalize the JSON data (for nested structures)
        # This converts nested JSON objects into columns with dot notation
        df_results = json_normalize(results)
        
        # If the API returns data in a nested structure like {"data_element": {...}}
        # Uncomment and modify this:
        # df_results = json_normalize(results, record_path=['data_element'])
        # or
        # df_results = json_normalize([r.get('data_element', {}) for r in results])
        
        # Clean up column names if needed (remove prefixes)
        # df_results.columns = [col.split('.')[-1] if '.' in col else col for col in df_results.columns]
        
        print("\nResults DataFrame:")
        print(df_results.head())
        
        # Save to CSV
        df_results.to_csv('api_results.csv', index=False)
        print("Results saved to api_results.csv")
    
    except Exception as e:
        print(f"Error creating DataFrame: {str(e)}")
        print("Falling back to manual flattening...")
        
        # Fallback: manually flatten nested JSON structure
        flat_data = []
        for item in results:
            flat_item = flatten_nested_dict(item)
            flat_data.append(flat_item)
        
        df_results = pd.DataFrame(flat_data)
        print("\nResults DataFrame (using manual flattening):")
        print(df_results.head())
        
        # Save to CSV
        df_results.to_csv('api_results.csv', index=False)
        print("Results saved to api_results.csv")
else:
    print("No results to process")

# Helper function to flatten nested dictionaries
def flatten_nested_dict(nested_dict, parent_key='', sep='_'):
    """Flatten a nested dictionary into a single level dictionary."""
    items = []
    for k, v in nested_dict.items():
        new_key = f"{parent_key}{sep}{k}" if parent_key else k
        if isinstance(v, dict):
            items.extend(flatten_nested_dict(v, new_key, sep=sep).items())
        else:
            items.append((new_key, v))
    return dict(items)
