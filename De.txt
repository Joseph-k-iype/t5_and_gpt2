"""
LangGraph-based Legislation to Machine-Readable JSON Rules Converter
Clean implementation with o3-mini and proper tool calling
Enhanced with Chain of Thought, Mixture of Thought, and Mixture of Reasoning
Focused on Data Governance Rules (Usage, Transfer, Storage, Access)
"""

import json
import re
import time
import os
from typing import List, Dict, Any, Optional, Annotated, Sequence, TypedDict, Literal
from enum import Enum

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field


# ========================= Global Configuration =========================

# Global model configuration for o3-mini
OPENAI_MODEL = "o3-mini"
OPENAI_BASE_URL = "https://api.openai.com/v1"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
REASONING_EFFORT = "high"  # high, medium, or low

# Global model instance
def get_model():
    """Get configured o3-mini model instance"""
    return ChatOpenAI(
        model=OPENAI_MODEL,
        base_url=OPENAI_BASE_URL,
        api_key=OPENAI_API_KEY,
        model_kwargs={
            "reasoning_effort": REASONING_EFFORT,
            "max_completion_tokens": 4000
        }
    )


# ========================= State Management =========================

class AgentState(TypedDict):
    """State for the legislation processing agent"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    legislation_text: str
    current_phase: str
    extracted_rules: Dict[str, List[Dict[str, Any]]]
    json_rules: List[Dict[str, Any]]
    validation_results: Dict[str, Any]


# ========================= Pydantic Models for Tools =========================

class AnalyzeWithReasoningInput(BaseModel):
    legislation_text: str = Field(..., description="Legislation text to analyze")
    reasoning_pathway: str = Field(..., description="Reasoning pathway: structural/semantic/logical/contextual/compliance")
    reasoning_mode: str = Field(..., description="Reasoning mode: deductive/inductive/abductive/analogical/causal")
    focus_domain: str = Field(..., description="Focus domain: data_usage/data_transfer/data_storage/data_access")


class ExtractDataRulesInput(BaseModel):
    legislation_text: str = Field(..., description="Legislation text to extract rules from")
    data_domain: str = Field(..., description="Domain: data_usage/data_transfer/data_storage/data_access")


class SynthesizeRulesInput(BaseModel):
    all_extracted_rules: Dict[str, List[Dict[str, Any]]] = Field(..., description="All extracted rules by domain")


class ConvertToJsonRulesInput(BaseModel):
    synthesized_rules: List[Dict[str, Any]] = Field(..., description="Synthesized rules to convert")


class ValidateJsonRulesInput(BaseModel):
    json_rules: List[Dict[str, Any]] = Field(..., description="JSON rules to validate")


# ========================= Tool Definitions =========================

@tool(args_schema=AnalyzeWithReasoningInput)
def analyze_with_reasoning(
    legislation_text: str,
    reasoning_pathway: str,
    reasoning_mode: str,
    focus_domain: str
) -> str:
    """Analyze legislation using o3-mini's reasoning capabilities"""
    
    pathway_prompts = {
        "structural": f"Analyze the STRUCTURE focusing on {focus_domain}: sections, hierarchy, organization",
        "semantic": f"Analyze the MEANING focusing on {focus_domain}: definitions, intent, stakeholder obligations", 
        "logical": f"Extract LOGICAL RELATIONSHIPS for {focus_domain}: conditions, requirements, prohibitions",
        "contextual": f"Understand the CONTEXT for {focus_domain}: regulatory environment, exceptions, deadlines",
        "compliance": f"Extract COMPLIANCE REQUIREMENTS for {focus_domain}: obligations, penalties, enforcement"
    }
    
    mode_prompts = {
        "deductive": "Apply top-down reasoning from general principles to specific rules",
        "inductive": "Apply bottom-up reasoning from specific patterns to general rules", 
        "abductive": "Find the best explanation for the legislative intent",
        "analogical": "Compare with standard data governance frameworks",
        "causal": "Identify cause-effect chains and triggers"
    }
    
    analysis_prompt = f"""
    {pathway_prompts.get(reasoning_pathway, pathway_prompts["structural"])}
    
    Reasoning Mode: {mode_prompts.get(reasoning_mode, mode_prompts["deductive"])}
    
    Legislation Text:
    {legislation_text}
    
    Provide structured analysis for {focus_domain} with:
    - Key findings
    - Relevant sections  
    - Requirements and prohibitions
    - Compliance obligations
    """
    
    model = get_model()
    response = model.invoke(analysis_prompt)
    
    return f"ANALYSIS ({reasoning_pathway}+{reasoning_mode} ‚Üí {focus_domain}):\n{response.content}"


@tool(args_schema=ExtractDataRulesInput)
def extract_data_rules(legislation_text: str, data_domain: str) -> str:
    """Extract specific data governance rules for a domain"""
    
    domain_instructions = {
        "data_usage": "Extract rules about how data can/cannot be used, consent requirements, purpose limitations",
        "data_transfer": "Extract rules about data sharing, cross-border transfers, third-party restrictions",
        "data_storage": "Extract rules about retention, deletion, encryption, storage location requirements", 
        "data_access": "Extract rules about who can access data, authentication, audit trails, subject rights"
    }
    
    extraction_prompt = f"""
    Extract ALL {data_domain} rules from this legislation.
    
    Focus: {domain_instructions.get(data_domain, "Extract relevant rules")}
    
    Legislation:
    {legislation_text}
    
    For each rule found, extract:
    - Clear description
    - Conditions when it applies
    - Requirements (what must be done)
    - Prohibitions (what cannot be done)
    - Consequences of violations
    
    Return as JSON array with this exact structure:
    [
        {{
            "rule_id": "unique_id",
            "domain": "{data_domain}",
            "description": "rule description", 
            "conditions": ["condition1", "condition2"],
            "requirements": ["requirement1", "requirement2"],
            "prohibitions": ["prohibition1", "prohibition2"],
            "consequences": ["consequence1", "consequence2"],
            "confidence": 0.9
        }}
    ]
    
    Return ONLY the JSON array, no other text.
    """
    
    model = get_model()
    response = model.invoke(extraction_prompt)
    
    return response.content


@tool(args_schema=SynthesizeRulesInput)
def synthesize_rules(all_extracted_rules: Dict[str, List[Dict[str, Any]]]) -> str:
    """Synthesize rules from all domains into coherent set"""
    
    synthesis_prompt = f"""
    Synthesize these extracted rules into a coherent, non-redundant set:
    
    {json.dumps(all_extracted_rules, indent=2)}
    
    Requirements:
    1. Remove exact duplicates
    2. Merge related rules addressing same topic
    3. Resolve conflicts between rules
    4. Ensure logical consistency
    5. Assign priority levels (1-100)
    
    Return JSON array of synthesized rules:
    [
        {{
            "rule_id": "unique_id",
            "domain": "domain_name",
            "description": "clear description",
            "conditions": ["condition1"],
            "requirements": ["requirement1"], 
            "prohibitions": ["prohibition1"],
            "consequences": ["consequence1"],
            "priority": 75,
            "confidence": 0.85
        }}
    ]
    
    Return ONLY the JSON array.
    """
    
    model = get_model()
    response = model.invoke(synthesis_prompt)
    
    return response.content


@tool(args_schema=ConvertToJsonRulesInput)
def convert_to_json_rules(synthesized_rules: List[Dict[str, Any]]) -> str:
    """Convert to json-rules-engine format"""
    
    conversion_prompt = f"""
    Convert these rules to json-rules-engine format:
    
    {json.dumps(synthesized_rules, indent=2)}
    
    Use this json-rules-engine structure:
    [
        {{
            "name": "rule_name",
            "conditions": {{
                "all": [
                    {{
                        "fact": "dataOperation",
                        "operator": "equal", 
                        "value": "usage"
                    }},
                    {{
                        "fact": "userConsent",
                        "operator": "equal",
                        "value": true
                    }}
                ]
            }},
            "event": {{
                "type": "data_governance_rule",
                "params": {{
                    "ruleId": "rule_id",
                    "domain": "data_usage",
                    "action": "enforce_consent_check",
                    "message": "User consent required for data usage"
                }}
            }},
            "priority": 80
        }}
    ]
    
    Available facts: dataOperation, userConsent, dataEncrypted, userAuthorized, crossBorderTransfer, dataType, retentionPeriod
    Available operators: equal, notEqual, lessThan, greaterThan, in, contains
    
    Return ONLY the JSON array of json-rules-engine formatted rules.
    """
    
    model = get_model()
    response = model.invoke(conversion_prompt)
    
    return response.content


@tool(args_schema=ValidateJsonRulesInput)
def validate_json_rules(json_rules: List[Dict[str, Any]]) -> str:
    """Validate json-rules-engine compatibility"""
    
    validation_prompt = f"""
    Validate these JSON rules for json-rules-engine compatibility:
    
    {json.dumps(json_rules, indent=2)}
    
    Check:
    1. Required fields: name, conditions, event
    2. Valid operators and fact names
    3. Proper condition structure  
    4. Event type and params structure
    5. Priority values are numbers
    6. Overall rule logic makes sense
    
    Return validation report:
    {{
        "valid": true,
        "total_rules": 5,
        "valid_rules": 5,
        "invalid_rules": 0,
        "errors": [],
        "warnings": [],
        "domain_coverage": {{
            "data_usage": 2,
            "data_transfer": 1, 
            "data_storage": 1,
            "data_access": 1
        }},
        "quality_score": 95
    }}
    
    Return ONLY the JSON validation report.
    """
    
    model = get_model()
    response = model.invoke(validation_prompt)
    
    return response.content


# ========================= Agent Nodes =========================

def agent_node(state: AgentState) -> Dict[str, Any]:
    """Main reasoning agent that decides which tools to call"""
    
    messages = state["messages"]
    current_phase = state.get("current_phase", "start")
    legislation_text = state.get("legislation_text", "")
    
    model = get_model()
    tools = [analyze_with_reasoning, extract_data_rules, synthesize_rules, convert_to_json_rules, validate_json_rules]
    model_with_tools = model.bind_tools(tools)
    
    # Phase-specific system prompts
    if current_phase == "start":
        system_msg = f"""You are an expert legal analyst. Process this legislation through systematic phases:

PHASE 1: Analysis (call analyze_with_reasoning 4 times with different approaches)
PHASE 2: Extraction (call extract_data_rules for each domain) 
PHASE 3: Synthesis (call synthesize_rules)
PHASE 4: Conversion (call convert_to_json_rules)
PHASE 5: Validation (call validate_json_rules)

Start with PHASE 1: Call analyze_with_reasoning to analyze the legislation.

Legislation: {legislation_text[:1000]}..."""
        
        new_messages = [SystemMessage(content=system_msg)] + list(messages)
        
    else:
        new_messages = list(messages)
    
    response = model_with_tools.invoke(new_messages)
    
    return {
        "messages": [response],
        "current_phase": "processing"
    }


def tool_node(state: AgentState) -> Dict[str, Any]:
    """Execute tools and update state"""
    
    tools = [analyze_with_reasoning, extract_data_rules, synthesize_rules, convert_to_json_rules, validate_json_rules]
    tool_node_instance = ToolNode(tools)
    result = tool_node_instance.invoke(state)
    
    # Parse tool results and update state
    messages = result.get("messages", [])
    updates = {"messages": messages}
    
    # Extract structured data from tool responses
    extracted_rules = state.get("extracted_rules", {})
    
    for message in messages:
        if isinstance(message, ToolMessage):
            content = message.content.strip()
            
            # Parse JSON responses
            try:
                if content.startswith('[') or content.startswith('{'):
                    # Remove markdown formatting if present
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0].strip()
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0].strip()
                    
                    parsed_data = json.loads(content)
                    
                    # Update state based on tool name
                    if message.name == "extract_data_rules" and isinstance(parsed_data, list):
                        # Determine domain from the rules
                        for rule in parsed_data:
                            if isinstance(rule, dict):
                                domain = rule.get("domain", "unknown")
                                if domain not in extracted_rules:
                                    extracted_rules[domain] = []
                                extracted_rules[domain].append(rule)
                    
                    elif message.name == "convert_to_json_rules" and isinstance(parsed_data, list):
                        updates["json_rules"] = parsed_data
                    
                    elif message.name == "validate_json_rules" and isinstance(parsed_data, dict):
                        updates["validation_results"] = parsed_data
                        
            except json.JSONDecodeError:
                pass
    
    if extracted_rules:
        updates["extracted_rules"] = extracted_rules
    
    return updates


def should_continue(state: AgentState) -> Literal["tools", "end"]:
    """Decide whether to continue processing or end"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # Continue if there are tool calls to execute
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    
    return "end"


# ========================= Create Graph =========================

def create_legislation_processing_graph():
    """Create the LangGraph workflow"""
    
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)
    
    # Set entry point
    workflow.set_entry_point("agent")
    
    # Add edges
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "end": END
        }
    )
    
    workflow.add_edge("tools", "agent")
    
    # Compile with memory
    memory = MemorySaver()
    return workflow.compile(checkpointer=memory)


# ========================= Main Processing Function =========================

def process_legislation(legislation_text: str) -> Dict[str, Any]:
    """Process legislation using the LangGraph agent"""
    
    print("üöÄ Processing legislation with o3-mini...")
    
    # Create the processing graph
    graph = create_legislation_processing_graph()
    
    # Initial state
    initial_state = {
        "messages": [HumanMessage(content=f"Process this legislation to extract data governance rules:\n\n{legislation_text}")],
        "legislation_text": legislation_text,
        "current_phase": "start",
        "extracted_rules": {},
        "json_rules": [],
        "validation_results": {}
    }
    
    # Configuration for memory
    config = {"configurable": {"thread_id": "legislation_processing"}}
    
    try:
        # Run the graph
        final_state = graph.invoke(initial_state, config)
        
        return {
            "status": "completed",
            "extracted_rules": final_state.get("extracted_rules", {}),
            "json_rules": final_state.get("json_rules", []),
            "validation_results": final_state.get("validation_results", {}),
            "messages": final_state.get("messages", [])
        }
        
    except Exception as e:
        print(f"‚ùå Error during processing: {e}")
        return {"status": "error", "error": str(e)}


# ========================= Helper Functions =========================

def save_rules_to_file(rules: List[Dict[str, Any]], filename: str = "data_governance_rules.json"):
    """Save JSON rules to file"""
    output = {
        "rules": rules,
        "metadata": {
            "created_by": "legislation_converter_o3mini",
            "model": OPENAI_MODEL,
            "reasoning_effort": REASONING_EFFORT,
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "rule_count": len(rules)
        }
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"‚úÖ Saved {len(rules)} rules to {filename}")


def print_results_summary(results: Dict[str, Any]):
    """Print processing results summary"""
    print("\n" + "="*60)
    print("üìä PROCESSING RESULTS SUMMARY")
    print("="*60)
    
    extracted = results.get("extracted_rules", {})
    total_extracted = sum(len(rules) for rules in extracted.values())
    print(f"Extracted Rules: {total_extracted}")
    for domain, rules in extracted.items():
        print(f"  ‚Ä¢ {domain}: {len(rules)} rules")
    
    json_rules = results.get("json_rules", [])
    print(f"Final JSON Rules: {len(json_rules)}")
    
    validation = results.get("validation_results", {})
    if validation:
        print(f"Validation Score: {validation.get('quality_score', 'N/A')}")
        print(f"Valid Rules: {validation.get('valid_rules', 0)}/{validation.get('total_rules', 0)}")
    
    if json_rules:
        print(f"\nüìÑ Sample Rule:")
        sample = json_rules[0]
        print(f"  Name: {sample.get('name', 'N/A')}")
        print(f"  Priority: {sample.get('priority', 'N/A')}")
        conditions = sample.get('conditions', {}).get('all', [])
        print(f"  Conditions: {len(conditions)}")


# ========================= Main Execution =========================

if __name__ == "__main__":
    # Check API key
    if not os.getenv("OPENAI_API_KEY"):
        print("‚ö†Ô∏è Please set OPENAI_API_KEY environment variable")
        print("   export OPENAI_API_KEY='your-openai-api-key'")
        exit(1)
    
    # Sample legislation
    SAMPLE_LEGISLATION = """
    DATA PROTECTION AND PRIVACY ACT
    
    PART II - DATA USAGE REQUIREMENTS
    
    Section 2. Lawful Basis for Data Usage
    2.1 Personal data shall only be used when there is a lawful basis, including:
        (a) The data subject has given explicit consent
        (b) Processing is necessary for contract performance
        (c) Processing is required for legal compliance
    
    2.2 Data controllers must not use personal data for purposes incompatible with those for which it was originally collected.
    
    PART III - DATA TRANSFER REGULATIONS
    
    Section 5. Third-Party Data Transfers
    5.1 Data controllers shall not transfer personal data to third parties unless:
        (a) A data processing agreement is in place
        (b) The third party provides appropriate security guarantees
        (c) The data subject has been informed of the transfer
    
    5.2 Cross-border transfers of personal data are prohibited unless:
        (a) The recipient country ensures adequate protection
        (b) Appropriate safeguards are implemented
        (c) The data subject has explicitly consented to the transfer
    
    PART IV - DATA STORAGE REQUIREMENTS
    
    Section 7. Storage Duration and Retention
    7.1 Personal data shall not be stored longer than necessary for the purposes for which it was collected.
    7.2 Data retention periods must be defined and documented for each category of personal data.
    
    Section 8. Storage Security Requirements
    8.1 Data controllers must implement appropriate technical measures including:
        (a) Encryption of personal data at rest
        (b) Regular backups with tested recovery procedures
    
    PART V - DATA ACCESS CONTROLS
    
    Section 10. Access Rights and Permissions
    10.1 Data controllers must implement role-based access controls ensuring:
        (a) Access is granted on a need-to-know basis
        (b) Privileged access is monitored and reviewed quarterly
    
    10.2 Authentication requirements:
        (a) Multi-factor authentication for accessing sensitive data
        (b) Strong password policies enforced
    """
    
    print("üöÄ Data Governance Rules Extractor")
    print(f"ü§ñ Model: {OPENAI_MODEL} (reasoning effort: {REASONING_EFFORT})")
    print("=" * 60)
    
    # Process the legislation
    results = process_legislation(SAMPLE_LEGISLATION)
    
    if results["status"] == "completed":
        print_results_summary(results)
        
        json_rules = results.get("json_rules", [])
        if json_rules:
            save_rules_to_file(json_rules)
            print(f"\n‚ú® Successfully generated {len(json_rules)} data governance rules!")
        else:
            print("\n‚ö†Ô∏è No JSON rules were generated. Check the processing steps.")
    else:
        print(f"\n‚ùå Processing failed: {results.get('error', 'Unknown error')}")
