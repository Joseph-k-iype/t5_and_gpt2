"""
LLM-based guidance analyzer for extracting ODRL components from guidance text.
Uses advanced prompting strategies for comprehensive analysis.

UPDATED:
- Added supervisor agent for validation and correction
- Ensures action taxonomy compliance (share, store, process, update, create)
- Removes assigner/assignee fields
- Validates detailed comments (2-3+ sentences)
- Handles legal references and DataVisa mentions

Location: src/analyzers/guidance_analyzer.py
"""
import logging
from typing import Dict, List, Any, Optional
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, ValidationError

from ..services.openai_service import OpenAIService
from ..utils.json_parser import SafeJsonParser
from ..prompting.strategies import PromptingStrategies
from ..validators import ODRLLogicalValidator

logger = logging.getLogger(__name__)


class ODRLComponents(BaseModel):
    """Extracted ODRL components from guidance text."""
    
    # Core ODRL elements
    actions: List[str] = Field(default_factory=list, description="Standard actions: share, store, process, update, create")
    permissions: List[Dict[str, Any]] = Field(default_factory=list, description="Permitted actions with details")
    prohibitions: List[Dict[str, Any]] = Field(default_factory=list, description="Prohibited actions with details")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="Constraints and conditions")
    
    # Data context
    data_categories: List[str] = Field(default_factory=list, description="Types of data involved")
    data_subjects: List[str] = Field(default_factory=list, description="Who the data is about")
    
    # Parties and roles (NO assigner/assignee)
    parties: Dict[str, List[str]] = Field(default_factory=dict, description="Parties by role (controller, processor, data_subject)")
    
    # Additional context
    purpose: Optional[str] = Field(None, description="Purpose of processing")
    legal_basis: Optional[str] = Field(None, description="Legal basis without article citations")
    geographic_scope: List[str] = Field(default_factory=list, description="Geographic applicability")
    
    # Evidence and verification
    evidence_requirements: List[str] = Field(default_factory=list, description="Evidence needed")
    verification_methods: List[str] = Field(default_factory=list, description="How to verify compliance")
    
    # Metadata
    confidence_score: float = Field(0.8, description="Confidence in extraction")
    extraction_reasoning: str = Field("", description="Reasoning for extraction")
    
    # Supervisor review metadata
    supervisor_reviewed: bool = Field(False, description="Whether supervisor agent reviewed")
    supervisor_corrections: int = Field(0, description="Number of corrections made by supervisor")


class GuidanceAnalyzer:
    """
    Analyzes guidance text using LLM to extract ODRL components.
    Uses complex prompting strategies for accurate extraction.
    Includes supervisor agent for validation and correction.
    """
    
    # Standard action taxonomy
    STANDARD_ACTIONS = {"share", "store", "process", "update", "create"}
    
    def __init__(self):
        """Initialize guidance analyzer with LLM service."""
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
    
    async def analyze_guidance(
        self, 
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        rule_id: str
    ) -> ODRLComponents:
        """
        Comprehensive analysis of guidance text to extract ODRL components.
        
        Args:
            guidance_text: Complete guidance text
            rule_name: Name/title of the rule
            framework_type: DSS or DataVISA
            restriction_condition: restriction or condition
            rule_id: Unique identifier
            
        Returns:
            ODRLComponents with extracted and validated information
        """
        logger.info(f"Analyzing guidance for rule: {rule_name} ({rule_id})")
        
        # Multi-stage analysis for comprehensive extraction
        
        # Stage 1: Initial comprehensive analysis
        initial_analysis = await self._stage1_comprehensive_analysis(
            guidance_text, rule_name, framework_type, restriction_condition
        )
        
        # Stage 2: ODRL-specific extraction
        odrl_extraction = await self._stage2_odrl_extraction(
            guidance_text, rule_name, initial_analysis
        )
        
        # Stage 3: Constraint analysis
        constraint_analysis = await self._stage3_constraint_analysis(
            guidance_text, rule_name, odrl_extraction
        )
        
        # Stage 4: Data category identification
        data_categories = await self._stage4_data_category_identification(
            guidance_text, rule_name, constraint_analysis
        )
        
        # Stage 5: Synthesis and verification
        synthesized_components = await self._stage5_synthesis(
            guidance_text, rule_name, framework_type, restriction_condition,
            initial_analysis, odrl_extraction, constraint_analysis, data_categories
        )
        
        # Stage 6: Supervisor review and correction (NEW)
        final_components = await self._stage6_supervisor_review(
            synthesized_components, guidance_text, rule_name
        )
        
        return final_components
    
    async def _stage1_comprehensive_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        framework_type: str,
        restriction_condition: str
    ) -> str:
        """Stage 1: Comprehensive understanding of guidance text."""
        
        prompt = PromptingStrategies.odrl_comprehensive_guidance_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition
        )
        
        messages = [
            SystemMessage(content="You are a legal and data protection expert analyzing regulatory guidance. Analyze text comprehensively to extract all relevant compliance requirements. Use ONLY standard action taxonomy: share, store, process, update, create. DO NOT include assigner or assignee fields."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 1 complete: Comprehensive analysis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 1 analysis: {e}")
            return f"Error in comprehensive analysis: {str(e)}"
    
    async def _stage2_odrl_extraction(
        self,
        guidance_text: str,
        rule_name: str,
        initial_analysis: str
    ) -> str:
        """Stage 2: Extract ODRL-specific components."""
        
        prompt = PromptingStrategies.odrl_component_extraction(
            guidance_text=guidance_text,
            rule_name=rule_name,
            initial_analysis=initial_analysis
        )
        
        messages = [
            SystemMessage(content="You are an ODRL policy expert. Extract permissions, prohibitions, and constraints using ODRL terminology. ALL actions MUST be from standard taxonomy: share, store, process, update, create. NO assigner/assignee fields. Include detailed comments (2-3+ sentences) for everything."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 2 complete: ODRL extraction")
            return response
        except Exception as e:
            logger.error(f"Error in stage 2 extraction: {e}")
            return f"Error in ODRL extraction: {str(e)}"
    
    async def _stage3_constraint_analysis(
        self,
        guidance_text: str,
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 3: Detailed constraint analysis."""
        
        prompt = PromptingStrategies.odrl_constraint_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            odrl_extraction=odrl_extraction
        )
        
        messages = [
            SystemMessage(content="You are a constraint analysis expert. Create precise, machine-readable ODRL constraints with detailed plain language descriptions. No legal citations."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 3 complete: Constraint analysis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 3 constraint analysis: {e}")
            return f"Error in constraint analysis: {str(e)}"
    
    async def _stage4_data_category_identification(
        self,
        guidance_text: str,
        rule_name: str,
        constraint_analysis: str
    ) -> str:
        """Stage 4: Identify data categories."""
        
        prompt = f"""
        Based on the guidance text and analyses, identify ALL data categories mentioned.
        
        RULE: {rule_name}
        
        CONSTRAINT ANALYSIS:
        {constraint_analysis}
        
        ORIGINAL GUIDANCE:
        {guidance_text}
        
        TASK:
        Extract all data categories, data types, and personal information types mentioned.
        Be comprehensive and specific.
        Use clear, descriptive names.
        
        Return a JSON array of data category strings.
        Example: ["personal_data", "financial_data", "health_data"]
        """
        
        messages = [
            SystemMessage(content="You are a data classification expert. Identify all data categories comprehensively. Return ONLY a JSON array of strings."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 4 complete: Data category identification")
            return response
        except Exception as e:
            logger.error(f"Error in stage 4 data category identification: {e}")
            return "[]"
    
    async def _stage5_synthesis(
        self,
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        initial_analysis: str,
        odrl_extraction: str,
        constraint_analysis: str,
        data_categories: str
    ) -> str:
        """Stage 5: Synthesize all analyses into final ODRL components."""
        
        prompt = PromptingStrategies.odrl_synthesis_prompt(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition,
            initial_analysis=initial_analysis,
            odrl_extraction=odrl_extraction,
            constraint_analysis=constraint_analysis,
            data_categories=data_categories
        )
        
        messages = [
            SystemMessage(content="You are synthesizing all analyses into final ODRL components. Return ONLY valid JSON. Ensure: (1) ALL actions use standard taxonomy (share, store, process, update, create), (2) NO assigner/assignee fields, (3) ALL permissions/prohibitions/duties have detailed comments (2-3+ sentences), (4) NO legal citations. This output will be validated by a supervisor agent."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 5 complete: Synthesis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 5 synthesis: {e}")
            return "{}"
    
    async def _stage6_supervisor_review(
        self,
        synthesized_components: str,
        guidance_text: str,
        rule_name: str
    ) -> ODRLComponents:
        """
        Stage 6: Supervisor agent review and correction.
        
        NEW STAGE: Validates action taxonomy, removes assigner/assignee,
        ensures detailed comments, and makes necessary corrections.
        """
        logger.info(f"Stage 6: Supervisor review for rule: {rule_name}")
        
        prompt = PromptingStrategies.supervisor_review_prompt(
            extracted_components=synthesized_components,
            original_guidance=guidance_text,
            rule_name=rule_name
        )
        
        messages = [
            SystemMessage(content="You are a SUPERVISOR AGENT. Your job is to validate and correct ODRL components. Check: (1) All actions use ONLY: share, store, process, update, create, (2) NO assigner/assignee anywhere, (3) ALL comments are 2-3+ sentences, (4) NO legal citations. Make ALL necessary corrections. Return ONLY valid JSON with validation results and corrected components."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            
            # Parse supervisor response
            supervisor_result = self.json_parser.parse_json_response(response)
            
            if not supervisor_result:
                logger.warning("Supervisor review failed to parse, using synthesized components")
                # Fallback to synthesized components
                parsed_components = self.json_parser.parse_json_response(synthesized_components)
                if parsed_components:
                    return self._convert_to_odrl_components(parsed_components)
                else:
                    return ODRLComponents()
            
            # Extract corrected components
            corrected_components = supervisor_result.get("corrected_components", {})
            validation_summary = supervisor_result.get("validation_summary", {})
            corrections_made = supervisor_result.get("corrections_made", {})
            
            # Log supervisor actions
            logger.info(f"Supervisor validation summary: {validation_summary}")
            logger.info(f"Corrections made: {corrections_made}")
            
            # Count total corrections
            total_corrections = sum([
                len(corrections_made.get("action_corrections", [])),
                len(corrections_made.get("fields_removed", [])),
                len(corrections_made.get("comments_enhanced", [])),
                len(corrections_made.get("citations_removed", [])),
                len(corrections_made.get("conditions_clarified", [])),
                len(corrections_made.get("logical_fixes", []))
            ])
            
            logger.info(f"Total corrections by supervisor: {total_corrections}")
            
            # Convert to ODRLComponents
            odrl_components = self._convert_to_odrl_components(corrected_components)
            
            # Add supervisor metadata
            odrl_components.supervisor_reviewed = True
            odrl_components.supervisor_corrections = total_corrections
            
            logger.info(f"Stage 6 complete: Supervisor review ({total_corrections} corrections)")
            
            return odrl_components
            
        except Exception as e:
            logger.error(f"Error in stage 6 supervisor review: {e}")
            # Fallback to synthesized components
            parsed_components = self.json_parser.parse_json_response(synthesized_components)
            if parsed_components:
                return self._convert_to_odrl_components(parsed_components)
            else:
                return ODRLComponents()
    
    def _convert_to_odrl_components(self, data: Dict[str, Any]) -> ODRLComponents:
        """
        Convert parsed JSON to ODRLComponents object.
        
        Args:
            data: Parsed JSON dictionary
            
        Returns:
            ODRLComponents object
        """
        try:
            # Validate actions use standard taxonomy
            actions = data.get("actions", [])
            validated_actions = []
            for action in actions:
                if action.lower() in self.STANDARD_ACTIONS:
                    validated_actions.append(action.lower())
                else:
                    logger.warning(f"Non-standard action '{action}' found, mapping to standard taxonomy")
                    # Map to standard action (this should have been done by supervisor)
                    validated_actions.append(self._map_to_standard_action(action))
            
            # Ensure no assigner/assignee in permissions
            permissions = data.get("permissions", [])
            for perm in permissions:
                if "assigner" in perm:
                    del perm["assigner"]
                    logger.warning(f"Removed assigner from permission (should have been caught by supervisor)")
                if "assignee" in perm:
                    del perm["assignee"]
                    logger.warning(f"Removed assignee from permission (should have been caught by supervisor)")
            
            # Ensure no assigner/assignee in prohibitions
            prohibitions = data.get("prohibitions", [])
            for prohib in prohibitions:
                if "assigner" in prohib:
                    del prohib["assigner"]
                    logger.warning(f"Removed assigner from prohibition (should have been caught by supervisor)")
                if "assignee" in prohib:
                    del prohib["assignee"]
                    logger.warning(f"Removed assignee from prohibition (should have been caught by supervisor)")
            
            # Create ODRLComponents
            return ODRLComponents(
                actions=validated_actions,
                permissions=permissions,
                prohibitions=prohibitions,
                constraints=data.get("constraints", []),
                data_categories=data.get("data_categories", []),
                data_subjects=data.get("data_subjects", []),
                parties=data.get("parties", {}),
                purpose=data.get("purpose"),
                legal_basis=data.get("legal_basis"),
                geographic_scope=data.get("geographic_scope", []),
                evidence_requirements=data.get("evidence_requirements", []),
                verification_methods=data.get("verification_methods", []),
                confidence_score=data.get("confidence_score", 0.8),
                extraction_reasoning=data.get("extraction_reasoning", "")
            )
        
        except Exception as e:
            logger.error(f"Error converting to ODRLComponents: {e}")
            return ODRLComponents()
    
    def _map_to_standard_action(self, action: str) -> str:
        """
        Map non-standard action to standard taxonomy.
        Fallback in case supervisor didn't catch it.
        """
        action_lower = action.lower()
        
        # Mapping dictionary
        mapping = {
            "transfer": "share", "distribute": "share", "disclose": "share",
            "transmit": "share", "send": "share", "communicate": "share",
            "retain": "store", "keep": "store", "archive": "store",
            "maintain": "store", "hold": "store", "save": "store",
            "use": "process", "analyze": "process", "transform": "process",
            "modify": "process", "manipulate": "process", "handle": "process",
            "change": "update", "amend": "update", "revise": "update",
            "alter": "update", "edit": "update", "correct": "update",
            "collect": "create", "generate": "create", "produce": "create",
            "derive": "create", "obtain": "create", "gather": "create"
        }
        
        return mapping.get(action_lower, "process")  # Default to process
