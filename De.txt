"""
LLM-based guidance analyzer for extracting ODRL components from guidance text.

UPDATED - COMPLETE FIX:
- Action validation and mapping AFTER LLM extraction
- Ensures ONLY 5 standard actions: share, store, process, update, create
- Supervisor agent validates and corrects
- Removes legal citations
- Generates detailed comments

Location: src/analyzers/guidance_analyzer.py
"""
import logging
from typing import Dict, List, Any, Optional
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, ValidationError

from ..services.openai_service import OpenAIService
from ..utils.json_parser import SafeJsonParser
from ..prompting.strategies import PromptingStrategies
from ..validators import ODRLLogicalValidator

logger = logging.getLogger(__name__)


class ODRLComponents(BaseModel):
    """Extracted ODRL components from guidance text."""
    
    # Core ODRL elements
    actions: List[str] = Field(default_factory=list, description="Standard actions: share, store, process, update, create")
    permissions: List[Dict[str, Any]] = Field(default_factory=list, description="Permitted actions with details")
    prohibitions: List[Dict[str, Any]] = Field(default_factory=list, description="Prohibited actions with details")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="Constraints and conditions")
    
    # Data context
    data_categories: List[str] = Field(default_factory=list, description="Types of data involved")
    data_subjects: List[str] = Field(default_factory=list, description="Who the data is about")
    
    # Parties and roles (NO assigner/assignee)
    parties: Dict[str, List[str]] = Field(default_factory=dict, description="Parties by role (controller, processor, data_subject)")
    
    # Additional context
    purpose: Optional[str] = Field(None, description="Purpose of processing")
    legal_basis: Optional[str] = Field(None, description="Legal basis without article citations")
    geographic_scope: List[str] = Field(default_factory=list, description="Geographic applicability")
    
    # Evidence and verification
    evidence_requirements: List[str] = Field(default_factory=list, description="Evidence needed")
    verification_methods: List[str] = Field(default_factory=list, description="How to verify compliance")
    
    # Metadata
    confidence_score: float = Field(0.8, description="Confidence in extraction")
    extraction_reasoning: str = Field("", description="Reasoning for extraction")
    
    # Supervisor review metadata
    supervisor_reviewed: bool = Field(False, description="Whether supervisor agent reviewed")
    supervisor_corrections: int = Field(0, description="Number of corrections made by supervisor")


class GuidanceAnalyzer:
    """
    Analyzes guidance text using LLM to extract ODRL components.
    Includes post-processing to validate and fix actions.
    """
    
    # Standard action taxonomy - STRICTLY enforced
    STANDARD_ACTIONS = {"share", "store", "process", "update", "create"}
    
    # Comprehensive synonym mapping
    ACTION_SYNONYMS = {
        # Share synonyms
        "share": "share", "distribute": "share", "transfer": "share",
        "disclose": "share", "transmit": "share", "send": "share",
        "communicate": "share", "provide": "share", "give": "share",
        "forward": "share",
        
        # Store synonyms
        "store": "store", "archive": "store", "retain": "store",
        "keep": "store", "maintain": "store", "hold": "store",
        "save": "store", "preserve": "store",
        
        # Process synonyms
        "process": "process", "use": "process", "analyze": "process",
        "transform": "process", "modify": "process", "manipulate": "process",
        "handle": "process", "execute": "process", "apply": "process",
        "implement": "process", "perform": "process",
        
        # Update synonyms
        "update": "update", "change": "update", "amend": "update",
        "revise": "update", "alter": "update", "edit": "update",
        "correct": "update", "rectify": "update",
        
        # Create synonyms
        "create": "create", "collect": "create", "generate": "create",
        "produce": "create", "derive": "create", "obtain": "create",
        "gather": "create", "acquire": "create"
    }
    
    def __init__(self):
        """Initialize guidance analyzer with LLM service."""
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
    
    def _validate_and_fix_action(self, action: str) -> str:
        """
        Validate and map action to standard taxonomy.
        
        Args:
            action: Action from LLM
            
        Returns:
            Mapped standard action
        """
        if not action:
            return "process"
        
        # Clean action
        action_clean = action.lower().strip()
        
        # Remove URI parts
        if "/" in action_clean:
            action_clean = action_clean.split("/")[-1]
        if ":" in action_clean:
            action_clean = action_clean.split(":")[-1]
        
        # Direct match
        if action_clean in self.STANDARD_ACTIONS:
            return action_clean
        
        # Synonym mapping
        if action_clean in self.ACTION_SYNONYMS:
            mapped = self.ACTION_SYNONYMS[action_clean]
            if action_clean != mapped:
                logger.info(f"Mapped action '{action}' → '{mapped}'")
            return mapped
        
        # Partial match
        for synonym, standard_action in self.ACTION_SYNONYMS.items():
            if synonym in action_clean or action_clean in synonym:
                logger.info(f"Inferred action '{action}' → '{standard_action}'")
                return standard_action
        
        # Default
        logger.warning(f"Unknown action '{action}', defaulting to 'process'")
        return "process"
    
    def _fix_actions_in_components(self, components: Dict[str, Any]) -> Dict[str, Any]:
        """
        Post-process to fix all actions in components.
        
        Args:
            components: Raw components from LLM
            
        Returns:
            Fixed components with validated actions
        """
        # Fix actions list
        if "actions" in components:
            fixed_actions = []
            for action in components["actions"]:
                fixed_action = self._validate_and_fix_action(action)
                if fixed_action not in fixed_actions:
                    fixed_actions.append(fixed_action)
            components["actions"] = fixed_actions
        
        # Fix permissions
        if "permissions" in components:
            for perm in components["permissions"]:
                if "action" in perm:
                    perm["action"] = self._validate_and_fix_action(perm["action"])
        
        # Fix prohibitions
        if "prohibitions" in components:
            for prohib in components["prohibitions"]:
                if "action" in prohib:
                    prohib["action"] = self._validate_and_fix_action(prohib["action"])
        
        # Fix duties
        if "duties" in components:
            for duty in components["duties"]:
                if isinstance(duty, dict) and "action" in duty:
                    duty["action"] = self._validate_and_fix_action(duty["action"])
        
        return components
    
    async def analyze_guidance(
        self, 
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        rule_id: str
    ) -> ODRLComponents:
        """
        Comprehensive analysis of guidance text to extract ODRL components.
        Includes post-processing to validate actions.
        
        Args:
            guidance_text: Complete guidance text
            rule_name: Name/title of the rule
            framework_type: Framework identifier
            restriction_condition: Type of restriction
            rule_id: Unique identifier
            
        Returns:
            ODRLComponents with validated actions
        """
        logger.info(f"Analyzing guidance for rule: {rule_name} ({rule_id})")
        
        # Multi-stage analysis
        initial_analysis = await self._stage1_comprehensive_analysis(
            guidance_text, rule_name, framework_type, restriction_condition
        )
        
        odrl_extraction = await self._stage2_odrl_extraction(
            guidance_text, rule_name, initial_analysis
        )
        
        constraint_analysis = await self._stage3_constraint_analysis(
            guidance_text, rule_name, odrl_extraction
        )
        
        data_categories = await self._stage4_data_category_identification(
            guidance_text, rule_name, constraint_analysis
        )
        
        synthesized_components = await self._stage5_synthesis(
            guidance_text, rule_name, framework_type, restriction_condition,
            initial_analysis, odrl_extraction, constraint_analysis, data_categories
        )
        
        final_components = await self._stage6_supervisor_review(
            synthesized_components, guidance_text, rule_name
        )
        
        return final_components
    
    async def _stage1_comprehensive_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        framework_type: str,
        restriction_condition: str
    ) -> str:
        """Stage 1: Comprehensive understanding of guidance text."""
        
        prompt = PromptingStrategies.odrl_comprehensive_guidance_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition
        )
        
        messages = [
            SystemMessage(content="You are a legal and data protection expert analyzing regulatory guidance. Use ONLY standard action taxonomy: share, store, process, update, create. DO NOT include assigner or assignee fields."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 1 complete: Comprehensive analysis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 1 analysis: {e}")
            return f"Error in comprehensive analysis: {str(e)}"
    
    async def _stage2_odrl_extraction(
        self,
        guidance_text: str,
        rule_name: str,
        initial_analysis: str
    ) -> str:
        """Stage 2: Extract ODRL-specific components."""
        
        prompt = PromptingStrategies.odrl_component_extraction(
            guidance_text=guidance_text,
            rule_name=rule_name,
            initial_analysis=initial_analysis
        )
        
        messages = [
            SystemMessage(content="You are an ODRL policy expert. Extract permissions, prohibitions, and constraints. ALL actions MUST be from standard taxonomy: share, store, process, update, create. NO assigner/assignee fields. Include detailed comments (2-3+ sentences)."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 2 complete: ODRL extraction")
            return response
        except Exception as e:
            logger.error(f"Error in stage 2 extraction: {e}")
            return f"Error in ODRL extraction: {str(e)}"
    
    async def _stage3_constraint_analysis(
        self,
        guidance_text: str,
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 3: Detailed constraint analysis."""
        
        prompt = PromptingStrategies.odrl_constraint_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            odrl_extraction=odrl_extraction
        )
        
        messages = [
            SystemMessage(content="You are a constraint analysis expert. Create precise, machine-readable ODRL constraints with detailed plain language descriptions. No legal citations."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 3 complete: Constraint analysis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 3 constraint analysis: {e}")
            return f"Error in constraint analysis: {str(e)}"
    
    async def _stage4_data_category_identification(
        self,
        guidance_text: str,
        rule_name: str,
        constraint_analysis: str
    ) -> str:
        """Stage 4: Identify data categories."""
        
        prompt = f"""
        Based on the guidance text and analyses, identify ALL data categories mentioned.
        
        RULE: {rule_name}
        
        CONSTRAINT ANALYSIS:
        {constraint_analysis}
        
        ORIGINAL GUIDANCE:
        {guidance_text}
        
        TASK:
        Extract all data categories, data types, and personal information types mentioned.
        Be comprehensive and specific.
        Use clear, descriptive names.
        
        Return a JSON array of data category strings.
        Example: ["personal_data", "financial_data", "health_data"]
        """
        
        messages = [
            SystemMessage(content="You are a data classification expert. Identify all data categories comprehensively. Return ONLY a JSON array of strings."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 4 complete: Data category identification")
            return response
        except Exception as e:
            logger.error(f"Error in stage 4 data category identification: {e}")
            return "[]"
    
    async def _stage5_synthesis(
        self,
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        initial_analysis: str,
        odrl_extraction: str,
        constraint_analysis: str,
        data_categories: str
    ) -> str:
        """Stage 5: Synthesize all analyses into final ODRL components."""
        
        prompt = PromptingStrategies.odrl_synthesis_prompt(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition,
            initial_analysis=initial_analysis,
            odrl_extraction=odrl_extraction,
            constraint_analysis=constraint_analysis,
            data_categories=data_categories
        )
        
        messages = [
            SystemMessage(content="You are synthesizing analyses into final ODRL components. Return ONLY valid JSON. Ensure: (1) ALL actions use standard taxonomy (share, store, process, update, create), (2) NO assigner/assignee fields, (3) ALL permissions/prohibitions/duties have detailed comments (2-3+ sentences), (4) NO legal citations."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 5 complete: Synthesis")
            return response
        except Exception as e:
            logger.error(f"Error in stage 5 synthesis: {e}")
            return "{}"
    
    async def _stage6_supervisor_review(
        self,
        synthesized_components: str,
        guidance_text: str,
        rule_name: str
    ) -> ODRLComponents:
        """
        Stage 6: Supervisor agent review and POST-PROCESSING action validation.
        """
        logger.info(f"Stage 6: Supervisor review for rule: {rule_name}")
        
        prompt = PromptingStrategies.supervisor_review_prompt(
            extracted_components=synthesized_components,
            original_guidance=guidance_text,
            rule_name=rule_name
        )
        
        messages = [
            SystemMessage(content="You are a SUPERVISOR AGENT. Validate and correct ODRL components. Check: (1) All actions use ONLY: share, store, process, update, create, (2) NO assigner/assignee anywhere, (3) ALL comments are 2-3+ sentences, (4) NO legal citations. Make ALL necessary corrections. Return ONLY valid JSON."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            
            # Parse supervisor response
            supervisor_result = self.json_parser.parse_json_response(response)
            
            if not supervisor_result:
                logger.warning("Supervisor review failed to parse, using synthesized components")
                parsed_components = self.json_parser.parse_json_response(synthesized_components)
                if parsed_components:
                    # POST-PROCESSING: Fix actions even if supervisor failed
                    parsed_components = self._fix_actions_in_components(parsed_components)
                    return self._convert_to_odrl_components(parsed_components)
                else:
                    return ODRLComponents()
            
            # Extract corrected components
            corrected_components = supervisor_result.get("corrected_components", {})
            
            # POST-PROCESSING: Fix actions after supervisor
            corrected_components = self._fix_actions_in_components(corrected_components)
            
            validation_summary = supervisor_result.get("validation_summary", {})
            corrections_made = supervisor_result.get("corrections_made", {})
            
            # Log supervisor actions
            logger.info(f"Supervisor validation summary: {validation_summary}")
            logger.info(f"Corrections made: {corrections_made}")
            
            # Count total corrections
            total_corrections = sum([
                len(corrections_made.get("action_corrections", [])),
                len(corrections_made.get("fields_removed", [])),
                len(corrections_made.get("comments_enhanced", [])),
                len(corrections_made.get("citations_removed", [])),
                len(corrections_made.get("conditions_clarified", [])),
                len(corrections_made.get("logical_fixes", []))
            ])
            
            logger.info(f"Total corrections by supervisor: {total_corrections}")
            
            # Convert to ODRLComponents
            odrl_components = self._convert_to_odrl_components(corrected_components)
            
            # Add supervisor metadata
            odrl_components.supervisor_reviewed = True
            odrl_components.supervisor_corrections = total_corrections
            
            logger.info(f"Stage 6 complete: Supervisor review ({total_corrections} corrections)")
            
            return odrl_components
            
        except Exception as e:
            logger.error(f"Error in stage 6 supervisor review: {e}")
            # Fallback with post-processing
            parsed_components = self.json_parser.parse_json_response(synthesized_components)
            if parsed_components:
                parsed_components = self._fix_actions_in_components(parsed_components)
                return self._convert_to_odrl_components(parsed_components)
            else:
                return ODRLComponents()
    
    def _convert_to_odrl_components(self, data: Dict[str, Any]) -> ODRLComponents:
        """Convert parsed JSON to ODRLComponents object with action validation."""
        try:
            # Final validation: ensure all actions are standard
            actions = data.get("actions", [])
            validated_actions = []
            for action in actions:
                validated = self._validate_and_fix_action(action)
                if validated not in validated_actions:
                    validated_actions.append(validated)
            
            # Remove assigner/assignee from permissions
            permissions = data.get("permissions", [])
            for perm in permissions:
                if "assigner" in perm:
                    del perm["assigner"]
                if "assignee" in perm:
                    del perm["assignee"]
            
            # Remove assigner/assignee from prohibitions
            prohibitions = data.get("prohibitions", [])
            for prohib in prohibitions:
                if "assigner" in prohib:
                    del prohib["assigner"]
                if "assignee" in prohib:
                    del prohib["assignee"]
            
            # Create ODRLComponents
            return ODRLComponents(
                actions=validated_actions,
                permissions=permissions,
                prohibitions=prohibitions,
                constraints=data.get("constraints", []),
                data_categories=data.get("data_categories", []),
                data_subjects=data.get("data_subjects", []),
                parties=data.get("parties", {}),
                purpose=data.get("purpose"),
                legal_basis=data.get("legal_basis"),
                geographic_scope=data.get("geographic_scope", []),
                evidence_requirements=data.get("evidence_requirements", []),
                verification_methods=data.get("verification_methods", []),
                confidence_score=data.get("confidence_score", 0.8),
                extraction_reasoning=data.get("extraction_reasoning", "")
            )
        
        except Exception as e:
            logger.error(f"Error converting to ODRLComponents: {e}")
            return ODRLComponents()
