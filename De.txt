#!/usr/bin/env python3
"""
Advanced Multi-Agent Legal Document Rule Extraction System using LangGraph
Mixture of Experts with Supervisor Agent and Chain of Thought for JSON Rules Engine Compatibility
Accurate rule extraction with proper definitions, conditions, and references
ERROR-FREE VERSION with comprehensive rule interpretation and supervisor validation
Rules and conditions in simple English without article references
"""

import os
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Literal, TypedDict
from datetime import datetime
import re
import uuid
import math
import hashlib
from dataclasses import dataclass

# Core libraries
import pandas as pd
import PyPDF2
from pydantic import BaseModel, Field, ValidationError, model_validator
from pydantic_core import from_json

# LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

# OpenAI for embeddings (if needed)
import openai

# Global Configuration
API_KEY = os.getenv("OPENAI_API_KEY", "your-openai-api-key-here")
BASE_URL = "https://api.openai.com/v1"
MODEL_NAME = "gpt-4o-mini"  
EMBEDDING_MODEL = "text-embedding-3-large"
CHUNK_SIZE = 12000  # Increased for better coverage
OVERLAP_SIZE = 2000  # Increased overlap
MAX_CHUNKS = 100  # Increased limit

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Enhanced Pydantic v2 Models for JSON Rules Engine Compatibility
class RuleCondition(BaseModel):
    """JSON Rules Engine compatible condition structure"""
    condition_id: str = Field(..., description="Unique condition identifier")
    condition_definition: str = Field(..., description="Human readable condition description in simple English")
    fact: str = Field(..., description="The data property to evaluate (e.g., 'user.role', 'data.category', 'request.type')")
    operator: str = Field(..., description="JSON rules engine operator (equal, notEqual, in, notIn, greaterThan, lessThan, contains)")
    value: Union[str, int, float, bool, List[Any]] = Field(..., description="Value to compare against")
    role: str = Field(..., description="Stakeholder role (data_controller, data_processor, joint_controller, data_subject, dpo, supervisory_authority, third_party)")
    if_condition: Optional[str] = Field(None, description="IF part of the condition logic in simple English")
    else_condition: Optional[str] = Field(None, description="ELSE part of the condition logic in simple English")

class ExtractedRule(BaseModel):
    """JSON Rules Engine compatible rule structure"""
    rule_id: str = Field(..., description="Unique rule identifier")
    rule_definition: str = Field(..., description="Specific, detailed rule definition in simple English without article references")
    rule_type: str = Field(..., description="Type of rule (access_right, processing_obligation, consent_requirement, data_transfer, etc.)")
    applicable_countries: List[str] = Field(..., description="ISO country codes where rule applies")
    adequacy_countries: List[str] = Field(default_factory=list, description="Countries with adequacy decisions")
    conditions: List[RuleCondition] = Field(..., description="List of rule conditions with if-else logic in simple English")
    aggregated_roles: List[str] = Field(default_factory=list, description="All stakeholder roles involved")
    data_category: str = Field(..., description="Specific data category (personal_data, special_category, pseudonymised, anonymised, etc.)")
    domain: str = Field(..., description="Legal domain (gdpr_compliance, data_subject_rights, cross_border_transfers, etc.)")
    action: str = Field(..., description="Specific required action in simple English without article references")
    consequence: str = Field(default="", description="Consequence if rule is violated")
    reference: str = Field(..., description="Exact article, section, and paragraph reference")
    priority: str = Field(default="medium", description="Rule priority (high, medium, low)")
    
    # JSON Rules Engine compatibility
    event_type: str = Field(default="rule_evaluation", description="Event that triggers rule evaluation")
    params: Dict[str, Any] = Field(default_factory=dict, description="Additional parameters for rule engine")

class MetadataConfig(BaseModel):
    """Configuration model"""
    pdf_path: str = Field(..., description="Path to PDF file")
    applicable_countries: List[str] = Field(..., description="ISO country codes where rules apply")
    document_type: str = Field(default="regulation", description="Type of document")

# Document Chunk Management
@dataclass
class DocumentChunk:
    """Document chunk with metadata"""
    content: str
    chunk_id: str
    start_page: int
    end_page: int
    section_type: str
    overlap_content: str = ""

# Multi-Agent State Management with Supervisor
class MultiAgentState(TypedDict):
    """Enhanced shared state between all agents with supervisor oversight"""
    # Input data
    document_text: str
    document_hash: str
    document_chunks: List[Dict[str, Any]]
    metadata_config: dict
    geography_data: dict
    
    # Expert analysis results
    legal_obligations: dict  # Expert 1 results
    regulatory_requirements: dict  # Expert 2 results  
    compliance_conditions: dict  # Expert 3 results
    stakeholder_roles: dict  # Expert 4 results
    
    # Processing stages
    parsed_sections: dict
    knowledge_graph: dict
    identified_countries: dict
    extracted_rules: list
    validated_rules: list
    supervisor_validated_rules: list
    
    # Agent reasoning traces
    agent1_reasoning: list
    agent1_knowledge_graph: dict
    agent2_reasoning: list  
    agent2_knowledge_graph: dict
    agent3_reasoning: list
    agent3_knowledge_graph: dict
    agent4_reasoning: list
    agent4_knowledge_graph: dict
    supervisor_reasoning: list
    supervisor_knowledge_graph: dict
    
    # Processing control
    current_agent: str
    processing_complete: bool
    chunks_processed: int
    total_chunks: int
    supervisor_validation_complete: bool

# Safe utility functions
def safe_get(obj: Any, key: str, default: Any = None) -> Any:
    """Safely get attribute from object"""
    try:
        if isinstance(obj, dict):
            return obj.get(key, default)
        elif hasattr(obj, key):
            return getattr(obj, key, default)
        else:
            return default
    except:
        return default

def safe_json_parse(json_str: str) -> Any:
    """Safely parse JSON string"""
    try:
        return json.loads(json_str)
    except Exception as e:
        logger.debug(f"JSON parsing failed: {e}")
        return None

def ensure_dict(obj: Any) -> Dict[str, Any]:
    """Ensure object is a dictionary"""
    if isinstance(obj, dict):
        return obj
    elif obj is None:
        return {}
    else:
        try:
            return {"value": str(obj)}
        except:
            return {}

def ensure_list(obj: Any) -> List[Any]:
    """Ensure object is a list"""
    if isinstance(obj, list):
        return obj
    elif obj is None:
        return []
    else:
        return [obj]

def generate_document_hash(text: str) -> str:
    """Generate unique hash for document"""
    try:
        return hashlib.md5(str(text).encode()).hexdigest()[:12]
    except:
        return hashlib.md5(str(datetime.now()).encode()).hexdigest()[:12]

def generate_unique_rule_id(document_hash: str, rule_type: str, sequence: int) -> str:
    """Generate unique rule ID based on document hash, rule type, and sequence"""
    try:
        base_id = f"{document_hash}_{rule_type}_{sequence:03d}"
        return base_id
    except:
        return f"rule_{uuid.uuid4().hex[:8]}"

def clean_text_to_simple_english(text: str) -> str:
    """Clean text to simple English by removing article/section references"""
    try:
        if not text:
            return ""
        
        text = str(text)
        
        # Remove article/section references at the beginning or end
        reference_patterns = [
            r'^(?:Article\s+\d+(?:\.\d+)?(?:\(\d+\))?[:\s\-]*)',
            r'^(?:Section\s+\d+(?:\.\d+)?[:\s\-]*)',
            r'^(?:Paragraph\s+\d+(?:\.\d+)?[:\s\-]*)',
            r'^(?:Chapter\s+\d+[:\s\-]*)',
            r'^(?:GDPR\s+Article\s+\d+[:\s\-]*)',
            r'^(?:Regulation\s+\(\w+\)\s+\d+/\d+[:\s\-]*)',
            r'(?:\s*\-\s*Article\s+\d+(?:\.\d+)?(?:\(\d+\))?)$',
            r'(?:\s*\-\s*Section\s+\d+(?:\.\d+)?)$',
            r'(?:\s*\-\s*Paragraph\s+\d+(?:\.\d+)?)$',
            r'(?:\s*\([Aa]rticle\s+\d+(?:\.\d+)?(?:\(\d+\))?\))$',
            r'(?:\s*\([Ss]ection\s+\d+(?:\.\d+)?\))$'
        ]
        
        for pattern in reference_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()
        
        # Remove leading/trailing punctuation that might be left
        text = re.sub(r'^[\s\-:;,\.]+|[\s\-:;,\.]+$', '', text).strip()
        
        # Ensure first letter is capitalized
        if text:
            text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()
        
        return text
    except Exception as e:
        logger.debug(f"Error cleaning text: {e}")
        return str(text) if text else ""

def extract_comprehensive_references(text: str) -> str:
    """Enhanced reference extraction with better patterns"""
    try:
        if not text:
            return "Legal requirement"
        
        text = str(text)
        
        # Enhanced reference patterns to capture actual legal citations
        reference_patterns = [
            r'((?:GDPR\s+)?Article\s+\d+(?:\.\d+)?(?:\(\d+\))?(?:\s+[a-z])?)',
            r'(Section\s+\d+(?:\.\d+)?(?:\(\d+\))?)',
            r'(Paragraph\s+\d+(?:\.\d+)?(?:\(\d+\))?)',
            r'(Chapter\s+\d+(?:\(\d+\))?)',
            r'(Regulation\s+\(\w+\)\s+\d+/\d+)',
            r'(Directive\s+\d+/\d+/\w+)',
            r'(Article\s+\d+\s+GDPR)',
            r'(\d+\s+GDPR)',
            r'(Art\.\s+\d+(?:\.\d+)?)',
            r'(Sec\.\s+\d+(?:\.\d+)?)',
            r'(Para\.\s+\d+(?:\.\d+)?)'
        ]
        
        found_references = []
        for pattern in reference_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                if match and match.strip():
                    cleaned_ref = re.sub(r'\s+', ' ', match.strip())
                    found_references.append(cleaned_ref)
        
        # Return the most specific reference found
        if found_references:
            # Prefer GDPR articles, then other articles, then sections
            gdpr_refs = [r for r in found_references if 'gdpr' in r.lower() or 'article' in r.lower()]
            if gdpr_refs:
                return gdpr_refs[0]
            return found_references[0]
        
        return "Legal requirement"
    except Exception as e:
        logger.debug(f"Error extracting references: {e}")
        return "Legal requirement"

def extract_comprehensive_roles_from_text(text: str) -> List[str]:
    """Enhanced role extraction to capture all stakeholder roles"""
    try:
        if not text:
            return ["data_controller"]
        
        text_lower = str(text).lower()
        found_roles = set()
        
        # Enhanced role detection patterns
        role_patterns = {
            "data_controller": [
                r'\bdata\s+controller\b',
                r'\bcontroller\b(?!\s+processor)',
                r'\bprocessing\s+responsible\b',
                r'\bentity\s+determining\b'
            ],
            "data_processor": [
                r'\bdata\s+processor\b',
                r'\bprocessor\b(?!\s+controller)',
                r'\bprocessing\s+on\s+behalf\b',
                r'\bservice\s+provider\b'
            ],
            "joint_controller": [
                r'\bjoint\s+controller\b',
                r'\bjointly\s+determine\b',
                r'\bshared\s+responsibility\b',
                r'\bjoint\s+processing\b'
            ],
            "data_subject": [
                r'\bdata\s+subject\b',
                r'\bindividual\b',
                r'\bnatural\s+person\b',
                r'\bperson\s+whose\s+data\b'
            ],
            "dpo": [
                r'\bdata\s+protection\s+officer\b',
                r'\bdpo\b',
                r'\bprotection\s+officer\b'
            ],
            "supervisory_authority": [
                r'\bsupervisory\s+authority\b',
                r'\bregulatory\s+authority\b',
                r'\bdata\s+protection\s+authority\b',
                r'\bcommission\b',
                r'\bauthority\b'
            ],
            "third_party": [
                r'\bthird\s+party\b',
                r'\bexternal\s+party\b',
                r'\brecipient\b'
            ]
        }
        
        for role, patterns in role_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    found_roles.add(role)
        
        # If no specific roles found, default to controller
        if not found_roles:
            found_roles.add("data_controller")
        
        return list(found_roles)
    except Exception as e:
        logger.debug(f"Error extracting roles: {e}")
        return ["data_controller"]

# Enhanced Geography Handler
class GeographyHandler:
    """Enhanced geography handler with better country verification"""
    
    def __init__(self, geography_file: str):
        self.geography_data = self._load_geography_data(geography_file)
        self.all_countries = self._extract_all_countries()
        self.country_variations = self._build_country_variations()
        self.adequacy_countries_list = self._build_adequacy_countries_list()
        logger.info(f"üåç Geography data loaded: {len(self.all_countries)} countries")
    
    def _load_geography_data(self, file_path: str) -> Dict[str, Any]:
        """Load geography data from JSON file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load geography data: {e}")
            return {}
    
    def _extract_all_countries(self) -> Dict[str, str]:
        """Extract all countries from geography.json"""
        countries = {}
        
        try:
            for region_key, region_data in self.geography_data.items():
                if isinstance(region_data, dict):
                    if 'countries' in region_data:
                        for country in ensure_list(region_data['countries']):
                            if isinstance(country, dict):
                                iso2 = safe_get(country, 'iso2', '')
                                name = safe_get(country, 'name', '')
                                if iso2 and name:
                                    countries[iso2] = name
                    
                    if region_key == 'By_Continent':
                        for continent, continent_data in region_data.items():
                            continent_dict = ensure_dict(continent_data)
                            if 'countries' in continent_dict:
                                for country in ensure_list(continent_dict['countries']):
                                    if isinstance(country, dict):
                                        iso2 = safe_get(country, 'iso2', '')
                                        name = safe_get(country, 'name', '')
                                        if iso2 and name:
                                            countries[iso2] = name
        except Exception as e:
            logger.error(f"Error extracting countries: {e}")
        
        return countries
    
    def _build_country_variations(self) -> Dict[str, str]:
        """Build country name variations for better matching"""
        variations = {}
        try:
            for iso, name in self.all_countries.items():
                if isinstance(name, str) and isinstance(iso, str):
                    variations[name.lower()] = iso.upper()
                    variations[iso.lower()] = iso.upper()
                    if "," in name:
                        short_name = name.split(",")[0].strip()
                        variations[short_name.lower()] = iso.upper()
        except Exception as e:
            logger.error(f"Error building country variations: {e}")
        return variations
    
    def _build_adequacy_countries_list(self) -> List[str]:
        """Build list of known adequacy countries for reference"""
        try:
            # Common adequacy countries (this should be updated based on current regulations)
            adequacy_countries = [
                "AD", "AR", "CA", "CH", "FO", "GG", "IL", "IM", "IS", "JE", "JP", 
                "KR", "NZ", "UY", "GB", "US"  # US for certain frameworks
            ]
            return adequacy_countries
        except:
            return []
    
    def is_valid_country(self, iso_code: str) -> bool:
        """Check if ISO code is valid country"""
        try:
            return str(iso_code).upper() in self.all_countries if iso_code else False
        except:
            return False
    
    def get_country_name(self, iso_code: str) -> str:
        """Get country name from ISO code"""
        try:
            return self.all_countries.get(str(iso_code).upper(), "")
        except:
            return ""
    
    def get_country_iso(self, country_name: str) -> str:
        """Get ISO code from country name"""
        try:
            return self.country_variations.get(str(country_name).lower(), "")
        except:
            return ""
    
    def find_countries_in_text(self, text: str) -> List[str]:
        """Enhanced country finding with better matching"""
        found_countries = set()
        try:
            if not text:
                return []
            
            text_lower = str(text).lower()
            
            # Direct ISO code matching
            iso_pattern = r'\b([A-Z]{2})\b'
            iso_matches = re.findall(iso_pattern, text.upper())
            for iso in iso_matches:
                if self.is_valid_country(iso):
                    found_countries.add(iso)
            
            # Country name matching
            for variation, iso in self.country_variations.items():
                if len(variation) > 2:
                    if re.search(r'\b' + re.escape(variation) + r'\b', text_lower):
                        found_countries.add(iso)
                        
            # Regional references
            if re.search(r'\beuropean\s+union\b|\beu\b|\beea\b', text_lower):
                eu_countries = ["AT", "BE", "BG", "HR", "CY", "CZ", "DK", "EE", "FI", 
                               "FR", "DE", "GR", "HU", "IE", "IT", "LV", "LT", "LU", 
                               "MT", "NL", "PL", "PT", "RO", "SK", "SI", "ES", "SE"]
                found_countries.update(eu_countries)
                
        except Exception as e:
            logger.error(f"Error finding countries in text: {e}")
        
        return list(found_countries)
    
    def find_adequacy_countries_in_text(self, text: str) -> List[str]:
        """Enhanced adequacy country detection"""
        found_adequacy = set()
        try:
            if not text:
                return []
            
            text_lower = str(text).lower()
            
            # Enhanced adequacy detection patterns
            adequacy_patterns = [
                r'adequacy\s+decision[^.]*?([A-Z]{2})',
                r'adequate\s+protection[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?adequacy\s+decision',
                r'([A-Z]{2})[^.]*?adequate\s+protection',
                r'commission\s+decision[^.]*?adequacy[^.]*?([A-Z]{2})',
                r'adequate\s+level\s+of\s+protection[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?adequate\s+level\s+of\s+protection'
            ]
            
            for pattern in adequacy_patterns:
                try:
                    matches = re.findall(pattern, text, re.IGNORECASE)
                    for match in matches:
                        if match and self.is_valid_country(str(match)):
                            found_adequacy.add(str(match).upper())
                except Exception as e:
                    logger.debug(f"Error in adequacy pattern: {e}")
                    continue
            
            # Country name based adequacy detection
            for variation, iso in self.country_variations.items():
                if len(variation) > 2:
                    adequacy_context_patterns = [
                        rf'{re.escape(variation)}[^.]*?adequacy',
                        rf'adequacy[^.]*?{re.escape(variation)}',
                        rf'{re.escape(variation)}[^.]*?adequate\s+protection',
                        rf'adequate\s+protection[^.]*?{re.escape(variation)}'
                    ]
                    
                    for pattern in adequacy_context_patterns:
                        if re.search(pattern, text_lower):
                            found_adequacy.add(iso)
                            break
            
            return list(found_adequacy)
        except Exception as e:
            logger.error(f"Error finding adequacy countries: {e}")
            return []

# Enhanced PDF Processing
class PDFProcessor:
    """Enhanced PDF processor with complete content extraction"""
    
    @staticmethod
    def extract_complete_text_from_pdf(pdf_path: str) -> Dict[str, Any]:
        """Extract complete text from PDF with page metadata"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                complete_text = ""
                page_contents = []
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            page_contents.append({
                                'page_number': page_num + 1,
                                'content': str(page_text),
                                'length': len(str(page_text))
                            })
                            complete_text += f"\n[PAGE {page_num + 1}]\n{page_text}\n"
                    except Exception as e:
                        logger.warning(f"Failed to extract page {page_num + 1}: {e}")
                        continue
                
                return {
                    'complete_text': complete_text,
                    'page_contents': page_contents,
                    'total_pages': len(pdf_reader.pages),
                    'total_length': len(complete_text)
                }
        except Exception as e:
            logger.error(f"Failed to extract text from PDF {pdf_path}: {e}")
            return {'complete_text': "", 'page_contents': [], 'total_pages': 0, 'total_length': 0}
    
    @staticmethod
    def create_comprehensive_chunks(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = OVERLAP_SIZE) -> List[DocumentChunk]:
        """Create comprehensive overlapping chunks from text for complete coverage"""
        chunks = []
        
        try:
            if not text:
                return chunks
            
            text = str(text)
            text_length = len(text)
            
            if text_length <= chunk_size:
                chunks.append(DocumentChunk(
                    content=text,
                    chunk_id="chunk_001",
                    start_page=1,
                    end_page=1,
                    section_type="complete_document"
                ))
                return chunks
            
            start = 0
            chunk_num = 1
            
            while start < text_length and chunk_num <= MAX_CHUNKS:
                end = min(start + chunk_size, text_length)
                chunk_content = text[start:end]
                
                overlap_content = ""
                if end < text_length:
                    overlap_end = min(end + overlap, text_length)
                    overlap_content = text[end:overlap_end]
                
                try:
                    page_matches = re.findall(r'\[PAGE (\d+)\]', text[:start])
                    start_page = int(page_matches[-1]) if page_matches else 1
                    
                    page_matches_end = re.findall(r'\[PAGE (\d+)\]', text[:end])
                    end_page = int(page_matches_end[-1]) if page_matches_end else start_page
                except:
                    start_page, end_page = 1, 1
                
                chunk = DocumentChunk(
                    content=chunk_content,
                    chunk_id=f"chunk_{chunk_num:03d}",
                    start_page=start_page,
                    end_page=end_page,
                    section_type="document_section",
                    overlap_content=overlap_content
                )
                
                chunks.append(chunk)
                start += chunk_size - overlap
                chunk_num += 1
            
            logger.info(f"üìÑ Created {len(chunks)} comprehensive chunks from {text_length} characters")
        except Exception as e:
            logger.error(f"Error creating chunks: {e}")
        
        return chunks

# MIXTURE OF EXPERTS AGENT 1: Legal Document Structure Expert
class LegalDocumentExpert:
    """Expert 1: Legal document structure and comprehensive section analysis"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.name = "LegalDocumentExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Extract precise document structure and legal obligations from entire document"""
        
        logger.info(f"üéì {self.name}: Analyzing complete legal document structure")
        
        try:
            pdf_processor = PDFProcessor()
            chunks = pdf_processor.create_comprehensive_chunks(state['document_text'])
            
            system_prompt = """You are a Legal Document Structure Expert specializing in comprehensive regulatory document analysis.

EXPERTISE: Complete document structure, legal obligations, regulatory requirements, compliance mandates

MISSION: Extract ALL PRECISE legal obligations, requirements, and mandates from the ENTIRE document with SPECIFIC details in SIMPLE ENGLISH.

CRITICAL INSTRUCTIONS:
- Analyze EVERY section of the document, not just high-level content
- Extract ALL legal obligations, including processor requirements, joint controller provisions
- Write rule definitions in SIMPLE, CLEAR English without any article/section references
- Extract reference information separately (Article X, Section Y, etc.)
- Identify ALL stakeholder roles: controller, processor, joint controller, data subject, DPO, supervisory authority
- Make rules understandable to non-lawyers

COMPREHENSIVE ANALYSIS REQUIRED:
1. COMPLETE OBLIGATION SCAN: Find ALL "must", "shall", "required" statements throughout document
2. ROLE IDENTIFICATION: Extract ALL roles mentioned (controller, processor, joint controller, DPO, etc.)
3. SIMPLE ENGLISH CONVERSION: Convert complex legal language to plain language
4. REFERENCE EXTRACTION: Capture exact article/section numbers (separate from rule text)
5. STAKEHOLDER MAPPING: Identify who has each obligation
6. REQUIREMENT CLASSIFICATION: Categorize by type (access, processing, consent, transfer, etc.)

OUTPUT FORMAT: Comprehensive analysis with simple English rules and separate references for ALL document content."""

            all_obligations = {}
            reasoning_trace = []
            knowledge_graph = {"entities": [], "relationships": [], "obligations": {}}
            
            for i, chunk in enumerate(chunks):
                if chunk and hasattr(chunk, 'content'):
                    logger.info(f"üìö Expert analyzing comprehensive chunk {i+1}/{len(chunks)}")
                    
                    user_prompt = f"""COMPREHENSIVE LEGAL DOCUMENT ANALYSIS - Chunk {i+1}/{len(chunks)}:

DOCUMENT CONTENT:
{chunk.content}

EXPERT ANALYSIS REQUIRED - EXTRACT EVERYTHING:
1. ALL LEGAL OBLIGATIONS: Every "must", "shall", "required" statement in SIMPLE ENGLISH
2. ALL STAKEHOLDER ROLES: Controller, processor, joint controller, data subject, DPO, supervisory authority
3. ALL REGULATORY REQUIREMENTS: Every compliance requirement with conditions in plain language
4. ALL RULE TYPES: Access rights, controller obligations, processor requirements, consent management, data transfers, etc.
5. ALL REFERENCES: Exact article/section numbers and titles (SEPARATE from rule text)
6. ALL OBLIGATIONS: From every part of this chunk, not just main sections

COMPREHENSIVE CHAIN OF THOUGHT:
Step 1: Scan ENTIRE chunk for legal obligation keywords (must, shall, required, obligated, entitled, prohibited)
Step 2: Extract EVERY obligation text and convert to SIMPLE ENGLISH
Step 3: REMOVE any article/section references from the rule text
Step 4: Extract reference information separately for each rule
Step 5: Identify ALL stakeholders mentioned (controller, processor, joint controller, DPO, etc.)
Step 6: Classify EVERY requirement by type
Step 7: Note any conditions or exceptions

EXAMPLE TRANSFORMATION:
Original: "Article 28(3) - The processor shall process personal data only on documented instructions from the controller"
Simple English Rule: "Data processors must only process personal data based on documented instructions from the data controller"
Reference: "Article 28(3)"
Roles: ["data_processor", "data_controller"]

Return comprehensive analysis with ALL simple English rules and separate references."""

                    messages = [
                        SystemMessage(content=system_prompt),
                        HumanMessage(content=user_prompt)
                    ]
                    
                    try:
                        response = self.llm.invoke(messages)
                        response_text = str(response.content) if response and response.content else ""
                        
                        chunk_reasoning = self._extract_reasoning_trace(response_text)
                        reasoning_trace.extend(chunk_reasoning)
                        
                        chunk_obligations = self._extract_comprehensive_obligations(response_text, chunk.content)
                        
                        # Merge obligations
                        for obligation_type, obligations in chunk_obligations.items():
                            if obligation_type in all_obligations:
                                all_obligations[obligation_type].extend(obligations)
                            else:
                                all_obligations[obligation_type] = obligations
                        
                        chunk_kg = self._extract_knowledge_graph(response_text)
                        self._merge_knowledge_graphs(knowledge_graph, chunk_kg)
                        
                    except Exception as e:
                        logger.error(f"‚ùå Expert chunk {i+1} failed: {e}")
                        reasoning_trace.append(f"ERROR Chunk {i+1}: {str(e)}")
            
            # Update state
            state['legal_obligations'] = all_obligations
            state['parsed_sections'] = self._create_structured_sections(all_obligations)
            state['agent1_reasoning'] = reasoning_trace
            state['agent1_knowledge_graph'] = knowledge_graph
            state['chunks_processed'] = len(chunks)
            state['total_chunks'] = len(chunks)
            state['current_agent'] = 'GeographyAgent'
            
            total_obligations = sum(len(obls) for obls in all_obligations.values())
            logger.info(f"‚úÖ {self.name}: Extracted {total_obligations} total obligations from {len(all_obligations)} categories")
            
        except Exception as e:
            logger.error(f"‚ùå {self.name}: Processing failed: {e}")
            state['legal_obligations'] = {}
            state['agent1_reasoning'] = [f"ERROR: {str(e)}"]
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace"""
        trace = []
        try:
            if response_text:
                # Look for chain of thought patterns
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'ANALYSIS:\s*(.*?)(?=CONCLUSION:|$)',
                    r'FINDINGS:\s*(.*?)(?=RECOMMENDATIONS:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_comprehensive_obligations(self, response_text: str, original_content: str) -> Dict[str, List]:
        """Extract comprehensive legal obligations from expert analysis"""
        obligations = {
            "data_subject_rights": [],
            "controller_obligations": [],
            "processor_requirements": [],
            "joint_controller_provisions": [],
            "consent_management": [],
            "data_transfers": [],
            "compliance_requirements": [],
            "dpo_obligations": [],
            "supervisory_authority_powers": [],
            "penalties": []
        }
        
        try:
            # Enhanced patterns to extract ALL legal obligations
            obligation_patterns = {
                "data_subject_rights": [
                    r'(data subject[^.]*?(?:right|entitled|may)[^.]*?\.)',
                    r'(individual[^.]*?(?:request|access|rectification|erasure|portability)[^.]*?\.)',
                    r'(person[^.]*?(?:right to|may request|entitled to)[^.]*?\.)'
                ],
                "controller_obligations": [
                    r'((?:data\s+)?controller[^.]*?(?:must|shall|required|obligated)[^.]*?\.)',
                    r'((?:data\s+)?controller[^.]*?(?:obligation|duty|responsibility)[^.]*?\.)'
                ],
                "processor_requirements": [
                    r'((?:data\s+)?processor[^.]*?(?:must|shall|required|obligated)[^.]*?\.)',
                    r'((?:data\s+)?processor[^.]*?(?:obligation|duty|responsibility)[^.]*?\.)'
                ],
                "joint_controller_provisions": [
                    r'(joint\s+controller[^.]*?(?:must|shall|required|obligated)[^.]*?\.)',
                    r'(joint[^.]*?(?:determine|responsibility|arrangement)[^.]*?\.)',
                    r'(jointly[^.]*?(?:determine|responsible)[^.]*?\.)'
                ],
                "consent_management": [
                    r'(consent[^.]*?(?:must|shall|required|obtained|withdrawn)[^.]*?\.)',
                    r'(consent[^.]*?(?:withdrawal|revocation|freely given)[^.]*?\.)'
                ],
                "data_transfers": [
                    r'(transfer[^.]*?(?:personal data|data)[^.]*?(?:third country|outside|adequacy)[^.]*?\.)',
                    r'(adequacy[^.]*?(?:decision|assessment|commission)[^.]*?\.)'
                ],
                "dpo_obligations": [
                    r'((?:data protection officer|dpo)[^.]*?(?:must|shall|required|task)[^.]*?\.)',
                    r'((?:data protection officer|dpo)[^.]*?(?:obligation|duty|responsibility)[^.]*?\.)'
                ],
                "supervisory_authority_powers": [
                    r'(supervisory authority[^.]*?(?:may|power|shall|investigate)[^.]*?\.)',
                    r'(authority[^.]*?(?:impose|fine|investigate|order)[^.]*?\.)'
                ]
            }
            
            # Search both response and original content
            search_texts = [response_text, original_content]
            
            for text in search_texts:
                if not text:
                    continue
                
                text = str(text)
                for obligation_type, patterns in obligation_patterns.items():
                    for pattern in patterns:
                        matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
                        for match in matches:
                            if isinstance(match, str) and len(match) > 20:
                                # Clean the text to simple English and extract reference
                                cleaned_text = clean_text_to_simple_english(match.strip())
                                reference = extract_comprehensive_references(match.strip())
                                roles = extract_comprehensive_roles_from_text(match.strip())
                                
                                obligations[obligation_type].append({
                                    "text": cleaned_text,
                                    "reference": reference,
                                    "roles": roles,
                                    "source": "expert_analysis" if text == response_text else "original_document"
                                })
            
            # Extract ALL requirements with must/shall patterns
            must_shall_pattern = r'([^.]*?(?:must|shall|required|obligated|entitled)[^.]*?\.)'
            must_shall_matches = re.findall(must_shall_pattern, original_content, re.IGNORECASE)
            
            for match in must_shall_matches:
                if len(match) > 30:  # Substantial requirement
                    # Clean to simple English and extract reference
                    cleaned_text = clean_text_to_simple_english(match.strip())
                    reference = extract_comprehensive_references(match.strip())
                    roles = extract_comprehensive_roles_from_text(match.strip())
                    
                    # Classify the requirement more comprehensively
                    match_lower = match.lower()
                    if any(keyword in match_lower for keyword in ['data subject', 'individual', 'person', 'right']):
                        obligations["data_subject_rights"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['joint controller', 'jointly determine']):
                        obligations["joint_controller_provisions"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['controller', 'data controller']):
                        obligations["controller_obligations"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['processor', 'data processor']):
                        obligations["processor_requirements"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['dpo', 'data protection officer']):
                        obligations["dpo_obligations"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['consent']):
                        obligations["consent_management"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['transfer', 'third country', 'adequacy']):
                        obligations["data_transfers"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    elif any(keyword in match_lower for keyword in ['supervisory authority', 'authority']):
                        obligations["supervisory_authority_powers"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
                    else:
                        obligations["compliance_requirements"].append({
                            "text": cleaned_text, "reference": reference, "roles": roles, "source": "pattern_match"
                        })
        
        except Exception as e:
            logger.error(f"Error extracting comprehensive obligations: {e}")
        
        return obligations
    
    def _extract_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract knowledge graph from expert analysis"""
        kg = {"entities": [], "relationships": [], "obligations": []}
        
        try:
            if response_text:
                # Extract legal entities
                entity_patterns = [
                    r'(?:Article|Section|Paragraph)\s+(\d+(?:\.\d+)*)',
                    r'(data controller|controller)',
                    r'(data processor|processor)',
                    r'(joint controller)',
                    r'(data subject)',
                    r'(personal data)',
                    r'(consent)',
                    r'(adequacy decision)',
                    r'(data protection officer|dpo)',
                    r'(supervisory authority)'
                ]
                
                for pattern in entity_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if isinstance(match, str) and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting knowledge graph: {e}")
        
        return kg
    
    def _merge_knowledge_graphs(self, main_kg: Dict, chunk_kg: Dict):
        """Merge knowledge graphs safely"""
        try:
            chunk_kg = ensure_dict(chunk_kg)
            
            # Merge entities
            chunk_entities = ensure_list(chunk_kg.get("entities", []))
            for entity in chunk_entities:
                entity_str = str(entity) if entity else ""
                if entity_str and entity_str not in main_kg["entities"]:
                    main_kg["entities"].append(entity_str)
        
        except Exception as e:
            logger.debug(f"Error merging knowledge graphs: {e}")
    
    def _create_structured_sections(self, obligations: Dict) -> Dict[str, str]:
        """Create structured sections from obligations"""
        sections = {}
        
        try:
            for obligation_type, obligation_list in obligations.items():
                if obligation_list:
                    section_content = f"## {obligation_type.replace('_', ' ').title()}\n\n"
                    for i, obligation in enumerate(obligation_list[:10], 1):  # Top 10 per type
                        if isinstance(obligation, dict):
                            text = obligation.get("text", "")
                            reference = obligation.get("reference", "")
                            roles = obligation.get("roles", [])
                            source = obligation.get("source", "")
                            section_content += f"{i}. {text}\n"
                            section_content += f"   Reference: {reference}\n"
                            section_content += f"   Roles: {', '.join(roles)}\n"
                            section_content += f"   Source: {source}\n\n"
                        else:
                            section_content += f"{i}. {str(obligation)}\n\n"
                    sections[f"Level-1-{obligation_type}"] = section_content
        
        except Exception as e:
            logger.error(f"Error creating structured sections: {e}")
        
        return sections

# MIXTURE OF EXPERTS AGENT 2: Geography and Jurisdiction Expert  
class GeographyJurisdictionExpert:
    """Expert 2: Enhanced geography, jurisdiction, and adequacy analysis"""
    
    def __init__(self, llm: ChatOpenAI, geography_handler: GeographyHandler):
        self.llm = llm
        self.geography_handler = geography_handler
        self.name = "GeographyJurisdictionExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Enhanced expert analysis of jurisdictions and country-specific requirements"""
        
        logger.info(f"üåç {self.name}: Analyzing comprehensive jurisdictions and adequacy")
        
        try:
            system_prompt = f"""You are a Geography and Jurisdiction Expert specializing in international data protection law.

EXPERTISE: Cross-border data transfers, adequacy decisions, jurisdictional requirements, comprehensive country analysis

AVAILABLE GEOGRAPHY DATA:
{json.dumps(dict(list(self.geography_handler.all_countries.items())[:30]), indent=2)}
... (Total: {len(self.geography_handler.all_countries)} countries)

MISSION: Identify ALL SPECIFIC countries mentioned in document with their legal context and FIND ALL adequacy references.

COMPREHENSIVE ANALYSIS REQUIRED:
1. SCAN ENTIRE DOCUMENT: Look for ALL country names, ISO codes, regional references (EU, EEA, etc.)
2. ENHANCED ADEQUACY DETECTION: Find ALL "adequacy decision", "adequate protection", "safe harbor" references
3. TRANSFER REQUIREMENTS: Identify ALL cross-border transfer conditions and restrictions
4. JURISDICTION MAPPING: Map ALL legal requirements to specific countries
5. REGIONAL EXPANSION: Convert regional references (EU, EEA) to complete country lists
6. VERIFICATION: Verify ALL countries against geography database

CRITICAL INSTRUCTIONS:
- Find ALL country mentions with their legal context throughout entire document
- Identify ALL adequacy countries with SPECIFIC context and exact text references
- Map ALL regional references to actual countries
- Extract ALL transfer requirements and restrictions
- Verify ALL countries against provided geography data
- NO generic answers - find ACTUAL countries from document with exact context"""

            # Combine all legal obligations for comprehensive analysis
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            all_content = state.get('document_text', '')  # Use full document text
            
            # Also include obligation text for context
            obligations_text = ""
            for obligation_type, obligations in legal_obligations.items():
                for obligation in ensure_list(obligations):
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        obligations_text += f"\n{text}\n"
            
            combined_content = f"{all_content}\n\n{obligations_text}"
            
            user_prompt = f"""COMPREHENSIVE GEOGRAPHY AND JURISDICTION ANALYSIS:

FULL DOCUMENT CONTENT FOR ANALYSIS:
{combined_content[:15000]}  

CONFIGURATION DATA:
- Applicable Countries (from config): {state['metadata_config'].get('applicable_countries', [])}

COMPREHENSIVE EXPERT ANALYSIS REQUIRED:
1. COMPLETE COUNTRY IDENTIFICATION: Find ALL specific country mentions with context throughout document
2. ENHANCED ADEQUACY ANALYSIS: Identify ALL countries with "adequacy decision", "adequate protection", or "commission decision" 
3. COMPREHENSIVE TRANSFER RULES: Extract ALL cross-border transfer requirements and restrictions
4. COMPLETE REGIONAL MAPPING: Convert ALL EU/EEA references to specific country lists
5. THOROUGH JURISDICTION VERIFICATION: Verify ALL countries against geography database

COMPREHENSIVE CHAIN OF THOUGHT:
Step 1: Scan ENTIRE document for ALL country names, ISO codes, regional terms
Step 2: Find ALL adequacy contexts with exact quotes: "Country X has adequacy decision", "adequate protection in Y"
Step 3: Extract ALL transfer restrictions and requirements with country context
Step 4: Map ALL regions (EU = 27 countries, EEA = EU + Iceland, Liechtenstein, Norway)
Step 5: Verify ALL identified countries exist in geography database
Step 6: Categorize by legal context (adequacy, restriction, requirement, general mention)

ADEQUACY DETECTION EXAMPLES:
- "Commission Decision on adequacy for Canada"
- "Argentina has adequate protection"
- "Safe Harbor framework for US"
- "Adequacy decision for Japan"

Return comprehensive country analysis with ALL specific legal contexts and exact quotes from document."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Enhanced country analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_geography_knowledge_graph(response_text)
            country_results = self._extract_and_verify_countries_comprehensive(response_text, combined_content)
            
            # Update state
            state['identified_countries'] = country_results
            state['agent2_reasoning'] = reasoning_trace
            state['agent2_knowledge_graph'] = knowledge_graph
            state['current_agent'] = 'RuleExtractionAgent'
            
            mentioned_count = len(country_results.get('mentioned_countries', []))
            adequacy_count = len(country_results.get('adequacy_countries', []))
            
            logger.info(f"‚úÖ {self.name}: Identified {mentioned_count} countries, {adequacy_count} with adequacy")
            
        except Exception as e:
            logger.error(f"‚ùå {self.name}: Processing failed: {e}")
            state['agent2_reasoning'] = [f"ERROR: {str(e)}"]
            state['identified_countries'] = {
                "mentioned_countries": [],
                "adequacy_countries": [],
                "transfer_restrictions": [],
                "verification_status": "failed"
            }
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace from geography expert"""
        trace = []
        try:
            if response_text:
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'COUNTRY ANALYSIS:\s*(.*?)(?=ADEQUACY ANALYSIS:|$)',
                    r'ADEQUACY ANALYSIS:\s*(.*?)(?=VERIFICATION:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_geography_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract geography knowledge graph"""
        kg = {"entities": [], "relationships": [], "adequacy_mapping": {}}
        
        try:
            if response_text:
                # Extract geography entities
                geo_patterns = [
                    r'([A-Z]{2})\s*-\s*([^,\n]+)',  # ISO-Country pairs
                    r'adequacy[^.]*?([A-Z]{2}|[A-Z][a-z]+)',  # Adequacy contexts
                    r'transfer[^.]*?([A-Z]{2}|[A-Z][a-z]+)'   # Transfer contexts
                ]
                
                for pattern in geo_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if isinstance(match, tuple):
                            kg["entities"].extend([str(m) for m in match if m])
                        elif match:
                            kg["entities"].append(str(match))
        
        except Exception as e:
            logger.debug(f"Error extracting geography knowledge graph: {e}")
        
        return kg
    
    def _extract_and_verify_countries_comprehensive(self, response_text: str, document_text: str) -> Dict[str, Any]:
        """Comprehensive extraction and verification of countries with enhanced adequacy detection"""
        try:
            # Enhanced country extraction with both methods
            mentioned_countries = self.geography_handler.find_countries_in_text(document_text)
            adequacy_countries = self.geography_handler.find_adequacy_countries_in_text(document_text)
            transfer_restrictions = []
            
            all_text = f"{response_text} {document_text}"
            
            # Enhanced adequacy detection with multiple pattern approaches
            additional_adequacy_patterns = [
                r'commission\s+decision[^.]*?adequacy[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?commission\s+decision[^.]*?adequacy',
                r'safe\s+harbor[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?safe\s+harbor',
                r'adequacy\s+finding[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?adequacy\s+finding',
                r'adequate\s+safeguards[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?adequate\s+safeguards'
            ]
            
            for pattern in additional_adequacy_patterns:
                try:
                    matches = re.findall(pattern, all_text, re.IGNORECASE)
                    for match in matches:
                        if match and self.geography_handler.is_valid_country(str(match)):
                            adequacy_countries.append(str(match).upper())
                except Exception as e:
                    logger.debug(f"Error in additional adequacy pattern: {e}")
                    continue
            
            # Enhanced transfer restriction detection
            restriction_patterns = [
                r'transfer[^.]*?prohibited[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?restricted[^.]*?transfer',
                r'no\s+transfer[^.]*?([A-Z]{2})',
                r'transfer\s+restriction[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?transfer\s+restriction'
            ]
            
            for pattern in restriction_patterns:
                try:
                    matches = re.findall(pattern, all_text, re.IGNORECASE)
                    for match in matches:
                        if match and self.geography_handler.is_valid_country(str(match)):
                            transfer_restrictions.append(str(match).upper())
                except Exception as e:
                    logger.debug(f"Error in restriction pattern: {e}")
                    continue
            
            # Enhanced country name matching for adequacy contexts
            for iso in mentioned_countries:
                try:
                    country_name = self.geography_handler.get_country_name(iso)
                    if country_name:
                        name_lower = str(country_name).lower()
                        adequacy_context_patterns = [
                            rf'{re.escape(name_lower)}[^.]*?adequacy',
                            rf'adequacy[^.]*?{re.escape(name_lower)}',
                            rf'{re.escape(name_lower)}[^.]*?adequate\s+protection',
                            rf'adequate\s+protection[^.]*?{re.escape(name_lower)}',
                            rf'{re.escape(name_lower)}[^.]*?commission\s+decision',
                            rf'commission\s+decision[^.]*?{re.escape(name_lower)}',
                            rf'{re.escape(name_lower)}[^.]*?safe\s+harbor',
                            rf'safe\s+harbor[^.]*?{re.escape(name_lower)}'
                        ]
                        
                        text_lower = all_text.lower()
                        for pattern in adequacy_context_patterns:
                            if re.search(pattern, text_lower):
                                adequacy_countries.append(iso)
                                break
                except Exception as e:
                    logger.debug(f"Error checking adequacy context for {iso}: {e}")
                    continue
            
            # Remove duplicates and validate
            mentioned_countries = list(set(mentioned_countries))
            adequacy_countries = list(set(adequacy_countries))
            transfer_restrictions = list(set(transfer_restrictions))
            
            return {
                "mentioned_countries": mentioned_countries,
                "adequacy_countries": adequacy_countries,
                "transfer_restrictions": transfer_restrictions,
                "verification_status": "verified against geography data",
                "total_countries_found": len(mentioned_countries),
                "total_adequacy_found": len(adequacy_countries)
            }
        
        except Exception as e:
            logger.error(f"Error in comprehensive country extraction: {e}")
            return {
                "mentioned_countries": [],
                "adequacy_countries": [],
                "transfer_restrictions": [],
                "verification_status": "error"
            }

# MIXTURE OF EXPERTS AGENT 3: Rule Engine Expert
class RuleEngineExpert:
    """Expert 3: Enhanced JSON Rules Engine compatible rule extraction"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.name = "RuleEngineExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Extract comprehensive rules in JSON Rules Engine compatible format"""
        
        logger.info(f"‚öñÔ∏è {self.name}: Extracting comprehensive JSON Rules Engine compatible rules")
        
        try:
            system_prompt = """You are a Rule Engine Expert specializing in converting legal requirements to machine-readable rules.

EXPERTISE: JSON Rules Engine format, if-else logic, machine-readable conditions, comprehensive rule extraction

MISSION: Convert ALL legal obligations to JSON Rules Engine compatible rules with precise conditions in SIMPLE ENGLISH.

IMPORTANT: 
- All rule definitions and condition descriptions must be in SIMPLE, CLEAR English
- NO article/section references in rule text or condition text
- Keep reference information separate in the "reference" field
- Extract ALL roles mentioned: controller, processor, joint controller, data subject, DPO, supervisory authority
- Make rules understandable to non-lawyers
- Create rules for EVERY obligation found, not just main ones

JSON RULES ENGINE FORMAT REQUIRED:
{
  "rule_id": "unique_identifier_based_on_document_and_sequence",
  "rule_definition": "EXACT legal requirement in SIMPLE ENGLISH (no article references)",
  "rule_type": "access_right|processing_obligation|consent_requirement|data_transfer|breach_notification|etc",
  "conditions": [
    {
      "condition_id": "specific_condition_id",
      "condition_definition": "Human readable condition in SIMPLE ENGLISH (no article references)",
      "fact": "user.role|data.category|request.type|processing.purpose|etc",
      "operator": "equal|notEqual|in|notIn|greaterThan|lessThan|contains",
      "value": "specific_value_or_list",
      "role": "data_controller|data_processor|joint_controller|data_subject|dpo|supervisory_authority|third_party",
      "if_condition": "IF this condition is true (SIMPLE ENGLISH)",
      "else_condition": "ELSE alternative condition (SIMPLE ENGLISH)"
    }
  ],
  "action": "SPECIFIC action in SIMPLE ENGLISH (no article references)",
  "consequence": "Penalty or outcome if rule violated",
  "reference": "EXACT Article X.Y or Section Z reference",
  "priority": "high|medium|low"
}

COMPREHENSIVE PROCESSING:
1. Convert EVERY legal obligation to a rule
2. Extract ALL stakeholder roles from text
3. Create proper aggregated_roles from all conditions
4. Use actual references from document
5. Generate unique rule IDs based on document hash and sequence

CRITICAL INSTRUCTIONS:
- Extract rules for ALL obligation types found
- Use ALL roles mentioned: controller, processor, joint controller, DPO, supervisory authority
- Include EXACT references from document in reference field ONLY
- Create comprehensive IF-ELSE condition logic in simple English
- Use proper JSON Rules Engine operators
- Set appropriate rule priorities based on content importance
- NO article/section references in rule_definition, action, or condition_definition fields"""

            # Get comprehensive legal obligations for rule extraction
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            country_info = ensure_dict(state.get('identified_countries', {}))
            document_hash = state.get('document_hash', 'doc')
            
            obligations_text = ""
            total_obligations = 0
            for obligation_type, obligations in legal_obligations.items():
                obligations_text += f"\n## {obligation_type.upper()}\n"
                for obligation in ensure_list(obligations):
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        reference = obligation.get("reference", "")
                        roles = obligation.get("roles", [])
                        obligations_text += f"- Rule: {text}\n- Reference: {reference}\n- Roles: {roles}\n"
                        total_obligations += 1
            
            applicable_countries = state['metadata_config'].get('applicable_countries', [])
            adequacy_countries = country_info.get('adequacy_countries', [])
            
            user_prompt = f"""COMPREHENSIVE RULE ENGINE CONVERSION TASK:

LEGAL OBLIGATIONS TO CONVERT (Total: {total_obligations}):
{obligations_text}

JURISDICTION CONTEXT:
- Applicable Countries: {applicable_countries}
- Adequacy Countries: {adequacy_countries}
- Document Hash: {document_hash}

COMPREHENSIVE EXPERT ANALYSIS REQUIRED:
Convert EVERY legal obligation to JSON Rules Engine format with:

1. UNIQUE RULE IDs using document hash and sequence
2. SPECIFIC RULE DEFINITIONS in SIMPLE ENGLISH (no article references)
3. COMPREHENSIVE ROLE EXTRACTION from obligation text
4. PRECISE CONDITIONS with if-else logic in plain language
5. PROPER JSON Rules Engine operators
6. ALL STAKEHOLDER ROLES (data_controller, data_processor, joint_controller, data_subject, dpo, supervisory_authority, third_party)
7. EXACT ACTIONS in simple language (no article references)
8. ACTUAL REFERENCES from document in reference field ONLY
9. CONSEQUENCES and priorities

COMPREHENSIVE CHAIN OF THOUGHT:
Step 1: For EACH obligation, extract the exact requirement text in simple English
Step 2: REMOVE any article/section references from rule text
Step 3: Extract ALL roles mentioned in the obligation text
Step 4: Identify WHO has the obligation (primary role)
Step 5: Determine WHEN it applies (conditions with if-else in simple English)
Step 6: Define WHAT must be done (specific action in plain language)
Step 7: Extract ACTUAL LEGAL REFERENCE for reference field ONLY
Step 8: Generate unique rule ID using document hash + rule type + sequence
Step 9: Set priority based on content (high for penalties, medium for obligations, low for recommendations)
Step 10: Create aggregated_roles list from all roles found

Return JSON array of ALL rules with comprehensive coverage."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse expert analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_rule_knowledge_graph(response_text)
            extracted_rules = self._extract_comprehensive_json_rules(response_text, state)
            
            # Update state
            state['extracted_rules'] = extracted_rules
            state['agent3_reasoning'] = reasoning_trace
            state['agent3_knowledge_graph'] = knowledge_graph
            state['current_agent'] = 'ValidationAgent'
            
            logger.info(f"‚úÖ {self.name}: Extracted {len(extracted_rules)} comprehensive JSON Rules Engine compatible rules")
            
        except Exception as e:
            logger.error(f"‚ùå {self.name}: Processing failed: {e}")
            state['agent3_reasoning'] = [f"ERROR: {str(e)}"]
            state['extracted_rules'] = []
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace from rule engine expert"""
        trace = []
        try:
            if response_text:
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'ANALYSIS:\s*(.*?)(?=CONVERSION:|$)',
                    r'RULE EXTRACTION:\s*(.*?)(?=VALIDATION:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_rule_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract rule knowledge graph"""
        kg = {"entities": [], "relationships": [], "rule_mappings": {}}
        
        try:
            if response_text:
                # Extract rule entities
                rule_patterns = [
                    r'rule_id[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'rule_type[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'fact[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'operator[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'role[\'"]:\s*[\'"]([^\'\"]+)[\'"]'
                ]
                
                for pattern in rule_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting rule knowledge graph: {e}")
        
        return kg
    
    def _extract_comprehensive_json_rules(self, response_text: str, state: MultiAgentState) -> List[Dict]:
        """Extract comprehensive JSON Rules Engine compatible rules"""
        rules = []
        
        try:
            # Try to extract JSON array from response
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                try:
                    rules_data = json.loads(json_match.group(0))
                    if isinstance(rules_data, list):
                        rules = rules_data
                    elif isinstance(rules_data, dict):
                        rules = [rules_data]
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON parsing failed: {e}")
            
            # If no valid JSON found, create comprehensive rules from legal obligations
            if not rules:
                rules = self._create_comprehensive_rules_from_obligations(state)
            
            # Enhance rules with proper JSON Rules Engine format and simple English
            enhanced_rules = []
            for i, rule in enumerate(rules):
                if rule:
                    enhanced_rule = self._enhance_rule_comprehensive(rule, state, i)
                    if enhanced_rule:
                        enhanced_rules.append(enhanced_rule)
            
            return enhanced_rules
        
        except Exception as e:
            logger.error(f"Error extracting comprehensive JSON rules: {e}")
            return []
    
    def _create_comprehensive_rules_from_obligations(self, state: MultiAgentState) -> List[Dict]:
        """Create comprehensive rules from all legal obligations"""
        rules = []
        
        try:
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            document_hash = state.get('document_hash', 'doc')
            
            rule_types_mapping = {
                "data_subject_rights": "access_right",
                "controller_obligations": "processing_obligation", 
                "processor_requirements": "processor_obligation",
                "joint_controller_provisions": "joint_controller_obligation",
                "consent_management": "consent_requirement",
                "data_transfers": "data_transfer",
                "compliance_requirements": "compliance_obligation",
                "dpo_obligations": "dpo_obligation",
                "supervisory_authority_powers": "supervisory_power",
                "penalties": "penalty_provision"
            }
            
            rule_sequence = 1
            
            for obligation_type, obligations in legal_obligations.items():
                rule_type = rule_types_mapping.get(obligation_type, "compliance_obligation")
                
                for obligation in ensure_list(obligations):
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        reference = obligation.get("reference", "Legal requirement")
                        roles = obligation.get("roles", ["data_controller"])
                        
                        if len(text) > 20:  # Substantial rule
                            # Clean text to simple English
                            cleaned_text = clean_text_to_simple_english(text)
                            
                            rule_id = generate_unique_rule_id(document_hash, rule_type, rule_sequence)
                            rule = {
                                "rule_id": rule_id,
                                "rule_definition": cleaned_text,
                                "rule_type": rule_type,
                                "conditions": self._create_comprehensive_conditions(cleaned_text, obligation_type, roles),
                                "action": self._extract_action_comprehensive(cleaned_text),
                                "reference": reference,
                                "priority": self._determine_priority_comprehensive(text),
                                "aggregated_roles": roles
                            }
                            rules.append(rule)
                            rule_sequence += 1
                    
                    if len(rules) >= 50:  # Reasonable limit
                        break
                
                if len(rules) >= 50:
                    break
        
        except Exception as e:
            logger.error("Error creating comprehensive rules from obligations: " + str(e))
        
        return rules
    
    def _create_comprehensive_conditions(self, text: str, obligation_type: str, roles: List[str]) -> List[Dict]:
        """Create comprehensive JSON Rules Engine compatible conditions"""
        conditions = []
        
        try:
            text_lower = str(text).lower()
            
            # Determine primary role from roles list
            primary_role = "data_controller"  # Default
            if "data_processor" in roles:
                primary_role = "data_processor"
            elif "joint_controller" in roles:
                primary_role = "joint_controller"
            elif "data_subject" in roles:
                primary_role = "data_subject"
            elif "dpo" in roles:
                primary_role = "dpo"
            elif "supervisory_authority" in roles:
                primary_role = "supervisory_authority"
            
            # Create comprehensive conditions based on obligation type
            condition_id = f"cond_{uuid.uuid4().hex[:8]}"
            
            if obligation_type == "data_subject_rights":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When a data subject exercises their rights",
                    "fact": "request.type",
                    "operator": "in",
                    "value": ["access_request", "rectification_request", "erasure_request", "portability_request", "restriction_request"],
                    "role": "data_subject",
                    "if_condition": "IF a valid data subject request is received",
                    "else_condition": "ELSE reject the invalid request"
                })
            elif obligation_type == "controller_obligations":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When the controller processes personal data",
                    "fact": "data.category",
                    "operator": "equal",
                    "value": "personal_data",
                    "role": primary_role,
                    "if_condition": "IF processing personal data",
                    "else_condition": "ELSE no obligation applies"
                })
            elif obligation_type == "processor_requirements":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When the processor handles personal data",
                    "fact": "processing.context",
                    "operator": "equal",
                    "value": "processor_role",
                    "role": "data_processor",
                    "if_condition": "IF acting as data processor",
                    "else_condition": "ELSE different obligations apply"
                })
            elif obligation_type == "joint_controller_provisions":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When joint controllers determine processing purposes",
                    "fact": "controller.type",
                    "operator": "equal",
                    "value": "joint_controller",
                    "role": "joint_controller",
                    "if_condition": "IF acting as joint controller",
                    "else_condition": "ELSE single controller obligations apply"
                })
            elif obligation_type == "consent_management":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When consent is required for processing",
                    "fact": "processing.lawful_basis",
                    "operator": "equal",
                    "value": "consent",
                    "role": primary_role,
                    "if_condition": "IF consent is the lawful basis",
                    "else_condition": "ELSE use alternative lawful basis"
                })
            elif obligation_type == "data_transfers":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When transferring data to a third country",
                    "fact": "transfer.destination_country",
                    "operator": "notIn",
                    "value": ["adequacy_countries"],
                    "role": primary_role,
                    "if_condition": "IF destination country lacks adequacy decision",
                    "else_condition": "ELSE transfer is allowed with adequacy"
                })
            elif obligation_type == "dpo_obligations":
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When DPO tasks are required",
                    "fact": "organization.dpo_required",
                    "operator": "equal",
                    "value": True,
                    "role": "dpo",
                    "if_condition": "IF DPO is required for the organization",
                    "else_condition": "ELSE DPO tasks are optional"
                })
            else:
                # Generic condition
                conditions.append({
                    "condition_id": condition_id,
                    "condition_definition": "When the obligation applies",
                    "fact": "obligation.context",
                    "operator": "equal",
                    "value": "applicable",
                    "role": primary_role,
                    "if_condition": "IF the conditions are met",
                    "else_condition": "ELSE no action is required"
                })
        
        except Exception as e:
            logger.debug("Error creating comprehensive conditions: " + str(e))
            # Fallback condition
            fallback_id = "cond_" + uuid.uuid4().hex[:8]
            conditions = [{
                "condition_id": fallback_id,
                "condition_definition": "Default condition for rule application",
                "fact": "obligation.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF the obligation applies",
                "else_condition": "ELSE no action is required"
            }]
        
        return conditions
    
    def _extract_action_comprehensive(self, text: str) -> str:
        """Extract comprehensive action from rule text in simple English"""
        try:
            text = str(text)
            
            # Clean the text first
            cleaned_text = clean_text_to_simple_english(text)
            
            # Enhanced action patterns
            action_patterns = [
                r'(?:must|shall|required to|need to|have to)\s+([^.]+)',
                r'(?:obligation to|duty to|responsible for)\s+([^.]+)',
                r'(?:right to|may|can)\s+([^.]+)',
                r'(?:ensure|provide|implement|maintain|establish)\s+([^.]+)'
            ]
            
            for pattern in action_patterns:
                match = re.search(pattern, cleaned_text, re.IGNORECASE)
                if match:
                    action = match.group(1).strip()
                    if len(action) > 10:
                        # Clean the action text as well
                        return clean_text_to_simple_english(action)
            
            # Fallback: try to extract the main verb phrase
            sentences = re.split(r'[.!?]', cleaned_text)
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 20:
                    # Look for action verbs
                    action_verbs = ['provide', 'ensure', 'implement', 'obtain', 'notify', 'maintain', 'establish', 'record', 'document', 'process']
                    for verb in action_verbs:
                        if verb in sentence.lower():
                            return clean_text_to_simple_english(sentence)
            
            return "Comply with the stated requirement"
        
        except Exception as e:
            logger.debug(f"Error extracting comprehensive action: {e}")
            return "Comply with the stated requirement"
    
    def _determine_priority_comprehensive(self, text: str) -> str:
        """Determine comprehensive rule priority based on content"""
        try:
            text_lower = str(text).lower()
            
            # High priority indicators
            high_priority_terms = ['penalty', 'fine', 'sanction', 'breach', 'violation', 'criminal', 'imprisonment', 'prosecution', 'administrative fine']
            if any(term in text_lower for term in high_priority_terms):
                return "high"
            
            # Medium priority indicators  
            medium_priority_terms = ['must', 'shall', 'required', 'obligation', 'mandatory', 'compulsory']
            if any(term in text_lower for term in medium_priority_terms):
                return "medium"
            
            # Low priority (recommendations, etc.)
            return "low"
        
        except Exception as e:
            logger.debug(f"Error determining comprehensive priority: {e}")
            return "medium"
    
    def _enhance_rule_comprehensive(self, rule: Dict, state: MultiAgentState, sequence: int) -> Dict:
        """Enhance rule comprehensively for JSON Rules Engine compatibility"""
        try:
            rule_dict = ensure_dict(rule)
            country_info = ensure_dict(state.get('identified_countries', {}))
            document_hash = state.get('document_hash', 'doc')
            
            # Generate proper unique rule ID if not present
            rule_type = safe_get(rule_dict, "rule_type", "compliance_obligation")
            rule_id = safe_get(rule_dict, "rule_id", generate_unique_rule_id(document_hash, rule_type, sequence))
            
            # Clean rule definition and action to simple English
            rule_definition = safe_get(rule_dict, "rule_definition", "Legal compliance requirement")
            rule_definition = clean_text_to_simple_english(rule_definition)
            
            action = safe_get(rule_dict, "action", "Comply with legal requirement")
            action = clean_text_to_simple_english(action)
            
            enhanced_rule = {
                "rule_id": rule_id,
                "rule_definition": rule_definition,
                "rule_type": rule_type,
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": ensure_list(country_info.get('adequacy_countries', [])),
                "conditions": self._validate_conditions_comprehensive(
                    ensure_list(rule_dict.get("conditions", []))
                ),
                "aggregated_roles": ensure_list(rule_dict.get("aggregated_roles", ["data_controller"])),
                "data_category": safe_get(rule_dict, "data_category", "personal_data"),
                "domain": safe_get(rule_dict, "domain", "data_protection_compliance"),
                "action": action,
                "consequence": safe_get(rule_dict, "consequence", ""),
                "reference": safe_get(rule_dict, "reference", "Legal requirement"),
                "priority": safe_get(rule_dict, "priority", "medium"),
                "event_type": "rule_evaluation",
                "params": {}
            }
            
            # Ensure aggregated_roles includes all roles from conditions
            condition_roles = set(enhanced_rule["aggregated_roles"])
            for condition in enhanced_rule['conditions']:
                if isinstance(condition, dict) and condition.get('role'):
                    condition_roles.add(str(condition['role']))
            enhanced_rule["aggregated_roles"] = list(condition_roles)
            
            return enhanced_rule
        
        except Exception as e:
            logger.error("Error enhancing comprehensive rule: " + str(e))
            return {}
    
    def _validate_conditions_comprehensive(self, conditions: List) -> List[Dict]:
        """Validate conditions comprehensively for JSON Rules Engine compatibility"""
        validated_conditions = []
        
        try:
            valid_operators = ['equal', 'notEqual', 'in', 'notIn', 'greaterThan', 'lessThan', 'contains']
            valid_roles = ['data_controller', 'data_processor', 'joint_controller', 'data_subject', 'dpo', 'supervisory_authority', 'third_party']
            
            for condition in ensure_list(conditions):
                condition_dict = ensure_dict(condition)
                
                # Validate and fix operator
                operator = safe_get(condition_dict, 'operator', 'equal')
                if operator not in valid_operators:
                    operator = 'equal'
                
                # Validate and fix role comprehensively
                role = safe_get(condition_dict, 'role', 'data_controller')
                if role not in valid_roles:
                    # Enhanced role mapping
                    role_lower = str(role).lower()
                    if 'joint' in role_lower and 'controller' in role_lower:
                        role = 'joint_controller'
                    elif 'controller' in role_lower:
                        role = 'data_controller'
                    elif 'processor' in role_lower:
                        role = 'data_processor'
                    elif 'subject' in role_lower:
                        role = 'data_subject'
                    elif 'dpo' in role_lower or 'protection officer' in role_lower:
                        role = 'dpo'
                    elif 'authority' in role_lower or 'supervisory' in role_lower:
                        role = 'supervisory_authority'
                    else:
                        role = 'data_controller'
                
                condition_id = safe_get(condition_dict, "condition_id", "cond_" + uuid.uuid4().hex[:8])
                
                # Clean condition definition to simple English
                condition_definition = safe_get(condition_dict, "condition_definition", "Condition for rule application")
                condition_definition = clean_text_to_simple_english(condition_definition)
                
                # Clean if/else conditions to simple English
                if_condition = safe_get(condition_dict, "if_condition", "IF condition is met")
                if_condition = clean_text_to_simple_english(if_condition)
                
                else_condition = safe_get(condition_dict, "else_condition", "ELSE no action required")
                else_condition = clean_text_to_simple_english(else_condition)
                
                validated_condition = {
                    "condition_id": condition_id,
                    "condition_definition": condition_definition,
                    "fact": safe_get(condition_dict, "fact", "obligation.applicable"),
                    "operator": operator,
                    "value": safe_get(condition_dict, "value", True),
                    "role": role,
                    "if_condition": if_condition,
                    "else_condition": else_condition
                }
                validated_conditions.append(validated_condition)
            
            # Ensure at least one condition
            if not validated_conditions:
                default_condition_id = "cond_" + uuid.uuid4().hex[:8]
                validated_conditions.append({
                    "condition_id": default_condition_id,
                    "condition_definition": "Default condition for rule application",
                    "fact": "rule.applicable",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF rule conditions are met",
                    "else_condition": "ELSE rule does not apply"
                })
        
        except Exception as e:
            logger.error("Error validating comprehensive conditions: " + str(e))
            fallback_condition_id = "cond_" + uuid.uuid4().hex[:8]
            validated_conditions = [{
                "condition_id": fallback_condition_id,
                "condition_definition": "Default condition",
                "fact": "rule.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF rule applies",
                "else_condition": "ELSE no action required"
            }]
        
        return validated_conditions

# MIXTURE OF EXPERTS AGENT 4: Validation and Quality Expert
class ValidationQualityExpert:
    """Expert 4: Enhanced rule validation and quality assurance"""
    
    def __init__(self, llm: ChatOpenAI, geography_handler: GeographyHandler):
        self.llm = llm
        self.geography_handler = geography_handler
        self.name = "ValidationQualityExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Enhanced expert validation of extracted rules"""
        
        logger.info(f"‚úÖ {self.name}: Validating and ensuring comprehensive rule quality")
        
        try:
            system_prompt = """You are a Validation and Quality Expert specializing in comprehensive rule accuracy and completeness.

EXPERTISE: Rule validation, quality assurance, completeness checking, JSON Rules Engine compatibility

MISSION: Ensure ACCURATE, SPECIFIC, and COMPLETE rules with proper references and conditions in SIMPLE ENGLISH.

COMPREHENSIVE VALIDATION REQUIREMENTS:
- All rule definitions must be in SIMPLE, CLEAR English
- NO article/section references in rule text or condition text
- References should be in the "reference" field ONLY
- ALL roles must be properly extracted: controller, processor, joint controller, DPO, supervisory authority
- Make rules understandable to non-lawyers
- Ensure comprehensive coverage of all obligation types

ENHANCED VALIDATION CHECKLIST:
1. RULE DEFINITION: Must be specific legal requirement in SIMPLE ENGLISH, not generic text
2. APPLICABLE COUNTRIES: Must match configuration countries
3. ADEQUACY COUNTRIES: Must be actual countries (not regions) with adequacy context
4. CONDITIONS: Must have proper if-else logic and valid JSON Rules Engine operators in simple English
5. ACTIONS: Must be specific requirements in plain language, not generic compliance statements
6. REFERENCES: Must be exact article/section numbers in reference field ONLY
7. ROLES: Must include ALL relevant stakeholders (controller, processor, joint controller, DPO, etc.)
8. CONSEQUENCES: Must include penalties/outcomes when specified
9. RULE IDS: Must be unique and based on document hash
10. AGGREGATED ROLES: Must include all roles from conditions and rule text

QUALITY STANDARDS:
- No duplicate rules (same requirement with different IDs)
- No generic fallback text ("Legal compliance requirement", "Must ensure compliance")
- No article references in rule_definition, action, or condition_definition fields
- All countries verified against geography database
- All conditions have valid operators (equal, in, greaterThan, etc.)
- All roles are valid and comprehensive
- All text in simple English understandable to non-lawyers

COMPREHENSIVE VALIDATION PROCESS:
1. CHECK: Each rule definition for specificity and simple English
2. VERIFY: Country codes against geography database
3. VALIDATE: Condition logic and JSON Rules Engine compatibility  
4. CONFIRM: Action specificity and simple language
5. ENSURE: Reference precision in reference field only
6. EXTRACT: All roles mentioned in rule text
7. CLEAN: Remove any article references from rule text
8. DEDUPLICATE: Remove identical or substantially similar rules
9. ENHANCE: Add missing consequences, priorities
10. VERIFY: Unique rule IDs based on document hash"""

            extracted_rules = ensure_list(state.get('extracted_rules', []))
            
            user_prompt = f"""COMPREHENSIVE RULE VALIDATION AND QUALITY ASSURANCE:

EXTRACTED RULES TO VALIDATE:
{json.dumps(extracted_rules[:3], indent=2) if extracted_rules else '[]'}
... (Total: {len(extracted_rules)} rules for comprehensive validation)

CONTEXT FOR VALIDATION:
- Available Countries: {len(self.geography_handler.all_countries)} in geography database
- Applicable Countries: {state['metadata_config'].get('applicable_countries', [])}
- Adequacy Countries Found: {state.get('identified_countries', {}).get('adequacy_countries', [])}
- Document Hash: {state.get('document_hash', 'doc')}

COMPREHENSIVE EXPERT VALIDATION REQUIRED:
1. SIMPLE ENGLISH CHECK: Ensure rule definitions are in plain language without article references
2. ROLE EXTRACTION: Extract ALL roles from rule text (controller, processor, joint controller, DPO, supervisory authority)
3. COUNTRY VERIFICATION: Validate all countries against geography database
4. CONDITION VALIDATION: Check JSON Rules Engine operator compatibility and simple English
5. REFERENCE SEPARATION: Ensure references are in reference field ONLY with actual article numbers
6. AGGREGATED ROLES: Ensure all roles from text and conditions are included
7. DEDUPLICATION: Remove identical or substantially similar rules
8. COMPLETENESS: Add missing consequences, priorities
9. QUALITY ENHANCEMENT: Improve generic statements to specific requirements in simple English
10. UNIQUE ID VERIFICATION: Ensure rule IDs are unique and properly formatted

COMPREHENSIVE VALIDATION CHAIN OF THOUGHT:
Step 1: Check each rule_definition is in simple English (reject complex legal language)
Step 2: Extract ALL roles mentioned in rule text and conditions
Step 3: Remove any article references from rule_definition, action, condition_definition
Step 4: Verify applicable_countries match configuration
Step 5: Validate adequacy_countries are real countries with context
Step 6: Check conditions have proper if-else logic and valid operators in simple English
Step 7: Ensure actions are specific in plain language (not "Must ensure compliance")
Step 8: Verify references are actual article numbers in reference field only
Step 9: Ensure aggregated_roles includes all roles found
Step 10: Remove duplicate rules with same essential requirement
Step 11: Enhance with missing details (consequences, priorities)
Step 12: Verify unique rule IDs

Return validated and enhanced rules array with comprehensive quality improvements."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse validation analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_validation_knowledge_graph(response_text)
            validated_rules = self._comprehensive_validation_enhanced(response_text, state)
            
            # Update state
            state['validated_rules'] = validated_rules
            state['agent4_reasoning'] = reasoning_trace
            state['agent4_knowledge_graph'] = knowledge_graph
            state['current_agent'] = 'SupervisorAgent'
            
            logger.info(f"‚úÖ {self.name}: Validated {len(validated_rules)} comprehensive high-quality rules")
            
        except Exception as e:
            logger.error(f"‚ùå {self.name}: Validation failed: {e}")
            state['agent4_reasoning'] = [f"ERROR: {str(e)}"]
            state['validated_rules'] = []
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract validation reasoning trace"""
        trace = []
        try:
            if response_text:
                validation_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'VALIDATION:\s*(.*?)(?=ENHANCEMENT:|$)',
                    r'QUALITY CHECK:\s*(.*?)(?=RESULT:|$)'
                ]
                
                for pattern in validation_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting validation reasoning: {e}")
        return trace
    
    def _extract_validation_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract validation knowledge graph"""
        kg = {"entities": [], "relationships": [], "validation_results": {}}
        
        try:
            if response_text:
                validation_patterns = [
                    r'VALIDATED:\s*([^,\n]+)',
                    r'ENHANCED:\s*([^,\n]+)',
                    r'REJECTED:\s*([^,\n]+)',
                    r'DUPLICATE:\s*([^,\n]+)'
                ]
                
                for pattern in validation_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting validation knowledge graph: {e}")
        
        return kg
    
    def _comprehensive_validation_enhanced(self, response_text: str, state: MultiAgentState) -> List[Dict]:
        """Enhanced comprehensive validation with quality improvements"""
        validated_rules = []
        
        try:
            # Try to extract validated rules from expert response
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                try:
                    expert_rules = json.loads(json_match.group(0))
                    if isinstance(expert_rules, list):
                        validated_rules = expert_rules
                except json.JSONDecodeError:
                    logger.warning("Expert validation JSON parsing failed")
            
            # If expert validation failed, apply comprehensive validation
            if not validated_rules:
                extracted_rules = ensure_list(state.get('extracted_rules', []))
                validated_rules = self._apply_enhanced_validation_rules(extracted_rules, state)
            
            # Apply final comprehensive quality checks and Pydantic validation
            final_validated_rules = []
            seen_definitions = set()  # For deduplication
            
            for rule_data in validated_rules:
                if not rule_data:
                    continue
                
                try:
                    rule_dict = ensure_dict(rule_data)
                    
                    # Skip duplicates
                    rule_def = str(rule_dict.get('rule_definition', '')).strip()
                    if rule_def in seen_definitions or len(rule_def) < 20:
                        continue
                    seen_definitions.add(rule_def)
                    
                    # Apply comprehensive validation with simple English
                    validated_rule = self._apply_comprehensive_validation_enhanced(rule_dict, state)
                    
                    # Validate with Pydantic
                    pydantic_rule = ExtractedRule.model_validate(validated_rule)
                    final_validated_rules.append(pydantic_rule.model_dump())
                    
                except ValidationError as e:
                    logger.warning(f"Pydantic validation failed: {e}")
                    # Try to fix and re-validate
                    fixed_rule = self._fix_validation_errors_enhanced(rule_dict, state)
                    if fixed_rule:
                        try:
                            pydantic_rule = ExtractedRule.model_validate(fixed_rule)
                            final_validated_rules.append(pydantic_rule.model_dump())
                        except ValidationError:
                            logger.debug("Could not fix validation errors")
                            continue
                except Exception as e:
                    logger.error(f"Unexpected validation error: {e}")
                    continue
            
            return final_validated_rules
        
        except Exception as e:
            logger.error(f"Error in enhanced comprehensive validation: {e}")
            return []
    
    def _apply_enhanced_validation_rules(self, rules: List[Dict], state: MultiAgentState) -> List[Dict]:
        """Apply enhanced validation rules when expert validation fails"""
        validated_rules = []
        
        try:
            for rule in ensure_list(rules):
                rule_dict = ensure_dict(rule)
                
                # Skip rules with generic content
                rule_def = str(rule_dict.get('rule_definition', '')).strip()
                if any(generic in rule_def.lower() for generic in [
                    'legal compliance requirement',
                    'must ensure compliance',
                    'comply with requirements'
                ]):
                    logger.debug(f"Skipping generic rule: {rule_def[:50]}...")
                    continue
                
                # Skip rules with generic references
                reference = str(rule_dict.get('reference', '')).strip()
                if any(generic in reference.lower() for generic in [
                    'document reference',
                    'level reference',
                    'document - level'
                ]):
                    logger.debug(f"Skipping rule with generic reference: {reference}")
                    continue
                
                validated_rules.append(rule_dict)
        
        except Exception as e:
            logger.error(f"Error applying enhanced validation rules: {e}")
        
        return validated_rules
    
    def _apply_comprehensive_validation_enhanced(self, rule_dict: Dict, state: MultiAgentState) -> Dict:
        """Apply enhanced comprehensive validation to a single rule"""
        try:
            country_info = ensure_dict(state.get('identified_countries', {}))
            
            # Clean all text fields to simple English
            rule_definition = safe_get(rule_dict, "rule_definition", "Specific legal requirement")
            rule_definition = clean_text_to_simple_english(rule_definition)
            
            action = safe_get(rule_dict, "action", "Implement required measures")
            action = clean_text_to_simple_english(action)
            
            # Extract comprehensive roles from rule text
            rule_text = f"{rule_definition} {action}"
            extracted_roles = extract_comprehensive_roles_from_text(rule_text)
            existing_roles = ensure_list(rule_dict.get("aggregated_roles", []))
            all_roles = list(set(extracted_roles + existing_roles))
            
            # Comprehensive validation and enhancement
            validated_rule = {
                "rule_id": safe_get(rule_dict, "rule_id", f"rule_{uuid.uuid4().hex[:8]}"),
                "rule_definition": rule_definition,
                "rule_type": safe_get(rule_dict, "rule_type", "compliance_obligation"),
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": self._verify_adequacy_countries_enhanced(
                    ensure_list(country_info.get('adequacy_countries', []))
                ),
                "conditions": self._validate_and_enhance_conditions_comprehensive(
                    ensure_list(rule_dict.get("conditions", []))
                ),
                "aggregated_roles": all_roles if all_roles else ["data_controller"],
                "data_category": safe_get(rule_dict, "data_category", "personal_data"),
                "domain": safe_get(rule_dict, "domain", "data_protection_compliance"),
                "action": action,
                "consequence": safe_get(rule_dict, "consequence", ""),
                "reference": safe_get(rule_dict, "reference", "Legal provision"),
                "priority": safe_get(rule_dict, "priority", "medium"),
                "event_type": "rule_evaluation",
                "params": ensure_dict(rule_dict.get("params", {}))
            }
            
            return validated_rule
        
        except Exception as e:
            logger.error(f"Error in enhanced comprehensive validation: {e}")
            return {}
    
    def _verify_adequacy_countries_enhanced(self, adequacy_countries: List[str]) -> List[str]:
        """Enhanced verification of adequacy countries"""
        verified = []
        
        try:
            for country in ensure_list(adequacy_countries):
                if not country:
                    continue
                
                country_str = str(country).strip()
                
                # Skip regions and invalid entries
                if len(country_str) == 2 and self.geography_handler.is_valid_country(country_str):
                    verified.append(country_str.upper())
                elif len(country_str) > 2:
                    # Try to convert country name to ISO
                    iso = self.geography_handler.get_country_iso(country_str)
                    if iso:
                        verified.append(iso.upper())
        
        except Exception as e:
            logger.debug(f"Error verifying adequacy countries: {e}")
        
        return list(set(verified))
    
    def _validate_and_enhance_conditions_comprehensive(self, conditions: List) -> List[Dict]:
        """Enhanced comprehensive validation of conditions for JSON Rules Engine"""
        validated_conditions = []
        
        try:
            valid_operators = ['equal', 'notEqual', 'in', 'notIn', 'greaterThan', 'lessThan', 'contains']
            valid_roles = ['data_controller', 'data_processor', 'joint_controller', 'data_subject', 'dpo', 'supervisory_authority', 'third_party']
            
            for condition in ensure_list(conditions):
                condition_dict = ensure_dict(condition)
                
                # Validate and fix operator
                operator = safe_get(condition_dict, 'operator', 'equal')
                if operator not in valid_operators:
                    operator = 'equal'
                
                # Enhanced role validation and mapping
                role = safe_get(condition_dict, 'role', 'data_controller')
                if role not in valid_roles:
                    # Comprehensive role mapping
                    role_lower = str(role).lower()
                    if 'joint' in role_lower and 'controller' in role_lower:
                        role = 'joint_controller'
                    elif 'controller' in role_lower:
                        role = 'data_controller'
                    elif 'processor' in role_lower:
                        role = 'data_processor'
                    elif 'subject' in role_lower:
                        role = 'data_subject'
                    elif 'dpo' in role_lower or 'protection officer' in role_lower:
                        role = 'dpo'
                    elif 'authority' in role_lower or 'supervisory' in role_lower:
                        role = 'supervisory_authority'
                    else:
                        role = 'data_controller'
                
                condition_id = safe_get(condition_dict, "condition_id", "cond_" + uuid.uuid4().hex[:8])
                
                # Clean all condition text to simple English
                condition_definition = safe_get(condition_dict, "condition_definition", "Condition for rule application")
                condition_definition = clean_text_to_simple_english(condition_definition)
                
                if_condition = safe_get(condition_dict, "if_condition", "IF condition is true")
                if_condition = clean_text_to_simple_english(if_condition)
                
                else_condition = safe_get(condition_dict, "else_condition", "ELSE condition is false")
                else_condition = clean_text_to_simple_english(else_condition)
                
                validated_condition = {
                    "condition_id": condition_id,
                    "condition_definition": condition_definition,
                    "fact": safe_get(condition_dict, "fact", "rule.context"),
                    "operator": operator,
                    "value": safe_get(condition_dict, "value", "applicable"),
                    "role": role,
                    "if_condition": if_condition,
                    "else_condition": else_condition
                }
                validated_conditions.append(validated_condition)
            
            # Ensure at least one condition
            if not validated_conditions:
                default_condition_id = "cond_" + uuid.uuid4().hex[:8]
                validated_conditions.append({
                    "condition_id": default_condition_id,
                    "condition_definition": "Rule applies when relevant context exists",
                    "fact": "context.relevant",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF relevant context exists",
                    "else_condition": "ELSE rule does not apply"
                })
        
        except Exception as e:
            logger.error("Error validating enhanced conditions: " + str(e))
            fallback_condition_id = "cond_" + uuid.uuid4().hex[:8]
            validated_conditions = [{
                "condition_id": fallback_condition_id,
                "condition_definition": "Default condition",
                "fact": "rule.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF rule is applicable",
                "else_condition": "ELSE rule does not apply"
            }]
        
        return validated_conditions
    
    def _fix_validation_errors_enhanced(self, rule_dict: Dict, state: MultiAgentState) -> Dict:
        """Enhanced attempt to fix common validation errors"""
        try:
            # Create a basic valid rule structure
            rule_id = "rule_" + uuid.uuid4().hex[:8]
            condition_id = "cond_" + uuid.uuid4().hex[:8]
            
            fixed_rule = {
                "rule_id": rule_id,
                "rule_definition": "Data protection compliance requirement",
                "rule_type": "compliance_obligation",
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": [],
                "conditions": [{
                    "condition_id": condition_id,
                    "condition_definition": "When data protection rules apply",
                    "fact": "data.processing",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF processing personal data",
                    "else_condition": "ELSE rule does not apply"
                }],
                "aggregated_roles": ["data_controller"],
                "data_category": "personal_data",
                "domain": "data_protection_compliance",
                "action": "Ensure compliance with data protection requirements",
                "consequence": "",
                "reference": "Data protection law",
                "priority": "medium",
                "event_type": "rule_evaluation",
                "params": {}
            }
            
            # Try to preserve original data where possible, cleaning to simple English
            for key in ['rule_definition', 'action']:
                original_value = safe_get(rule_dict, key, "")
                if original_value and len(str(original_value)) > 5:
                    cleaned_value = clean_text_to_simple_english(str(original_value))
                    fixed_rule[key] = cleaned_value
            
            # Preserve other fields that don't need cleaning
            for key in ['reference', 'rule_type', 'consequence']:
                original_value = safe_get(rule_dict, key, "")
                if original_value and len(str(original_value)) > 2:
                    fixed_rule[key] = str(original_value)
            
            return fixed_rule
        
        except Exception as e:
            logger.error("Error fixing enhanced validation errors: " + str(e))
            return {}

# NEW SUPERVISOR AGENT: Multi-Agent System Supervisor
class SupervisorAgent:
    """Supervisor Agent: Orchestrates and validates the entire multi-agent process"""
    
    def __init__(self, llm: ChatOpenAI, geography_handler: GeographyHandler):
        self.llm = llm
        self.geography_handler = geography_handler
        self.name = "SupervisorAgent"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Supervisor validation and final quality assurance"""
        
        logger.info(f"üéØ {self.name}: Final supervisor validation and quality control")
        
        try:
            system_prompt = """You are a Supervisor Agent overseeing a multi-agent legal rule extraction system.

EXPERTISE: Multi-agent coordination, final quality control, comprehensive validation, supervisor oversight

MISSION: Perform FINAL VALIDATION of all agent work and ensure COMPREHENSIVE, ACCURATE, and HIGH-QUALITY rule extraction.

SUPERVISOR RESPONSIBILITIES:
1. VALIDATE ALL AGENT WORK: Review outputs from all 4 expert agents
2. ENSURE COMPLETENESS: Verify all obligations from document have been extracted
3. QUALITY CONTROL: Check rule quality, accuracy, and JSON Rules Engine compatibility
4. ROLE VERIFICATION: Ensure ALL stakeholder roles are properly captured
5. COUNTRY VALIDATION: Verify adequacy countries are correctly identified
6. REFERENCE ACCURACY: Ensure references point to actual document sections
7. DEDUPLICATION: Remove any remaining duplicate or similar rules
8. FINAL ENHANCEMENT: Add any missing critical information

SUPERVISOR VALIDATION CRITERIA:
- Rules cover ALL obligations found in document (not just main sections)
- ALL stakeholder roles properly identified: controller, processor, joint controller, DPO, supervisory authority
- References are ACTUAL article/section numbers from document
- Adequacy countries are REAL countries with actual adequacy context
- Rules in simple English without article references in rule text
- JSON Rules Engine compatibility with proper operators and conditions
- Unique rule IDs with proper formatting
- Comprehensive aggregated_roles for each rule

SUPERVISOR QUALITY STANDARDS:
- Minimum 80% coverage of document obligations
- ALL roles mentioned in document captured
- NO generic references ("Legal requirement" should be replaced with actual citations)
- NO generic rule definitions ("Legal compliance requirement" should be specific)
- Proper priority assignment based on content
- IF-ELSE logic in conditions using simple English

CRITICAL SUPERVISOR TASKS:
1. Verify adequacy countries are mentioned in actual document context
2. Ensure aggregated_roles include ALL roles from rule text and conditions
3. Replace generic references with actual article numbers where possible
4. Check that rule coverage spans entire document, not just high-level content
5. Validate that processor and joint controller obligations are captured
6. Ensure DPO and supervisory authority rules are included if mentioned
7. Verify country codes are valid and adequacy context is real"""

            # Gather all agent outputs for supervisor review
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            identified_countries = ensure_dict(state.get('identified_countries', {}))
            extracted_rules = ensure_list(state.get('extracted_rules', []))
            validated_rules = ensure_list(state.get('validated_rules', []))
            
            # Create comprehensive summary for supervisor
            agent_summary = {
                "agent1_obligations": len(sum([ensure_list(obls) for obls in legal_obligations.values()], [])),
                "agent2_countries": len(identified_countries.get('mentioned_countries', [])),
                "agent2_adequacy": len(identified_countries.get('adequacy_countries', [])),
                "agent3_extracted_rules": len(extracted_rules),
                "agent4_validated_rules": len(validated_rules)
            }
            
            user_prompt = f"""SUPERVISOR FINAL VALIDATION AND QUALITY CONTROL:

MULTI-AGENT SYSTEM OUTPUTS TO SUPERVISE:

AGENT 1 (Legal Document Expert) RESULTS:
- Total obligations extracted: {agent_summary['agent1_obligations']}
- Obligation categories: {list(legal_obligations.keys())}

AGENT 2 (Geography Expert) RESULTS:
- Countries mentioned: {identified_countries.get('mentioned_countries', [])}
- Adequacy countries: {identified_countries.get('adequacy_countries', [])}
- Total countries found: {agent_summary['agent2_countries']}

AGENT 3 (Rule Engine Expert) RESULTS:
- Rules extracted: {agent_summary['agent3_extracted_rules']}

AGENT 4 (Validation Expert) RESULTS:
- Rules validated: {agent_summary['agent4_validated_rules']}

SAMPLE VALIDATED RULES FOR SUPERVISOR REVIEW:
{json.dumps(validated_rules[:2], indent=2) if validated_rules else 'No validated rules'}

CONFIGURATION CONTEXT:
- Document Hash: {state.get('document_hash', 'doc')}
- Applicable Countries: {state['metadata_config'].get('applicable_countries', [])}

SUPERVISOR COMPREHENSIVE VALIDATION REQUIRED:

1. COMPLETENESS CHECK: Are all major obligations from document captured?
2. ROLE VERIFICATION: Are ALL roles properly extracted (controller, processor, joint controller, DPO, supervisory authority)?
3. ADEQUACY VALIDATION: Are adequacy countries real and properly referenced in document?
4. REFERENCE ACCURACY: Do references point to actual document sections (not generic "Legal requirement")?
5. QUALITY CONTROL: Are rules in simple English with proper JSON Rules Engine format?
6. COVERAGE ANALYSIS: Does rule extraction span entire document or just main sections?
7. DEDUPLICATION: Are there any duplicate or substantially similar rules?
8. ENHANCEMENT OPPORTUNITIES: What critical information is missing?

SUPERVISOR FINAL VALIDATION:
Based on multi-agent outputs, provide final validated rules with:
- Corrected references (actual article numbers)
- Enhanced aggregated_roles (all roles from text)
- Verified adequacy countries (only real ones with document context)
- Quality improvements
- Coverage completion

Return final supervisor-validated rules array with comprehensive quality assurance."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse supervisor analysis
            reasoning_trace = self._extract_supervisor_reasoning(response_text)
            knowledge_graph = self._extract_supervisor_knowledge_graph(response_text)
            supervisor_validated_rules = self._supervisor_final_validation(response_text, state, validated_rules)
            
            # Update state with supervisor results
            state['supervisor_validated_rules'] = supervisor_validated_rules
            state['supervisor_reasoning'] = reasoning_trace
            state['supervisor_knowledge_graph'] = knowledge_graph
            state['supervisor_validation_complete'] = True
            state['processing_complete'] = True
            
            logger.info(f"‚úÖ {self.name}: Supervisor validated {len(supervisor_validated_rules)} final rules")
            
        except Exception as e:
            logger.error(f"‚ùå {self.name}: Supervisor validation failed: {e}")
            state['supervisor_reasoning'] = [f"ERROR: {str(e)}"]
            state['supervisor_validated_rules'] = validated_rules  # Fallback to previous validation
            state['supervisor_validation_complete'] = True
            state['processing_complete'] = True
        
        return state
    
    def _extract_supervisor_reasoning(self, response_text: str) -> List[str]:
        """Extract supervisor reasoning trace"""
        trace = []
        try:
            if response_text:
                supervisor_patterns = [
                    r'SUPERVISOR ANALYSIS:\s*(.*?)(?=VALIDATION:|$)',
                    r'QUALITY CHECK:\s*(.*?)(?=ENHANCEMENT:|$)',
                    r'COMPLETENESS REVIEW:\s*(.*?)(?=FINAL:|$)',
                    r'FINAL VALIDATION:\s*(.*?)(?=RESULT:|$)'
                ]
                
                for pattern in supervisor_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting supervisor reasoning: {e}")
        return trace
    
    def _extract_supervisor_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract supervisor knowledge graph"""
        kg = {"entities": [], "relationships": [], "supervisor_findings": {}}
        
        try:
            if response_text:
                supervisor_patterns = [
                    r'ENHANCED:\s*([^,\n]+)',
                    r'CORRECTED:\s*([^,\n]+)',
                    r'COMPLETED:\s*([^,\n]+)',
                    r'VALIDATED:\s*([^,\n]+)'
                ]
                
                for pattern in supervisor_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting supervisor knowledge graph: {e}")
        
        return kg
    
    def _supervisor_final_validation(self, response_text: str, state: MultiAgentState, validated_rules: List[Dict]) -> List[Dict]:
        """Supervisor final validation and enhancement"""
        supervisor_rules = []
        
        try:
            # Try to extract supervisor-enhanced rules from response
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                try:
                    supervisor_enhanced = json.loads(json_match.group(0))
                    if isinstance(supervisor_enhanced, list):
                        supervisor_rules = supervisor_enhanced
                except json.JSONDecodeError:
                    logger.warning("Supervisor JSON parsing failed")
            
            # If supervisor extraction failed, apply supervisor enhancements to validated rules
            if not supervisor_rules:
                supervisor_rules = self._apply_supervisor_enhancements(validated_rules, state)
            
            # Final supervisor quality control
            final_rules = []
            seen_rules = set()
            
            for rule_data in supervisor_rules:
                if not rule_data:
                    continue
                
                try:
                    rule_dict = ensure_dict(rule_data)
                    
                    # Supervisor deduplication
                    rule_signature = self._create_rule_signature(rule_dict)
                    if rule_signature in seen_rules:
                        continue
                    seen_rules.add(rule_signature)
                    
                    # Apply supervisor enhancements
                    enhanced_rule = self._apply_supervisor_quality_control(rule_dict, state)
                    
                    if enhanced_rule:
                        final_rules.append(enhanced_rule)
                
                except Exception as e:
                    logger.debug(f"Error in supervisor rule processing: {e}")
                    continue
            
            return final_rules
        
        except Exception as e:
            logger.error(f"Error in supervisor final validation: {e}")
            return validated_rules  # Fallback
    
    def _apply_supervisor_enhancements(self, validated_rules: List[Dict], state: MultiAgentState) -> List[Dict]:
        """Apply supervisor enhancements to validated rules"""
        enhanced_rules = []
        
        try:
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            document_text = state.get('document_text', '')
            
            for rule in validated_rules:
                rule_dict = ensure_dict(rule)
                
                # Supervisor enhancement: improve generic references
                reference = str(rule_dict.get('reference', '')).strip()
                if reference in ['Legal requirement', 'Legal provision', 'Document reference']:
                    # Try to find actual reference in document
                    rule_text = rule_dict.get('rule_definition', '')
                    improved_reference = self._find_actual_reference_in_document(rule_text, document_text)
                    if improved_reference != 'Legal requirement':
                        rule_dict['reference'] = improved_reference
                
                # Supervisor enhancement: improve aggregated roles
                rule_text = f"{rule_dict.get('rule_definition', '')} {rule_dict.get('action', '')}"
                comprehensive_roles = extract_comprehensive_roles_from_text(rule_text)
                existing_roles = ensure_list(rule_dict.get('aggregated_roles', []))
                
                # Include roles from conditions
                condition_roles = []
                for condition in ensure_list(rule_dict.get('conditions', [])):
                    if isinstance(condition, dict) and condition.get('role'):
                        condition_roles.append(condition['role'])
                
                all_roles = list(set(comprehensive_roles + existing_roles + condition_roles))
                rule_dict['aggregated_roles'] = all_roles if all_roles else ['data_controller']
                
                enhanced_rules.append(rule_dict)
        
        except Exception as e:
            logger.error(f"Error applying supervisor enhancements: {e}")
            return validated_rules
        
        return enhanced_rules
    
    def _find_actual_reference_in_document(self, rule_text: str, document_text: str) -> str:
        """Supervisor function to find actual references in document"""
        try:
            if not rule_text or not document_text:
                return 'Legal requirement'
            
            # Search for rule text context in document and extract nearby references
            rule_words = rule_text.lower().split()[:5]  # First 5 words
            search_phrase = ' '.join(rule_words)
            
            # Find the context in document
            document_lower = document_text.lower()
            search_start = document_lower.find(search_phrase)
            
            if search_start >= 0:
                # Look for references in surrounding context (500 chars before and after)
                context_start = max(0, search_start - 500)
                context_end = min(len(document_text), search_start + 500)
                context = document_text[context_start:context_end]
                
                # Extract reference from context
                reference = extract_comprehensive_references(context)
                if reference != 'Legal requirement':
                    return reference
            
            return 'Legal requirement'
        
        except Exception as e:
            logger.debug(f"Error finding actual reference: {e}")
            return 'Legal requirement'
    
    def _create_rule_signature(self, rule_dict: Dict) -> str:
        """Create signature for rule deduplication"""
        try:
            rule_def = str(rule_dict.get('rule_definition', '')).lower().strip()
            rule_type = str(rule_dict.get('rule_type', '')).lower().strip()
            action = str(rule_dict.get('action', '')).lower().strip()
            
            # Create hash-based signature
            signature_text = f"{rule_def}_{rule_type}_{action}"
            return hashlib.md5(signature_text.encode()).hexdigest()[:16]
        except:
            return str(uuid.uuid4().hex[:16])
    
    def _apply_supervisor_quality_control(self, rule_dict: Dict, state: MultiAgentState) -> Dict:
        """Apply final supervisor quality control"""
        try:
            # Ensure rule has all required fields
            enhanced_rule = {
                "rule_id": safe_get(rule_dict, "rule_id", f"rule_{uuid.uuid4().hex[:8]}"),
                "rule_definition": clean_text_to_simple_english(safe_get(rule_dict, "rule_definition", "Specific legal requirement")),
                "rule_type": safe_get(rule_dict, "rule_type", "compliance_obligation"),
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": self._supervisor_verify_adequacy_countries(
                    ensure_list(rule_dict.get("adequacy_countries", [])), state
                ),
                "conditions": ensure_list(rule_dict.get("conditions", [])),
                "aggregated_roles": ensure_list(rule_dict.get("aggregated_roles", ["data_controller"])),
                "data_category": safe_get(rule_dict, "data_category", "personal_data"),
                "domain": safe_get(rule_dict, "domain", "data_protection_compliance"),
                "action": clean_text_to_simple_english(safe_get(rule_dict, "action", "Implement required measures")),
                "consequence": safe_get(rule_dict, "consequence", ""),
                "reference": safe_get(rule_dict, "reference", "Legal provision"),
                "priority": safe_get(rule_dict, "priority", "medium"),
                "event_type": "rule_evaluation",
                "params": {}
            }
            
            return enhanced_rule
        
        except Exception as e:
            logger.error(f"Error applying supervisor quality control: {e}")
            return rule_dict
    
    def _supervisor_verify_adequacy_countries(self, adequacy_countries: List[str], state: MultiAgentState) -> List[str]:
        """Supervisor verification of adequacy countries against document"""
        verified = []
        
        try:
            document_text = state.get('document_text', '')
            
            for country in adequacy_countries:
                if not country:
                    continue
                
                country_str = str(country).strip().upper()
                
                # Verify country is valid
                if not self.geography_handler.is_valid_country(country_str):
                    continue
                
                # Verify adequacy context exists in document
                country_name = self.geography_handler.get_country_name(country_str)
                if country_name:
                    # Check for adequacy context
                    adequacy_patterns = [
                        rf'{re.escape(country_name.lower())}[^.]*?adequacy',
                        rf'adequacy[^.]*?{re.escape(country_name.lower())}',
                        rf'{country_str}[^.]*?adequacy',
                        rf'adequacy[^.]*?{country_str}'
                    ]
                    
                    document_lower = document_text.lower()
                    found_adequacy_context = False
                    
                    for pattern in adequacy_patterns:
                        if re.search(pattern, document_lower):
                            found_adequacy_context = True
                            break
                    
                    if found_adequacy_context:
                        verified.append(country_str)
        
        except Exception as e:
            logger.debug(f"Error in supervisor adequacy verification: {e}")
        
        return verified

# Enhanced Multi-Agent Orchestrator with Supervisor
class MultiAgentLegalProcessor:
    """Multi-agent orchestrator with Mixture of Experts and Supervisor approach"""
    
    def __init__(self, geography_file: str):
        try:
            # Initialize LLM
            self.llm = ChatOpenAI(
                model=MODEL_NAME,
                openai_api_key=API_KEY,
                openai_api_base=BASE_URL
            )
            
            # Initialize geography handler
            self.geography_handler = GeographyHandler(geography_file)
            
            # Initialize Mixture of Experts with Supervisor
            self.legal_document_expert = LegalDocumentExpert(self.llm)
            self.geography_expert = GeographyJurisdictionExpert(self.llm, self.geography_handler)
            self.rule_engine_expert = RuleEngineExpert(self.llm)
            self.validation_expert = ValidationQualityExpert(self.llm, self.geography_handler)
            self.supervisor_agent = SupervisorAgent(self.llm, self.geography_handler)
            
            # Create enhanced workflow with supervisor
            self.workflow = self._create_expert_workflow_with_supervisor()
            
            logger.info("üéì Mixture of Experts Legal Processor with Supervisor initialized")
            logger.info(f"üìç Geography data: {len(self.geography_handler.all_countries)} countries")
        
        except Exception as e:
            logger.error(f"Error initializing processor: {e}")
            raise
    
    def _create_expert_workflow_with_supervisor(self) -> StateGraph:
        """Create Mixture of Experts workflow with Supervisor oversight"""
        
        try:
            workflow = StateGraph(MultiAgentState)
            
            # Add expert nodes including supervisor
            workflow.add_node("legal_document_expert", self.legal_document_expert.process)
            workflow.add_node("geography_expert", self.geography_expert.process)
            workflow.add_node("rule_engine_expert", self.rule_engine_expert.process)
            workflow.add_node("validation_expert", self.validation_expert.process)
            workflow.add_node("supervisor_agent", self.supervisor_agent.process)
            
            # Set entry point
            workflow.set_entry_point("legal_document_expert")
            
            # Sequential expert processing with supervisor oversight
            workflow.add_edge("legal_document_expert", "geography_expert")
            workflow.add_edge("geography_expert", "rule_engine_expert")
            workflow.add_edge("rule_engine_expert", "validation_expert")
            workflow.add_edge("validation_expert", "supervisor_agent")
            workflow.add_edge("supervisor_agent", END)
            
            return workflow.compile(checkpointer=MemorySaver())
        
        except Exception as e:
            logger.error(f"Error creating expert workflow with supervisor: {e}")
            raise
    
    async def process_document(self, metadata_config: MetadataConfig) -> List[ExtractedRule]:
        """Process document with Mixture of Experts and Supervisor"""
        
        try:
            logger.info(f"üéì Starting Mixture of Experts processing with Supervisor: {metadata_config.pdf_path}")
            
            # Extract complete PDF content
            pdf_processor = PDFProcessor()
            pdf_data = pdf_processor.extract_complete_text_from_pdf(metadata_config.pdf_path)
            
            if not pdf_data['complete_text']:
                raise ValueError("No text extracted from PDF")
            
            # Generate document hash for unique rule IDs
            document_hash = generate_document_hash(pdf_data['complete_text'])
            
            logger.info(f"üìä PDF: {pdf_data['total_pages']} pages, {pdf_data['total_length']} characters")
            logger.info(f"üîë Document hash: {document_hash}")
            
            # Initialize comprehensive expert state
            initial_state = MultiAgentState(
                document_text=pdf_data['complete_text'],
                document_hash=document_hash,
                document_chunks=[],
                metadata_config=metadata_config.model_dump(),
                geography_data=self.geography_handler.geography_data,
                legal_obligations={},
                regulatory_requirements={},
                compliance_conditions={},
                stakeholder_roles={},
                parsed_sections={},
                knowledge_graph={"entities": [], "relationships": []},
                identified_countries={},
                extracted_rules=[],
                validated_rules=[],
                supervisor_validated_rules=[],
                agent1_reasoning=[],
                agent1_knowledge_graph={},
                agent2_reasoning=[],
                agent2_knowledge_graph={},
                agent3_reasoning=[],
                agent3_knowledge_graph={},
                agent4_reasoning=[],
                agent4_knowledge_graph={},
                supervisor_reasoning=[],
                supervisor_knowledge_graph={},
                current_agent="LegalDocumentExpert",
                processing_complete=False,
                chunks_processed=0,
                total_chunks=0,
                supervisor_validation_complete=False
            )
            
            # Run expert workflow with supervisor
            config = {"configurable": {"thread_id": f"expert_supervisor_{uuid.uuid4().hex[:8]}"}}
            
            final_state = self.workflow.invoke(initial_state, config)
            
            # Get supervisor-validated rules as final output
            supervisor_rules = ensure_list(final_state.get('supervisor_validated_rules', []))
            
            # Convert to Pydantic models
            final_validated_rules = []
            for rule_data in supervisor_rules:
                if rule_data:
                    try:
                        rule = ExtractedRule.model_validate(ensure_dict(rule_data))
                        final_validated_rules.append(rule)
                    except ValidationError as e:
                        logger.warning(f"Final supervisor rule validation failed: {e}")
                        continue
            
            # Log comprehensive expert summary with supervisor
            self._log_expert_supervisor_summary(final_state, final_validated_rules, pdf_data)
            
            return final_validated_rules
            
        except Exception as e:
            logger.error(f"Expert processing with supervisor failed: {e}")
            raise
    
    def _log_expert_supervisor_summary(self, final_state: MultiAgentState, rules: List[ExtractedRule], pdf_data: Dict):
        """Log comprehensive expert processing summary with supervisor oversight"""
        
        try:
            logger.info("üéì Mixture of Experts with Supervisor Processing Complete!")
            logger.info(f"üìÑ PDF: {pdf_data.get('total_pages', 0)} pages")
            logger.info(f"üéØ Legal obligations: {len(final_state.get('legal_obligations', {}))}")
            logger.info(f"üåç Countries identified: {len(final_state.get('identified_countries', {}).get('mentioned_countries', []))}")
            logger.info(f"üìç Adequacy countries: {len(final_state.get('identified_countries', {}).get('adequacy_countries', []))}")
            logger.info(f"‚öñÔ∏è Rules extracted: {len(final_state.get('extracted_rules', []))}")
            logger.info(f"‚úÖ Rules validated: {len(final_state.get('validated_rules', []))}")
            logger.info(f"üéØ Supervisor final rules: {len(rules)}")
            
            # Expert knowledge graphs
            expert_names = ['LegalDocumentExpert', 'GeographyExpert', 'RuleEngineExpert', 'ValidationExpert', 'SupervisorAgent']
            for i, expert_name in enumerate(expert_names, 1):
                kg_key = f'agent{i}_knowledge_graph' if i <= 4 else 'supervisor_knowledge_graph'
                kg = final_state.get(kg_key, {})
                entities = len(ensure_list(kg.get('entities', [])))
                logger.info(f"üß† {expert_name}: {entities} knowledge entities")
            
            # Sample high-quality supervisor-validated rule
            if rules:
                sample_rule = rules[0]
                logger.info("üìã Sample Supervisor-Validated Rule:")
                logger.info(f"   üÜî ID: {sample_rule.rule_id}")
                logger.info(f"   üìù Definition: {sample_rule.rule_definition[:100]}...")
                logger.info(f"   üè∑Ô∏è Type: {sample_rule.rule_type}")
                logger.info(f"   üåç Applicable: {sample_rule.applicable_countries}")
                logger.info(f"   ‚úÖ Adequacy: {sample_rule.adequacy_countries}")
                logger.info(f"   üë• Roles: {sample_rule.aggregated_roles}")
                logger.info(f"   ‚ö° Action: {sample_rule.action[:100]}...")
                logger.info(f"   üìç Reference: {sample_rule.reference}")
                logger.info(f"   üß© Conditions: {len(sample_rule.conditions)}")
        
        except Exception as e:
            logger.debug(f"Error logging expert supervisor summary: {e}")

# Enhanced Pipeline with Mixture of Experts and Supervisor
class LegalRuleExtractionPipeline:
    """Enhanced pipeline with Mixture of Experts and Supervisor"""
    
    def __init__(self, geography_file: str):
        try:
            self.processor = MultiAgentLegalProcessor(geography_file)
            logger.info("üéì Mixture of Experts Legal Rule Extraction Pipeline with Supervisor initialized")
        except Exception as e:
            logger.error(f"Error initializing pipeline: {e}")
            raise
    
    async def process_document(self, metadata_config: MetadataConfig) -> List[ExtractedRule]:
        """Process single document with experts and supervisor"""
        return await self.processor.process_document(metadata_config)
    
    async def process_multiple_documents(self, config_file: str) -> List[ExtractedRule]:
        """Process multiple documents with expert analysis and supervisor oversight"""
        logger.info("üìÅ Processing multiple documents with experts and supervisor: " + str(config_file))
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                configs_data = json.load(f)
        except Exception as e:
            logger.error(f"Config loading failed: {e}")
            raise
        
        all_rules = []
        
        for config_data in ensure_list(configs_data):
            if not config_data:
                continue
            
            try:
                config_dict = ensure_dict(config_data)
                metadata_config = MetadataConfig.model_validate(config_dict)
                rules = await self.process_document(metadata_config)
                all_rules.extend(rules)
                
                logger.info("‚úÖ Processed " + str(config_dict.get('pdf_path', 'unknown')) + ": " + str(len(rules)) + " rules")
                
            except ValidationError as e:
                logger.error(f"Invalid config: {e}")
                continue
            except Exception as e:
                logger.error(f"Processing failed for {config_dict.get('pdf_path', 'unknown')}: {e}")
                continue
        
        return all_rules
    
    def save_results(self, rules: List[ExtractedRule], output_dir: str):
        """Save comprehensive JSON Rules Engine compatible results with supervisor validation"""
        try:
            logger.info("üíæ Saving comprehensive JSON Rules Engine compatible results to " + str(output_dir))
            
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            # Convert to dictionaries
            rules_dicts = []
            for rule in rules:
                if rule:
                    try:
                        rule_dict = rule.model_dump()
                        rules_dicts.append(rule_dict)
                    except Exception as e:
                        logger.debug(f"Error converting rule to dict: {e}")
                        continue
            
            # Save comprehensive JSON Rules Engine compatible JSON
            json_file = Path(output_dir) / "json_rules_engine_rules.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "engine_version": "1.0",
                    "rules": rules_dicts,
                    "metadata": {
                        "generated_by": "Multi-Agent Legal Rule Extraction System with Supervisor",
                        "generation_date": datetime.now().isoformat(),
                        "total_rules": len(rules_dicts),
                        "methodology": "Mixture of Experts with Supervisor Agent and Chain of Thought",
                        "supervisor_validated": True,
                        "simple_english_rules": True
                    }
                }, f, indent=2, ensure_ascii=False)
            
            # Save comprehensive CSV analysis
            csv_file = Path(output_dir) / "comprehensive_rule_analysis.csv"
            if rules_dicts:
                detailed_rules = []
                for rule in rules_dicts:
                    try:
                        rule_dict = ensure_dict(rule)
                        
                        # Create comprehensive analysis row
                        detailed_rule = {
                            "rule_id": safe_get(rule_dict, "rule_id", ""),
                            "rule_definition": safe_get(rule_dict, "rule_definition", ""),
                            "rule_type": safe_get(rule_dict, "rule_type", ""),
                            "applicable_countries": json.dumps(ensure_list(rule_dict.get("applicable_countries", [])), ensure_ascii=False),
                            "adequacy_countries": json.dumps(ensure_list(rule_dict.get("adequacy_countries", [])), ensure_ascii=False),
                            "aggregated_roles": json.dumps(ensure_list(rule_dict.get("aggregated_roles", [])), ensure_ascii=False),
                            "data_category": safe_get(rule_dict, "data_category", ""),
                            "domain": safe_get(rule_dict, "domain", ""),
                            "action": safe_get(rule_dict, "action", ""),
                            "consequence": safe_get(rule_dict, "consequence", ""),
                            "reference": safe_get(rule_dict, "reference", ""),
                            "priority": safe_get(rule_dict, "priority", ""),
                            "conditions_count": len(ensure_list(rule_dict.get("conditions", []))),
                            "has_if_else_logic": "Yes" if any(
                                safe_get(ensure_dict(cond), "if_condition", "") and safe_get(ensure_dict(cond), "else_condition", "")
                                for cond in ensure_list(rule_dict.get("conditions", []))
                            ) else "No",
                            "json_rules_engine_compatible": "Yes",
                            "supervisor_validated": "Yes",
                            "simple_english": "Yes",
                            "conditions_details": json.dumps(ensure_list(rule_dict.get("conditions", [])), ensure_ascii=False)
                        }
                        detailed_rules.append(detailed_rule)
                    except Exception as e:
                        logger.debug(f"Error creating detailed rule: {e}")
                        continue
                
                if detailed_rules:
                    df = pd.DataFrame(detailed_rules)
                    df.to_csv(csv_file, index=False, encoding='utf-8')
            
            # Save comprehensive rule types summary
            rule_types_file = Path(output_dir) / "comprehensive_rule_summary.json"
            rule_types_summary = {}
            role_distribution = {}
            reference_analysis = {}
            
            for rule in rules_dicts:
                rule_dict = ensure_dict(rule)
                
                # Count rule types
                rule_type = safe_get(rule_dict, "rule_type", "unknown")
                rule_types_summary[rule_type] = rule_types_summary.get(rule_type, 0) + 1
                
                # Count role distribution
                for role in ensure_list(rule_dict.get("aggregated_roles", [])):
                    role_distribution[str(role)] = role_distribution.get(str(role), 0) + 1
                
                # Analyze references
                reference = safe_get(rule_dict, "reference", "")
                if reference and reference != "Legal requirement":
                    reference_analysis[reference] = reference_analysis.get(reference, 0) + 1
            
            summary_data = {
                "total_rules": len(rules_dicts),
                "rule_types": rule_types_summary,
                "role_distribution": role_distribution,
                "reference_analysis": reference_analysis,
                "unique_countries": list(set([
                    country 
                    for rule in rules_dicts 
                    for country in ensure_list(ensure_dict(rule).get("applicable_countries", []))
                ])),
                "adequacy_countries": list(set([
                    country 
                    for rule in rules_dicts 
                    for country in ensure_list(ensure_dict(rule).get("adequacy_countries", []))
                ])),
                "supervisor_validation_features": {
                    "total_supervisor_validated": len(rules_dicts),
                    "roles_extracted": list(role_distribution.keys()),
                    "actual_references_found": len([r for r in reference_analysis.keys() if r != "Legal requirement"]),
                    "generic_references": sum(1 for rule in rules_dicts 
                                           if safe_get(ensure_dict(rule), "reference", "") == "Legal requirement")
                },
                "json_rules_engine_features": {
                    "operators_used": list(set([
                        safe_get(ensure_dict(cond), "operator", "")
                        for rule in rules_dicts
                        for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                    ])),
                    "facts_used": list(set([
                        safe_get(ensure_dict(cond), "fact", "")
                        for rule in rules_dicts
                        for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                    ])),
                    "if_else_conditions": sum(1 for rule in rules_dicts
                        if any(
                            safe_get(ensure_dict(cond), "if_condition", "") and safe_get(ensure_dict(cond), "else_condition", "")
                            for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                        )
                    )
                }
            }
            
            with open(rule_types_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)
            
            # Save comprehensive processing methodology report
            methodology_file = Path(output_dir) / "comprehensive_expert_methodology.json"
            with open(methodology_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "methodology": "Mixture of Experts with Supervisor Agent and Chain of Thought Reasoning",
                    "simple_english_rules": "All rules and conditions written in simple English without article references",
                    "supervisor_validation": "Final supervisor agent validates and enhances all expert outputs",
                    "experts_used": [
                        {
                            "name": "Legal Document Structure Expert",
                            "role": "Extract ALL legal obligations and requirements in simple English from entire document",
                            "techniques": ["Comprehensive pattern matching", "Complete obligation analysis", "Enhanced structure parsing", "Simple English conversion"],
                            "coverage": "Entire document, not just main sections"
                        },
                        {
                            "name": "Geography and Jurisdiction Expert", 
                            "role": "Identify ALL countries and adequacy contexts with enhanced detection",
                            "techniques": ["Enhanced country extraction", "Comprehensive adequacy analysis", "Regional jurisdiction mapping", "Document-wide country scanning"]
                        },
                        {
                            "name": "Rule Engine Expert",
                            "role": "Convert ALL obligations to JSON Rules Engine format with comprehensive role extraction",
                            "techniques": ["Complete condition mapping", "Enhanced IF-ELSE logic", "Comprehensive operator validation", "All-role extraction", "Simple English conversion"]
                        },
                        {
                            "name": "Validation and Quality Expert",
                            "role": "Ensure accuracy and completeness with enhanced role and reference validation", 
                            "techniques": ["Comprehensive quality checks", "Enhanced deduplication", "Reference validation", "Role extraction verification", "Simple English verification"]
                        },
                        {
                            "name": "Supervisor Agent",
                            "role": "Final validation, quality control, and comprehensive rule enhancement",
                            "techniques": ["Multi-agent coordination", "Final quality assurance", "Reference accuracy improvement", "Role completeness verification", "Coverage validation"]
                        }
                    ],
                    "comprehensive_features_implemented": [
                        "NO truncation - complete document processing with enhanced coverage",
                        "Mixture of Experts approach with specialized analysis",
                        "Supervisor agent for final validation and quality control",
                        "Chain of Thought reasoning in all experts and supervisor",
                        "JSON Rules Engine compatibility with enhanced validation",
                        "Simple English rules and conditions without article references",
                        "Article/section references in reference field only with actual citations",
                        "IF-ELSE condition logic in plain language",
                        "Comprehensive stakeholder roles extraction (7+ types)",
                        "Enhanced rule definitions (not generic)",
                        "Actual legal references separated from rule text",
                        "Comprehensive country verification against geography database",
                        "Enhanced adequacy country detection with document context",
                        "Comprehensive rule type classification",
                        "Enhanced priority assignment based on content analysis",
                        "Supervisor-level deduplication and quality control",
                        "Unique rule IDs based on document hash and sequence"
                    ],
                    "enhanced_simple_english_approach": {
                        "rule_definitions": "Written in plain language understandable to non-lawyers with supervisor validation",
                        "condition_descriptions": "Human-readable conditions without legal jargon, supervisor-enhanced",
                        "if_else_logic": "Simple language if-then statements validated by supervisor",
                        "actions": "Clear instructions without article references, supervisor-verified",
                        "reference_separation": "Legal citations kept in dedicated reference field only, supervisor-improved with actual article numbers"
                    },
                    "supervisor_enhancements": {
                        "final_validation": "Supervisor validates all agent outputs for completeness and accuracy",
                        "reference_improvement": "Supervisor replaces generic references with actual article numbers where possible",
                        "role_completion": "Supervisor ensures all stakeholder roles are captured comprehensively",
                        "adequacy_verification": "Supervisor verifies adequacy countries have actual document context",
                        "quality_control": "Final quality checks for JSON Rules Engine compatibility and simple English"
                    },
                    "comprehensive_json_rules_engine_compatibility": {
                        "supported_operators": ["equal", "notEqual", "in", "notIn", "greaterThan", "lessThan", "contains"],
                        "fact_structure": "Hierarchical facts (user.role, data.category, request.type, processing.purpose, etc.)",
                        "condition_logic": "IF-ELSE conditions for each rule condition in simple English with supervisor validation",
                        "event_handling": "rule_evaluation events with comprehensive parameters"
                    },
                    "comprehensive_stakeholder_roles": [
                        "data_controller", "data_processor", "joint_controller", 
                        "data_subject", "dpo", "supervisory_authority", "third_party"
                    ],
                    "enhanced_rule_types": [
                        "access_right", "processing_obligation", "consent_requirement",
                        "data_transfer", "breach_notification", "compliance_obligation",
                        "penalty_provision", "processor_obligation", "joint_controller_obligation",
                        "dpo_obligation", "supervisory_power"
                    ]
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"‚úÖ Comprehensive JSON Rules Engine compatible results saved:")
            logger.info(f"   üìÑ Rules JSON: {json_file}")
            logger.info(f"   üìä Detailed CSV: {csv_file}")
            logger.info(f"   üìà Summary: {rule_types_file}")
            logger.info(f"   üìã Methodology: {methodology_file}")
            
        except Exception as e:
            logger.error(f"Error saving comprehensive results: {e}")
            raise

# Enhanced CLI Interface with Expert Processing and Supervisor
async def main():
    """Enhanced CLI interface with Mixture of Experts and Supervisor Agent"""
    import argparse
    
    try:
        parser = argparse.ArgumentParser(
            description="Mixture of Experts Legal Rule Extraction with Supervisor Agent for JSON Rules Engine",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
Examples:
  python enhanced_legal_extraction.py --config metadata_config.json --geography geography.json --output ./output

Enhanced Features:
  - Mixture of Experts approach with specialized agents
  - Supervisor Agent for final validation and quality control
  - Chain of Thought reasoning for accurate extraction  
  - JSON Rules Engine compatible output format
  - Rules and conditions in simple English without article references
  - Comprehensive stakeholder role extraction (controller, processor, joint controller, DPO, supervisory authority)
  - Enhanced adequacy country detection with document context verification
  - Actual legal references separated in reference field
  - IF-ELSE condition logic for complex rules
  - Complete document processing (no truncation)
  - Unique rule IDs based on document hash
  - Supervisor validation for maximum accuracy
            """
        )
        parser.add_argument("--config", required=True, help="Metadata configuration JSON file")
        parser.add_argument("--geography", required=True, help="Geography JSON file")
        parser.add_argument("--output", default="./output", help="Output directory")
        
        args = parser.parse_args()
        
        logger.info("üéì Starting Mixture of Experts Legal Rule Extraction with Supervisor Agent")
        logger.info("üìÅ Config: " + str(args.config))
        logger.info("üåç Geography: " + str(args.geography))
        logger.info("üì§ Output: " + str(args.output))
        
        # Initialize enhanced expert pipeline with supervisor
        pipeline = LegalRuleExtractionPipeline(args.geography)
        
        # Process documents with comprehensive expert analysis and supervisor validation
        rules = await pipeline.process_multiple_documents(args.config)
        
        # Save comprehensive JSON Rules Engine compatible results
        pipeline.save_results(rules, args.output)
        
        # Final comprehensive expert summary with supervisor validation
        logger.info("üéâ Mixture of Experts with Supervisor processing complete!")
        logger.info("üìä Total supervisor-validated rules generated: " + str(len(rules)))
        
        if rules:
            # Comprehensive results analysis
            rule_types = {}
            roles = set()
            countries = set()
            adequacy_countries = set()
            has_consequences = 0
            has_if_else = 0
            actual_references = 0
            unique_rule_ids = set()
            
            for rule in rules:
                # Count rule types
                rule_type = getattr(rule, 'rule_type', 'unknown')
                rule_types[rule_type] = rule_types.get(rule_type, 0) + 1
                
                # Collect comprehensive roles
                rule_roles = getattr(rule, 'aggregated_roles', [])
                roles.update(rule_roles)
                
                # Collect countries
                countries.update(getattr(rule, 'applicable_countries', []))
                adequacy_countries.update(getattr(rule, 'adequacy_countries', []))
                
                # Count enhanced features
                if getattr(rule, 'consequence', ''):
                    has_consequences += 1
                
                # Check IF-ELSE logic
                conditions = getattr(rule, 'conditions', [])
                if any(getattr(cond, 'if_condition', '') and getattr(cond, 'else_condition', '') 
                       for cond in conditions):
                    has_if_else += 1
                
                # Check for actual references (not generic)
                reference = getattr(rule, 'reference', '')
                if reference and reference not in ['Legal requirement', 'Legal provision', 'Document reference']:
                    actual_references += 1
                
                # Check unique rule IDs
                rule_id = getattr(rule, 'rule_id', '')
                if rule_id:
                    unique_rule_ids.add(rule_id)
            
            logger.info("üìà Comprehensive Expert Analysis Results:")
            rule_types_str = ', '.join(rule_types.keys())
            roles_str = ', '.join(sorted(roles))
            countries_str = ', '.join(sorted(countries))
            adequacy_str = ', '.join(sorted(adequacy_countries))
            
            logger.info("   üè∑Ô∏è Rule types: " + str(len(rule_types)) + " (" + rule_types_str + ")")
            logger.info("   üë• Stakeholder roles: " + str(len(roles)) + " (" + roles_str + ")")
            logger.info("   üåç Countries: " + str(len(countries)) + " (" + countries_str + ")")
            logger.info("   ‚úÖ Adequacy countries: " + str(len(adequacy_countries)) + " (" + adequacy_str + ")")
            logger.info("   ‚öñÔ∏è Rules with consequences: " + str(has_consequences) + "/" + str(len(rules)))
            logger.info("   üîÄ Rules with IF-ELSE logic: " + str(has_if_else) + "/" + str(len(rules)))
            logger.info("   üìç Actual references (not generic): " + str(actual_references) + "/" + str(len(rules)))
            logger.info("   üÜî Unique rule IDs: " + str(len(unique_rule_ids)) + "/" + str(len(rules)))
            
            # Display sample supervisor-validated rule
            sample_rule = rules[0]
            logger.info("üìã Sample Supervisor-Validated Rule (Simple English):")
            logger.info(f"   üÜî ID: {sample_rule.rule_id}")
            logger.info(f"   üìù Definition: {sample_rule.rule_definition[:120]}...")
            logger.info(f"   üè∑Ô∏è Type: {sample_rule.rule_type}")
            logger.info(f"   üåç Countries: {sample_rule.applicable_countries}")
            logger.info(f"   ‚úÖ Adequacy: {sample_rule.adequacy_countries}")
            logger.info(f"   üë• Roles: {sample_rule.aggregated_roles}")
            logger.info(f"   üéØ Domain: {sample_rule.domain}")
            logger.info(f"   ‚ö° Action: {sample_rule.action[:100]}...")
            logger.info(f"   üìç Reference: {sample_rule.reference}")
            
            if sample_rule.consequence:
                logger.info(f"   ‚öñÔ∏è Consequence: {sample_rule.consequence}")
            
            logger.info(f"   üß© Conditions: {len(sample_rule.conditions)}")
            if sample_rule.conditions:
                sample_condition = sample_rule.conditions[0]
                logger.info(f"   üìã Sample Condition (Simple English):")
                logger.info(f"      üîç Definition: {sample_condition.condition_definition}")
                logger.info(f"      üìä Fact: {sample_condition.fact}")
                logger.info(f"      üîß Operator: {sample_condition.operator}")
                logger.info(f"      üíé Value: {sample_condition.value}")
                logger.info(f"      üë§ Role: {sample_condition.role}")
                if hasattr(sample_condition, 'if_condition') and sample_condition.if_condition:
                    logger.info(f"      ‚û°Ô∏è IF: {sample_condition.if_condition}")
                if hasattr(sample_condition, 'else_condition') and sample_condition.else_condition:
                    logger.info(f"      ‚¨ÖÔ∏è ELSE: {sample_condition.else_condition}")
        
        logger.info("üéì Expert processing with Supervisor validation completed successfully!")
        logger.info("üìÑ JSON Rules Engine compatible output generated with comprehensive validation.")
        logger.info("üìö All rules and conditions written in plain language without article references.")
        logger.info("üéØ Supervisor agent ensured maximum accuracy and completeness.")
        
        return 0
        
    except Exception as e:
        logger.error(f"Expert processing pipeline with supervisor failed: {e}")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
