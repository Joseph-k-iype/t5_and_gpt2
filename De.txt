"""
ISO 11179 Data Enrichment with Semantic Knowledge Graph & Advanced Reasoning
===========================================================================
Features:
- Semantic Knowledge Graph construction with NetworkX
- LLM-powered graph reasoning and relationship discovery
- Lexical + Semantic hybrid matching
- Dynamic Chain-of-Thought prompting
- Graph-based pattern discovery and inference
"""

import json
import os
import pandas as pd
from typing import TypedDict, Annotated, List, Dict, Any, Literal, Sequence, Tuple
import numpy as np
from openai import OpenAI
import time
from datetime import datetime
from collections import defaultdict
import networkx as nx
from difflib import SequenceMatcher
import pickle

# LangChain and LangGraph imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.embeddings import Embeddings
from langchain_community.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
OPENAI_BASE_URL = "https://api.openai.com/v1"
OPENAI_REASONING_MODEL = "o3-mini"
OPENAI_EMBEDDING_MODEL = "text-embedding-3-large"

openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

INPUT_JSON_PATH = "cib_long_json.json"
EXCEL_PATH = "pbt.xlsx"
ACRONYM_CSV_PATH = "acronyms.csv"
OUTPUT_CSV_PATH = "enriched_mapped_output.csv"
CACHE_JSON_PATH = "mapping_cache.json"
PROCEDURAL_MEMORY_PATH = "procedural_memory.json"
EPISODIC_MEMORY_PATH = "episodic_memory.json"
KNOWLEDGE_GRAPH_PATH = "semantic_knowledge_graph.gpickle"
GRAPH_STATS_PATH = "graph_statistics.json"

# Global stores
MAPPING_CACHE = {}
PROCEDURAL_MEMORY = {}
EPISODIC_MEMORY = []
SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()


# ============================================================================
# KNOWLEDGE GRAPH MANAGEMENT
# ============================================================================

def initialize_knowledge_graph():
    """Initialize or load semantic knowledge graph."""
    global SEMANTIC_KNOWLEDGE_GRAPH
    
    if os.path.exists(KNOWLEDGE_GRAPH_PATH):
        try:
            with open(KNOWLEDGE_GRAPH_PATH, 'rb') as f:
                SEMANTIC_KNOWLEDGE_GRAPH = pickle.load(f)
            print(f"   ‚Üí Loaded knowledge graph: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
            print_graph_statistics()
        except Exception as e:
            print(f"   ‚Üí Could not load knowledge graph: {e}")
            SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()
    else:
        print(f"   ‚Üí Creating new knowledge graph")
        SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()


def save_knowledge_graph():
    """Save knowledge graph to disk."""
    try:
        with open(KNOWLEDGE_GRAPH_PATH, 'wb') as f:
            pickle.dump(SEMANTIC_KNOWLEDGE_GRAPH, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        # Save statistics
        stats = compute_graph_statistics()
        with open(GRAPH_STATS_PATH, 'w') as f:
            json.dump(stats, f, indent=2)
        
        print(f"   ‚Üí Saved knowledge graph: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
    except Exception as e:
        print(f"   ‚ö† Warning: Could not save knowledge graph: {e}")


def add_field_to_graph(
    field_name: str,
    enriched_name: str,
    object_name: str,
    property_name: str,
    confidence: float,
    pii_category: str,
    application: str,
    eim_id: str
):
    """Add a processed field and its relationships to the knowledge graph."""
    
    # Add field node
    field_node = f"field:{field_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(
        field_node,
        type='field',
        original_name=field_name,
        enriched_name=enriched_name,
        application=application,
        eim_id=eim_id,
        timestamp=datetime.now().isoformat(),
        processing_count=SEMANTIC_KNOWLEDGE_GRAPH.nodes.get(field_node, {}).get('processing_count', 0) + 1
    )
    
    # Add enriched concept node
    enriched_node = f"concept:{enriched_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(
        enriched_node,
        type='concept',
        name=enriched_name,
        frequency=SEMANTIC_KNOWLEDGE_GRAPH.nodes.get(enriched_node, {}).get('frequency', 0) + 1
    )
    
    # Add object node
    object_node = f"object:{object_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(
        object_node,
        type='object',
        name=object_name,
        frequency=SEMANTIC_KNOWLEDGE_GRAPH.nodes.get(object_node, {}).get('frequency', 0) + 1
    )
    
    # Add property node
    property_node = f"property:{property_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(
        property_node,
        type='property',
        name=property_name,
        frequency=SEMANTIC_KNOWLEDGE_GRAPH.nodes.get(property_node, {}).get('frequency', 0) + 1
    )
    
    # Add PII category node
    pii_node = f"pii:{pii_category.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(
        pii_node,
        type='pii_category',
        category=pii_category
    )
    
    # Add edges with metadata
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(
        field_node, enriched_node,
        relationship='enriched_to',
        confidence=confidence,
        timestamp=datetime.now().isoformat()
    )
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(
        enriched_node, object_node,
        relationship='mapped_to_object',
        confidence=confidence
    )
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(
        enriched_node, property_node,
        relationship='mapped_to_property',
        confidence=confidence
    )
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(
        enriched_node, pii_node,
        relationship='classified_as',
        confidence=confidence
    )
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(
        object_node, property_node,
        relationship='has_property',
        frequency=SEMANTIC_KNOWLEDGE_GRAPH.get_edge_data(object_node, property_node, default={}).get('frequency', 0) + 1
    )


def query_graph_patterns(field_name: str, enriched_name: str) -> Dict[str, Any]:
    """Query knowledge graph for relevant patterns and relationships."""
    
    patterns = {
        'similar_fields': [],
        'common_objects': [],
        'common_properties': [],
        'related_concepts': [],
        'reasoning_paths': []
    }
    
    # Find similar field nodes
    field_lower = field_name.lower()
    for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True):
        if data.get('type') == 'field':
            original = data.get('original_name', '').lower()
            similarity = calculate_lexical_similarity(field_lower, original)
            if similarity > 0.6 and node != f"field:{field_lower}":
                # Get what this similar field mapped to
                neighbors = list(SEMANTIC_KNOWLEDGE_GRAPH.successors(node))
                for neighbor in neighbors:
                    neighbor_data = SEMANTIC_KNOWLEDGE_GRAPH.nodes[neighbor]
                    if neighbor_data.get('type') == 'concept':
                        # Find the object and property
                        concept_neighbors = list(SEMANTIC_KNOWLEDGE_GRAPH.successors(neighbor))
                        obj = None
                        prop = None
                        for cn in concept_neighbors:
                            cn_data = SEMANTIC_KNOWLEDGE_GRAPH.nodes[cn]
                            if cn_data.get('type') == 'object':
                                obj = cn_data.get('name')
                            elif cn_data.get('type') == 'property':
                                prop = cn_data.get('name')
                        
                        if obj and prop:
                            patterns['similar_fields'].append({
                                'field': data.get('original_name'),
                                'enriched': neighbor_data.get('name'),
                                'object': obj,
                                'property': prop,
                                'similarity': similarity
                            })
    
    # Find most common objects in similar contexts
    enriched_lower = enriched_name.lower()
    enriched_words = set(enriched_lower.split())
    for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True):
        if data.get('type') == 'concept':
            concept_words = set(data.get('name', '').lower().split())
            overlap = len(enriched_words & concept_words) / max(len(enriched_words), len(concept_words), 1)
            if overlap > 0.4:
                # Get objects this concept maps to
                for successor in SEMANTIC_KNOWLEDGE_GRAPH.successors(node):
                    successor_data = SEMANTIC_KNOWLEDGE_GRAPH.nodes[successor]
                    if successor_data.get('type') == 'object':
                        patterns['common_objects'].append({
                            'object': successor_data.get('name'),
                            'frequency': successor_data.get('frequency', 0),
                            'overlap': overlap
                        })
    
    # Remove duplicates and sort
    patterns['similar_fields'] = sorted(patterns['similar_fields'], key=lambda x: x['similarity'], reverse=True)[:5]
    patterns['common_objects'] = sorted(list({obj['object']: obj for obj in patterns['common_objects']}.values()), key=lambda x: x['frequency'], reverse=True)[:5]
    
    return patterns


def discover_graph_relationships_with_llm(patterns: Dict[str, Any], enriched_name: str) -> str:
    """Use LLM to reason about graph patterns and discover implicit relationships."""
    
    if not patterns['similar_fields'] and not patterns['common_objects']:
        return "No significant graph patterns found for reasoning."
    
    prompt = f"""You are analyzing a semantic knowledge graph to discover patterns and relationships.

CURRENT FIELD: {enriched_name}

GRAPH PATTERNS DISCOVERED:

Similar Fields (based on lexical and semantic similarity):
{json.dumps(patterns['similar_fields'], indent=2)}

Common Objects in Similar Contexts:
{json.dumps(patterns['common_objects'], indent=2)}

TASK: Analyze these patterns and provide insights:

1. What consistent mapping patterns do you observe?
2. Are there strong object-property co-occurrences?
3. What implicit relationships can be inferred?
4. What recommendations emerge from the graph structure?
5. Are there any contradictions or anomalies?

Provide your analysis in a structured format focusing on actionable insights for mapping the current field.
Keep your response concise (max 300 words)."""

    try:
        messages = [{"role": "user", "content": prompt}]
        response = openai_client.chat.completions.create(
            model=OPENAI_REASONING_MODEL,
            messages=messages
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Graph reasoning failed: {e}"


def compute_graph_statistics() -> Dict[str, Any]:
    """Compute comprehensive statistics about the knowledge graph."""
    
    stats = {
        'total_nodes': SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes(),
        'total_edges': SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges(),
        'node_types': {},
        'edge_types': {},
        'top_objects': [],
        'top_properties': [],
        'graph_density': 0,
        'average_degree': 0
    }
    
    # Count node types
    for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True):
        node_type = data.get('type', 'unknown')
        stats['node_types'][node_type] = stats['node_types'].get(node_type, 0) + 1
    
    # Count edge types
    for u, v, data in SEMANTIC_KNOWLEDGE_GRAPH.edges(data=True):
        edge_type = data.get('relationship', 'unknown')
        stats['edge_types'][edge_type] = stats['edge_types'].get(edge_type, 0) + 1
    
    # Top objects by frequency
    objects = [(data.get('name'), data.get('frequency', 0)) for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True) if data.get('type') == 'object']
    stats['top_objects'] = sorted(objects, key=lambda x: x[1], reverse=True)[:10]
    
    # Top properties by frequency
    properties = [(data.get('name'), data.get('frequency', 0)) for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True) if data.get('type') == 'property']
    stats['top_properties'] = sorted(properties, key=lambda x: x[1], reverse=True)[:10]
    
    # Graph metrics
    if stats['total_nodes'] > 1:
        stats['graph_density'] = nx.density(SEMANTIC_KNOWLEDGE_GRAPH)
        degrees = [d for n, d in SEMANTIC_KNOWLEDGE_GRAPH.degree()]
        stats['average_degree'] = sum(degrees) / len(degrees) if degrees else 0
    
    return stats


def print_graph_statistics():
    """Print formatted graph statistics."""
    stats = compute_graph_statistics()
    print(f"      ‚Ä¢ Node types: {stats['node_types']}")
    print(f"      ‚Ä¢ Edge types: {stats['edge_types']}")
    print(f"      ‚Ä¢ Graph density: {stats['graph_density']:.4f}")
    print(f"      ‚Ä¢ Avg degree: {stats['average_degree']:.2f}")


# ============================================================================
# LEXICAL + SEMANTIC MATCHING
# ============================================================================

def calculate_lexical_similarity(str1: str, str2: str) -> float:
    """Calculate lexical similarity using multiple metrics."""
    
    str1 = str1.lower()
    str2 = str2.lower()
    
    # Sequence Matcher (gestalt pattern matching)
    seq_similarity = SequenceMatcher(None, str1, str2).ratio()
    
    # Jaccard similarity (word-level)
    words1 = set(str1.split('_') + str1.split())
    words2 = set(str2.split('_') + str2.split())
    jaccard = len(words1 & words2) / len(words1 | words2) if words1 or words2 else 0
    
    # N-gram overlap (character trigrams)
    def get_trigrams(s):
        return set([s[i:i+3] for i in range(len(s)-2)])
    
    trigrams1 = get_trigrams(str1)
    trigrams2 = get_trigrams(str2)
    trigram_sim = len(trigrams1 & trigrams2) / len(trigrams1 | trigrams2) if trigrams1 or trigrams2 else 0
    
    # Weighted average
    lexical_score = (0.4 * seq_similarity + 0.4 * jaccard + 0.2 * trigram_sim)
    
    return lexical_score


def hybrid_similarity_search(
    query: str,
    vector_store: Any,
    all_items: List[str],
    top_k: int = 5,
    lexical_weight: float = 0.3,
    semantic_weight: float = 0.7
) -> List[Tuple[str, float, Dict[str, float]]]:
    """
    Perform hybrid lexical + semantic similarity search.
    
    Returns: List of (item, combined_score, score_breakdown)
    """
    
    # Semantic search
    semantic_results = vector_store.similarity_search_with_score(query, k=top_k * 2)
    semantic_dict = {}
    for doc, score in semantic_results:
        item = doc.metadata.get('object') or doc.metadata.get('property') or doc.page_content
        semantic_dict[item] = float(score)
    
    # Lexical search
    lexical_scores = {}
    for item in all_items:
        lex_score = calculate_lexical_similarity(query, item)
        lexical_scores[item] = lex_score
    
    # Combine scores
    all_items_set = set(semantic_dict.keys()) | set(lexical_scores.keys())
    combined_results = []
    
    for item in all_items_set:
        semantic_score = semantic_dict.get(item, 0)
        lexical_score = lexical_scores.get(item, 0)
        
        # Normalize semantic score (lower is better for some vector stores)
        # Assuming similarity_search_with_score returns distance (lower = more similar)
        semantic_score_norm = 1 / (1 + semantic_score) if semantic_score > 0 else 0
        
        combined_score = (lexical_weight * lexical_score) + (semantic_weight * semantic_score_norm)
        
        combined_results.append((
            item,
            combined_score,
            {
                'lexical': lexical_score,
                'semantic': semantic_score_norm,
                'combined': combined_score
            }
        ))
    
    # Sort by combined score
    combined_results.sort(key=lambda x: x[1], reverse=True)
    
    return combined_results[:top_k]


# ============================================================================
# DYNAMIC CHAIN-OF-THOUGHT PROMPTING
# ============================================================================

def generate_dynamic_cot_prompt(
    task: str,
    context: Dict[str, Any],
    complexity_level: str = "medium"
) -> str:
    """
    Generate dynamic chain-of-thought prompts that adapt based on context.
    
    complexity_level: "low", "medium", "high"
    """
    
    # Base thinking structure
    base_cot = """Think through this step-by-step:

STEP 1 - UNDERSTAND THE PROBLEM:
- What are we trying to accomplish?
- What information do we have?
- What constraints exist?

STEP 2 - ANALYZE AVAILABLE DATA:
- What patterns are evident?
- What relationships matter?
- What uncertainties exist?

STEP 3 - REASON THROUGH OPTIONS:
- What are possible approaches?
- What are pros and cons of each?
- Which approach best fits the evidence?

STEP 4 - MAKE A DECISION:
- What is the best choice?
- Why is this better than alternatives?
- What confidence level is appropriate?

STEP 5 - VALIDATE THE DECISION:
- Does this make semantic sense?
- Is it consistent with patterns?
- What could go wrong?"""
    
    # Add context-specific reasoning steps
    context_additions = []
    
    # Add graph-based reasoning if graph patterns exist
    if context.get('graph_patterns') and context['graph_patterns'].get('similar_fields'):
        context_additions.append("""
ADDITIONAL STEP - GRAPH PATTERN ANALYSIS:
- What do similar fields suggest?
- Are there consistent mapping patterns in the graph?
- What implicit relationships can be inferred?
- How do graph statistics inform this decision?""")
    
    # Add memory-based reasoning if insights exist
    if context.get('procedural_insights'):
        insights = context['procedural_insights']
        if insights.get('likely_objects') or insights.get('likely_properties'):
            context_additions.append("""
ADDITIONAL STEP - MEMORY PATTERN ANALYSIS:
- What have we learned from similar past cases?
- What patterns consistently work well?
- How should historical confidence inform current decision?
- Are there any contradictions with learned patterns?""")
    
    # Add episodic reasoning if similar cases exist
    if context.get('similar_episodes') and len(context['similar_episodes']) > 0:
        context_additions.append("""
ADDITIONAL STEP - EPISODIC CASE ANALYSIS:
- How were similar cases handled before?
- What strategies worked well in analogous situations?
- What can we learn from past successes/failures?
- How does this case differ from previous ones?""")
    
    # Adjust depth based on complexity
    if complexity_level == "high":
        context_additions.append("""
ADDITIONAL STEP - DEEP SEMANTIC ANALYSIS:
- What are the deeper semantic implications?
- Are there ontological considerations?
- How does this fit into the broader domain model?
- What are second-order effects of this decision?""")
    
    if complexity_level == "low":
        # Simplify for straightforward cases
        base_cot = """Think through this concisely:
1. What patterns match?
2. What's the best fit?
3. Why is this correct?"""
    
    # Combine all parts
    full_prompt = base_cot
    if context_additions:
        full_prompt += "\n" + "\n".join(context_additions)
    
    return full_prompt


def generate_supervisor_cot_prompt(
    state: Dict[str, Any],
    validation_focus: List[str] = None
) -> str:
    """Generate dynamic chain-of-thought for supervisor validation."""
    
    if validation_focus is None:
        validation_focus = ['enrichment', 'mapping', 'modelling', 'pii']
    
    base_prompt = """As a supervisor agent, think through your validation systematically:

PHASE 1 - HOLISTIC ASSESSMENT:
- Does the overall result make intuitive sense?
- Is there internal consistency across all decisions?
- What is your gut reaction to this mapping?

PHASE 2 - DETAILED VALIDATION:"""
    
    validation_sections = []
    
    if 'enrichment' in validation_focus:
        validation_sections.append("""
>>> ENRICHMENT VALIDATION:
- Does the enriched name follow ISO 11179 standards precisely?
- Is it semantically accurate for this specific field?
- Are there any remaining ambiguities or technical artifacts?
- Compare to similar successful enrichments - is quality comparable?""")
    
    if 'mapping' in validation_focus:
        validation_sections.append("""
>>> MAPPING VALIDATION:
- Is the object-property combination semantically correct?
- Does the object truly represent the entity being described?
- Does the property accurately capture the characteristic?
- Check graph patterns - is this consistent with learned relationships?
- What alternative mappings were considered? Why is this better?""")
    
    if 'modelling' in validation_focus and (state.get('object_was_modelled') or state.get('property_was_modelled')):
        validation_sections.append("""
>>> MODELLING DECISION VALIDATION:
- Was modelling truly necessary, or could an existing PBT term work?
- If modelled, does it follow ISO 11179/BIAN/FIBO standards?
- Is the modelled term semantically superior to available alternatives?
- What is the likelihood this modelled term will be reusable?
- CRITICAL: Be strict - only approve modelling if genuinely no suitable PBT term exists""")
    
    if 'pii' in validation_focus:
        validation_sections.append("""
>>> PII CLASSIFICATION VALIDATION:
- Is the PII category appropriate for this data element?
- Are all regulatory considerations accounted for?
- Does classification align with similar fields in graph?
- Could this data be misused if classified incorrectly?""")
    
    base_prompt += "\n".join(validation_sections)
    
    base_prompt += """

PHASE 3 - CONFIDENCE ASSESSMENT:
For EACH aspect (enrichment, mapping, PII):

A. List 3 SUPPORTING reasons (things that increase confidence):
   - Each with a weight (0.0 = weak support, 1.0 = very strong support)
   - Be specific and evidence-based

B. List 3 CONTRADICTORY reasons (things that decrease confidence):
   - Each with a weight (0.0 = minor concern, 1.0 = major concern)
   - Include any doubts, inconsistencies, or weaknesses

C. Calculate confidence score:
   - Formula: ((sum of supporting weights) - (sum of contradictory weights)) / 
              ((sum of supporting weights) + (sum of contradictory weights)) * 100
   - This gives a score from -100 to +100, normalized to 0-100 range

D. Explain your confidence calculation:
   - Why did you assign these specific weights?
   - What would increase/decrease confidence?
   - What are the key factors driving the score?

PHASE 4 - FINAL JUDGMENT:
- Given all analysis, what is your final approval decision?
- What are your key concerns (if any)?
- What recommendations would improve quality?
- Assign overall quality score (1-10)

Remember: Be rigorous but fair. High standards while acknowledging inherent uncertainty."""
    
    return base_prompt


# ============================================================================
# MEMORY FUNCTIONS (Simplified from previous version)
# ============================================================================

def load_all_memory():
    """Load all memory systems."""
    global MAPPING_CACHE, PROCEDURAL_MEMORY, EPISODIC_MEMORY
    
    # Load cache
    if os.path.exists(CACHE_JSON_PATH):
        with open(CACHE_JSON_PATH, 'r') as f:
            MAPPING_CACHE = json.load(f)
        print(f"   ‚Üí Cache: {len(MAPPING_CACHE)} entries")
    
    # Load procedural memory
    if os.path.exists(PROCEDURAL_MEMORY_PATH):
        with open(PROCEDURAL_MEMORY_PATH, 'r') as f:
            PROCEDURAL_MEMORY = json.load(f)
        print(f"   ‚Üí Procedural: {sum(len(v) for v in PROCEDURAL_MEMORY.values())} patterns")
    else:
        PROCEDURAL_MEMORY = {
            "prefix_patterns": {}, "suffix_patterns": {},
            "enrichment_rules": [], "pii_patterns": {},
            "modelling_decisions": [], "high_confidence_strategies": {},
            "acronym_patterns": {}
        }
    
    # Load episodic memory
    if os.path.exists(EPISODIC_MEMORY_PATH):
        with open(EPISODIC_MEMORY_PATH, 'r') as f:
            EPISODIC_MEMORY = json.load(f)
        print(f"   ‚Üí Episodic: {len(EPISODIC_MEMORY)} episodes")
    
    # Load knowledge graph
    initialize_knowledge_graph()


def save_all_memory():
    """Save all memory systems."""
    with open(CACHE_JSON_PATH, 'w') as f:
        json.dump(MAPPING_CACHE, f, indent=2)
    
    save_data = dict(PROCEDURAL_MEMORY)
    with open(PROCEDURAL_MEMORY_PATH, 'w') as f:
        json.dump(save_data, f, indent=2)
    
    with open(EPISODIC_MEMORY_PATH, 'w') as f:
        json.dump(EPISODIC_MEMORY, f, indent=2)
    
    save_knowledge_graph()


def update_all_memory(field_name, enriched_name, obj, prop, strategy, confidence, pii, obj_mod, prop_mod, application, eim_id):
    """Update all memory systems with new processing results."""
    
    # Update cache
    cache_key = f"{enriched_name.lower()}|{field_name.lower()[:100]}"
    MAPPING_CACHE[cache_key] = {
        'object': obj, 'property': prop, 'confidence': confidence,
        'object_was_modelled': obj_mod, 'property_was_modelled': prop_mod
    }
    
    # Update procedural memory (simplified)
    if confidence >= 70:
        field_lower = field_name.lower()
        for prefix_len in [3, 4, 5]:
            if len(field_lower) >= prefix_len:
                prefix = field_lower[:prefix_len]
                if prefix not in PROCEDURAL_MEMORY['prefix_patterns']:
                    PROCEDURAL_MEMORY['prefix_patterns'][prefix] = {}
                PROCEDURAL_MEMORY['prefix_patterns'][prefix][obj] = PROCEDURAL_MEMORY['prefix_patterns'][prefix].get(obj, 0) + 1
    
    # Add to episodic memory
    EPISODIC_MEMORY.append({
        "timestamp": datetime.now().isoformat(),
        "field": field_name,
        "enriched": enriched_name,
        "mapping": {"object": obj, "property": prop},
        "confidence": confidence,
        "pii": pii
    })
    if len(EPISODIC_MEMORY) > 1000:
        EPISODIC_MEMORY[:] = EPISODIC_MEMORY[-1000:]
    
    # Add to knowledge graph
    add_field_to_graph(field_name, enriched_name, obj, prop, confidence, pii, application, eim_id)


# ============================================================================
# EMBEDDINGS & UTILITIES
# ============================================================================

class OpenAIEmbeddings(Embeddings):
    def __init__(self, model: str = OPENAI_EMBEDDING_MODEL):
        self.model = model
        self.client = openai_client
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for idx, text in enumerate(texts, 1):
            print(f"      üìä Embedding {idx}/{len(texts)}")
            embeddings.append(self.embed_query(text))
            time.sleep(0.1)
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        response = self.client.embeddings.create(model=self.model, input=[text[:8000]])
        return response.data[0].embedding


def call_openai_with_retry(messages: List[Dict], max_retries: int = 10) -> str:
    for attempt in range(max_retries):
        try:
            response = openai_client.chat.completions.create(
                model=OPENAI_REASONING_MODEL,
                messages=messages
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"      ‚ö† Attempt {attempt + 1} failed: {e}")
            time.sleep(2 ** attempt)
    raise Exception(f"Failed after {max_retries} attempts")


# ============================================================================
# ISO 11179 PROMPTS
# ============================================================================

ISO_11179_NAMING = "ISO/IEC 11179: Use Title Case, proper spacing, semantic clarity. Structure: [Object] [Qualifier] [Property]. OUTPUT: Enriched name only."
ISO_11179_DEFINITION = "ISO/IEC 11179: State what concept IS. Include characteristics, context, constraints. OUTPUT: Definition only."
PII_FRAMEWORK = "CATEGORIES: NON PERSONAL DATA, PERSONAL DATA, SENSITIVE PERSONAL DATA. OUTPUT: JSON with pii_category, is_pii, regulatory_considerations, detailed_rationale."


# ============================================================================
# AGENT STATE
# ============================================================================

class EnrichmentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    current_field: Dict[str, Any]
    enriched_name: str
    enriched_description: str
    object_name: str
    property_name: str
    object_was_modelled: bool
    property_was_modelled: bool
    pii_classification: Dict[str, Any]
    enrichment_rationale: str
    mapping_rationale: str
    enrichment_confidence: Dict[str, Any]
    mapping_confidence: Dict[str, Any]
    pii_confidence: Dict[str, Any]
    intersection_vector_store: Any
    object_vector_store: Any
    property_vector_store: Any
    all_objects: List[str]
    all_properties: List[str]
    objects_dict: Dict[str, List[str]]
    acronym_dict: Dict[str, str]
    expert_opinions: List[str]
    reasoning_chain: List[str]
    graph_patterns: Dict[str, Any]
    graph_reasoning: str
    mapping_strategy: str
    complexity_level: str


# ============================================================================
# ENRICHMENT COORDINATOR WITH GRAPH REASONING
# ============================================================================

def enrichment_coordinator_node(state: EnrichmentState) -> EnrichmentState:
    """Coordinator with graph reasoning and hybrid matching."""
    
    field_name = state['current_field'].get('Field Name', '')
    app_name = state['current_field'].get('Application Name', '')
    
    print(f"\n{'='*80}")
    print(f"PROCESSING: {field_name}")
    print(f"{'='*80}")
    
    state['reasoning_chain'] = []
    state['expert_opinions'] = []
    
    # Determine complexity
    word_count = len(field_name.split('_')) + len(field_name.split())
    state['complexity_level'] = 'high' if word_count > 5 else 'medium' if word_count > 3 else 'low'
    
    # STEP 1: Enrichment with Dynamic CoT
    print("\n[STEP 1] Enrichment with Dynamic Chain-of-Thought...")
    
    enrichment_context = {
        'procedural_insights': {},
        'graph_patterns': {},
        'complexity_level': state['complexity_level']
    }
    cot_prompt = generate_dynamic_cot_prompt("enrichment", enrichment_context, state['complexity_level'])
    
    prompt = f"""You are an ISO 11179 expert. Transform this field name.

FIELD: {field_name}
APPLICATION: {app_name}

{ISO_11179_NAMING}

{cot_prompt}

After thinking through, provide ONLY the enriched name."""
    
    try:
        enriched_name = call_openai_with_retry([{"role": "user", "content": prompt}]).strip()
        # Clean up if LLM added extra text
        if '\n' in enriched_name:
            enriched_name = enriched_name.split('\n')[0]
        state['enriched_name'] = enriched_name
        print(f"   ‚úì Enriched: {enriched_name}")
    except:
        state['enriched_name'] = field_name
    
    # STEP 2: Definition
    print("\n[STEP 2] Definition Generation...")
    try:
        definition = call_openai_with_retry([{
            "role": "user",
            "content": f"Create ISO 11179 definition for: {state['enriched_name']}. {ISO_11179_DEFINITION}"
        }]).strip()
        state['enriched_description'] = definition
        print(f"   ‚úì Definition: {definition[:80]}...")
    except:
        state['enriched_description'] = f"A data element representing {state['enriched_name'].lower()}."
    
    # STEP 3: Query Knowledge Graph
    print("\n[STEP 3] Querying Knowledge Graph...")
    graph_patterns = query_graph_patterns(field_name, state['enriched_name'])
    state['graph_patterns'] = graph_patterns
    
    if graph_patterns['similar_fields']:
        print(f"   üìä Found {len(graph_patterns['similar_fields'])} similar fields in graph")
        for sf in graph_patterns['similar_fields'][:3]:
            print(f"      ‚Ä¢ {sf['field']} ‚Üí {sf['object']}.{sf['property']} (sim: {sf['similarity']:.2f})")
    
    # STEP 4: LLM-Powered Graph Reasoning
    print("\n[STEP 4] LLM Graph Reasoning...")
    graph_reasoning = discover_graph_relationships_with_llm(graph_patterns, state['enriched_name'])
    state['graph_reasoning'] = graph_reasoning
    print(f"   üß† Graph insights: {graph_reasoning[:150]}...")
    
    # STEP 5: Hybrid Lexical + Semantic Matching
    print("\n[STEP 5] Hybrid Matching (Lexical + Semantic)...")
    
    query = f"{state['enriched_name']} {state['enriched_description']}"
    
    # Object matching
    print("   ‚Üí Matching objects...")
    object_results = hybrid_similarity_search(
        query,
        state['object_vector_store'],
        state['all_objects'],
        top_k=5,
        lexical_weight=0.3,
        semantic_weight=0.7
    )
    
    print(f"      Top object: {object_results[0][0]} (combined: {object_results[0][1]:.3f}, lex: {object_results[0][2]['lexical']:.3f}, sem: {object_results[0][2]['semantic']:.3f})")
    
    # Property matching
    print("   ‚Üí Matching properties...")
    property_results = hybrid_similarity_search(
        query,
        state['property_vector_store'],
        state['all_properties'],
        top_k=5,
        lexical_weight=0.3,
        semantic_weight=0.7
    )
    
    print(f"      Top property: {property_results[0][0]} (combined: {property_results[0][1]:.3f}, lex: {property_results[0][2]['lexical']:.3f}, sem: {property_results[0][2]['semantic']:.3f})")
    
    # STEP 6: Semantic Mapping with Dynamic CoT
    print("\n[STEP 6] Semantic Mapping with Graph-Informed CoT...")
    
    mapping_context = {
        'graph_patterns': graph_patterns,
        'graph_reasoning': graph_reasoning,
        'complexity_level': state['complexity_level']
    }
    
    mapping_cot = generate_dynamic_cot_prompt("mapping", mapping_context, state['complexity_level'])
    
    mapping_prompt = f"""You are a semantic mapping expert.

ENRICHED: {state['enriched_name']}
DESCRIPTION: {state['enriched_description']}

HYBRID MATCHING RESULTS:
Objects (lexical+semantic): {json.dumps([(r[0], r[1], r[2]) for r in object_results[:3]], indent=2)}
Properties (lexical+semantic): {json.dumps([(r[0], r[1], r[2]) for r in property_results[:3]], indent=2)}

GRAPH INSIGHTS:
{graph_reasoning}

{mapping_cot}

Based on your reasoning, provide ONLY JSON:
{{
    "best_object": "<object>",
    "best_property": "<property>",
    "object_was_modelled": <bool>,
    "property_was_modelled": <bool>,
    "confidence": <0-100>,
    "strategy": "<hybrid_matching|graph_informed|modelling>",
    "reasoning": "<concise explanation>"
}}"""
    
    try:
        mapping_response = call_openai_with_retry([{"role": "user", "content": mapping_prompt}])
        # Extract JSON
        if '```json' in mapping_response:
            mapping_response = mapping_response.split('```json')[1].split('```')[0]
        mapping_data = json.loads(mapping_response.strip())
        
        state['object_name'] = mapping_data['best_object']
        state['property_name'] = mapping_data['best_property']
        state['object_was_modelled'] = mapping_data.get('object_was_modelled', False)
        state['property_was_modelled'] = mapping_data.get('property_was_modelled', False)
        state['mapping_strategy'] = mapping_data.get('strategy', 'hybrid_matching')
        
        print(f"   ‚úì Mapped: {state['object_name']}.{state['property_name']}")
        print(f"      Strategy: {state['mapping_strategy']}")
        print(f"      Modelling: Obj={state['object_was_modelled']}, Prop={state['property_was_modelled']}")
        
    except Exception as e:
        print(f"   ‚ùå Mapping failed: {e}")
        state['object_name'] = object_results[0][0] if object_results else 'Unknown'
        state['property_name'] = property_results[0][0] if property_results else 'Unknown'
        state['object_was_modelled'] = False
        state['property_was_modelled'] = False
        state['mapping_strategy'] = 'fallback'
    
    # STEP 7: PII Classification
    print("\n[STEP 7] PII Classification...")
    try:
        pii_response = call_openai_with_retry([{
            "role": "user",
            "content": f"Classify PII for: {state['enriched_name']} ({state['object_name']}.{state['property_name']}). {PII_FRAMEWORK}"
        }])
        if '```json' in pii_response:
            pii_response = pii_response.split('```json')[1].split('```')[0]
        pii_data = json.loads(pii_response.strip())
        state['pii_classification'] = pii_data
        print(f"   ‚úì PII: {pii_data.get('pii_category', 'UNKNOWN')}")
    except:
        state['pii_classification'] = {"pii_category": "NON PERSONAL DATA", "is_pii": False, "regulatory_considerations": [], "detailed_rationale": "Classification failed"}
    
    # STEP 8: Supervisor with Dynamic CoT
    print("\n[STEP 8] Supervisor Validation with Dynamic CoT...")
    
    supervisor_cot = generate_supervisor_cot_prompt(state)
    
    supervisor_prompt = f"""You are a SUPERVISOR validating this enrichment and mapping.

ORIGINAL: {field_name}
ENRICHED: {state['enriched_name']}
MAPPING: {state['object_name']}.{state['property_name']}
STRATEGY: {state['mapping_strategy']}
MODELLED: Obj={state['object_was_modelled']}, Prop={state['property_was_modelled']}

GRAPH INSIGHTS:
{graph_reasoning[:300]}

{supervisor_cot}

Provide ONLY JSON with your validation results including confidence scoring."""
    
    try:
        supervisor_response = call_openai_with_retry([{"role": "user", "content": supervisor_prompt}])
        if '```json' in supervisor_response:
            supervisor_response = supervisor_response.split('```json')[1].split('```')[0]
        supervisor_data = json.loads(supervisor_response.strip())
        
        state['enrichment_rationale'] = supervisor_data.get('enrichment_rationale', '')
        state['mapping_rationale'] = supervisor_data.get('mapping_rationale', '')
        state['enrichment_confidence'] = supervisor_data.get('enrichment_confidence', {})
        state['mapping_confidence'] = supervisor_data.get('mapping_confidence', {})
        state['pii_confidence'] = supervisor_data.get('pii_confidence', {})
        
        print(f"   ‚úì Validation: Quality {supervisor_data.get('quality_score', 0)}/10")
        print(f"      Confidence: E={state['enrichment_confidence'].get('confidence_score', 0)}, M={state['mapping_confidence'].get('confidence_score', 0)}, P={state['pii_confidence'].get('confidence_score', 0)}")
        
    except Exception as e:
        print(f"   ‚ö† Supervisor failed: {e}")
        state['enrichment_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
        state['mapping_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
        state['pii_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Failed'}
    
    # STEP 9: Update Memory & Graph
    print("\n[STEP 9] Updating Memory & Knowledge Graph...")
    update_all_memory(
        field_name,
        state['enriched_name'],
        state['object_name'],
        state['property_name'],
        state['mapping_strategy'],
        state['mapping_confidence'].get('confidence_score', 0),
        state['pii_classification'].get('pii_category', 'NON PERSONAL DATA'),
        state['object_was_modelled'],
        state['property_was_modelled'],
        app_name,
        state['current_field'].get('EIM ID', '')
    )
    
    print(f"{'='*80}\n")
    return state


def should_continue(state: EnrichmentState) -> Literal["end"]:
    return "end"


def create_enrichment_graph():
    workflow = StateGraph(EnrichmentState)
    workflow.add_node("enrichment_coordinator", enrichment_coordinator_node)
    workflow.set_entry_point("enrichment_coordinator")
    workflow.add_conditional_edges("enrichment_coordinator", should_continue, {"end": END})
    return workflow.compile()


# ============================================================================
# MAIN PROCESSING
# ============================================================================

def process_data_enrichment_and_mapping():
    print("="*80)
    print("ISO 11179 WITH SEMANTIC KNOWLEDGE GRAPH & ADVANCED REASONING")
    print("="*80)
    
    # Load memory & graph
    print("\n[1] Loading Memory & Knowledge Graph...")
    load_all_memory()
    
    # Load input
    print("\n[2] Loading Input...")
    with open(INPUT_JSON_PATH, 'r') as f:
        input_data = json.load(f)
    print(f"   ‚Üí {len(input_data)} records")
    
    # Load acronyms
    acronym_dict = {}
    if os.path.exists(ACRONYM_CSV_PATH):
        df = pd.read_csv(ACRONYM_CSV_PATH)
        for _, row in df.iterrows():
            acronym_dict[str(row['acronym']).strip().upper()] = str(row['expansion']).strip()
        print(f"   ‚Üí {len(acronym_dict)} acronyms")
    
    # Load PBT and create vector stores
    print("\n[3] Creating Vector Stores...")
    excel_df = pd.read_excel(EXCEL_PATH)
    
    objects_dict = {}
    all_objects = []
    all_properties = []
    
    for _, row in excel_df.iterrows():
        obj = str(row['Object name']).strip()
        prop = str(row['Property name']).strip()
        
        if obj not in objects_dict:
            objects_dict[obj] = []
            all_objects.append(obj)
        if prop not in objects_dict[obj]:
            objects_dict[obj].append(prop)
        if prop not in all_properties:
            all_properties.append(prop)
    
    print(f"   ‚Üí {len(all_objects)} objects, {len(all_properties)} properties")
    
    embeddings = OpenAIEmbeddings()
    
    intersection_docs = [Document(page_content=f"{obj} {prop}", metadata={"object": obj, "property": prop}) for obj in all_objects for prop in objects_dict[obj]]
    intersection_store = InMemoryVectorStore.from_documents(intersection_docs, embeddings)
    
    object_docs = [Document(page_content=obj, metadata={"object": obj}) for obj in all_objects]
    object_store = InMemoryVectorStore.from_documents(object_docs, embeddings)
    
    property_docs = [Document(page_content=prop, metadata={"property": prop}) for prop in all_properties]
    property_store = InMemoryVectorStore.from_documents(property_docs, embeddings)
    
    print(f"   ‚úì Created 3 vector stores")
    
    # Create workflow
    print("\n[4] Initializing Workflow...")
    app = create_enrichment_graph()
    
    # Process records
    print(f"\n[5] Processing Records...")
    
    successful = 0
    failed = 0
    modelled_obj = 0
    modelled_prop = 0
    
    for idx, record in enumerate(input_data):
        eim_id = record.get("EIM ID", "")
        print(f"\nRecord {idx + 1}/{len(input_data)}")
        
        try:
            initial_state = {
                "messages": [], "current_field": record, "enriched_name": "", "enriched_description": "",
                "object_name": "", "property_name": "", "object_was_modelled": False, "property_was_modelled": False,
                "pii_classification": {}, "enrichment_rationale": "", "mapping_rationale": "",
                "enrichment_confidence": {}, "mapping_confidence": {}, "pii_confidence": {},
                "intersection_vector_store": intersection_store, "object_vector_store": object_store,
                "property_vector_store": property_store, "all_objects": all_objects, "all_properties": all_properties,
                "objects_dict": objects_dict, "acronym_dict": acronym_dict, "expert_opinions": [],
                "reasoning_chain": [], "graph_patterns": {}, "graph_reasoning": "",
                "mapping_strategy": "unknown", "complexity_level": "medium"
            }
            
            final_state = app.invoke(initial_state)
            
            def fmt_reasons(reasons):
                return " | ".join([f"{i+1}. {r.get('reason', 'N/A')} (w:{r.get('weight', 0)})" for i, r in enumerate(reasons)]) if reasons else ""
            
            pii = final_state['pii_classification']
            ec = final_state.get('enrichment_confidence', {})
            mc = final_state.get('mapping_confidence', {})
            pc = final_state.get('pii_confidence', {})
            
            result = {
                "EIM ID": eim_id,
                "Application Name": record.get("Application Name", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": final_state['enriched_name'],
                "Enriched Description": final_state['enriched_description'],
                "Mapped Object": final_state['object_name'],
                "Mapped Property": final_state['property_name'],
                "Mapping Strategy": final_state.get('mapping_strategy', 'unknown'),
                "Object Was Modelled": final_state.get('object_was_modelled', False),
                "Property Was Modelled": final_state.get('property_was_modelled', False),
                "PII Category": pii.get('pii_category', ''),
                "Is PII": pii.get('is_pii', False),
                "Enrichment Confidence": ec.get('confidence_score', 0),
                "Enrichment Supporting": fmt_reasons(ec.get('supporting_reasons', [])),
                "Enrichment Contradictory": fmt_reasons(ec.get('contradictory_reasons', [])),
                "Mapping Confidence": mc.get('confidence_score', 0),
                "Mapping Supporting": fmt_reasons(mc.get('supporting_reasons', [])),
                "Mapping Contradictory": fmt_reasons(mc.get('contradictory_reasons', [])),
                "PII Confidence": pc.get('confidence_score', 0),
                "Graph Reasoning": final_state.get('graph_reasoning', '')[:200],
                "Status": "SUCCESS"
            }
            
            successful += 1
            if result["Object Was Modelled"]:
                modelled_obj += 1
            if result["Property Was Modelled"]:
                modelled_prop += 1
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            result = {
                "EIM ID": eim_id, "Application Name": record.get("Application Name", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": record.get("Field Name", ""),
                "Enriched Description": f"Error: {str(e)[:200]}",
                "Mapped Object": "Unknown", "Mapped Property": "Unknown",
                "Mapping Strategy": "error", "Object Was Modelled": False, "Property Was Modelled": False,
                "PII Category": "NON PERSONAL DATA", "Is PII": False,
                "Enrichment Confidence": 0, "Enrichment Supporting": "", "Enrichment Contradictory": "",
                "Mapping Confidence": 0, "Mapping Supporting": "", "Mapping Contradictory": "",
                "PII Confidence": 0, "Graph Reasoning": "", "Status": "FAILED"
            }
            failed += 1
        
        # Write incrementally
        pd.DataFrame([result]).to_csv(OUTPUT_CSV_PATH, mode='a', header=(successful+failed==1), index=False)
    
    # Save memory & graph
    print("\n[6] Saving Memory & Knowledge Graph...")
    save_all_memory()
    
    print(f"\n{'='*80}")
    print("COMPLETE!")
    print(f"{'='*80}")
    print(f"Success: {successful}, Failed: {failed}")
    print(f"Modelled: Obj={modelled_obj}, Prop={modelled_prop}")
    print(f"\nüìä Knowledge Graph Statistics:")
    print_graph_statistics()
    print(f"\nOutput: {OUTPUT_CSV_PATH}")


if __name__ == "__main__":
    process_data_enrichment_and_mapping()
