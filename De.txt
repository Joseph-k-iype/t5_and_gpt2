"""
Enhanced Legal Document Analyzer with Graph Database Integration
Complete implementation with all features - FIXED VERSION
Location: src/analyzers/legal_document_analyzer_enhanced.py
"""

from typing import Dict, List, Optional, Any, TypedDict, Annotated
import json
from dataclasses import dataclass
import logging
import re
import operator
import os

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage
from langgraph.graph import StateGraph, END
from langchain_community.graphs import FalkorDBGraph

from openai import OpenAI

from src.utils.document_chunker import DocumentChunker
from src.config import Config

logger = logging.getLogger(__name__)


# ============================================================================
# EMBEDDING SERVICE (Direct OpenAI API)
# ============================================================================

class EmbeddingService:
    """Direct OpenAI embedding service"""
    
    def __init__(self, api_key: str, model: str = "text-embedding-3-large"):
        self.client = OpenAI(api_key=api_key)
        self.model = model
        self.dimension = 3072
    
    def embed_text(self, text: str) -> List[float]:
        """Generate embedding for single text"""
        try:
            response = self.client.embeddings.create(
                input=text,
                model=self.model
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Embedding error: {e}")
            return [0.0] * self.dimension
    
    def embed_texts(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings for multiple texts"""
        try:
            response = self.client.embeddings.create(
                input=texts,
                model=self.model
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            logger.error(f"Batch embedding error: {e}")
            return [[0.0] * self.dimension for _ in texts]


# ============================================================================
# FALKORDB KNOWLEDGE GRAPH (FIXED)
# ============================================================================

class FalkorDBKnowledgeGraph:
    """FalkorDB-based knowledge graph for legal analysis - FIXED VERSION"""
    
    def __init__(self, host: str = "localhost", port: int = 6379, 
                 graph_name: str = "legal_knowledge_graph",
                 embedding_service: EmbeddingService = None):
        """Initialize FalkorDB connection"""
        try:
            self.graph = FalkorDBGraph(
                database=graph_name,
                host=host,
                port=port
            )
            self.graph_name = graph_name
            self.embedding_service = embedding_service
            
            # Statistics
            self.stats = {
                "requirements": 0,
                "actions": 0,
                "evidence": 0,
                "constraints": 0
            }
            
            logger.info(f"Connected to FalkorDB: {host}:{port}/{graph_name}")
            
        except Exception as e:
            logger.error(f"FalkorDB connection error: {e}")
            self.graph = None
            self.stats = {}
    
    def _escape_text(self, text: str) -> str:
        """Escape text for Cypher query"""
        if not text:
            return ""
        # Replace single quotes with escaped version
        text = text.replace("'", "\\'")
        # Replace double quotes
        text = text.replace('"', '\\"')
        # Limit length
        return text[:2000]
    
    def add_requirement(self, req_id: str, description: str, level: int,
                       classification: str, citations: List[str]):
        """Add requirement node - FIXED"""
        if not self.graph:
            self.stats["requirements"] = self.stats.get("requirements", 0) + 1
            return
        
        try:
            desc_escaped = self._escape_text(description)
            citations_str = "|".join([self._escape_text(c) for c in citations[:3]])
            
            query = f"""
            CREATE (r:Requirement {{
                id: '{req_id}',
                description: '{desc_escaped}',
                level: {level},
                classification: '{classification}',
                citations: '{citations_str}',
                timestamp: timestamp()
            }})
            RETURN r.id AS created_id
            """
            
            result = self.graph.query(query)
            if result:
                self.stats["requirements"] = self.stats.get("requirements", 0) + 1
                logger.info(f"Created requirement node: {req_id}")
            
        except Exception as e:
            logger.error(f"Error adding requirement {req_id}: {e}")
    
    def add_action(self, action_id: str, action_type: str, description: str,
                  actor: str, req_id: str, citations: List[str]):
        """Add action node and link to requirement - FIXED"""
        if not self.graph:
            self.stats["actions"] = self.stats.get("actions", 0) + 1
            return
        
        try:
            desc_escaped = self._escape_text(description)
            citations_str = "|".join([self._escape_text(c) for c in citations[:2]])
            
            query = f"""
            MATCH (r:Requirement {{id: '{req_id}'}})
            CREATE (a:Action {{
                id: '{action_id}',
                type: '{action_type}',
                description: '{desc_escaped}',
                actor: '{actor}',
                citations: '{citations_str}',
                timestamp: timestamp()
            }})
            CREATE (r)-[:REQUIRES_ACTION]->(a)
            RETURN a.id AS created_id
            """
            
            result = self.graph.query(query)
            if result:
                self.stats["actions"] = self.stats.get("actions", 0) + 1
                logger.info(f"Created action node: {action_id}")
            
        except Exception as e:
            logger.error(f"Error adding action {action_id}: {e}")
    
    def add_evidence(self, evidence_id: str, evidence_type: str, 
                    description: str, perspective: str, req_id: str,
                    citations: List[str]):
        """Add evidence node - FIXED"""
        if not self.graph:
            self.stats["evidence"] = self.stats.get("evidence", 0) + 1
            return
        
        try:
            desc_escaped = self._escape_text(description)
            citations_str = "|".join([self._escape_text(c) for c in citations[:2]])
            
            query = f"""
            MATCH (r:Requirement {{id: '{req_id}'}})
            CREATE (e:Evidence {{
                id: '{evidence_id}',
                type: '{evidence_type}',
                description: '{desc_escaped}',
                perspective: '{perspective}',
                citations: '{citations_str}',
                timestamp: timestamp()
            }})
            CREATE (r)-[:REQUIRES_EVIDENCE]->(e)
            RETURN e.id AS created_id
            """
            
            result = self.graph.query(query)
            if result:
                self.stats["evidence"] = self.stats.get("evidence", 0) + 1
                logger.info(f"Created evidence node: {evidence_id}")
            
        except Exception as e:
            logger.error(f"Error adding evidence {evidence_id}: {e}")
    
    def add_constraint(self, constraint_id: str, constraint_type: str,
                      description: str, operator: str, value: Any, req_id: str):
        """Add constraint node - FIXED"""
        if not self.graph:
            self.stats["constraints"] = self.stats.get("constraints", 0) + 1
            return
        
        try:
            desc_escaped = self._escape_text(description)
            value_str = self._escape_text(str(value))
            
            query = f"""
            MATCH (r:Requirement {{id: '{req_id}'}})
            CREATE (c:Constraint {{
                id: '{constraint_id}',
                type: '{constraint_type}',
                description: '{desc_escaped}',
                operator: '{operator}',
                value: '{value_str}',
                timestamp: timestamp()
            }})
            CREATE (r)-[:HAS_CONSTRAINT]->(c)
            RETURN c.id AS created_id
            """
            
            result = self.graph.query(query)
            if result:
                self.stats["constraints"] = self.stats.get("constraints", 0) + 1
                logger.info(f"Created constraint node: {constraint_id}")
            
        except Exception as e:
            logger.error(f"Error adding constraint {constraint_id}: {e}")
    
    def get_statistics(self) -> Dict[str, Any]:
        """Get graph statistics - FIXED for FalkorDB result structure"""
        if not self.graph:
            return self.stats
        
        try:
            stats = {}
            
            # Count each node type
            for node_type in ["Requirement", "Action", "Evidence", "Constraint"]:
                try:
                    query = f"MATCH (n:{node_type}) RETURN count(n) AS count"
                    result = self.graph.query(query)
                    
                    # FalkorDB returns list of lists or list of Row objects
                    if result and len(result) > 0:
                        first_row = result[0]
                        
                        # Handle different result types
                        if isinstance(first_row, dict):
                            count_value = first_row.get('count', 0)
                        elif isinstance(first_row, (list, tuple)):
                            count_value = first_row[0] if len(first_row) > 0 else 0
                        elif hasattr(first_row, 'count'):
                            count_value = first_row.count
                        else:
                            # Try to access as attribute or index
                            try:
                                count_value = first_row[0]
                            except:
                                count_value = 0
                        
                        stats[node_type.lower()] = int(count_value) if count_value else 0
                    else:
                        stats[node_type.lower()] = 0
                        
                except Exception as e:
                    logger.warning(f"Error counting {node_type}: {e}")
                    stats[node_type.lower()] = 0
            
            # Count relationships
            try:
                query = "MATCH ()-[r]->() RETURN count(r) AS count"
                result = self.graph.query(query)
                
                if result and len(result) > 0:
                    first_row = result[0]
                    
                    # Handle different result types
                    if isinstance(first_row, dict):
                        count_value = first_row.get('count', 0)
                    elif isinstance(first_row, (list, tuple)):
                        count_value = first_row[0] if len(first_row) > 0 else 0
                    elif hasattr(first_row, 'count'):
                        count_value = first_row.count
                    else:
                        try:
                            count_value = first_row[0]
                        except:
                            count_value = 0
                    
                    stats['relationships'] = int(count_value) if count_value else 0
                else:
                    stats['relationships'] = 0
                    
            except Exception as e:
                logger.warning(f"Error counting relationships: {e}")
                stats['relationships'] = 0
            
            return stats
            
        except Exception as e:
            logger.error(f"Error getting statistics: {e}")
            return self.stats


# ============================================================================
# STATE DEFINITIONS FOR LANGGRAPH
# ============================================================================

class AgentState(TypedDict):
    """State for LangGraph agent"""
    messages: Annotated[List[BaseMessage], operator.add]
    chunk_text: str
    chunk_id: int
    level: int
    rule_name: str
    jurisdiction: str
    enterprise_context: Optional[Dict[str, Any]]
    
    description: str
    citations: List[Dict[str, Any]]
    data_actions: List[Dict[str, Any]]
    user_evidence: List[Dict[str, Any]]
    system_evidence: List[Dict[str, Any]]
    constraints: List[Dict[str, Any]]
    enterprise_policies: List[Dict[str, Any]]
    classification: str
    classification_reasoning: str
    
    chain_of_thought: List[str]
    expert_opinions: Dict[str, Any]
    thought_tree: Dict[str, Any]
    
    kg_nodes: List[Dict[str, Any]]
    kg_edges: List[Dict[str, Any]]
    
    next_step: str
    iteration: int
    max_iterations: int


# ============================================================================
# LANGGRAPH AGENT NODES (FIXED ROUTING)
# ============================================================================

class LegalAnalysisAgent:
    """LangGraph agent with advanced reasoning - FIXED"""
    
    def __init__(self, llm: ChatOpenAI, kg: FalkorDBKnowledgeGraph):
        self.llm = llm
        self.kg = kg
    
    def chain_of_thought_reasoning(self, state: AgentState) -> AgentState:
        """Chain of Thought reasoning node"""
        level_names = {1: "Primary Legislation", 2: "Regulatory Guidance", 3: "Enterprise Policy"}
        level_name = level_names.get(state['level'], "Document")
        
        prompt = f"""Analyze this legal text from {level_name} using systematic step-by-step reasoning.

TEXT:
{state['chunk_text'][:2500]}

Rule: {state['rule_name']}
Jurisdiction: {state['jurisdiction']}
Document Level: Level {state['level']} - {level_name}

IMPORTANT NOTES:
- "DataVisa" is an internal data governance tool
- Ignore classification markers like "INTERNAL" at document end

Think through systematically:
1. What is the core legal requirement stated in this text?
2. Who is affected - users performing actions, or systems that must be implemented?
3. What specific data operations are mentioned (sharing/accessing, storing/hosting, or using/processing)?
4. What conditions or limitations apply?
5. Is this describing actions that ARE allowed under conditions (CONDITION), or actions that are NOT allowed (RESTRICTION)?

For each point, provide exact citations from the text (max 150 characters each) with source reference.

Return valid JSON:
{{
    "thought_steps": ["clear step 1", "clear step 2", "clear step 3", "clear step 4", "clear step 5"],
    "main_requirement": "Complete sentence describing the requirement",
    "affected_parties": ["user", "system"],
    "data_operations": ["specific operation"],
    "conditions": ["condition 1", "condition 2"],
    "classification": "condition" or "restriction",
    "citations": [
        {{
            "text": "exact quote from text",
            "reasoning": "why this supports the requirement",
            "source_reference": "Level {state['level']} - {level_name}, Section/Article reference if visible"
        }}
    ]
}}"""
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        try:
            result = self._extract_json(response.content)
            state['chain_of_thought'] = result.get('thought_steps', [])
            
            if result.get('main_requirement'):
                state['description'] += result['main_requirement'] + " "
            
            for cite in result.get('citations', []):
                if cite.get('text') and len(cite['text']) > 20:
                    state['citations'].append({
                        "text": cite['text'],
                        "reasoning": cite.get('reasoning', ''),
                        "source_reference": cite.get('source_reference', f"Level {state['level']} - {level_name}"),
                        "chunk_id": state['chunk_id'],
                        "level": state['level'],
                        "level_name": level_name
                    })
            
            if not state.get('classification') and result.get('classification'):
                state['classification'] = result['classification']
            
        except Exception as e:
            logger.error(f"Chain of thought error: {e}")
            state['chain_of_thought'].append(f"Error in reasoning: {str(e)}")
        
        state['next_step'] = 'mixture_of_experts'
        return state
    
    def mixture_of_experts(self, state: AgentState) -> AgentState:
        """Mixture of Experts reasoning"""
        level_names = {1: "Primary Legislation", 2: "Regulatory Guidance", 3: "Enterprise Policy"}
        level_name = level_names.get(state['level'], "Document")
        
        experts = {
            "legal_expert": "Extract legal obligations with precise citations",
            "data_privacy_specialist": "Identify data handling operations",
            "technical_architect": "Determine system requirements",
            "compliance_officer": "Identify user compliance actions"
        }
        
        expert_results = {}
        
        for expert_role, expert_task in experts.items():
            prompt = f"""You are a {expert_role.replace('_', ' ').title()}.

Task: {expert_task}

TEXT (from {level_name}):
{state['chunk_text'][:2000]}

Rule: {state['rule_name']}

Provide JSON:
{{
    "key_findings": ["complete finding 1", "complete finding 2"],
    "data_actions": [
        {{
            "type": "data_sharing_and_access" or "data_storage_and_hosting" or "data_usage",
            "description": "Complete sentence",
            "actor": "user" or "system",
            "citations": [{{"text": "exact quote", "source_reference": "Level {state['level']} - {level_name}"}}]
        }}
    ],
    "requirements": [
        {{
            "description": "Complete sentence",
            "perspective": "user" or "system",
            "citations": [{{"text": "exact quote", "source_reference": "Level {state['level']} - {level_name}"}}]
        }}
    ],
    "constraints": [
        {{
            "type": "temporal" or "technical" or "procedural",
            "description": "Complete sentence",
            "citations": [{{"text": "exact quote", "source_reference": "Level {state['level']} - {level_name}"}}]
        }}
    ]
}}"""
            
            try:
                response = self.llm.invoke([HumanMessage(content=prompt)])
                expert_results[expert_role] = self._extract_json(response.content)
            except Exception as e:
                logger.error(f"Expert {expert_role} error: {e}")
                expert_results[expert_role] = {"error": str(e)}
        
        state['expert_opinions'] = expert_results
        self._consolidate_expert_findings(state, expert_results, level_name)
        
        state['next_step'] = 'tree_of_thought'
        return state
    
    def tree_of_thought(self, state: AgentState) -> AgentState:
        """Tree of Thought exploration"""
        prompt = f"""Explore alternative interpretations of this rule.

TEXT:
{state['chunk_text'][:2000]}

Current understanding:
- Description: {state['description'][:300]}
- Actions: {len(state['data_actions'])}
- Evidence: {len(state['user_evidence']) + len(state['system_evidence'])}

Generate 3 interpretation paths:

Path 1 - Conservative: Strictest reading
Path 2 - Balanced: Reasonable middle-ground
Path 3 - Expansive: Broadest reasonable interpretation

Return JSON:
{{
    "paths": [
        {{
            "name": "conservative",
            "interpretation": "Complete explanation",
            "implications": ["implication 1", "implication 2"],
            "required_actions": ["action 1", "action 2"],
            "confidence": "high" or "medium" or "low"
        }}
    ],
    "recommended_path": "conservative" or "balanced" or "expansive",
    "reasoning": "Complete explanation"
}}"""
        
        try:
            response = self.llm.invoke([HumanMessage(content=prompt)])
            result = self._extract_json(response.content)
            state['thought_tree'] = result
            
            state['chain_of_thought'].append(
                f"Explored {len(result.get('paths', []))} interpretation paths. "
                f"Recommended: {result.get('recommended_path', 'balanced')}"
            )
        except Exception as e:
            logger.error(f"Tree of thought error: {e}")
            state['thought_tree'] = {"error": str(e)}
        
        # FIXED: Correct next step name
        state['next_step'] = 'knowledge_graph'
        return state
    
    def knowledge_graph_integration(self, state: AgentState) -> AgentState:
        """Integrate into FalkorDB knowledge graph - FIXED"""
        chunk_id = state['chunk_id']
        level = state['level']
        
        req_id = f"req_{state['rule_name']}_{level}_{chunk_id}".replace(" ", "_").replace("/", "_")
        
        # Add requirement node
        self.kg.add_requirement(
            req_id,
            state['description'],
            level,
            state['classification'],
            [c['text'] for c in state['citations'][:5]]
        )
        
        # Add action nodes
        for i, action in enumerate(state['data_actions']):
            action_id = f"{req_id}_action_{i}"
            self.kg.add_action(
                action_id,
                action.get('type', 'data_usage'),
                action.get('description', ''),
                action.get('actor', 'unknown'),
                req_id,
                [c.get('text', '') for c in action.get('citations', [])]
            )
        
        # Add user evidence nodes
        for i, evidence in enumerate(state['user_evidence']):
            evidence_id = f"{req_id}_evidence_user_{i}"
            self.kg.add_evidence(
                evidence_id,
                'user_requirement',
                evidence.get('description', ''),
                'user',
                req_id,
                [c.get('text', '') for c in evidence.get('citations', [])]
            )
        
        # Add system evidence nodes
        for i, evidence in enumerate(state['system_evidence']):
            evidence_id = f"{req_id}_evidence_system_{i}"
            self.kg.add_evidence(
                evidence_id,
                'system_requirement',
                evidence.get('description', ''),
                'system',
                req_id,
                [c.get('text', '') for c in evidence.get('citations', [])]
            )
        
        # Add constraint nodes
        for i, constraint in enumerate(state['constraints']):
            constraint_id = f"{req_id}_constraint_{i}"
            self.kg.add_constraint(
                constraint_id,
                constraint.get('type', 'general'),
                constraint.get('description', ''),
                constraint.get('operator', 'eq'),
                constraint.get('right_operand', ''),
                req_id
            )
        
        # Get statistics
        stats = self.kg.get_statistics()
        state['kg_nodes'] = [{"type": k, "count": v} for k, v in stats.items()]
        state['chain_of_thought'].append(f"Graph integration: {stats}")
        
        state['next_step'] = 'validate'
        return state
    
    def validate_and_refine(self, state: AgentState) -> AgentState:
        """Validation and refinement"""
        issues = []
        
        if len(state['description']) < 100:
            issues.append("Description too short")
        
        if len(state['citations']) == 0:
            issues.append("No citations")
        
        if len(state['data_actions']) == 0:
            issues.append("No data actions")
        
        if len(state['user_evidence']) == 0 and len(state['system_evidence']) == 0:
            issues.append("No evidence")
        
        if not state.get('classification'):
            issues.append("No classification")
        
        if issues and state['iteration'] < state['max_iterations']:
            level_names = {1: "Primary Legislation", 2: "Regulatory Guidance", 3: "Enterprise Policy"}
            level_name = level_names.get(state['level'], "Document")
            
            prompt = f"""Refine this analysis to address: {', '.join(issues)}

Current state:
- Description: {state['description'][:400]}
- Citations: {len(state['citations'])}
- Actions: {len(state['data_actions'])}

Original text (from {level_name}):
{state['chunk_text'][:2000]}

Extract what was missed. Include source references for all citations (Level {state['level']} - {level_name}). Return JSON."""
            
            try:
                response = self.llm.invoke([HumanMessage(content=prompt)])
                refinements = self._extract_json(response.content)
                
                if refinements.get('description'):
                    state['description'] += " " + refinements['description']
                
                for cite in refinements.get('citations', []):
                    if cite.get('text'):
                        if 'source_reference' not in cite:
                            cite['source_reference'] = f"Level {state['level']} - {level_name}"
                        state['citations'].append(cite)
                
                for action in refinements.get('data_actions', []):
                    state['data_actions'].append(action)
                
                for evidence in refinements.get('user_evidence', []):
                    state['user_evidence'].append(evidence)
                
                for evidence in refinements.get('system_evidence', []):
                    state['system_evidence'].append(evidence)
                
                if refinements.get('classification') and not state.get('classification'):
                    state['classification'] = refinements['classification']
                
                state['iteration'] += 1
                state['next_step'] = 'validate'
            except Exception as e:
                logger.error(f"Refinement error: {e}")
                state['next_step'] = 'end'
        else:
            state['next_step'] = 'end'
        
        return state
    
    def _extract_json(self, text: str) -> Dict[str, Any]:
        """Extract JSON from response"""
        try:
            return json.loads(text)
        except:
            pass
        
        match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except:
                pass
        
        pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
        matches = re.findall(pattern, text, re.DOTALL)
        for match in sorted(matches, key=len, reverse=True):
            try:
                parsed = json.loads(match)
                if isinstance(parsed, dict) and len(parsed) > 2:
                    return parsed
            except:
                continue
        
        return {}
    
    def _consolidate_expert_findings(self, state: AgentState, expert_results: Dict[str, Any], level_name: str):
        """Consolidate expert findings"""
        for expert_role, results in expert_results.items():
            if 'error' in results:
                continue
            
            for action in results.get('data_actions', []):
                if action.get('description'):
                    # Ensure source reference
                    for cite in action.get('citations', []):
                        if 'source_reference' not in cite:
                            cite['source_reference'] = f"Level {state['level']} - {level_name}"
                    state['data_actions'].append(action)
            
            for req in results.get('requirements', []):
                if req.get('description'):
                    # Ensure source reference
                    for cite in req.get('citations', []):
                        if 'source_reference' not in cite:
                            cite['source_reference'] = f"Level {state['level']} - {level_name}"
                    
                    perspective = req.get('perspective', 'user')
                    if perspective == 'user':
                        state['user_evidence'].append(req)
                    else:
                        state['system_evidence'].append(req)
            
            for constraint in results.get('constraints', []):
                if constraint.get('description'):
                    # Ensure source reference
                    for cite in constraint.get('citations', []):
                        if 'source_reference' not in cite:
                            cite['source_reference'] = f"Level {state['level']} - {level_name}"
                    state['constraints'].append(constraint)


# ============================================================================
# ENHANCED ANALYZER (FIXED WORKFLOW)
# ============================================================================

class EnhancedLegalDocumentAnalyzer:
    """Enhanced analyzer with graph database - FIXED"""
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        
        if not self.config.API_KEY:
            raise ValueError("OPENAI_API_KEY required")
        
        # Initialize LLM
        self.llm = ChatOpenAI(
            model=self.config.CHAT_MODEL,
            openai_api_key=self.config.API_KEY,
            openai_api_base=self.config.BASE_URL
        )
        
        self.chunker = DocumentChunker(
            chunk_size=getattr(self.config, 'CHUNK_SIZE', 4000),
            chunk_overlap=getattr(self.config, 'OVERLAP_SIZE', 300),
            respect_boundaries=True
        )
        
        # Initialize embedding service
        self.embedding_service = EmbeddingService(
            api_key=self.config.API_KEY,
            model=self.config.EMBEDDING_MODEL
        )
        
        # Initialize FalkorDB
        self.kg = FalkorDBKnowledgeGraph(
            host=getattr(self.config, 'FALKORDB_HOST', 'localhost'),
            port=getattr(self.config, 'FALKORDB_PORT', 6379),
            embedding_service=self.embedding_service
        )
        
        self.agent = LegalAnalysisAgent(self.llm, self.kg)
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """Build LangGraph workflow - FIXED ROUTING"""
        workflow = StateGraph(AgentState)
        
        workflow.add_node("chain_of_thought", self.agent.chain_of_thought_reasoning)
        workflow.add_node("mixture_of_experts", self.agent.mixture_of_experts)
        workflow.add_node("tree_of_thought", self.agent.tree_of_thought)
        workflow.add_node("knowledge_graph", self.agent.knowledge_graph_integration)
        workflow.add_node("validate", self.agent.validate_and_refine)
        
        workflow.set_entry_point("chain_of_thought")
        
        # FIXED: Proper edge mappings
        workflow.add_conditional_edges(
            "chain_of_thought",
            lambda state: state['next_step'],
            {
                "mixture_of_experts": "mixture_of_experts",
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "mixture_of_experts",
            lambda state: state['next_step'],
            {
                "tree_of_thought": "tree_of_thought",
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "tree_of_thought",
            lambda state: state['next_step'],
            {
                "knowledge_graph": "knowledge_graph",  # FIXED: was "knowledge_graph_integration"
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "knowledge_graph",
            lambda state: state['next_step'],
            {
                "validate": "validate",
                "end": END
            }
        )
        
        workflow.add_conditional_edges(
            "validate",
            lambda state: state['next_step'],
            {
                "validate": "validate",
                "end": END
            }
        )
        
        return workflow.compile()
    
    def analyze_chunk(self, chunk: Dict[str, Any], rule_name: str,
                     jurisdiction: str, level: int,
                     enterprise_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Analyze chunk with LangGraph"""
        
        initial_state = AgentState(
            messages=[],
            chunk_text=chunk['text'],
            chunk_id=chunk['chunk_id'],
            level=level,
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            enterprise_context=enterprise_context,
            description="",
            citations=[],
            data_actions=[],
            user_evidence=[],
            system_evidence=[],
            constraints=[],
            enterprise_policies=[],
            classification="",
            classification_reasoning="",
            chain_of_thought=[],
            expert_opinions={},
            thought_tree={},
            kg_nodes=[],
            kg_edges=[],
            next_step="chain_of_thought",
            iteration=0,
            max_iterations=2
        )
        
        try:
            final_state = self.workflow.invoke(initial_state)
            
            return {
                "description": final_state['description'].strip(),
                "citations": final_state['citations'],
                "data_actions": final_state['data_actions'],
                "user_evidence": final_state['user_evidence'],
                "system_evidence": final_state['system_evidence'],
                "constraints": final_state['constraints'],
                "enterprise_policies": final_state['enterprise_policies'],
                "classification": final_state['classification'] or "condition",
                "classification_reasoning": final_state['classification_reasoning'],
                "metadata": {
                    "chunk_id": chunk['chunk_id'],
                    "level": level,
                    "kg_integration": {
                        "nodes": final_state['kg_nodes']
                    }
                }
            }
        except Exception as e:
            logger.error(f"Workflow error: {e}")
            import traceback
            traceback.print_exc()
            return self._empty_analysis(chunk['chunk_id'], level)
    
    def analyze_document(self, rule_name: str, jurisdiction: str,
                        document_text: str, level: int,
                        enterprise_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Analyze document"""
        print(f"\n{'='*60}")
        print(f"Level {level}: {rule_name}")
        print(f"Document: {len(document_text)} characters")
        print(f"{'='*60}")
        
        chunks = self.chunker.chunk_document(
            text=document_text,
            metadata={"rule_name": rule_name, "jurisdiction": jurisdiction, "level": level}
        )
        
        print(f"Created {len(chunks)} chunks")
        
        chunk_analyses = []
        for i, chunk in enumerate(chunks):
            print(f"\nChunk {i+1}/{len(chunks)}...")
            
            analysis = self.analyze_chunk(
                chunk, rule_name, jurisdiction, level, enterprise_context
            )
            
            if analysis:
                chunk_analyses.append(analysis)
                print(f"  ✓ Description: {len(analysis['description'])} chars")
                print(f"  ✓ Citations: {len(analysis['citations'])}")
                print(f"  ✓ Actions: {len(analysis['data_actions'])}")
        
        print(f"\nMerging {len(chunk_analyses)} analyses...")
        final = self._merge_analyses(chunk_analyses, rule_name, jurisdiction, level)
        
        return final
    
    def _merge_analyses(self, analyses: List[Dict[str, Any]], rule_name: str,
                       jurisdiction: str, level: int) -> Dict[str, Any]:
        """Merge analyses"""
        if not analyses:
            return self._empty_analysis(0, level)
        
        descriptions = [a['description'] for a in analyses if a['description']]
        combined_desc = " ".join(descriptions).strip()
        if combined_desc and not combined_desc.endswith('.'):
            combined_desc += '.'
        
        all_citations = []
        seen_cites = set()
        for analysis in analyses:
            for cite in analysis.get('citations', []):
                cite_key = cite.get('text', '')[:50]
                if cite_key and cite_key not in seen_cites:
                    all_citations.append(cite)
                    seen_cites.add(cite_key)
        
        all_actions = []
        seen_actions = set()
        for analysis in analyses:
            for action in analysis.get('data_actions', []):
                action_key = (action.get('type', ''), action.get('description', '')[:50])
                if action_key[1] and action_key not in seen_actions:
                    all_actions.append(action)
                    seen_actions.add(action_key)
        
        all_user_evidence = []
        seen_user = set()
        for analysis in analyses:
            for evidence in analysis.get('user_evidence', []):
                evidence_key = evidence.get('description', '')[:50]
                if evidence_key and evidence_key not in seen_user:
                    all_user_evidence.append(evidence)
                    seen_user.add(evidence_key)
        
        all_system_evidence = []
        seen_system = set()
        for analysis in analyses:
            for evidence in analysis.get('system_evidence', []):
                evidence_key = evidence.get('description', '')[:50]
                if evidence_key and evidence_key not in seen_system:
                    all_system_evidence.append(evidence)
                    seen_system.add(evidence_key)
        
        all_constraints = []
        seen_constraints = set()
        for analysis in analyses:
            for constraint in analysis.get('constraints', []):
                constraint_key = (constraint.get('type', ''), constraint.get('description', '')[:50])
                if constraint_key[1] and constraint_key not in seen_constraints:
                    all_constraints.append(constraint)
                    seen_constraints.add(constraint_key)
        
        classifications = [a.get('classification', '') for a in analyses if a.get('classification')]
        final_classification = "condition"
        if "restriction" in classifications:
            final_classification = "restriction"
        elif classifications:
            final_classification = classifications[0]
        
        reasonings = [a.get('classification_reasoning', '') for a in analyses if a.get('classification_reasoning')]
        combined_reasoning = " ".join(reasonings)
        
        return {
            "description": combined_desc,
            "citations": all_citations,
            "data_actions": all_actions,
            "user_evidence": all_user_evidence,
            "system_evidence": all_system_evidence,
            "constraints": all_constraints,
            "enterprise_policies": [],
            "classification": final_classification,
            "classification_reasoning": combined_reasoning,
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level,
                "chunks_processed": len(analyses),
                "total_citations": len(all_citations),
                "total_actions": len(all_actions),
                "total_user_evidence": len(all_user_evidence),
                "total_system_evidence": len(all_system_evidence),
                "total_constraints": len(all_constraints),
                "kg_stats": self.kg.get_statistics()
            }
        }
    
    def _empty_analysis(self, chunk_id: int, level: int) -> Dict[str, Any]:
        """Empty analysis"""
        return {
            "description": "",
            "citations": [],
            "data_actions": [],
            "user_evidence": [],
            "system_evidence": [],
            "constraints": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": "",
            "metadata": {"chunk_id": chunk_id, "level": level}
        }
    
    def analyze_multi_level(self, rule_name: str, jurisdiction: str,
                           level_1_text: str, level_2_text: str, level_3_text: str,
                           enterprise_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Multi-level analysis"""
        print(f"\n{'#'*60}")
        print(f"# MULTI-LEVEL: {rule_name}")
        print(f"{'#'*60}")
        
        print(f"\n>>> LEVEL 1: PRIMARY LEGISLATION ({len(level_1_text)} chars)")
        level_1 = self.analyze_document(rule_name, jurisdiction, level_1_text, 1, enterprise_context)
        
        print(f"\n>>> LEVEL 2: REGULATORY GUIDANCE ({len(level_2_text)} chars)")
        level_2 = self.analyze_document(rule_name, jurisdiction, level_2_text, 2, enterprise_context)
        
        print(f"\n>>> LEVEL 3: ENTERPRISE POLICY ({len(level_3_text)} chars)")
        level_3 = self.analyze_document(rule_name, jurisdiction, level_3_text, 3, enterprise_context)
        
        combined = {
            "description": " ".join([
                level_1['description'],
                level_2['description'],
                level_3['description']
            ]).strip(),
            "citations": level_1['citations'] + level_2['citations'] + level_3['citations'],
            "data_actions": level_1['data_actions'] + level_2['data_actions'] + level_3['data_actions'],
            "user_evidence": level_1['user_evidence'] + level_2['user_evidence'] + level_3['user_evidence'],
            "system_evidence": level_1['system_evidence'] + level_2['system_evidence'] + level_3['system_evidence'],
            "constraints": level_1['constraints'] + level_2['constraints'] + level_3['constraints'],
            "enterprise_policies": level_3.get('enterprise_policies', []),
            "classification": level_1['classification'],
            "classification_reasoning": " ".join([
                level_1.get('classification_reasoning', ''),
                level_2.get('classification_reasoning', ''),
                level_3.get('classification_reasoning', '')
            ]).strip(),
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "enterprise_context": enterprise_context,
                "level_1_chunks": level_1['metadata']['chunks_processed'],
                "level_2_chunks": level_2['metadata']['chunks_processed'],
                "level_3_chunks": level_3['metadata']['chunks_processed'],
                "total_citations": len(level_1['citations']) + len(level_2['citations']) + len(level_3['citations']),
                "total_actions": len(level_1['data_actions']) + len(level_2['data_actions']) + len(level_3['data_actions']),
                "kg_stats": self.kg.get_statistics()
            }
        }
        
        print(f"\n{'#'*60}")
        print(f"# COMPLETE")
        print(f"{'#'*60}")
        print(f"  Description: {len(combined['description'])} chars")
        print(f"  Citations: {len(combined['citations'])}")
        print(f"  Actions: {len(combined['data_actions'])}")
        print(f"  User Evidence: {len(combined['user_evidence'])}")
        print(f"  System Evidence: {len(combined['system_evidence'])}")
        
        kg_stats = combined['metadata']['kg_stats']
        if kg_stats:
            print(f"  Graph Database: {kg_stats}")
        
        return combined
