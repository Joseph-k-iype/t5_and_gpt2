"""
Agentic RAG implementation using LangGraph for business term matching.

This package implements an agentic RAG (Retrieval Augmented Generation) system
using LangGraph for improved business term matching capabilities.
"""

from .graph import AgenticRagGraph

__all__ = ["AgenticRagGraph"]




"""
Main LangGraph implementation for the Agentic RAG system.

This module provides the LangGraph implementation of the Agentic RAG system,
which orchestrates the flow between different nodes to provide an intelligent
term matching capability.
"""

import logging
import time
from typing import Dict, Any, List, Tuple, Optional, Union, Literal

# LangGraph imports
from langgraph.graph import StateGraph, END

# Node implementations
from .nodes.query_understanding import query_understanding
from .nodes.vector_retrieval import vector_retrieval
from .nodes.keyword_retrieval import keyword_retrieval
from .nodes.synonym_expansion import synonym_expansion
from .nodes.relevance_evaluation import relevance_evaluation
from .nodes.result_preparation import result_preparation

logger = logging.getLogger(__name__)

class AgenticRagGraph:
    """
    Agentic RAG graph for business term matching using LangGraph.
    
    This class implements a LangGraph workflow for intelligent business term
    matching, combining multiple approaches for improved accuracy.
    """
    
    def __init__(self, business_term_manager):
        """
        Initialize the Agentic RAG graph.
        
        Args:
            business_term_manager: BusinessTermManager instance
        """
        self.bt_manager = business_term_manager
        self.graph = self._build_graph()
    
    def _decide_next_step(self, state: Dict[str, Any]) -> str:
        """
        Decide which node to execute next based on the current state.
        This conditional edge function determines the flow through the graph.
        
        Args:
            state: Current graph state
            
        Returns:
            String name of next node or "end" to terminate graph
        """
        # Check for errors
        if state.get("error"):
            logger.warning(f"Error detected, ending graph: {state['error']}")
            return "end"
        
        # Check if we've just started
        if not state.get("query"):
            logger.info("Starting with query understanding")
            return "query_understanding"
        
        # Check if we've completed query understanding
        if state.get("query") and not state.get("vector_results"):
            logger.info("Query understood, proceeding to vector retrieval")
            return "vector_retrieval"
        
        # Check if we've completed vector retrieval
        if state.get("vector_results") and not state.get("keyword_results"):
            logger.info("Vector retrieval complete, proceeding to keyword retrieval")
            return "keyword_retrieval"
        
        # Check if we've completed keyword retrieval
        if state.get("keyword_results") and not state.get("expanded_results"):
            logger.info("Keyword retrieval complete, proceeding to synonym expansion")
            return "synonym_expansion"
        
        # Check if we've completed synonym expansion
        if state.get("expanded_results") and not state.get("top_candidates"):
            logger.info("Synonym expansion complete, proceeding to relevance evaluation")
            return "relevance_evaluation"
        
        # Check if we've completed relevance evaluation
        if state.get("top_candidates") and not state.get("result"):
            logger.info("Relevance evaluation complete, preparing final results")
            return "result_preparation"
        
        # If we've completed all steps, end the graph
        logger.info("All steps completed, ending graph")
        return "end"
    
    def _build_graph(self) -> StateGraph:
        """
        Build the LangGraph workflow.
        
        Returns:
            Compiled LangGraph StateGraph
        """
        # Create graph
        graph = StateGraph("AgenticRagState")
        
        # Add nodes
        graph.add_node("query_understanding", query_understanding)
        graph.add_node("vector_retrieval", vector_retrieval)
        graph.add_node("keyword_retrieval", keyword_retrieval)
        graph.add_node("synonym_expansion", synonym_expansion)
        graph.add_node("relevance_evaluation", relevance_evaluation)
        graph.add_node("result_preparation", result_preparation)
        
        # Add conditional edges
        graph.add_conditional_edges(
            None,  # This means any node can go to the decided next node
            self._decide_next_step,
            {
                "query_understanding": "query_understanding",
                "vector_retrieval": "vector_retrieval",
                "keyword_retrieval": "keyword_retrieval", 
                "synonym_expansion": "synonym_expansion",
                "relevance_evaluation": "relevance_evaluation",
                "result_preparation": "result_preparation",
                "end": END
            }
        )
        
        # Set entry point
        graph.set_entry_point("query_understanding")
        
        # Compile graph
        return graph.compile()
    
    async def run(self, 
                 element_id: str,
                 element_name: str, 
                 element_description: str, 
                 top_k: int = 3,
                 threshold: float = 0.5,
                 cdm_context: Optional[str] = None,
                 example_context: Optional[str] = None,
                 process_name_context: Optional[str] = None,
                 process_description_context: Optional[str] = None) -> Tuple[List[Dict[str, Any]], List[float], bool, str]:
        """
        Run the agentic RAG graph to find matching terms.
        
        Args:
            element_id: Unique identifier for the element
            element_name: Name of the element to match
            element_description: Description of the element
            top_k: Number of top matches to return
            threshold: Minimum similarity threshold
            cdm_context: Optional CDM context
            example_context: Optional example context
            process_name_context: Optional process name context
            process_description_context: Optional process description context
            
        Returns:
            Tuple containing:
            - List of matching terms
            - List of confidence scores
            - Whether modeling is required
            - Message describing the result
        """
        logger.info(f"Running agentic RAG for element: {element_name}")
        
        # Initialize state
        state: Dict[str, Any] = {
            "element_id": element_id,
            "element_name": element_name,
            "element_description": element_description,
            "cdm_context": cdm_context,
            "example_context": example_context,
            "process_name_context": process_name_context,
            "process_description_context": process_description_context,
            "top_k": top_k,
            "threshold": threshold,
            "_bt_manager": self.bt_manager  # Pass manager for node access
        }
        
        # Run graph
        try:
            start_time = time.time()
            result = await self.graph.ainvoke(state)
            execution_time = time.time() - start_time
            
            logger.info(f"Graph execution completed in {execution_time:.2f}s")
            
            if result.get("error"):
                logger.error(f"Graph execution error: {result['error']}")
                return [], [], True, f"Error: {result['error']}"
            
            # Extract results
            graph_result = result.get("result", {})
            matching_terms = graph_result.get("matching_terms", [])
            confidence_scores = graph_result.get("confidence_scores", [])
            modeling_required = graph_result.get("modeling_required", True)
            message = graph_result.get("message", "")
            
            logger.info(f"Agentic RAG complete for '{element_name}': {len(matching_terms)} matches found")
            return matching_terms, confidence_scores, modeling_required, message
            
        except Exception as e:
            logger.error(f"Error running graph: {e}", exc_info=True)
            return [], [], True, f"Graph execution failed: {str(e)}"














"""
State definitions for the Agentic RAG system using LangGraph.

This module defines the state structures used in the LangGraph implementation
of the Agentic RAG system for business term matching.
"""

from typing import Dict, List, Any, Optional, TypedDict, Union
from pydantic import BaseModel, Field


class RagQuery(BaseModel):
    """Represents a query in the RAG system."""
    original_text: str = Field(..., description="Original query text")
    rephrased_text: Optional[str] = Field(None, description="Rephrased query for better retrieval")
    expanded_terms: List[str] = Field(default_factory=list, description="Expanded terms/synonyms")
    relevant_context: Optional[str] = Field(None, description="Any additional context for the query")


class RagCandidate(BaseModel):
    """Represents a candidate document/term retrieved from the system."""
    id: str = Field(..., description="Unique identifier for the candidate")
    name: str = Field(..., description="Name of the business term")
    description: str = Field(..., description="Description of the business term")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
    vector_score: float = Field(0.0, description="Vector similarity score")
    keyword_score: float = Field(0.0, description="Keyword match score")
    semantic_score: Optional[float] = Field(None, description="Semantic relevance score (LLM-evaluated)")
    final_score: Optional[float] = Field(None, description="Final combined score")
    reasoning: Optional[str] = Field(None, description="Reasoning about relevance")


class AgenticRagState(TypedDict, total=False):
    """State for the Agentic RAG system."""
    # Input parameters
    element_id: str
    element_name: str
    element_description: str
    cdm_context: Optional[str]
    example_context: Optional[str]
    process_name_context: Optional[str]
    process_description_context: Optional[str]
    top_k: int
    threshold: float
    
    # Processing state
    query: Dict[str, Any]  # Will hold RagQuery as dict
    candidates: List[Dict[str, Any]]  # Will hold RagCandidate as dict
    vector_results: List[Dict[str, Any]]
    keyword_results: List[Dict[str, Any]]
    expanded_results: List[Dict[str, Any]]
    top_candidates: List[Dict[str, Any]]
    
    # Result state
    result: Dict[str, Any]
    error: Optional[str]
    
    # System references (not serialized)
    _bt_manager: Any
