"""
Advanced GDPR Q&A Chatbot with Dynamic Multi-Agent ReAct Architecture + LangChain Elasticsearch

This system provides comprehensive, business-friendly answers using completely dynamic
approaches without any hardcoded terms or patterns.

Features:
- Fully dynamic term extraction and concept discovery
- AI-powered query analysis and intent detection
- Adaptive search strategies based on content analysis
- Self-learning document relationship discovery
- Dynamic QA chain selection based on query patterns
- LangChain Elasticsearch integration with hybrid search
- O3-mini reasoning model for intelligent analysis
- Direct OpenAI API integration for embeddings
- Business-friendly response formatting

Requirements:
- OpenAI API access with o3-mini model
- Elasticsearch with pre-indexed GDPR data
- Python 3.9+
- pip install langchain-elasticsearch langchain langchain-openai langchain-core elasticsearch

Environment Variables:
- OPENAI_API_KEY: Your OpenAI API key
- ES_USERNAME: Elasticsearch username
- ES_PASSWORD: Elasticsearch password
- ES_HOST: Elasticsearch host (default: localhost)
- ES_PORT: Elasticsearch port (default: 9200)
"""

import asyncio
import json
import logging
import os
import ssl
import uuid
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, TypedDict, Annotated, Sequence, Tuple, Union
from dataclasses import dataclass
import re
from collections import defaultdict, Counter

import openai
from elasticsearch import Elasticsearch

# LangChain Elasticsearch integration
from langchain_elasticsearch import ElasticsearchStore, ElasticsearchRetriever
from langchain_elasticsearch.vectorstores import DenseVectorStrategy, BaseRetrievalStrategy

# LangChain core
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langchain_core.retrievers import BaseRetriever
from langchain_core.embeddings import Embeddings
from langchain_core.prompts import ChatPromptTemplate

# LangChain OpenAI
from langchain_openai import ChatOpenAI

# LangChain QA chains
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.chains.question_answering import load_qa_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# LangGraph
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import MemorySaver
from langgraph.store.memory import InMemoryStore
from langgraph.prebuilt import ToolNode, create_react_agent

# Pydantic
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration
class Config:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    ES_USERNAME = os.getenv("ES_USERNAME", "elastic")
    ES_PASSWORD = os.getenv("ES_PASSWORD")
    ES_HOST = os.getenv("ES_HOST", "localhost")
    ES_PORT = int(os.getenv("ES_PORT", "9200"))
    ES_CACERT_PATH = os.getenv("ES_CACERT_PATH", "cacert.crt")
    
    # Model configurations
    REASONING_MODEL = "o3-mini-2025-01-31"
    EMBEDDING_MODEL = "text-embedding-3-large"
    EMBEDDING_DIMENSIONS = 3072
    REASONING_EFFORT = "high"
    
    # Search configurations
    MAX_SEARCH_RESULTS = 10
    SIMILARITY_THRESHOLD = 0.6
    MAX_CONTEXT_LENGTH = 8000

# Enhanced Data Models
@dataclass
class SearchResult:
    """Enhanced search result with metadata"""
    content: str
    title: str
    document_type: str
    article_number: Optional[str]
    chapter_number: str
    score: float
    chunk_id: Optional[str] = None
    article_id: Optional[str] = None
    page_number: Optional[int] = None
    key_concepts: List[str] = None
    supporting_references: List[Dict] = None

@dataclass
class ConversationContext:
    """Conversation context and memory"""
    thread_id: str
    query: str
    intent: str
    entities: List[str]
    previous_searches: List[Dict]
    conversation_history: List[BaseMessage]
    current_analysis: Dict[str, Any]

@dataclass
class DynamicConcepts:
    """Dynamically discovered concepts from documents"""
    terms: List[str]
    definitions: Dict[str, str]
    relationships: Dict[str, List[str]]
    importance_scores: Dict[str, float]
    contexts: Dict[str, List[str]]

class ChatbotState(TypedDict):
    """State for the chatbot workflow"""
    messages: Annotated[Sequence[BaseMessage], "The conversation messages"]
    current_query: str
    conversation_context: ConversationContext
    search_results: List[SearchResult]
    analysis_results: Dict[str, Any]
    final_answer: str
    citations: List[Dict]
    processing_stage: str

# Dynamic Concept Discovery Engine
class DynamicConceptEngine:
    """Engine for dynamically discovering concepts, terms, and patterns from documents"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
        self.concept_cache = {}
        self.pattern_cache = {}
        self.relationship_cache = {}
    
    async def extract_key_terms_from_query(self, query: str) -> List[str]:
        """Dynamically extract key terms from a query using AI"""
        system_prompt = """
        Analyze the given query and extract key terms, concepts, and entities that would be important 
        for searching legal/regulatory documents. Focus on:
        1. Technical terms and acronyms
        2. Legal concepts
        3. Regulatory terms
        4. Business processes
        5. Roles and responsibilities
        
        Return only a JSON array of terms:
        ["term1", "term2", "term3"]
        """
        
        try:
            messages = [{"role": "user", "content": f"Extract key terms from: {query}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Parse JSON response
            try:
                terms = json.loads(response)
                return terms if isinstance(terms, list) else []
            except json.JSONDecodeError:
                # Fallback: extract using simple NLP
                return await self._fallback_term_extraction(query)
                
        except Exception as e:
            logger.error(f"Error in dynamic term extraction: {e}")
            return await self._fallback_term_extraction(query)
    
    async def _fallback_term_extraction(self, query: str) -> List[str]:
        """Fallback term extraction using basic NLP"""
        # Remove common words and extract potential terms
        words = re.findall(r'\b[A-Z][A-Za-z]*\b|\b[a-z]{3,}\b', query)
        
        # Filter for meaningful terms
        meaningful_terms = []
        for word in words:
            if (len(word) >= 3 and 
                word.lower() not in ['the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'man', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 'did', 'its', 'let', 'put', 'say', 'she', 'too', 'use']):
                meaningful_terms.append(word.lower())
        
        return list(set(meaningful_terms))
    
    async def discover_document_concepts(self, documents: List[Document]) -> DynamicConcepts:
        """Dynamically discover concepts from a set of documents"""
        if not documents:
            return DynamicConcepts([], {}, {}, {}, {})
        
        # Combine document content for analysis
        combined_content = "\n".join([doc.page_content[:1000] for doc in documents[:5]])
        
        system_prompt = """
        Analyze the provided legal/regulatory document content and extract:
        1. Key terms and concepts (with importance scores 0-1)
        2. Definitions or explanations of terms
        3. Relationships between concepts
        4. Context where terms are used
        
        Return JSON in this format:
        {
            "terms": ["term1", "term2"],
            "definitions": {"term1": "definition", "term2": "definition"},
            "relationships": {"term1": ["related_term1", "related_term2"]},
            "importance_scores": {"term1": 0.9, "term2": 0.7},
            "contexts": {"term1": ["context1", "context2"]}
        }
        """
        
        try:
            messages = [{"role": "user", "content": f"Analyze this content:\n{combined_content}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            try:
                concept_data = json.loads(response)
                return DynamicConcepts(
                    terms=concept_data.get("terms", []),
                    definitions=concept_data.get("definitions", {}),
                    relationships=concept_data.get("relationships", {}),
                    importance_scores=concept_data.get("importance_scores", {}),
                    contexts=concept_data.get("contexts", {})
                )
            except json.JSONDecodeError:
                logger.warning("Failed to parse concept analysis, using fallback")
                return await self._fallback_concept_discovery(documents)
                
        except Exception as e:
            logger.error(f"Error in concept discovery: {e}")
            return await self._fallback_concept_discovery(documents)
    
    async def _fallback_concept_discovery(self, documents: List[Document]) -> DynamicConcepts:
        """Fallback concept discovery using pattern matching"""
        all_text = " ".join([doc.page_content for doc in documents])
        
        # Extract potential terms using patterns
        terms = []
        
        # Pattern 1: Capitalized terms
        capitalized_terms = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', all_text)
        terms.extend([term.lower() for term in capitalized_terms if len(term) > 3])
        
        # Pattern 2: Acronyms
        acronyms = re.findall(r'\b[A-Z]{2,}\b', all_text)
        terms.extend([term.lower() for term in acronyms])
        
        # Pattern 3: Quoted terms
        quoted_terms = re.findall(r'"([^"]*)"', all_text)
        terms.extend([term.lower() for term in quoted_terms if len(term) > 3])
        
        # Count frequency and calculate importance
        term_counts = Counter(terms)
        total_terms = sum(term_counts.values())
        
        unique_terms = list(set(terms))[:20]  # Limit to top 20
        importance_scores = {term: term_counts[term] / total_terms for term in unique_terms}
        
        return DynamicConcepts(
            terms=unique_terms,
            definitions={},
            relationships={},
            importance_scores=importance_scores,
            contexts={}
        )
    
    async def generate_dynamic_search_patterns(self, query: str, discovered_terms: List[str]) -> List[str]:
        """Generate dynamic search patterns based on query and discovered terms"""
        system_prompt = """
        Given a query and discovered terms, generate effective search patterns for finding 
        definitions, explanations, and related content in legal/regulatory documents.
        
        Return JSON array of search patterns:
        ["pattern1", "pattern2", "pattern3"]
        """
        
        try:
            context = f"Query: {query}\nDiscovered terms: {', '.join(discovered_terms)}"
            messages = [{"role": "user", "content": context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            try:
                patterns = json.loads(response)
                return patterns if isinstance(patterns, list) else []
            except json.JSONDecodeError:
                return await self._generate_fallback_patterns(query, discovered_terms)
                
        except Exception as e:
            logger.error(f"Error generating search patterns: {e}")
            return await self._generate_fallback_patterns(query, discovered_terms)
    
    async def _generate_fallback_patterns(self, query: str, discovered_terms: List[str]) -> List[str]:
        """Generate fallback search patterns"""
        patterns = []
        
        for term in discovered_terms[:5]:  # Use top 5 terms
            patterns.extend([
                f'"{term}" means',
                f'definition of {term}',
                f'{term} is defined as',
                f'{term} refers to',
                f'what is {term}',
                f'{term} requirements',
                f'{term} obligations'
            ])
        
        return patterns

# Custom Embeddings Wrapper for Direct OpenAI API
class DirectOpenAIEmbeddings(Embeddings):
    """Custom embeddings class that uses direct OpenAI API calls"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs synchronously"""
        return asyncio.run(self._aembed_documents(texts))
    
    def embed_query(self, text: str) -> List[float]:
        """Embed query text synchronously"""
        return asyncio.run(self.openai_manager.create_embedding(text))
    
    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs asynchronously"""
        return await self._aembed_documents(texts)
    
    async def aembed_query(self, text: str) -> List[float]:
        """Embed query text asynchronously"""
        return await self.openai_manager.create_embedding(text)
    
    async def _aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Internal method to embed multiple documents"""
        embeddings = []
        for text in texts:
            try:
                embedding = await self.openai_manager.create_embedding(text)
                embeddings.append(embedding)
            except Exception as e:
                logger.error(f"Error embedding document: {e}")
                # Return zero vector as fallback
                embeddings.append([0.0] * Config.EMBEDDING_DIMENSIONS)
        return embeddings

# Enhanced OpenAI Manager
class AdvancedOpenAIManager:
    """Advanced OpenAI manager with direct API integration"""
    
    def __init__(self):
        self.client = openai.OpenAI(
            api_key=Config.OPENAI_API_KEY,
            base_url=Config.OPENAI_BASE_URL
        )
    
    async def create_embedding(self, text: str) -> List[float]:
        """Create embedding using direct OpenAI API"""
        try:
            # Clean and truncate text for embedding
            clean_text = text.strip()[:8000]  # Limit text length
            
            response = self.client.embeddings.create(
                model=Config.EMBEDDING_MODEL,
                input=clean_text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Error creating embedding: {e}")
            raise
    
    async def reasoning_completion(self, messages: List[Dict], system_prompt: str = None) -> str:
        """Create completion using o3-mini with high reasoning effort"""
        try:
            formatted_messages = []
            
            if system_prompt:
                formatted_messages.append({"role": "developer", "content": system_prompt})
            
            formatted_messages.extend(messages)
            
            response = self.client.chat.completions.create(
                model=Config.REASONING_MODEL,
                messages=formatted_messages,
                reasoning_effort=Config.REASONING_EFFORT
            )
            
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error in reasoning completion: {e}")
            raise

# Dynamic Elasticsearch Manager
class DynamicElasticsearchManager:
    """Dynamic Elasticsearch manager that adapts to content and queries"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.concept_engine = DynamicConceptEngine(openai_manager)
        self.client = self._create_client()
        self.embeddings = DirectOpenAIEmbeddings(openai_manager)
        
        # Initialize LangChain Elasticsearch stores
        self._setup_langchain_stores()
    
    def _create_client(self) -> Elasticsearch:
        """Create Elasticsearch client with SSL configuration"""
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        if os.path.exists(Config.ES_CACERT_PATH):
            ssl_context.load_verify_locations(Config.ES_CACERT_PATH)
        
        return Elasticsearch(
            [{"host": Config.ES_HOST, "port": Config.ES_PORT, "scheme": "https"}],
            basic_auth=(Config.ES_USERNAME, Config.ES_PASSWORD),
            ssl_context=ssl_context,
            verify_certs=True,
            request_timeout=30,
            max_retries=3,
            retry_on_timeout=True
        )
    
    def _setup_langchain_stores(self):
        """Setup LangChain Elasticsearch stores for different indexes"""
        try:
            # Articles store with hybrid search capability
            self.articles_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="gdpr_articles",
                embedding=self.embeddings,
                vector_query_field="full_article_embedding",
                query_field="full_content",
                strategy=DenseVectorStrategy(
                    hybrid=True,  # Enable hybrid search (vector + text)
                    rrf=True      # Use Reciprocal Rank Fusion
                ),
                distance_strategy="COSINE"
            )
            
            # Chunks store with hybrid search capability
            self.chunks_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="gdpr_chunks",
                embedding=self.embeddings,
                vector_query_field="chunk_embedding",
                query_field="content",
                strategy=DenseVectorStrategy(
                    hybrid=True,  # Enable hybrid search (vector + text)
                    rrf=True      # Use Reciprocal Rank Fusion
                ),
                distance_strategy="COSINE"
            )
            
            # Create retrievers
            self.articles_retriever = self.articles_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            )
            
            self.chunks_retriever = self.chunks_store.as_retriever(
                search_type="similarity", 
                search_kwargs={"k": 10}
            )
            
            logger.info("Dynamic LangChain Elasticsearch stores initialized successfully")
            
        except Exception as e:
            logger.error(f"Error setting up LangChain stores: {e}")
            raise
    
    async def dynamic_search_articles(self, query: str, k: int = 5) -> List[Document]:
        """Dynamic search that adapts based on query analysis"""
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            return self.articles_store.similarity_search(query=enhanced_query, k=k)
        except Exception as e:
            logger.error(f"Error in dynamic article search: {e}")
            return []
    
    async def dynamic_search_chunks(self, query: str, k: int = 10) -> List[Document]:
        """Dynamic chunk search with adaptive strategies"""
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            return self.chunks_store.similarity_search(query=enhanced_query, k=k)
        except Exception as e:
            logger.error(f"Error in dynamic chunk search: {e}")
            return []
    
    async def find_definitions_dynamically(self, query: str) -> List[Document]:
        """Dynamically find definitions using AI-generated search patterns"""
        try:
            # Extract terms that might need definition
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Generate dynamic search patterns for definitions
            search_patterns = await self.concept_engine.generate_dynamic_search_patterns(query, key_terms)
            
            all_results = []
            for pattern in search_patterns[:5]:  # Use top 5 patterns
                try:
                    results = self.chunks_store.similarity_search(query=pattern, k=2)
                    all_results.extend(results)
                except Exception as e:
                    logger.warning(f"Error with search pattern '{pattern}': {e}")
                    continue
            
            # Remove duplicates based on content
            seen_content = set()
            unique_results = []
            for doc in all_results:
                content_hash = hash(doc.page_content[:200])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_results.append(doc)
            
            return unique_results[:8]  # Return top 8 unique results
            
        except Exception as e:
            logger.error(f"Error finding definitions dynamically: {e}")
            return []
    
    async def discover_cross_references_dynamically(self, query: str) -> List[Document]:
        """Dynamically discover cross-references using content analysis"""
        try:
            # First, get initial relevant documents
            initial_docs = await self.dynamic_search_chunks(query, k=5)
            
            if not initial_docs:
                return []
            
            # Discover concepts from initial documents
            concepts = await self.concept_engine.discover_document_concepts(initial_docs)
            
            # Use discovered concepts to find related content
            related_docs = []
            for term in concepts.terms[:5]:  # Use top 5 discovered terms
                try:
                    # Search for documents containing the discovered term
                    term_docs = self.chunks_store.similarity_search(query=term, k=3)
                    related_docs.extend(term_docs)
                except Exception as e:
                    logger.warning(f"Error searching for term '{term}': {e}")
                    continue
            
            # Remove duplicates and original documents
            initial_content_hashes = {hash(doc.page_content[:200]) for doc in initial_docs}
            
            unique_related = []
            seen_content = set()
            for doc in related_docs:
                content_hash = hash(doc.page_content[:200])
                if (content_hash not in seen_content and 
                    content_hash not in initial_content_hashes):
                    seen_content.add(content_hash)
                    unique_related.append(doc)
            
            return unique_related[:8]  # Return top 8 cross-references
            
        except Exception as e:
            logger.error(f"Error discovering cross-references dynamically: {e}")
            return []
    
    async def _enhance_query_with_terms(self, original_query: str, key_terms: List[str]) -> str:
        """Enhance query with dynamically discovered terms"""
        if not key_terms:
            return original_query
        
        # Use AI to intelligently combine query with terms
        system_prompt = """
        Enhance the original query by incorporating the key terms in a natural way 
        that would improve search results in legal/regulatory documents.
        
        Return only the enhanced query string.
        """
        
        try:
            context = f"Original query: {original_query}\nKey terms: {', '.join(key_terms[:5])}"
            messages = [{"role": "user", "content": context}]
            enhanced_query = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Clean the response
            enhanced_query = enhanced_query.strip().strip('"\'')
            
            return enhanced_query if enhanced_query else original_query
            
        except Exception as e:
            logger.error(f"Error enhancing query: {e}")
            # Fallback: simple concatenation
            return f"{original_query} {' '.join(key_terms[:3])}"

# Dynamic Retriever for QA Chains
class DynamicElasticsearchRetriever(BaseRetriever):
    """Dynamic retriever that adapts its search strategy based on query analysis"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        super().__init__()
        self.es_manager = es_manager
    
    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:
        """Synchronous wrapper for async search"""
        return asyncio.run(self._aget_relevant_documents(query))
    
    async def _aget_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:
        """Get relevant documents using dynamic search strategies"""
        try:
            # Dynamic multi-strategy search
            article_docs = await self.es_manager.dynamic_search_articles(query, k=3)
            chunk_docs = await self.es_manager.dynamic_search_chunks(query, k=5)
            
            # Dynamic definition finding
            definition_docs = await self.es_manager.find_definitions_dynamically(query)
            
            # Dynamic cross-reference discovery
            cross_ref_docs = await self.es_manager.discover_cross_references_dynamically(query)
            
            # Combine all results
            all_docs = article_docs + chunk_docs + definition_docs + cross_ref_docs
            
            # Remove duplicates and limit results
            seen_content = set()
            unique_docs = []
            for doc in all_docs:
                content_hash = hash(doc.page_content[:200])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_docs.append(doc)
                
                if len(unique_docs) >= Config.MAX_SEARCH_RESULTS:
                    break
            
            return unique_docs
            
        except Exception as e:
            logger.error(f"Error in dynamic retriever: {e}")
            return []

# Dynamic QA Chain Manager
class DynamicQAChainManager:
    """Dynamic QA Chain Manager that adapts chain selection based on query analysis"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        self.es_manager = es_manager
        self.retriever = DynamicElasticsearchRetriever(es_manager)
        
        # Create LLM without temperature/token limits
        self.llm = ChatOpenAI(
            model=Config.REASONING_MODEL,
            api_key=Config.OPENAI_API_KEY,
            base_url=Config.OPENAI_BASE_URL
        )
        
        self._setup_dynamic_chains()
    
    def _setup_dynamic_chains(self):
        """Setup QA chains with dynamic prompts"""
        
        # 1. Basic RetrievalQA Chain
        self.retrieval_qa = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            return_source_documents=True
        )
        
        # 2. Conversational Retrieval Chain
        self.conversational_qa = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.retriever,
            return_source_documents=True
        )
        
        # 3. Dynamic Business Chain
        self.business_chain = create_stuff_documents_chain(
            self.llm,
            self._create_dynamic_business_prompt()
        )
        self.business_retrieval_chain = create_retrieval_chain(self.retriever, self.business_chain)
        
        # 4. Dynamic Definition Chain
        self.definition_chain = create_stuff_documents_chain(
            self.llm,
            self._create_dynamic_definition_prompt()
        )
        self.definition_retrieval_chain = create_retrieval_chain(self.retriever, self.definition_chain)
        
        # 5. Dynamic Compliance Chain
        self.compliance_chain = create_stuff_documents_chain(
            self.llm,
            self._create_dynamic_compliance_prompt()
        )
        self.compliance_retrieval_chain = create_retrieval_chain(self.retriever, self.compliance_chain)
    
    def _create_dynamic_business_prompt(self) -> ChatPromptTemplate:
        """Create dynamic business-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are a business consultant specializing in regulatory compliance. 
            Analyze the provided context to answer questions in a business-friendly way.
            
            Adapt your response structure based on the query type:
            - For complex queries: Use structured sections with clear headings
            - For simple queries: Provide direct, concise answers
            - For technical queries: Include practical implementation guidance
            - For strategic queries: Focus on business implications and decisions
            
            Always cite specific sources and focus on actionable insights."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    def _create_dynamic_definition_prompt(self) -> ChatPromptTemplate:
        """Create dynamic definition-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are an expert in regulatory terminology and definitions.
            Analyze the context to provide comprehensive explanations that are:
            
            1. Precise and legally accurate
            2. Contextually relevant to the specific query
            3. Supplemented with practical examples when helpful
            4. Connected to related concepts when relevant
            5. Tailored to the user's apparent knowledge level
            
            Adapt your explanation depth based on the complexity of the term being defined."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    def _create_dynamic_compliance_prompt(self) -> ChatPromptTemplate:
        """Create dynamic compliance-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are a compliance specialist with deep regulatory expertise.
            Analyze the context to provide compliance guidance that includes:
            
            1. Specific requirements and obligations
            2. Responsible parties and their roles
            3. Implementation timelines and deadlines
            4. Risk assessment and mitigation strategies
            5. Monitoring and reporting requirements
            
            Tailor your guidance to the specific context and scale of the inquiry."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    async def choose_optimal_chain_dynamically(self, query: str, context: ConversationContext) -> str:
        """Dynamically choose the best QA chain based on AI analysis"""
        system_prompt = """
        Analyze the query and context to determine the optimal response approach.
        Consider:
        1. Query intent and complexity
        2. Required expertise level
        3. Expected response format
        4. User context and background
        
        Return one of: "definition", "compliance", "business", "conversational", "retrieval"
        """
        
        try:
            analysis_context = f"Query: {query}\nContext: {context.current_analysis}"
            messages = [{"role": "user", "content": analysis_context}]
            response = await self.es_manager.openai_manager.reasoning_completion(messages, system_prompt)
            
            chain_type = response.strip().lower()
            if chain_type in ["definition", "compliance", "business", "conversational", "retrieval"]:
                return chain_type
            else:
                return "business"  # Default fallback
                
        except Exception as e:
            logger.error(f"Error in dynamic chain selection: {e}")
            return "business"  # Default fallback
    
    async def answer_with_dynamic_chain(self, query: str, context: ConversationContext, 
                                      chain_type: str = None) -> Dict[str, Any]:
        """Answer using dynamically selected QA chain"""
        try:
            if not chain_type:
                chain_type = await self.choose_optimal_chain_dynamically(query, context)
            
            logger.info(f"Using dynamic QA chain: {chain_type}")
            
            if chain_type == "definition":
                result = await self.definition_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "definition"
                }
            
            elif chain_type == "compliance":
                result = await self.compliance_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "compliance"
                }
            
            elif chain_type == "conversational":
                # Format chat history dynamically
                chat_history = []
                messages = context.conversation_history
                for i in range(0, len(messages)-1, 2):
                    if i+1 < len(messages):
                        human_msg = messages[i]
                        ai_msg = messages[i+1]
                        if hasattr(human_msg, 'content') and hasattr(ai_msg, 'content'):
                            chat_history.append((human_msg.content, ai_msg.content))
                
                result = await self.conversational_qa.ainvoke({
                    "question": query,
                    "chat_history": chat_history
                })
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "conversational"
                }
            
            elif chain_type == "retrieval":
                result = self.retrieval_qa.invoke({"query": query})
                return {
                    "answer": result["result"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "retrieval"
                }
            
            else:  # business or default
                result = await self.business_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "business"
                }
                
        except Exception as e:
            logger.error(f"Error in dynamic QA chain {chain_type}: {e}")
            # Fallback to basic retrieval
            try:
                result = self.retrieval_qa.invoke({"query": query})
                return {
                    "answer": result["result"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "fallback"
                }
            except Exception as e2:
                logger.error(f"Fallback chain also failed: {e2}")
                return {
                    "answer": f"I apologize, but I encountered an error processing your question: {str(e)}",
                    "source_documents": [],
                    "chain_type": "error"
                }

# Dynamic Search Agent
class DynamicSearchAgent:
    """Agent that performs intelligent, adaptive search operations"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        self.es_manager = es_manager
        self.name = "DynamicSearchAgent"
    
    async def comprehensive_dynamic_search(self, query: str, context: ConversationContext) -> List[SearchResult]:
        """Perform comprehensive search with dynamic adaptation"""
        try:
            # Use dynamic search methods
            article_docs = await self.es_manager.dynamic_search_articles(query, k=3)
            chunk_docs = await self.es_manager.dynamic_search_chunks(query, k=5)
            
            # Dynamic definition finding
            definition_docs = await self.es_manager.find_definitions_dynamically(query)
            
            # Dynamic cross-reference discovery
            cross_ref_docs = await self.es_manager.discover_cross_references_dynamically(query)
            
            # Convert Documents to SearchResults
            all_results = []
            
            for doc_list, doc_type in [
                (article_docs, "article"),
                (chunk_docs, "chunk"), 
                (definition_docs, "definition"),
                (cross_ref_docs, "cross_reference")
            ]:
                for doc in doc_list:
                    result = self._document_to_search_result(doc, doc_type)
                    if result:
                        all_results.append(result)
            
            # Remove duplicates and rank by relevance
            seen_content = set()
            unique_results = []
            for result in all_results:
                content_hash = hash(result.content[:200])
                if content_hash not in seen_content and result.score > Config.SIMILARITY_THRESHOLD:
                    seen_content.add(content_hash)
                    unique_results.append(result)
            
            # Sort by score and limit results
            unique_results.sort(key=lambda x: x.score, reverse=True)
            return unique_results[:Config.MAX_SEARCH_RESULTS]
            
        except Exception as e:
            logger.error(f"Error in comprehensive dynamic search: {e}")
            return []
    
    def _document_to_search_result(self, doc: Document, doc_type: str) -> Optional[SearchResult]:
        """Convert LangChain Document to SearchResult"""
        try:
            metadata = doc.metadata
            
            # Extract score from metadata or use default
            score = float(metadata.get('_score', 0.8))
            
            result = SearchResult(
                content=doc.page_content,
                title=metadata.get('title', f'{doc_type.title()} Document'),
                document_type=metadata.get('document_type', 'Unknown'),
                article_number=metadata.get('article_number'),
                chapter_number=metadata.get('chapter_number', 'Unknown'),
                score=score,
                chunk_id=metadata.get('chunk_id'),
                article_id=metadata.get('article_id'),
                page_number=metadata.get('page_number'),
                key_concepts=metadata.get('key_concepts', []),
                supporting_references=metadata.get('supporting_references', [])
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error converting document to search result: {e}")
            return None

# Dynamic Analysis Agent
class DynamicAnalysisAgent:
    """Agent that performs adaptive query and content analysis"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.name = "DynamicAnalysisAgent"
    
    async def analyze_query_dynamically(self, query: str, context: ConversationContext) -> Dict[str, Any]:
        """Perform dynamic, adaptive query analysis"""
        system_prompt = """
        Perform a comprehensive analysis of the user's query. Consider:
        
        1. Primary intent and secondary objectives
        2. Complexity level and required expertise
        3. Key entities, concepts, and relationships
        4. Context clues and domain indicators
        5. Optimal response format and approach
        6. Cross-document analysis requirements
        7. Business vs technical vs legal focus
        
        Adapt your analysis to the specific query characteristics.
        
        Return JSON:
        {
            "intent": "primary intent",
            "complexity": "simple|moderate|complex",
            "entities": ["entity1", "entity2"],
            "domain_focus": "business|technical|legal|mixed",
            "requires_cross_analysis": boolean,
            "optimal_approach": "approach_type",
            "response_format": "format_type",
            "reasoning": "analysis reasoning"
        }
        """
        
        try:
            analysis_context = f"Query: {query}\nPrevious context: {context.current_analysis}"
            messages = [{"role": "user", "content": analysis_context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            try:
                analysis = json.loads(response)
                return analysis
            except json.JSONDecodeError:
                logger.warning("Failed to parse dynamic query analysis, using adaptive defaults")
                return await self._adaptive_fallback_analysis(query, context)
                
        except Exception as e:
            logger.error(f"Error in dynamic query analysis: {e}")
            return await self._adaptive_fallback_analysis(query, context)
    
    async def _adaptive_fallback_analysis(self, query: str, context: ConversationContext) -> Dict[str, Any]:
        """Adaptive fallback analysis based on query patterns"""
        query_lower = query.lower()
        
        # Dynamic intent detection
        intent = "explanation"  # default
        if any(word in query_lower for word in ['what is', 'define', 'definition', 'meaning']):
            intent = "definition"
        elif any(word in query_lower for word in ['how to', 'implement', 'comply', 'requirement']):
            intent = "compliance"
        elif any(word in query_lower for word in ['difference', 'compare', 'versus', 'vs']):
            intent = "comparison"
        
        # Dynamic complexity assessment
        complexity = "moderate"
        if len(query.split()) < 5:
            complexity = "simple"
        elif len(query.split()) > 15 or any(word in query_lower for word in ['comprehensive', 'detailed', 'analysis']):
            complexity = "complex"
        
        return {
            "intent": intent,
            "complexity": complexity,
            "entities": [],
            "domain_focus": "mixed",
            "requires_cross_analysis": complexity == "complex",
            "optimal_approach": "business",
            "response_format": "structured",
            "reasoning": "Adaptive fallback analysis based on query patterns"
        }

# Dynamic Tools for ReAct Agent

@tool
async def dynamic_search_tool(query: str, search_strategy: str = "adaptive", 
                            k: int = 5, config: RunnableConfig = None) -> str:
    """
    Perform dynamic search that adapts its strategy based on query analysis.
    
    Args:
        query: The search query
        search_strategy: Strategy type ("adaptive", "articles", "chunks", "definitions", "cross_references")
        k: Maximum number of results
    
    Returns:
        Formatted search results
    """
    try:
        es_manager = config["configurable"]["es_manager"]
        
        if search_strategy == "articles":
            docs = await es_manager.dynamic_search_articles(query, k=k)
        elif search_strategy == "chunks":
            docs = await es_manager.dynamic_search_chunks(query, k=k)
        elif search_strategy == "definitions":
            docs = await es_manager.find_definitions_dynamically(query)
        elif search_strategy == "cross_references":
            docs = await es_manager.discover_cross_references_dynamically(query)
        else:  # adaptive
            # Use comprehensive approach
            article_docs = await es_manager.dynamic_search_articles(query, k=k//2)
            chunk_docs = await es_manager.dynamic_search_chunks(query, k=k//2)
            docs = article_docs + chunk_docs
        
        if not docs:
            return f"No relevant results found for query: {query}"
        
        formatted_results = []
        for i, doc in enumerate(docs):
            metadata = doc.metadata
            score = metadata.get('_score', 0.0)
            
            formatted_results.append(
                f"Result {i+1} (Score: {score:.3f}):\n"
                f"Title: {metadata.get('title', 'N/A')}\n"
                f"Document: {metadata.get('document_type', 'N/A')}\n"
                f"Article: {metadata.get('article_number', 'N/A')}\n"
                f"Content: {doc.page_content[:400]}...\n"
            )
        
        return "\n---\n".join(formatted_results)
        
    except Exception as e:
        return f"Error in dynamic search: {str(e)}"

@tool
async def adaptive_qa_chain_tool(query: str, chain_type: str = "auto", config: RunnableConfig = None) -> str:
    """
    Use adaptive QA chains that dynamically select optimal approach.
    
    Args:
        query: The question to answer
        chain_type: Chain type ("auto", "definition", "compliance", "business", "conversational")
    
    Returns:
        Comprehensive answer from adaptive QA chain
    """
    try:
        qa_manager = config["configurable"]["qa_manager"]
        context = config["configurable"]["context"]
        
        if chain_type == "auto":
            chain_type = None  # Let the manager dynamically choose
        
        result = await qa_manager.answer_with_dynamic_chain(query, context, chain_type)
        
        answer = result["answer"]
        chain_used = result["chain_type"]
        num_sources = len(result.get("source_documents", []))
        
        formatted_response = f"**Answer (using adaptive {chain_used} chain with {num_sources} sources):**\n\n{answer}"
        
        # Add source information
        if result.get("source_documents"):
            formatted_response += "\n\n**Sources:**\n"
            for i, doc in enumerate(result["source_documents"][:3]):
                metadata = doc.metadata
                formatted_response += f"{i+1}. {metadata.get('title', 'Unknown')} ({metadata.get('document_type', 'Unknown')})\n"
        
        return formatted_response
        
    except Exception as e:
        return f"Error in adaptive QA chain: {str(e)}"

@tool
async def dynamic_concept_discovery_tool(query: str, config: RunnableConfig = None) -> str:
    """
    Discover concepts and relationships dynamically from query and related documents.
    
    Args:
        query: The query to analyze for concept discovery
    
    Returns:
        Discovered concepts and relationships
    """
    try:
        es_manager = config["configurable"]["es_manager"]
        
        # Get relevant documents first
        docs = await es_manager.dynamic_search_chunks(query, k=5)
        
        if not docs:
            return f"No documents found to analyze for concept discovery: {query}"
        
        # Discover concepts from documents
        concepts = await es_manager.concept_engine.discover_document_concepts(docs)
        
        result = f"**Dynamic Concept Discovery for: {query}**\n\n"
        
        if concepts.terms:
            result += f"**Discovered Terms:** {', '.join(concepts.terms[:10])}\n\n"
        
        if concepts.definitions:
            result += "**Key Definitions:**\n"
            for term, definition in list(concepts.definitions.items())[:3]:
                result += f"• {term}: {definition[:200]}...\n"
            result += "\n"
        
        if concepts.relationships:
            result += "**Concept Relationships:**\n"
            for term, related in list(concepts.relationships.items())[:3]:
                result += f"• {term}: related to {', '.join(related[:3])}\n"
            result += "\n"
        
        if concepts.importance_scores:
            top_concepts = sorted(concepts.importance_scores.items(), key=lambda x: x[1], reverse=True)[:5]
            result += "**Top Important Concepts:**\n"
            for term, score in top_concepts:
                result += f"• {term} (importance: {score:.3f})\n"
        
        return result
        
    except Exception as e:
        return f"Error in dynamic concept discovery: {str(e)}"

@tool
async def adaptive_comparison_tool(topic: str, config: RunnableConfig = None) -> str:
    """
    Perform adaptive comparison that discovers differences dynamically.
    
    Args:
        topic: The topic to compare across different sources/regulations
    
    Returns:
        Dynamic comparative analysis
    """
    try:
        es_manager = config["configurable"]["es_manager"]
        
        # Dynamically discover comparison aspects
        docs = await es_manager.dynamic_search_articles(topic, k=6)
        
        if not docs:
            return f"No documents found for comparative analysis of: {topic}"
        
        # Group documents by type for comparison
        doc_groups = defaultdict(list)
        for doc in docs:
            doc_type = doc.metadata.get('document_type', 'Unknown')
            doc_groups[doc_type].append(doc)
        
        comparison = f"=== DYNAMIC COMPARISON: {topic.upper()} ===\n\n"
        
        for doc_type, type_docs in doc_groups.items():
            comparison += f"--- {doc_type} ---\n"
            if type_docs:
                for doc in type_docs[:2]:
                    metadata = doc.metadata
                    comparison += f"• {metadata.get('title', 'N/A')}\n  {doc.page_content[:200]}...\n\n"
            else:
                comparison += f"No relevant {doc_type} content found.\n\n"
        
        # Add dynamic insights
        if len(doc_groups) > 1:
            comparison += "--- DYNAMIC INSIGHTS ---\n"
            comparison += "This comparison was generated by dynamically discovering differences "
            comparison += "across the available document types and their specific approaches to this topic.\n"
        
        return comparison
        
    except Exception as e:
        return f"Error in adaptive comparison: {str(e)}"

# Main Dynamic GDPR Chatbot
class DynamicGDPRChatbot:
    """Main GDPR Q&A Chatbot with fully dynamic, adaptive architecture"""
    
    def __init__(self):
        self.openai_manager = AdvancedOpenAIManager()
        self.es_manager = DynamicElasticsearchManager(self.openai_manager)
        self.search_agent = DynamicSearchAgent(self.es_manager)
        self.analysis_agent = DynamicAnalysisAgent(self.openai_manager)
        self.qa_manager = DynamicQAChainManager(self.es_manager)
        self.memory_store = InMemoryStore()
        
        # Create ReAct agent
        self.react_agent = None
        self._create_dynamic_react_agent()
    
    def _create_dynamic_react_agent(self):
        """Create ReAct agent with dynamic, adaptive tools"""
        try:
            # Create dynamic tools
            tools = [
                dynamic_search_tool,
                adaptive_qa_chain_tool,
                dynamic_concept_discovery_tool,
                adaptive_comparison_tool
            ]
            
            # Create chat model without constraints
            chat_model = ChatOpenAI(
                model=Config.REASONING_MODEL,
                api_key=Config.OPENAI_API_KEY,
                base_url=Config.OPENAI_BASE_URL
            )
            
            # Dynamic system prompt
            system_prompt = """
            You are an expert consultant with advanced dynamic analysis capabilities.
            You adapt your approach based on each unique query and context.
            
            Your Dynamic Capabilities:
            1. **Adaptive Search**: Dynamically discover and use the most relevant search strategies
            2. **Intelligent QA**: Select optimal response approaches based on query analysis
            3. **Concept Discovery**: Dynamically identify and explore key concepts from content
            4. **Adaptive Comparison**: Compare topics by discovering differences dynamically
            
            Your Approach:
            1. **Analyze** each query to understand its unique characteristics and requirements
            2. **Adapt** your strategy based on the analysis - no two queries are the same
            3. **Discover** relevant concepts, terms, and relationships dynamically
            4. **Synthesize** comprehensive answers using the most appropriate tools
            5. **Respond** with insights tailored to the specific query and context
            
            Key Principles:
            - Never assume what terms or concepts are important - discover them dynamically
            - Adapt your search and analysis strategy for each unique query
            - Use AI reasoning to make intelligent decisions about tool selection
            - Provide responses that are specifically tailored to the query characteristics
            - Focus on discovering and leveraging the actual content rather than assumptions
            
            You have access to powerful dynamic tools that adapt to any domain or query type.
            Use them intelligently to provide the most relevant and comprehensive responses.
            """
            
            # Create ReAct agent
            self.react_agent = create_react_agent(
                model=chat_model,
                tools=tools,
                state_modifier=system_prompt
            )
            
            logger.info("Dynamic ReAct GDPR chatbot created successfully")
            
        except Exception as e:
            logger.error(f"Error creating dynamic ReAct agent: {e}")
            raise
    
    async def chat(self, user_query: str, thread_id: str = None) -> Dict[str, Any]:
        """Main chat interface with fully dynamic processing"""
        try:
            if not user_query or len(user_query.strip()) < 3:
                return {
                    "answer": "Please provide a more detailed question.",
                    "confidence": "low",
                    "thread_id": thread_id
                }
            
            if not thread_id:
                thread_id = f"dynamic_chat_{uuid.uuid4().hex[:8]}"
            
            # Create conversation context
            context = ConversationContext(
                thread_id=thread_id,
                query=user_query,
                intent="",
                entities=[],
                previous_searches=[],
                conversation_history=[],
                current_analysis={}
            )
            
            # Dynamic query analysis
            try:
                intent_analysis = await self.analysis_agent.analyze_query_dynamically(user_query, context)
                context.current_analysis = intent_analysis
                logger.info(f"Dynamic analysis - Intent: {intent_analysis.get('intent')}, Approach: {intent_analysis.get('optimal_approach')}")
            except Exception as e:
                logger.warning(f"Dynamic analysis failed: {e}")
            
            # Configure ReAct agent
            config = RunnableConfig(
                configurable={
                    "thread_id": thread_id,
                    "es_manager": self.es_manager,
                    "qa_manager": self.qa_manager,
                    "context": context
                }
            )
            
            # Run dynamic ReAct agent
            logger.info(f"Processing with dynamic ReAct agent: {user_query[:100]}...")
            
            messages = [HumanMessage(content=user_query)]
            
            response = await self.react_agent.ainvoke(
                {"messages": messages},
                config=config
            )
            
            # Extract final answer
            final_answer = ""
            if response and "messages" in response:
                for message in reversed(response["messages"]):
                    if hasattr(message, 'content') and message.content:
                        content = str(message.content).strip()
                        if (content and 
                            not content.startswith('{"') and 
                            not content.startswith('Error:') and
                            len(content) > 50):
                            final_answer = content
                            break
            
            if not final_answer:
                # Fallback to dynamic QA chain
                logger.info("ReAct didn't provide answer, using dynamic QA chain fallback")
                try:
                    qa_result = await self.qa_manager.answer_with_dynamic_chain(user_query, context)
                    final_answer = qa_result["answer"]
                except Exception as e:
                    final_answer = "I apologize, but I couldn't generate a comprehensive answer. Please try rephrasing your question."
            
            # Dynamic answer quality assessment
            confidence = await self._assess_answer_quality_dynamically(final_answer, intent_analysis)
            
            # Store conversation in memory
            try:
                await self._store_conversation_memory(user_query, final_answer, thread_id, confidence)
            except Exception as e:
                logger.warning(f"Failed to store conversation memory: {e}")
            
            return {
                "answer": final_answer,
                "confidence": confidence,
                "thread_id": thread_id,
                "intent": intent_analysis.get('intent', 'unknown'),
                "complexity": intent_analysis.get('complexity', 'unknown'),
                "approach": intent_analysis.get('optimal_approach', 'adaptive')
            }
            
        except Exception as e:
            logger.error(f"Error in dynamic chat processing: {e}")
            return {
                "answer": f"I apologize, but I encountered an error processing your question: {str(e)}",
                "confidence": "low",
                "thread_id": thread_id or "error"
            }
    
    async def _assess_answer_quality_dynamically(self, answer: str, intent_analysis: Dict) -> str:
        """Dynamically assess answer quality based on multiple factors"""
        if not answer or len(answer) < 50:
            return "low"
        
        # Dynamic quality indicators based on intent
        intent = intent_analysis.get('intent', 'unknown')
        complexity = intent_analysis.get('complexity', 'moderate')
        
        base_score = 0
        
        # Length-based scoring
        if len(answer) > 200:
            base_score += 1
        if len(answer) > 500:
            base_score += 1
        
        # Structure-based scoring
        if "**" in answer or "###" in answer:  # Has formatting
            base_score += 1
        
        # Content relevance scoring
        query_terms = intent_analysis.get('entities', [])
        if any(term.lower() in answer.lower() for term in query_terms):
            base_score += 1
        
        # Intent-specific scoring
        if intent == "definition" and any(word in answer.lower() for word in ['means', 'refers to', 'defined as']):
            base_score += 1
        elif intent == "compliance" and any(word in answer.lower() for word in ['requirement', 'must', 'obligation']):
            base_score += 1
        
        # Dynamic thresholds based on complexity
        if complexity == "simple":
            return "high" if base_score >= 3 else "medium" if base_score >= 2 else "low"
        elif complexity == "complex":
            return "high" if base_score >= 4 else "medium" if base_score >= 3 else "low"
        else:  # moderate
            return "high" if base_score >= 4 else "medium" if base_score >= 2 else "low"
    
    async def _store_conversation_memory(self, query: str, answer: str, thread_id: str, confidence: str):
        """Store conversation in memory for context"""
        try:
            memory_data = {
                "query": query,
                "answer_length": len(answer),
                "confidence": confidence,
                "timestamp": datetime.now().isoformat(),
                "thread_id": thread_id,
                "processing_type": "dynamic"
            }
            
            await self.memory_store.aput(
                namespace=("conversations", "dynamic_gdpr_chatbot"),
                key=f"conversation_{uuid.uuid4()}",
                value=memory_data
            )
        except Exception as e:
            logger.error(f"Error storing conversation memory: {e}")

# Interface classes remain similar but with updated descriptions
class DynamicGDPRChatbotInterface:
    """Dynamic interface for GDPR chatbot with fully adaptive capabilities"""
    
    def __init__(self):
        self.chatbot = None
    
    async def initialize(self):
        """Initialize the dynamic chatbot"""
        try:
            logger.info("Initializing Dynamic GDPR Chatbot...")
            self.chatbot = DynamicGDPRChatbot()
            logger.info("Dynamic GDPR Chatbot initialized successfully!")
            return True
        except Exception as e:
            logger.error(f"Failed to initialize dynamic chatbot: {e}")
            return False
    
    async def ask_question(self, question: str, thread_id: str = None) -> Dict[str, Any]:
        """Ask a question to the dynamic chatbot"""
        if not self.chatbot:
            if not await self.initialize():
                return {
                    "answer": "Chatbot failed to initialize. Please check your configuration.",
                    "confidence": "low",
                    "thread_id": thread_id or "error"
                }
        
        return await self.chatbot.chat(question, thread_id)
    
    def run_interactive_session(self):
        """Run an interactive session with dynamic capabilities"""
        print("="*80)
        print("Dynamic GDPR Q&A Chatbot - Fully Adaptive Architecture")
        print("="*80)
        print("Features: Dynamic Term Discovery, Adaptive Search, AI-Powered Analysis")
        print("No hardcoded terms or patterns - everything is discovered dynamically!")
        print("Ask any questions - the system adapts to your specific query.")
        print("Type 'exit' to quit, 'help' for examples")
        print("="*80)
        
        async def interactive_loop():
            if not await self.initialize():
                print("❌ Failed to initialize dynamic chatbot.")
                return
            
            thread_id = f"dynamic_{uuid.uuid4().hex[:8]}"
            print(f"✅ Dynamic Chatbot ready! (Thread ID: {thread_id})")
            
            while True:
                try:
                    question = input("\n💬 Your question: ").strip()
                    
                    if question.lower() in ['exit', 'quit', 'bye']:
                        print("👋 Goodbye!")
                        break
                    
                    if question.lower() == 'help':
                        print("\n🧠 Dynamic Analysis Examples:")
                        print("• Ask about any legal/regulatory concept - terms discovered dynamically")
                        print("• Complex questions - system adapts search strategy automatically")
                        print("• Domain-specific queries - concepts learned from your documents")
                        print("• Comparative analysis - differences discovered automatically")
                        print("• Technical vs business focus - approach adapted to your query")
                        continue
                    
                    if not question:
                        print("Please enter a question.")
                        continue
                    
                    print("\n🔍 Analyzing query and adapting approach dynamically...")
                    
                    response = await self.ask_question(question, thread_id)
                    
                    print(f"\n📋 **Dynamic Answer** (Confidence: {response.get('confidence', 'unknown')})")
                    print(f"Intent: {response.get('intent', 'unknown')} | Approach: {response.get('approach', 'unknown')}")
                    print("="*70)
                    print(response['answer'])
                    print("="*70)
                    
                except KeyboardInterrupt:
                    print("\n👋 Goodbye!")
                    break
                except Exception as e:
                    print(f"\n❌ Error: {e}")
        
        asyncio.run(interactive_loop())

# Main execution
async def main():
    """Main function to run the dynamic chatbot"""
    print("Dynamic GDPR Q&A Chatbot - Fully Adaptive Architecture")
    print("=" * 80)
    
    # Validate configuration
    if not Config.OPENAI_API_KEY:
        print("❌ Error: OPENAI_API_KEY environment variable is required")
        return
    
    if not Config.ES_PASSWORD:
        print("❌ Error: ES_PASSWORD environment variable is required")
        return
    
    print("🧠 Dynamic Features:")
    print("• AI-powered term and concept discovery")
    print("• Adaptive search strategies based on query analysis")
    print("• Dynamic QA chain selection")
    print("• No hardcoded terms or patterns")
    print("• Self-learning from document content")
    print("• Fully adaptive to any domain or query type")
    print()
    
    # Choose mode
    mode = input("Choose mode:\n1. Interactive Session\n2. Demo\n3. Single Question\nEnter choice (1-3): ").strip()
    
    interface = DynamicGDPRChatbotInterface()
    
    if mode == "1":
        interface.run_interactive_session()
    
    elif mode == "2":
        await demo_dynamic_chatbot()
    
    elif mode == "3":
        if not await interface.initialize():
            print("❌ Failed to initialize dynamic chatbot")
            return
        
        question = input("Enter your question: ").strip()
        if question:
            print("\n🧠 Processing with dynamic analysis and adaptation...")
            response = await interface.ask_question(question)
            print(f"\n📋 Dynamic Answer (Confidence: {response.get('confidence', 'unknown')}):")
            print(f"Intent: {response.get('intent')} | Approach: {response.get('approach')}")
            print("=" * 70)
            print(response['answer'])
            print("=" * 70)
        else:
            print("No question provided.")
    
    else:
        print("Invalid choice. Please run again and select 1, 2, or 3.")

# Demo function
async def demo_dynamic_chatbot():
    """Demonstrate the dynamic chatbot capabilities"""
    interface = DynamicGDPRChatbotInterface()
    
    if not await interface.initialize():
        print("❌ Failed to initialize dynamic chatbot for demo")
        return
    
    print("\n" + "="*80)
    print("DYNAMIC GDPR CHATBOT DEMONSTRATION")
    print("="*80)
    
    demo_questions = [
        "What regulatory concepts are most important in data protection?",
        "How should organizations approach compliance requirements?",
        "What are the key differences between various data protection frameworks?",
        "Explain the relationship between data processing and user rights."
    ]
    
    for i, question in enumerate(demo_questions, 1):
        print(f"\n📌 Dynamic Demo Question {i}: {question}")
        print("-" * 70)
        
        try:
            response = await interface.ask_question(question)
            print(f"🎯 Confidence: {response.get('confidence', 'unknown')}")
            print(f"📝 Intent: {response.get('intent', 'unknown')}")
            print(f"🧠 Approach: {response.get('approach', 'unknown')}")
            print("\n📋 Answer:")
            print(response['answer'][:600] + "..." if len(response['answer']) > 600 else response['answer'])
            
        except Exception as e:
            print(f"❌ Error: {e}")
        
        print("\n" + "="*80)

if __name__ == "__main__":
    asyncio.run(main())
