"""
Legal Document Analyzer - COMPLETE VERSION WITH PROPER FORMATTING
- Fixed character-by-character bullet point issue
- Each bullet point has proper citation and reasoning
- Legible, structured output
- NO TRUNCATION

Location: src/analyzers/legal_document_analyzer.py
"""

from typing import Dict, List, Optional, Any, Tuple, Set
import json
from dataclasses import dataclass, field
import logging
import re
from collections import defaultdict

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import networkx as nx

from src.prompting.advanced_strategies import AdvancedPromptingStrategies
from src.services.openai_service import OpenAIService
from src.utils.document_chunker import DocumentChunker
from src.config import Config

logger = logging.getLogger(__name__)


# SIMPLIFIED ACTION TAXONOMY
class DataActionType:
    """Simplified data action taxonomy"""
    DATA_SHARING_AND_ACCESS = "data_sharing_and_access"
    DATA_STORAGE_AND_HOSTING = "data_storage_and_hosting"
    DATA_USAGE = "data_usage"


class RuleClassification:
    """Rule classification"""
    CONDITION = "condition"
    RESTRICTION = "restriction"


@dataclass
class Citation:
    """Citation for extracted information"""
    text_excerpt: str
    chunk_id: int
    document_level: int
    reasoning: str = ""


@dataclass
class Evidence:
    """Evidence supporting a rule or requirement"""
    description: str
    citations: List[Citation] = field(default_factory=list)
    thought_process: str = ""


@dataclass
class Constraint:
    """Constraint or condition"""
    type: str
    description: str
    left_operand: str
    operator: str
    right_operand: Any
    citations: List[Citation] = field(default_factory=list)
    scope: str = "general"
    thought_process: str = ""


@dataclass
class EnterprisePolicy:
    """Enterprise-specific policy"""
    policy_name: str
    description: str
    organization: str
    applies_to: List[str]
    internal_tools: List[str]
    citations: List[Citation] = field(default_factory=list)
    level: int = 3
    thought_process: str = ""


class KnowledgeGraphBuilder:
    """Builds and maintains knowledge graph of legal requirements"""
    
    def __init__(self):
        self.graph = nx.DiGraph()
        self.node_counter = 0
        
    def add_rule(self, rule_id: str, rule_data: Dict[str, Any]):
        """Add a rule node to the graph"""
        self.graph.add_node(
            rule_id,
            type='rule',
            data=rule_data,
            level=rule_data.get('level', 1)
        )
        
    def add_constraint(self, constraint_id: str, constraint: Constraint, rule_id: str):
        """Add constraint and link to rule"""
        self.graph.add_node(
            constraint_id,
            type='constraint',
            constraint_type=constraint.type,
            description=constraint.description,
            operator=constraint.operator,
            scope=constraint.scope
        )
        self.graph.add_edge(rule_id, constraint_id, relationship='has_constraint')
        
    def add_action(self, action_id: str, action_data: Dict[str, Any], rule_id: str):
        """Add action and link to rule"""
        self.graph.add_node(
            action_id,
            type='action',
            action_type=action_data['type'],
            description=action_data['description']
        )
        self.graph.add_edge(rule_id, action_id, relationship='requires_action')
        
    def add_evidence(self, evidence_id: str, evidence_data: Dict[str, Any], rule_id: str, evidence_type: str):
        """Add evidence (user or system) and link to rule"""
        self.graph.add_node(
            evidence_id,
            type=f'{evidence_type}_evidence',
            description=evidence_data.get('description', '')
        )
        self.graph.add_edge(rule_id, evidence_id, relationship=f'has_{evidence_type}_evidence')
        
    def add_enterprise_policy(self, policy_id: str, policy: EnterprisePolicy, rule_id: str):
        """Add enterprise policy and link to rule"""
        self.graph.add_node(
            policy_id,
            type='enterprise_policy',
            policy_name=policy.policy_name,
            organization=policy.organization,
            description=policy.description,
            level=policy.level
        )
        self.graph.add_edge(rule_id, policy_id, relationship='implements_policy')
        
    def link_rules(self, source_rule_id: str, target_rule_id: str, relationship: str):
        """Link two rules with a relationship"""
        self.graph.add_edge(source_rule_id, target_rule_id, relationship=relationship)
        
    def find_conflicts(self) -> List[Tuple[str, str, str]]:
        """Find conflicting rules in the graph"""
        conflicts = []
        constraint_nodes = [n for n, d in self.graph.nodes(data=True) if d.get('type') == 'constraint']
        
        for i, c1 in enumerate(constraint_nodes):
            for c2 in constraint_nodes[i+1:]:
                c1_data = self.graph.nodes[c1]
                c2_data = self.graph.nodes[c2]
                
                if (c1_data.get('constraint_type') == c2_data.get('constraint_type') and
                    self._operators_conflict(c1_data.get('operator'), c2_data.get('operator'))):
                    conflicts.append((c1, c2, "conflicting_operators"))
                    
        return conflicts
        
    def _operators_conflict(self, op1: str, op2: str) -> bool:
        """Check if two operators conflict"""
        conflicting_pairs = [
            ('eq', 'neq'),
            ('gt', 'lt'),
            ('gte', 'lte'),
            ('isAnyOf', 'isNoneOf')
        ]
        return (op1, op2) in conflicting_pairs or (op2, op1) in conflicting_pairs
        
    def find_dependencies(self, rule_id: str) -> List[str]:
        """Find all rules that this rule depends on"""
        return list(self.graph.predecessors(rule_id))
        
    def find_dependents(self, rule_id: str) -> List[str]:
        """Find all rules that depend on this rule"""
        return list(self.graph.successors(rule_id))
        
    def get_rule_subgraph(self, rule_id: str, depth: int = 2) -> nx.DiGraph:
        """Get subgraph centered on a specific rule"""
        nodes = nx.single_source_shortest_path_length(self.graph, rule_id, cutoff=depth).keys()
        return self.graph.subgraph(nodes).copy()
        
    def find_cross_level_relationships(self) -> List[Tuple[str, str, int, int]]:
        """Find relationships between rules at different levels"""
        relationships = []
        
        for source, target, data in self.graph.edges(data=True):
            source_level = self.graph.nodes[source].get('level', 0)
            target_level = self.graph.nodes[target].get('level', 0)
            
            if source_level != target_level:
                relationships.append((source, target, source_level, target_level))
                
        return relationships
        
    def reason_about_rule(self, rule_id: str) -> Dict[str, Any]:
        """Reason about a rule using graph structure"""
        reasoning = {
            'rule_id': rule_id,
            'has_constraints': False,
            'has_actions': False,
            'has_evidence': False,
            'has_enterprise_policies': False,
            'dependencies': [],
            'dependents': [],
            'conflicts': [],
            'completeness_score': 0.0,
            'insights': []
        }
        
        if rule_id not in self.graph:
            reasoning['insights'].append("Rule not found in graph")
            return reasoning
            
        for neighbor in self.graph.neighbors(rule_id):
            neighbor_type = self.graph.nodes[neighbor].get('type')
            
            if neighbor_type == 'constraint':
                reasoning['has_constraints'] = True
            elif neighbor_type == 'action':
                reasoning['has_actions'] = True
            elif neighbor_type in ['user_evidence', 'system_evidence']:
                reasoning['has_evidence'] = True
            elif neighbor_type == 'enterprise_policy':
                reasoning['has_enterprise_policies'] = True
                
        reasoning['dependencies'] = self.find_dependencies(rule_id)
        reasoning['dependents'] = self.find_dependents(rule_id)
        
        score = 0.0
        if reasoning['has_constraints']: score += 0.25
        if reasoning['has_actions']: score += 0.25
        if reasoning['has_evidence']: score += 0.25
        if reasoning['has_enterprise_policies']: score += 0.25
        reasoning['completeness_score'] = score
        
        if not reasoning['has_constraints']:
            reasoning['insights'].append("Missing constraints - rule may lack specific conditions")
        if not reasoning['has_actions']:
            reasoning['insights'].append("Missing actions - rule may lack actionable requirements")
        if not reasoning['has_evidence']:
            reasoning['insights'].append("Missing evidence requirements - validation may be unclear")
            
        rule_level = self.graph.nodes[rule_id].get('level', 0)
        if rule_level == 3 and not reasoning['has_enterprise_policies']:
            reasoning['insights'].append("Level 3 rule missing enterprise policies")
            
        return reasoning
        
    def get_statistics(self) -> Dict[str, Any]:
        """Get graph statistics"""
        stats = {
            'total_nodes': self.graph.number_of_nodes(),
            'total_edges': self.graph.number_of_edges(),
            'rules': 0,
            'constraints': 0,
            'actions': 0,
            'evidence': 0,
            'enterprise_policies': 0
        }
        
        for node, data in self.graph.nodes(data=True):
            node_type = data.get('type', '')
            if node_type == 'rule':
                stats['rules'] += 1
            elif node_type == 'constraint':
                stats['constraints'] += 1
            elif node_type == 'action':
                stats['actions'] += 1
            elif 'evidence' in node_type:
                stats['evidence'] += 1
            elif node_type == 'enterprise_policy':
                stats['enterprise_policies'] += 1
                
        return stats


class SupervisorAgent:
    """Supervisor agent that validates and reasons about analysis results"""
    
    def __init__(self, llm: ChatOpenAI, knowledge_graph: KnowledgeGraphBuilder):
        self.llm = llm
        self.kg = knowledge_graph
        
    def validate_analysis(self, analysis: Dict[str, Any], rule_id: str) -> Dict[str, Any]:
        """Comprehensive validation of analysis results"""
        validation_result = {
            'valid': True,
            'errors': [],
            'warnings': [],
            'suggestions': [],
            'graph_insights': {}
        }
        
        required_fields = ['description', 'citations', 'data_actions', 'constraints']
        for field in required_fields:
            if field not in analysis:
                validation_result['errors'].append(f"Missing required field: {field}")
                validation_result['valid'] = False
                
        if 'description' in analysis and len(analysis['description']) < 50:
            validation_result['warnings'].append("Description seems too short")
            
        if 'citations' in analysis and len(analysis['citations']) == 0:
            validation_result['warnings'].append("No citations provided - claims may not be traceable")
            
        if 'constraints' in analysis and len(analysis['constraints']) == 0:
            validation_result['warnings'].append("No constraints extracted - rule may lack specificity")
            
        if rule_id in self.kg.graph:
            graph_reasoning = self.kg.reason_about_rule(rule_id)
            validation_result['graph_insights'] = graph_reasoning
            
            if graph_reasoning['completeness_score'] < 0.5:
                validation_result['suggestions'].append(
                    f"Rule completeness is {graph_reasoning['completeness_score']:.0%} - consider extracting more components"
                )
                
            for insight in graph_reasoning['insights']:
                validation_result['suggestions'].append(insight)
                
        conflicts = self.kg.find_conflicts()
        if conflicts:
            validation_result['warnings'].append(f"Found {len(conflicts)} potential conflicts in knowledge graph")
            
        return validation_result
        
    def reason_about_levels(self, level_1_analysis: Dict, level_2_analysis: Dict, level_3_analysis: Dict) -> Dict[str, Any]:
        """Reason about relationships between the three document levels"""
        reasoning = {
            'level_alignment': {},
            'enhancement_opportunities': [],
            'consistency_issues': []
        }
        
        l1_constraints = len(level_1_analysis.get('constraints', []))
        l2_constraints = len(level_2_analysis.get('constraints', []))
        
        if l2_constraints > l1_constraints:
            reasoning['level_alignment']['guidance_adds_detail'] = True
            reasoning['enhancement_opportunities'].append(
                f"Level 2 guidance adds {l2_constraints - l1_constraints} additional constraints"
            )
        else:
            reasoning['level_alignment']['guidance_adds_detail'] = False
            
        l3_policies = level_3_analysis.get('enterprise_policies', [])
        if len(l3_policies) > 0:
            reasoning['level_alignment']['enterprise_specific'] = True
            reasoning['enhancement_opportunities'].append(
                f"Level 3 provides {len(l3_policies)} enterprise-specific policies"
            )
        else:
            reasoning['level_alignment']['enterprise_specific'] = False
            reasoning['enhancement_opportunities'].append(
                "Level 3 missing enterprise-specific policies"
            )
            
        classifications = [
            level_1_analysis.get('classification'),
            level_2_analysis.get('classification'),
            level_3_analysis.get('classification')
        ]
        
        if len(set(classifications)) > 1:
            reasoning['consistency_issues'].append(
                f"Inconsistent classifications across levels: {classifications}"
            )
            
        return reasoning


class LegalDocumentAnalyzer:
    """
    COMPLETE Legal Document Analyzer - FIXED CHARACTER SPLITTING ISSUE
    - Proper bullet point formatting
    - Citations for every item
    - Thought process included
    - NO TRUNCATION
    """
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        
        if not self.config.API_KEY:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.openai_service = OpenAIService()
        self.llm = ChatOpenAI(
            model=self.config.CHAT_MODEL,
            openai_api_key=self.config.API_KEY,
            openai_api_base=self.config.BASE_URL
        )
        
        chunk_size = getattr(self.config, 'CHUNK_SIZE', 3000)
        overlap_size = getattr(self.config, 'OVERLAP_SIZE', 200)
        
        self.chunker = DocumentChunker(
            chunk_size=chunk_size,
            chunk_overlap=overlap_size,
            respect_boundaries=True
        )
        
        self.knowledge_graph = KnowledgeGraphBuilder()
        self.supervisor = SupervisorAgent(self.llm, self.knowledge_graph)
        
    def analyze_document(
        self,
        rule_name: str,
        jurisdiction: str,
        document_text: str,
        level: int,
        enterprise_context: Optional[Dict[str, Any]] = None,
        previous_level_analysis: Optional[str] = None
    ) -> Dict[str, Any]:
        """Main document analysis with proper formatting"""
        print(f"\n{'='*60}")
        print(f"Analyzing: {rule_name} (Level {level})")
        print(f"Document length: {len(document_text)} chars")
        print(f"{'='*60}")
        
        strategies = AdvancedPromptingStrategies(rule_name, jurisdiction)
        
        chunks = self.chunker.chunk_document(
            text=document_text,
            metadata={
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level
            }
        )
        
        print(f"Created {len(chunks)} chunks")
        
        chunk_analyses = []
        for i, chunk in enumerate(chunks):
            print(f"\nProcessing chunk {i+1}/{len(chunks)} (size: {len(chunk['text'])} chars)...")
            
            try:
                analysis = self._analyze_single_chunk_complete(
                    chunk=chunk,
                    strategies=strategies,
                    level=level,
                    enterprise_context=enterprise_context,
                    full_document_text=document_text
                )
                
                if analysis:
                    chunk_analyses.append(analysis)
                    print(f"  âœ“ Extracted: {len(analysis.get('data_actions', []))} actions, "
                          f"{len(analysis.get('citations', []))} citations, "
                          f"{len(analysis.get('constraints', []))} constraints, "
                          f"{len(analysis.get('enterprise_policies', []))} enterprise policies")
                else:
                    print(f"  âš  No data extracted from chunk {i+1}")
                    
            except Exception as e:
                print(f"  âœ— Error processing chunk {i+1}: {e}")
                logger.error(f"Chunk {i+1} error: {e}", exc_info=True)
                continue
        
        print(f"\nMerging {len(chunk_analyses)} chunk analyses...")
        final_analysis = self._merge_chunk_analyses_complete(
            chunk_analyses=chunk_analyses,
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            level=level,
            enterprise_context=enterprise_context
        )
        
        rule_id = f"{rule_name}_level_{level}"
        final_analysis['rule_id'] = rule_id
        self._add_to_knowledge_graph(rule_id, final_analysis, level)
        
        validation = self.supervisor.validate_analysis(final_analysis, rule_id)
        final_analysis['validation'] = validation
        
        if not validation['valid']:
            print(f"\nâš  VALIDATION ERRORS:")
            for error in validation['errors']:
                print(f"  - {error}")
                
        if validation['warnings']:
            print(f"\nâš  VALIDATION WARNINGS:")
            for warning in validation['warnings']:
                print(f"  - {warning}")
                
        if validation['suggestions']:
            print(f"\nðŸ’¡ SUGGESTIONS:")
            for suggestion in validation['suggestions']:
                print(f"  - {suggestion}")
        
        return final_analysis
    
    def _analyze_single_chunk_complete(
        self,
        chunk: Dict[str, Any],
        strategies: AdvancedPromptingStrategies,
        level: int,
        enterprise_context: Optional[Dict[str, Any]],
        full_document_text: str
    ) -> Optional[Dict[str, Any]]:
        """Analyze single chunk with COMPLETE extraction and proper formatting"""
        chunk_text = chunk['text']
        chunk_id = chunk.get('chunk_id', 0)
        chunk_context = self.chunker.get_chunk_context(chunk)
        
        prompt = f"""Analyze this legal text comprehensively. Extract ALL components with complete citations and thought process.

CHUNK CONTEXT: {chunk_context}

ENTERPRISE CONTEXT: {json.dumps(enterprise_context) if enterprise_context else 'None'}

DOCUMENT LEVEL: {level} - {self._get_level_description(level)}

FULL CHUNK TEXT (NO TRUNCATION):
{chunk_text}

CRITICAL FORMATTING RULES:
1. Each bullet point must be a COMPLETE sentence or phrase (minimum 10 characters)
2. NEVER return single characters as separate items
3. Each item must have its own citation
4. Each item must have thought process/reasoning

EXTRACTION REQUIREMENTS:

1. DESCRIPTION: 
   - Comprehensive description of requirements
   - Include all context and details

2. CITATIONS:
   - For EVERY claim, provide exact text excerpts (up to 200 chars)
   - Include reasoning for why this text supports the claim
   - Format: {{"text": "exact quote", "reasoning": "why this supports the claim"}}

3. DATA ACTIONS:
   - Map to taxonomy: data_sharing_and_access | data_storage_and_hosting | data_usage
   - Format: {{"type": "taxonomy_type", "description": "COMPLETE sentence describing action", "citations": [...], "thought_process": "why this is classified this way"}}

4. CONSTRAINTS (Conditions & Requirements):
   - Extract ALL constraints and conditions
   - Format: {{
       "type": "temporal|spatial|technical|procedural|purpose|party",
       "description": "COMPLETE description (minimum 20 chars)",
       "left_operand": "What is being constrained",
       "operator": "eq|neq|gt|lt|gte|lte|isAnyOf|isNoneOf",
       "right_operand": "Constraint value",
       "scope": "permission|prohibition|duty|general",
       "citations": [{{"text": "...", "reasoning": "..."}}],
       "thought_process": "Why this is a constraint and how it applies"
     }}

5. USER EVIDENCE (User Perspective - What Users Must/Can/Cannot Do):
   - Format: {{
       "description": "COMPLETE requirement description (minimum 15 chars)",
       "citations": [{{"text": "exact supporting text", "reasoning": "how this supports the requirement"}}],
       "thought_process": "Why this is a user requirement and what it means"
     }}
   - Examples: "Users must obtain consent before processing", "Users can access their data within 30 days"

6. SYSTEM EVIDENCE (System Perspective - What Systems Must Implement):
   - Format: {{
       "description": "COMPLETE system requirement (minimum 15 chars)",
       "citations": [{{"text": "exact supporting text", "reasoning": "how this supports the requirement"}}],
       "thought_process": "Why this is a system requirement and what it means"
     }}
   - Examples: "System must encrypt data at rest", "System must log all access attempts"

7. ENTERPRISE POLICIES (especially Level 3):
   - Format: {{
       "policy_name": "Clear policy name",
       "description": "COMPLETE policy description (minimum 30 chars)",
       "organization": "Organization name",
       "applies_to": ["department", "system", "process"],
       "internal_tools": ["tool1", "tool2"],
       "citations": [{{"text": "...", "reasoning": "..."}}],
       "thought_process": "Why this is an enterprise policy and its significance"
     }}

8. CLASSIFICATION:
   - "condition" (allowed under certain conditions) OR "restriction" (prohibited/restricted)
   - Include detailed reasoning

QUALITY CHECKS:
- NO single-character items
- NO truncated descriptions
- EVERY item has citation
- EVERY item has thought process
- Descriptions are COMPLETE sentences

Return valid JSON with ALL fields fully populated."""

        messages = [
            SystemMessage(content=strategies.get_react_agent_system_prompt()),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = self.llm.invoke(messages)
            response_text = response.content
            
            logger.info(f"Chunk {chunk_id} response length: {len(response_text)} chars")
            
            extracted = self._extract_complete_from_response(
                response_text=response_text,
                chunk_id=chunk_id,
                level=level
            )
            
            return extracted
            
        except Exception as e:
            logger.error(f"Error in LLM call for chunk {chunk_id}: {e}")
            return None
    
    def _get_level_description(self, level: int) -> str:
        """Get description of document level"""
        descriptions = {
            1: "PRIMARY LEGISLATION - Base legal requirements",
            2: "REGULATORY GUIDANCE - Detailed interpretation and guidance",
            3: "ENTERPRISE POLICIES - Organization-specific implementation"
        }
        return descriptions.get(level, "")
    
    def _extract_complete_from_response(
        self,
        response_text: str,
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """COMPLETE extraction with proper formatting - FIXES CHARACTER SPLITTING"""
        parsed = self._try_json_extraction(response_text)
        
        if parsed:
            logger.info(f"Chunk {chunk_id}: Successfully extracted JSON")
            return self._normalize_complete_data(parsed, chunk_id, level)
        else:
            logger.warning(f"Chunk {chunk_id}: JSON extraction failed, using text extraction")
            return self._extract_complete_from_text(response_text, chunk_id, level)
    
    def _try_json_extraction(self, text: str) -> Optional[Dict]:
        """Try multiple JSON extraction strategies"""
        try:
            return json.loads(text)
        except:
            pass
        
        try:
            match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if match:
                return json.loads(match.group(1))
        except:
            pass
        
        try:
            pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
            matches = re.findall(pattern, text, re.DOTALL)
            for match in sorted(matches, key=len, reverse=True):
                try:
                    parsed = json.loads(match)
                    if isinstance(parsed, dict) and len(parsed) > 3:
                        return parsed
                except:
                    continue
        except:
            pass
        
        return None
    
    def _normalize_complete_data(
        self,
        data: Dict[str, Any],
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """
        FIXED: Normalize with proper handling - prevents character splitting
        """
        normalized = {
            "description": str(data.get("description", "")),
            "citations": [],
            "data_actions": [],
            "user_evidence": [],
            "system_evidence": [],
            "constraints": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": ""
        }
        
        # Extract citations - FIXED: Ensure we handle lists properly
        citations_raw = data.get("citations", [])
        if isinstance(citations_raw, list):
            for cite in citations_raw:
                if isinstance(cite, dict):
                    text = str(cite.get("text", "")).strip()
                    if len(text) >= 10:  # Minimum length check
                        normalized["citations"].append({
                            "text": text,
                            "chunk_id": chunk_id,
                            "level": level,
                            "reasoning": str(cite.get("reasoning", ""))
                        })
                elif isinstance(cite, str) and len(cite.strip()) >= 10:
                    normalized["citations"].append({
                        "text": cite.strip(),
                        "chunk_id": chunk_id,
                        "level": level,
                        "reasoning": ""
                    })
        
        # Extract data actions - FIXED: Proper list handling
        actions_raw = data.get("data_actions", [])
        if isinstance(actions_raw, list):
            for action in actions_raw:
                if isinstance(action, dict):
                    desc = str(action.get("description", "")).strip()
                    if len(desc) >= 10:  # Minimum length check
                        action_type = self._map_to_taxonomy(action.get("type", ""))
                        normalized["data_actions"].append({
                            "type": action_type,
                            "description": desc,
                            "citations": self._safe_extract_citations(action.get("citations", [])),
                            "thought_process": str(action.get("thought_process", ""))
                        })
                elif isinstance(action, str) and len(action.strip()) >= 10:
                    normalized["data_actions"].append({
                        "type": DataActionType.DATA_USAGE,
                        "description": action.strip(),
                        "citations": [],
                        "thought_process": ""
                    })
        
        # Extract constraints - FIXED: Proper list handling
        constraints_raw = data.get("constraints", [])
        if isinstance(constraints_raw, list):
            for constraint in constraints_raw:
                if isinstance(constraint, dict):
                    desc = str(constraint.get("description", "")).strip()
                    if len(desc) >= 15:  # Minimum length check
                        normalized["constraints"].append({
                            "type": constraint.get("type", "general"),
                            "description": desc,
                            "left_operand": str(constraint.get("left_operand", "")),
                            "operator": str(constraint.get("operator", "eq")),
                            "right_operand": constraint.get("right_operand"),
                            "scope": constraint.get("scope", "general"),
                            "citations": self._safe_extract_citations(constraint.get("citations", [])),
                            "thought_process": str(constraint.get("thought_process", "")),
                            "chunk_id": chunk_id,
                            "level": level
                        })
                elif isinstance(constraint, str) and len(constraint.strip()) >= 15:
                    normalized["constraints"].append({
                        "type": "general",
                        "description": constraint.strip(),
                        "left_operand": "",
                        "operator": "eq",
                        "right_operand": True,
                        "scope": "general",
                        "citations": [],
                        "thought_process": "Extracted from text",
                        "chunk_id": chunk_id,
                        "level": level
                    })
        
        # Extract user evidence - FIXED: Critical fix for character splitting
        user_evidence_raw = data.get("user_evidence", [])
        if isinstance(user_evidence_raw, list):
            for evidence in user_evidence_raw:
                if isinstance(evidence, dict):
                    desc = str(evidence.get("description", "")).strip()
                    if len(desc) >= 15:  # Minimum 15 chars to prevent single character bullets
                        normalized["user_evidence"].append({
                            "description": desc,
                            "citations": self._safe_extract_citations(evidence.get("citations", [])),
                            "thought_process": str(evidence.get("thought_process", ""))
                        })
                elif isinstance(evidence, str) and len(evidence.strip()) >= 15:
                    # CRITICAL: Only add if it's a complete sentence, not a single character
                    normalized["user_evidence"].append({
                        "description": evidence.strip(),
                        "citations": [],
                        "thought_process": "Extracted from text"
                    })
        
        # Extract system evidence - FIXED: Critical fix for character splitting
        system_evidence_raw = data.get("system_evidence", [])
        if isinstance(system_evidence_raw, list):
            for evidence in system_evidence_raw:
                if isinstance(evidence, dict):
                    desc = str(evidence.get("description", "")).strip()
                    if len(desc) >= 15:  # Minimum 15 chars to prevent single character bullets
                        normalized["system_evidence"].append({
                            "description": desc,
                            "citations": self._safe_extract_citations(evidence.get("citations", [])),
                            "thought_process": str(evidence.get("thought_process", ""))
                        })
                elif isinstance(evidence, str) and len(evidence.strip()) >= 15:
                    # CRITICAL: Only add if it's a complete sentence, not a single character
                    normalized["system_evidence"].append({
                        "description": evidence.strip(),
                        "citations": [],
                        "thought_process": "Extracted from text"
                    })
        
        # Extract enterprise policies - FIXED: Proper list handling
        policies_raw = data.get("enterprise_policies", [])
        if isinstance(policies_raw, list):
            for policy in policies_raw:
                if isinstance(policy, dict):
                    policy_name = str(policy.get("policy_name", "")).strip()
                    desc = str(policy.get("description", "")).strip()
                    if len(policy_name) >= 5 and len(desc) >= 20:  # Minimum length checks
                        # FIXED: Ensure applies_to and internal_tools are lists
                        applies_to = policy.get("applies_to", [])
                        if isinstance(applies_to, str):
                            applies_to = [applies_to]
                        elif not isinstance(applies_to, list):
                            applies_to = []
                            
                        internal_tools = policy.get("internal_tools", [])
                        if isinstance(internal_tools, str):
                            internal_tools = [internal_tools]
                        elif not isinstance(internal_tools, list):
                            internal_tools = []
                        
                        normalized["enterprise_policies"].append({
                            "policy_name": policy_name,
                            "description": desc,
                            "organization": str(policy.get("organization", "")),
                            "applies_to": applies_to,
                            "internal_tools": internal_tools,
                            "citations": self._safe_extract_citations(policy.get("citations", [])),
                            "thought_process": str(policy.get("thought_process", "")),
                            "level": level
                        })
        
        # Classification
        classification = str(data.get("classification", "condition")).lower()
        if "restriction" in classification or "prohibit" in classification:
            normalized["classification"] = "restriction"
        else:
            normalized["classification"] = "condition"
        
        normalized["classification_reasoning"] = str(data.get("classification_reasoning", ""))
        
        return normalized
    
    def _safe_extract_citations(self, citations_raw: Any) -> List[Dict[str, str]]:
        """
        FIXED: Safely extract citations, preventing character splitting
        """
        citations = []
        
        if not citations_raw:
            return citations
            
        if isinstance(citations_raw, list):
            for cite in citations_raw:
                if isinstance(cite, dict):
                    text = str(cite.get("text", "")).strip()
                    if len(text) >= 10:  # Minimum length
                        citations.append({
                            "text": text,
                            "reasoning": str(cite.get("reasoning", ""))
                        })
                elif isinstance(cite, str) and len(cite.strip()) >= 10:
                    citations.append({
                        "text": cite.strip(),
                        "reasoning": ""
                    })
        elif isinstance(citations_raw, str) and len(citations_raw.strip()) >= 10:
            citations.append({
                "text": citations_raw.strip(),
                "reasoning": ""
            })
        
        return citations
    
    def _extract_complete_from_text(
        self,
        text: str,
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """
        COMPLETE text extraction - fallback with proper formatting
        FIXED: Prevents character-by-character splitting
        """
        result = {
            "description": "",
            "citations": [],
            "data_actions": [],
            "user_evidence": [],
            "system_evidence": [],
            "constraints": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": ""
        }
        
        lines = text.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if not line or len(line) < 10:  # FIXED: Skip very short lines
                continue
            
            line_lower = line.lower()
            
            # Section identification
            if "description:" in line_lower:
                current_section = "description"
                desc = line.split(":", 1)[1].strip() if ":" in line else ""
                if len(desc) >= 20:
                    result["description"] = desc
            elif "citation" in line_lower:
                current_section = "citations"
            elif "data action" in line_lower or "action:" in line_lower:
                current_section = "data_actions"
            elif "user evidence" in line_lower or "user perspective" in line_lower or "user requirement" in line_lower:
                current_section = "user_evidence"
            elif "system evidence" in line_lower or "system perspective" in line_lower or "system requirement" in line_lower:
                current_section = "system_evidence"
            elif "constraint" in line_lower or "condition" in line_lower:
                current_section = "constraints"
            elif "enterprise polic" in line_lower or "organizational polic" in line_lower:
                current_section = "enterprise_policies"
            elif "classification:" in line_lower:
                if "restriction" in line_lower or "prohibit" in line_lower:
                    result["classification"] = "restriction"
                else:
                    result["classification"] = "condition"
            elif current_section and (line.startswith("-") or line.startswith("â€¢") or line.startswith("*")):
                # FIXED: Extract full item, not character by character
                item = line.lstrip("-â€¢* ").strip()
                
                if len(item) >= 15:  # CRITICAL: Minimum length to prevent character bullets
                    if current_section == "citations":
                        result["citations"].append({
                            "text": item,
                            "chunk_id": chunk_id,
                            "level": level,
                            "reasoning": "Text extraction"
                        })
                    elif current_section == "data_actions":
                        action_type = self._map_to_taxonomy(item)
                        result["data_actions"].append({
                            "type": action_type,
                            "description": item,
                            "citations": [],
                            "thought_process": "Extracted from text"
                        })
                    elif current_section == "user_evidence":
                        result["user_evidence"].append({
                            "description": item,
                            "citations": [],
                            "thought_process": "User requirement extracted from text"
                        })
                    elif current_section == "system_evidence":
                        result["system_evidence"].append({
                            "description": item,
                            "citations": [],
                            "thought_process": "System requirement extracted from text"
                        })
                    elif current_section == "constraints":
                        result["constraints"].append({
                            "type": "general",
                            "description": item,
                            "left_operand": "",
                            "operator": "eq",
                            "right_operand": True,
                            "scope": "general",
                            "citations": [],
                            "thought_process": "Constraint extracted from text",
                            "chunk_id": chunk_id,
                            "level": level
                        })
        
        # Fallback description
        if not result["description"] and text:
            result["description"] = text[:500]
            result["citations"].append({
                "text": text[:200],
                "chunk_id": chunk_id,
                "level": level,
                "reasoning": "Fallback citation"
            })
        
        logger.info(f"Text extraction: {len(result['user_evidence'])} user evidence, "
                   f"{len(result['system_evidence'])} system evidence items")
        
        return result
    
    def _map_to_taxonomy(self, action_type: str) -> str:
        """Map action to simplified taxonomy"""
        action_lower = action_type.lower().strip()
        
        if any(word in action_lower for word in ['share', 'transfer', 'disclose', 'access', 'provide', 'send']):
            return DataActionType.DATA_SHARING_AND_ACCESS
        
        if any(word in action_lower for word in ['store', 'host', 'retain', 'keep', 'maintain', 'archive']):
            return DataActionType.DATA_STORAGE_AND_HOSTING
        
        return DataActionType.DATA_USAGE
    
    def _merge_chunk_analyses_complete(
        self,
        chunk_analyses: List[Dict[str, Any]],
        rule_name: str,
        jurisdiction: str,
        level: int,
        enterprise_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        COMPLETE merge - FIXED to prevent character splitting during merge
        """
        if not chunk_analyses:
            return self._empty_analysis(rule_name, jurisdiction, level, enterprise_context)
        
        # Merge descriptions
        descriptions = [c.get("description", "") for c in chunk_analyses if c.get("description") and len(c.get("description", "")) >= 20]
        merged_description = " ".join(descriptions).strip()
        
        # Deduplicate all components properly
        all_citations = []
        seen_citations = set()
        for chunk in chunk_analyses:
            citations = chunk.get("citations", [])
            if isinstance(citations, list):
                for cite in citations:
                    if isinstance(cite, dict):
                        cite_text = cite.get("text", "")[:50]
                        if cite_text and len(cite_text) >= 10 and cite_text not in seen_citations:
                            all_citations.append(cite)
                            seen_citations.add(cite_text)
        
        all_actions = []
        seen_actions = set()
        for chunk in chunk_analyses:
            actions = chunk.get("data_actions", [])
            if isinstance(actions, list):
                for action in actions:
                    if isinstance(action, dict):
                        desc = action.get("description", "")
                        key = (action.get("type", ""), desc[:50])
                        if len(desc) >= 10 and key not in seen_actions:
                            all_actions.append(action)
                            seen_actions.add(key)
        
        all_constraints = []
        seen_constraints = set()
        for chunk in chunk_analyses:
            constraints = chunk.get("constraints", [])
            if isinstance(constraints, list):
                for constraint in constraints:
                    if isinstance(constraint, dict):
                        desc = constraint.get("description", "")
                        key = (constraint.get("type", ""), desc[:50], constraint.get("operator", ""))
                        if len(desc) >= 15 and key not in seen_constraints:
                            all_constraints.append(constraint)
                            seen_constraints.add(key)
        
        # FIXED: User evidence deduplication with proper length check
        all_user_evidence = []
        seen_user = set()
        for chunk in chunk_analyses:
            evidence_list = chunk.get("user_evidence", [])
            if isinstance(evidence_list, list):
                for evidence in evidence_list:
                    if isinstance(evidence, dict):
                        desc = evidence.get("description", "")
                        desc_key = desc[:50]
                        # CRITICAL: Only add if description is substantial
                        if len(desc) >= 15 and desc_key not in seen_user:
                            all_user_evidence.append(evidence)
                            seen_user.add(desc_key)
        
        # FIXED: System evidence deduplication with proper length check
        all_system_evidence = []
        seen_system = set()
        for chunk in chunk_analyses:
            evidence_list = chunk.get("system_evidence", [])
            if isinstance(evidence_list, list):
                for evidence in evidence_list:
                    if isinstance(evidence, dict):
                        desc = evidence.get("description", "")
                        desc_key = desc[:50]
                        # CRITICAL: Only add if description is substantial
                        if len(desc) >= 15 and desc_key not in seen_system:
                            all_system_evidence.append(evidence)
                            seen_system.add(desc_key)
        
        all_enterprise_policies = []
        seen_policies = set()
        for chunk in chunk_analyses:
            policies = chunk.get("enterprise_policies", [])
            if isinstance(policies, list):
                for policy in policies:
                    if isinstance(policy, dict):
                        policy_name = policy.get("policy_name", "")
                        if len(policy_name) >= 5 and policy_name not in seen_policies:
                            all_enterprise_policies.append(policy)
                            seen_policies.add(policy_name)
        
        classifications = [c.get("classification", "") for c in chunk_analyses if c.get("classification")]
        final_classification = "condition"
        if "restriction" in classifications:
            final_classification = "restriction"
        elif classifications:
            final_classification = classifications[0]
        
        reasonings = [c.get("classification_reasoning", "") for c in chunk_analyses if c.get("classification_reasoning")]
        combined_reasoning = "; ".join(reasonings).strip()
        
        final = {
            "description": merged_description,
            "citations": all_citations,
            "data_actions": all_actions,
            "constraints": all_constraints,
            "user_evidence": all_user_evidence,
            "system_evidence": all_system_evidence,
            "enterprise_policies": all_enterprise_policies,
            "classification": final_classification,
            "classification_reasoning": combined_reasoning,
            "level": level,
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level,
                "document_length": sum(len(c.get("description", "")) for c in chunk_analyses),
                "chunks_processed": len(chunk_analyses),
                "enterprise_context": enterprise_context,
                "total_citations": len(all_citations),
                "total_actions": len(all_actions),
                "total_constraints": len(all_constraints),
                "total_user_evidence": len(all_user_evidence),
                "total_system_evidence": len(all_system_evidence),
                "total_enterprise_policies": len(all_enterprise_policies)
            }
        }
        
        print(f"\nâœ“ Merge complete:")
        print(f"  Description: {len(merged_description)} chars")
        print(f"  Citations: {len(all_citations)} (each with text & reasoning)")
        print(f"  Actions: {len(all_actions)} (each with citations & thought process)")
        print(f"  Constraints: {len(all_constraints)} (each with citations & thought process)")
        print(f"  User Evidence: {len(all_user_evidence)} (each with citations & thought process)")
        print(f"  System Evidence: {len(all_system_evidence)} (each with citations & thought process)")
        print(f"  Enterprise Policies: {len(all_enterprise_policies)} (each with citations & thought process)")
        print(f"  Classification: {final_classification}")
        
        return final
    
    def _empty_analysis(self, rule_name: str, jurisdiction: str, level: int, enterprise_context: Optional[Dict]) -> Dict:
        """Return empty analysis structure"""
        return {
            "description": "",
            "citations": [],
            "data_actions": [],
            "constraints": [],
            "user_evidence": [],
            "system_evidence": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": "",
            "level": level,
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level,
                "chunks_processed": 0,
                "enterprise_context": enterprise_context
            }
        }
    
    def _add_to_knowledge_graph(self, rule_id: str, analysis: Dict[str, Any], level: int):
        """Add analysis to knowledge graph"""
        self.knowledge_graph.add_rule(rule_id, {
            'description': analysis.get('description'),
            'level': level,
            'classification': analysis.get('classification')
        })
        
        for i, constraint in enumerate(analysis.get('constraints', [])):
            constraint_id = f"{rule_id}_constraint_{i}"
            constraint_obj = Constraint(
                type=constraint.get('type', 'general'),
                description=constraint.get('description', ''),
                left_operand=constraint.get('left_operand', ''),
                operator=constraint.get('operator', 'eq'),
                right_operand=constraint.get('right_operand'),
                scope=constraint.get('scope', 'general'),
                thought_process=constraint.get('thought_process', '')
            )
            self.knowledge_graph.add_constraint(constraint_id, constraint_obj, rule_id)
        
        for i, action in enumerate(analysis.get('data_actions', [])):
            action_id = f"{rule_id}_action_{i}"
            self.knowledge_graph.add_action(action_id, action, rule_id)
        
        for i, evidence in enumerate(analysis.get('user_evidence', [])):
            evidence_id = f"{rule_id}_user_evidence_{i}"
            self.knowledge_graph.add_evidence(evidence_id, evidence, rule_id, 'user')
            
        for i, evidence in enumerate(analysis.get('system_evidence', [])):
            evidence_id = f"{rule_id}_system_evidence_{i}"
            self.knowledge_graph.add_evidence(evidence_id, evidence, rule_id, 'system')
        
        for i, policy in enumerate(analysis.get('enterprise_policies', [])):
            policy_id = f"{rule_id}_policy_{i}"
            policy_obj = EnterprisePolicy(
                policy_name=policy.get('policy_name', ''),
                description=policy.get('description', ''),
                organization=policy.get('organization', ''),
                applies_to=policy.get('applies_to', []),
                internal_tools=policy.get('internal_tools', []),
                level=level,
                thought_process=policy.get('thought_process', '')
            )
            self.knowledge_graph.add_enterprise_policy(policy_id, policy_obj, rule_id)
    
    def analyze_multi_level(
        self,
        rule_name: str,
        jurisdiction: str,
        level_1_text: str,
        level_2_text: str,
        level_3_text: str,
        enterprise_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """COMPLETE multi-level analysis with supervisor reasoning"""
        print(f"\n{'#'*60}")
        print(f"# MULTI-LEVEL ANALYSIS: {rule_name}")
        print(f"# WITH SUPERVISOR VALIDATION & KNOWLEDGE GRAPH REASONING")
        print(f"{'#'*60}")
        
        print(f"\n>>> LEVEL 1: LEGISLATION ({len(level_1_text)} chars)")
        level_1_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_1_text,
            level=1,
            enterprise_context=enterprise_context
        )
        
        print(f"\n>>> LEVEL 2: GUIDANCE ({len(level_2_text)} chars)")
        level_2_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_2_text,
            level=2,
            enterprise_context=enterprise_context
        )
        
        print(f"\n>>> LEVEL 3: ENTERPRISE POLICIES ({len(level_3_text)} chars)")
        level_3_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_3_text,
            level=3,
            enterprise_context=enterprise_context
        )
        
        print(f"\n>>> SUPERVISOR: REASONING ABOUT LEVEL RELATIONSHIPS")
        level_reasoning = self.supervisor.reason_about_levels(
            level_1_analysis,
            level_2_analysis,
            level_3_analysis
        )
        
        print(f"\n>>> COMBINING ALL LEVELS")
        
        # Combine all citations
        combined_citations = (
            level_1_analysis.get("citations", []) +
            level_2_analysis.get("citations", []) +
            level_3_analysis.get("citations", [])
        )
        
        # Combine all data actions
        combined_data_actions = (
            level_1_analysis.get("data_actions", []) +
            level_2_analysis.get("data_actions", []) +
            level_3_analysis.get("data_actions", [])
        )
        
        # Combine all constraints
        combined_constraints = (
            level_1_analysis.get("constraints", []) +
            level_2_analysis.get("constraints", []) +
            level_3_analysis.get("constraints", [])
        )
        
        # Combine all user evidence
        combined_user_evidence = (
            level_1_analysis.get("user_evidence", []) +
            level_2_analysis.get("user_evidence", []) +
            level_3_analysis.get("user_evidence", [])
        )
        
        # Combine all system evidence
        combined_system_evidence = (
            level_1_analysis.get("system_evidence", []) +
            level_2_analysis.get("system_evidence", []) +
            level_3_analysis.get("system_evidence", [])
        )
        
        # Combine all enterprise policies
        combined_enterprise_policies = (
            level_1_analysis.get("enterprise_policies", []) +
            level_2_analysis.get("enterprise_policies", []) +
            level_3_analysis.get("enterprise_policies", [])
        )
        
        # Build combined dictionary with all pre-computed values
        combined = {
            "description": " ".join([
                level_1_analysis.get("description", ""),
                level_2_analysis.get("description", ""),
                level_3_analysis.get("description", "")
            ]).strip(),
            
            "citations": combined_citations,
            "data_actions": combined_data_actions,
            "constraints": combined_constraints,
            "user_evidence": combined_user_evidence,
            "system_evidence": combined_system_evidence,
            "enterprise_policies": combined_enterprise_policies,
            
            "classification": level_1_analysis.get("classification", "condition"),
            
            "classification_reasoning": "; ".join([
                level_1_analysis.get("classification_reasoning", ""),
                level_2_analysis.get("classification_reasoning", ""),
                level_3_analysis.get("classification_reasoning", "")
            ]).strip(),
            
            "level_reasoning": level_reasoning,
            "knowledge_graph_stats": self.knowledge_graph.get_statistics(),
            
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "enterprise_context": enterprise_context,
                "level_1_chunks": level_1_analysis.get("metadata", {}).get("chunks_processed", 0),
                "level_2_chunks": level_2_analysis.get("metadata", {}).get("chunks_processed", 0),
                "level_3_chunks": level_3_analysis.get("metadata", {}).get("chunks_processed", 0),
                "total_citations": len(combined_citations),
                "total_actions": len(combined_data_actions),
                "total_constraints": len(combined_constraints),
                "total_user_evidence": len(combined_user_evidence),
                "total_system_evidence": len(combined_system_evidence),
                "total_enterprise_policies": len(combined_enterprise_policies)
            }
        }
        
        print(f"\n{'#'*60}")
        print(f"# MULTI-LEVEL ANALYSIS COMPLETE")
        print(f"{'#'*60}")
        print(f"Total description: {len(combined['description'])} chars")
        print(f"Total citations: {len(combined_citations)} (each with reasoning)")
        print(f"Total actions: {len(combined_data_actions)} (each with citations & thought process)")
        print(f"Total constraints: {len(combined_constraints)} (each with citations & thought process)")
        print(f"Total user evidence: {len(combined_user_evidence)} (each with citations & thought process)")
        print(f"Total system evidence: {len(combined_system_evidence)} (each with citations & thought process)")
        print(f"Total enterprise policies: {len(combined_enterprise_policies)} (each with citations & thought process)")
        print(f"Classification: {combined['classification']}")
        
        print(f"\n{'='*60}")
        print(f"KNOWLEDGE GRAPH STATISTICS:")
        for key, value in combined["knowledge_graph_stats"].items():
            print(f"  {key}: {value}")
        
        print(f"\n{'='*60}")
        print(f"LEVEL REASONING:")
        for key, value in level_reasoning.items():
            print(f"  {key}: {value}")
        
        return combined
