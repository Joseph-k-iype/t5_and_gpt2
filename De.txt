import json
import csv
import os

def create_dashboard_csv(data: dict, output_dir: str):
    """
    Converts the entire nested JSON into a single, flattened CSV file
    suitable for a dashboard.

    Args:
        data (dict): The dictionary loaded from the JSON file.
        output_dir (str): The path to the folder for output files.
    """
    # 1. Pre-process simplified rules into a lookup dictionary for efficiency
    simplified_rules_lookup = {}
    for rule in data.get("unified_simplified_rules", []):
        rule_id = rule.get("rule_id")
        if rule_id:
            # Pre-flatten lists into strings
            rule['conditions'] = "; ".join(rule.get('conditions', []))
            rule['key_phrases'] = "; ".join(map(str, rule.get('key_phrases', [])))
            simplified_rules_lookup[rule_id] = rule

    flat_data_rows = []
    
    # 2. Iterate through the nested decision table structure
    decision_tables = data.get("unified_decision_tables", {}).get("decision_tables", [])

    for table in decision_tables:
        for rule in table.get("rules", []):
            source_rule_id = rule.get("source_rule")
            # Get the corresponding simplified rule data from the lookup
            simplified_rule_data = simplified_rules_lookup.get(source_rule_id, {})

            # Base information for the row, combining table, rule, and simplified rule data
            base_row = {
                # Table Info (prefixed with 'table_')
                'table_id': table.get('table_id'),
                'table_name': table.get('name'),
                'table_description': table.get('description'),
                
                # Decision Table Rule Info (prefixed with 'dt_rule_')
                'dt_rule_id': rule.get('rule_id'),
                'dt_rule_priority': rule.get('priority'),
                'dt_rule_conditions': "; ".join([f"{k}:{v}" for k, v in rule.get("conditions", {}).items()]),
                'dt_rule_actions': "; ".join(rule.get("actions", [])),

                # Simplified Rule Info (prefixed with 'sr_')
                'sr_rule_id': simplified_rule_data.get('rule_id'),
                'sr_rule_text': simplified_rule_data.get('rule_text'),
                'sr_conditions': simplified_rule_data.get('conditions'),
                'sr_domain': simplified_rule_data.get('domain'),
                'sr_role': simplified_rule_data.get('role'),
                'sr_confidence': simplified_rule_data.get('confidence'),
                'sr_deontic_type': simplified_rule_data.get('deontic_type'),
                'sr_source_document': simplified_rule_data.get('source_document'),
                'sr_legal_authority': simplified_rule_data.get('legal_authority'),
                'sr_jurisdiction': simplified_rule_data.get('jurisdiction'),
                'sr_complexity_level': simplified_rule_data.get('complexity_level'),
                'sr_key_phrases': simplified_rule_data.get('key_phrases')
            }

            references = rule.get("references", [])
            # If a rule has no references, create one row for the rule itself
            if not references:
                flat_data_rows.append(base_row)
            else:
                # If there are references, create a new row for each one
                for reference in references:
                    # Copy the base info and add the specific reference info
                    final_row = base_row.copy()
                    for key, value in reference.items():
                        # Add a 'ref_' prefix to all reference keys to avoid conflicts
                        final_row[f'ref_{key}'] = value
                    flat_data_rows.append(final_row)
    
    # 3. Write the fully flattened data to a single CSV
    if not flat_data_rows:
        print("‚ö†Ô∏è No data available to write to CSV.")
        return

    output_path = os.path.join(output_dir, 'dashboard_data.csv')
    try:
        # Dynamically create headers from all keys found across all rows
        all_headers = set().union(*(d.keys() for d in flat_data_rows))
        
        # Define a logical order for columns
        ordered_headers = sorted([h for h in all_headers if not h.startswith('ref_')])
        ordered_headers += sorted([h for h in all_headers if h.startswith('ref_')])

        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=ordered_headers)
            writer.writeheader()
            writer.writerows(flat_data_rows)
        print(f"‚úÖ Successfully created a single flattened CSV: {output_path}")

    except Exception as e:
        print(f"‚ùå Error writing CSV file: {e}")


# --- Main Execution ---
if __name__ == "__main__":
    io_directory = 'output'
    os.makedirs(io_directory, exist_ok=True)
    input_filename = os.path.join(io_directory, 'input.json')

    try:
        with open(input_filename, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        create_dashboard_csv(json_data, io_directory)

    except FileNotFoundError:
        print(f"‚ùå Error: The file '{input_filename}' was not found.")
        print(f"üëâ Please place your JSON file inside the '{io_directory}' folder and name it 'input.json'.")
    except json.JSONDecodeError:
        print(f"‚ùå Error: The file '{input_filename}' is not a valid JSON file.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
