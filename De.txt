from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import logging
import asyncio
import sys
import os
from typing import Dict, Any
from pydantic import BaseModel

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Add current directory to path for enhanced_chatbot import
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from enhanced_chatbot import EnhancedChatbotInterface
    CHATBOT_AVAILABLE = True
    logger.info("‚úÖ Enhanced chatbot imported successfully")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Enhanced chatbot not available: {e}")
    CHATBOT_AVAILABLE = False

# Create FastAPI app
app = FastAPI(
    title="Deep Research Chatbot API",
    description="Advanced AI-powered research assistant",
    version="1.0.0",
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global chatbot instance
chatbot_interface = None

# Pydantic models
class QuickChatRequest(BaseModel):
    message: str
    session_id: str = None
    user_id: str = None

class QuickChatResponse(BaseModel):
    answer: str
    confidence: str
    approach: str
    session_id: str
    user_id: str
    timestamp: str
    metadata: Dict[str, Any] = {}

class DeepResearchRequest(BaseModel):
    topic: str
    session_id: str = None
    user_id: str = None

class ResearchResult(BaseModel):
    final_synthesis: str
    overall_confidence: float
    session_id: str
    user_id: str
    timestamp: str

# Initialize chatbot on startup
@app.on_event("startup")
async def startup_event():
    global chatbot_interface
    if CHATBOT_AVAILABLE:
        try:
            logger.info("üöÄ Initializing chatbot interface...")
            chatbot_interface = EnhancedChatbotInterface()
            
            # Initialize in thread pool to avoid blocking
            loop = asyncio.get_event_loop()
            success = await loop.run_in_executor(
                None, 
                lambda: asyncio.run(chatbot_interface.initialize())
            )
            
            if success:
                logger.info("‚úÖ Chatbot interface initialized successfully")
            else:
                logger.error("‚ùå Chatbot interface initialization failed")
        except Exception as e:
            logger.error(f"‚ùå Error initializing chatbot: {e}")
            chatbot_interface = None

# Mock session storage
sessions = {}

@app.get("/")
async def root():
    return {
        "message": "Deep Research Chatbot API",
        "status": "running",
        "chatbot_available": chatbot_interface is not None
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "chatbot_available": chatbot_interface is not None
    }

@app.post("/api/v1/chat/quick", response_model=QuickChatResponse)
async def quick_chat(request: QuickChatRequest):
    try:
        # Handle session initialization
        if request.message == "__session_init__":
            import uuid
            from datetime import datetime
            
            session_id = str(uuid.uuid4())
            user_id = request.user_id or f"user_{uuid.uuid4().hex[:8]}"
            
            sessions[session_id] = {
                "user_id": user_id,
                "created_at": datetime.utcnow().isoformat(),
                "messages": []
            }
            
            return QuickChatResponse(
                answer="Session initialized",
                confidence="high",
                approach="session_init",
                session_id=session_id,
                user_id=user_id,
                timestamp=datetime.utcnow().isoformat()
            )
        
        # Get or create session
        session_id = request.session_id or str(__import__('uuid').uuid4())
        user_id = request.user_id or f"user_{__import__('uuid').uuid4().hex[:8]}"
        
        if session_id not in sessions:
            sessions[session_id] = {
                "user_id": user_id,
                "created_at": __import__('datetime').datetime.utcnow().isoformat(),
                "messages": []
            }
        
        # Process with chatbot if available
        if chatbot_interface:
            try:
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: asyncio.run(
                        chatbot_interface.ask_question(
                            request.message,
                            user_id=user_id,
                            thread_id=session_id
                        )
                    )
                )
                
                return QuickChatResponse(
                    answer=result.get("answer", "No response"),
                    confidence=result.get("confidence", "medium"),
                    approach=result.get("approach", "chatbot"),
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=__import__('datetime').datetime.utcnow().isoformat(),
                    metadata=result.get("metadata", {})
                )
                
            except Exception as e:
                logger.error(f"Chatbot error: {e}")
                # Fallback response
                return QuickChatResponse(
                    answer=f"I understand you're asking about: '{request.message}'. However, I'm currently experiencing technical difficulties. Please try again in a moment.",
                    confidence="low",
                    approach="fallback",
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=__import__('datetime').datetime.utcnow().isoformat()
                )
        else:
            # Mock response when chatbot not available
            return QuickChatResponse(
                answer=f"Mock response for: {request.message}. The full AI research system is currently initializing.",
                confidence="medium",
                approach="mock",
                session_id=session_id,
                user_id=user_id,
                timestamp=__import__('datetime').datetime.utcnow().isoformat()
            )
            
    except Exception as e:
        logger.error(f"Quick chat error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/research/deep", response_model=ResearchResult)
async def deep_research(request: DeepResearchRequest):
    try:
        session_id = request.session_id or str(__import__('uuid').uuid4())
        user_id = request.user_id or f"user_{__import__('uuid').uuid4().hex[:8]}"
        
        if chatbot_interface:
            try:
                loop = asyncio.get_event_loop()
                result = await loop.run_in_executor(
                    None,
                    lambda: asyncio.run(
                        chatbot_interface.conduct_deep_research(
                            request.topic,
                            user_id=user_id
                        )
                    )
                )
                
                return ResearchResult(
                    final_synthesis=result.get("final_synthesis", "Research completed"),
                    overall_confidence=result.get("overall_confidence", 0.7),
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=__import__('datetime').datetime.utcnow().isoformat()
                )
                
            except Exception as e:
                logger.error(f"Research error: {e}")
                return ResearchResult(
                    final_synthesis=f"Deep research on '{request.topic}' encountered technical difficulties. The system is working to resolve this issue.",
                    overall_confidence=0.3,
                    session_id=session_id,
                    user_id=user_id,
                    timestamp=__import__('datetime').datetime.utcnow().isoformat()
                )
        else:
            # Mock research response
            return ResearchResult(
                final_synthesis=f"Mock deep research results for: {request.topic}\n\nThis is a placeholder response while the full research system initializes. The actual system would conduct comprehensive multi-agent research on this topic.",
                overall_confidence=0.5,
                session_id=session_id,
                user_id=user_id,
                timestamp=__import__('datetime').datetime.utcnow().isoformat()
            )
            
    except Exception as e:
        logger.error(f"Deep research error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# Simple knowledge graph endpoint
@app.post("/api/v1/knowledge-graph/generate")
async def generate_knowledge_graph(request: dict):
    return {
        "nodes": [],
        "edges": [],
        "metadata": {"message": "Knowledge graph generation coming soon"}
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
