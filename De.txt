import asyncio
import json
import logging
import os
import csv
import glob
import math
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, Tuple
from enum import Enum
from datetime import datetime, timedelta
from urllib.parse import urljoin

# Core dependencies
import openai
from openai import OpenAI
from pydantic import BaseModel, Field, field_validator, model_validator, ConfigDict, ValidationInfo
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from langchain_openai import ChatOpenAI

# PDF processing
try:
    import pymupdf  # Modern PyMuPDF
    PDF_AVAILABLE = True
except ImportError:
    try:
        import pdfplumber
        PDF_AVAILABLE = True
    except ImportError:
        PDF_AVAILABLE = False
        print("Warning: No PDF library found. Install PyMuPDF or pdfplumber: pip install PyMuPDF pdfplumber")

# Optional: RDF library for advanced semantic processing
try:
    import rdflib
    from rdflib import Graph, Namespace, URIRef, Literal, BNode
    from rdflib.namespace import RDF, RDFS, XSD
    import urllib.parse
    RDF_AVAILABLE = True
    print("RDFLib available for advanced RDF processing")
except ImportError:
    RDF_AVAILABLE = False
    print("Warning: RDFLib not found. Install with: pip install rdflib")
    pass

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===============================
# GLOBAL CONFIGURATION
# ===============================

class Config:
    """Global configuration for the legislation rules converter."""
    BASE_URL = "https://api.openai.com/v1"
    API_KEY = os.getenv("OPENAI_API_KEY")
    CHAT_MODEL = "o3-mini-2025-01-31"
    EMBEDDING_MODEL = "text-embedding-3-large"
    
    # Paths
    LEGISLATION_PDF_PATH = "./legislation_pdfs/"
    RULES_OUTPUT_PATH = "./extracted_rules/"
    EMBEDDINGS_PATH = "./embeddings/"
    LOGS_PATH = "./logs/"
    EXISTING_RULES_FILE = "./extracted_rules/all_rules.json"
    METADATA_CONFIG_FILE = "./legislation_metadata.json"
    
    # Combined Standards Output Path
    STANDARDS_OUTPUT_PATH = "./standards_output/"
    
    # Updated Standard Namespaces - Latest DPV v2.1
    DPV_NAMESPACE = "https://w3id.org/dpv#"
    DPV_PD_NAMESPACE = "https://w3id.org/dpv/dpv-pd#"
    DPV_TECH_NAMESPACE = "https://w3id.org/dpv/tech#"
    DPV_LEGAL_NAMESPACE = "https://w3id.org/dpv/legal/"
    ODRL_NAMESPACE = "http://www.w3.org/ns/odrl/2/"
    DPVCG_NAMESPACE = "https://w3id.org/dpv/"
    ACTION_NAMESPACE = "https://w3id.org/dpv/actions#"
    
    # PDF Processing Configuration
    CHUNK_SIZE = 4000  # Characters per chunk for large documents
    OVERLAP_SIZE = 200  # Character overlap between chunks
    MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB threshold for chunking

# Validate API key
if not Config.API_KEY:
    raise ValueError("OPENAI_API_KEY environment variable is required")

# ===============================
# ENHANCED DATA MODELS WITH PYDANTIC V2
# ===============================

class DataDomain(str, Enum):
    """Data domains as per privacy regulations."""
    DATA_TRANSFER = "data_transfer"
    DATA_USAGE = "data_usage" 
    DATA_STORAGE = "data_storage"
    DATA_COLLECTION = "data_collection"
    DATA_DELETION = "data_deletion"

class DataRole(str, Enum):
    """Roles in data processing."""
    CONTROLLER = "controller"
    PROCESSOR = "processor"
    JOINT_CONTROLLER = "joint_controller"
    DATA_SUBJECT = "data_subject"

class DataCategory(str, Enum):
    """Categories of personal data."""
    PERSONAL_DATA = "personal_data"
    SENSITIVE_DATA = "sensitive_data"
    BIOMETRIC_DATA = "biometric_data"
    HEALTH_DATA = "health_data"
    FINANCIAL_DATA = "financial_data"
    LOCATION_DATA = "location_data"
    BEHAVIORAL_DATA = "behavioral_data"
    IDENTIFICATION_DATA = "identification_data"

class ConditionOperator(str, Enum):
    """Operators for rule conditions."""
    EQUAL = "equal"
    NOT_EQUAL = "notEqual"
    GREATER_THAN = "greaterThan"
    LESS_THAN = "lessThan"
    GREATER_THAN_EQUAL = "greaterThanInclusive"
    LESS_THAN_EQUAL = "lessThanInclusive"
    CONTAINS = "contains"
    NOT_CONTAINS = "doesNotContain"
    IN = "in"
    NOT_IN = "notIn"

class DocumentLevel(str, Enum):
    """Document processing levels."""
    LEVEL_1 = "level_1"  # Actual legislation
    LEVEL_2 = "level_2"  # Regulator guidance
    LEVEL_3 = "level_3"  # Additional guidance

# GDPR Processing Purposes - Updated to match GDPR specifications
class ProcessingPurpose(str, Enum):
    """GDPR-compliant processing purposes."""
    CONSENT = "consent"
    CONTRACTUAL_NECESSITY = "contractual_necessity"
    LEGAL_OBLIGATION = "legal_obligation"
    VITAL_INTERESTS = "vital_interests"
    PUBLIC_TASK = "public_task"
    LEGITIMATE_INTERESTS = "legitimate_interests"

# GDPR Legal Basis - Updated to match GDPR specifications
class LegalBasis(str, Enum):
    """GDPR-compliant legal basis."""
    CONSENT = "consent"
    CONTRACTUAL_OBLIGATION = "contractual_obligation"
    LEGAL_OBLIGATION = "legal_obligation"
    VITAL_INTERESTS = "vital_interests"
    PUBLIC_INTEREST_OFFICIAL_AUTHORITY = "public_interest_official_authority"
    LEGITIMATE_INTERESTS = "legitimate_interests"

# RuleAction class - Updated for better inference
class RuleAction(BaseModel):
    """Action that can be taken based on a rule - inferred from legislation."""
    model_config = ConfigDict(use_enum_values=True)
    
    id: str = Field(..., description="Unique action identifier")
    action_type: str = Field(..., description="Type of action inferred from legislation")
    title: str = Field(..., description="Action title in simple English")
    description: str = Field(..., description="What must be done in simple English")
    priority: str = Field(..., description="Action priority based on legislative language")
    
    # Implementation details
    data_specific_steps: List[str] = Field(..., description="Specific steps for data handling")
    responsible_role: Optional[str] = Field(None, description="Who is responsible for this action")
    
    # Compliance context
    legislative_requirement: str = Field(..., description="Specific legislative requirement")
    data_impact: str = Field(..., description="How this affects data processing")
    verification_method: List[str] = Field(default_factory=list, description="How to verify completion")
    
    # Optional timeline
    timeline: Optional[str] = Field(None, description="Timeline if specified in legislation")
    
    # Metadata
    derived_from_text: str = Field(..., description="Legislative text this action was derived from")
    applicable_countries: List[str] = Field(default_factory=list, description="Countries where action applies")
    confidence_score: float = Field(..., ge=0.0, le=1.0, description="Confidence in action relevance")

# UserAction class - For user-specific inference
class UserAction(BaseModel):
    """Specific user action inferred from legislation."""
    model_config = ConfigDict(use_enum_values=True)
    
    id: str = Field(..., description="Unique user action identifier")
    action_type: str = Field(..., description="Type of data action user must perform")
    title: str = Field(..., description="Clear action title in simple English")
    description: str = Field(..., description="What the user must do in simple English")
    priority: str = Field(..., description="Priority level based on legislative context")
    
    # User-specific implementation details
    user_data_steps: List[str] = Field(..., description="Concrete steps for user data handling")
    affected_data_categories: List[str] = Field(default_factory=list, description="Data categories affected")
    user_role_context: Optional[str] = Field(None, description="User's role when performing this action")
    
    # Legislative basis
    legislative_requirement: str = Field(..., description="Specific legal requirement")
    compliance_outcome: str = Field(..., description="What compliance outcome this achieves")
    user_verification_steps: List[str] = Field(default_factory=list, description="How user can verify completion")
    
    # Implementation guidance for users
    timeline: Optional[str] = Field(None, description="Timeline if specified in legislation")
    prerequisites: List[str] = Field(default_factory=list, description="What must be done before this action")
    tools_needed: List[str] = Field(default_factory=list, description="Tools/systems user needs")
    
    # Metadata
    derived_from_text: str = Field(..., description="Legislative text this action was derived from")
    confidence_score: float = Field(..., ge=0.0, le=1.0, description="Confidence in action inference")

class RuleCondition(BaseModel):
    """Individual condition within a rule."""
    model_config = ConfigDict(use_enum_values=True)
    
    fact: str = Field(..., description="The fact/data point to evaluate")
    operator: ConditionOperator = Field(..., description="Comparison operator")
    value: Union[str, int, float, bool, List[Any]] = Field(..., description="Value to compare against")
    path: Optional[str] = Field(None, description="JSONPath to navigate nested objects")
    description: str = Field(..., description="Human-readable description of this condition")
    data_domain: List[DataDomain] = Field(default_factory=list, description="Applicable data domains")
    role: Optional[DataRole] = Field(None, description="Role this condition applies to")
    reasoning: str = Field(..., description="LLM reasoning for why this condition was extracted")
    document_level: DocumentLevel = Field(..., description="Document level this condition was extracted from")
    chunk_reference: Optional[str] = Field(None, description="Reference to source chunk if document was chunked")

    @field_validator('data_domain', mode='before')
    @classmethod
    def validate_data_domain(cls, v):
        if not v:
            return []
        if isinstance(v, list):
            result = []
            for item in v:
                if isinstance(item, str):
                    try:
                        result.append(DataDomain(item))
                    except ValueError:
                        continue
                elif isinstance(item, DataDomain):
                    result.append(item)
            return result
        return []

    @field_validator('role', mode='before')
    @classmethod
    def validate_role(cls, v):
        if v is None:
            return None
        if isinstance(v, str):
            try:
                return DataRole(v)
            except ValueError:
                return None
        elif isinstance(v, DataRole):
            return v
        return None

    @field_validator('operator', mode='before')
    @classmethod
    def validate_operator(cls, v):
        if isinstance(v, str):
            try:
                return ConditionOperator(v)
            except ValueError:
                return ConditionOperator.EQUAL
        elif isinstance(v, ConditionOperator):
            return v
        return ConditionOperator.EQUAL

    @field_validator('document_level', mode='before')
    @classmethod
    def validate_document_level(cls, v):
        if isinstance(v, str):
            try:
                return DocumentLevel(v)
            except ValueError:
                return DocumentLevel.LEVEL_1
        elif isinstance(v, DocumentLevel):
            return v
        return DocumentLevel.LEVEL_1

class RuleEvent(BaseModel):
    """Event triggered when rule conditions are met."""
    type: str = Field(..., description="Type of event/action")
    params: Dict[str, Any] = Field(default_factory=dict, description="Event parameters")

class LegislationRule(BaseModel):
    """Complete rule structure aligned with json-rules-engine format."""
    model_config = ConfigDict(use_enum_values=True)
    
    id: str = Field(..., description="Unique rule identifier")
    name: str = Field(..., description="Rule name")
    description: str = Field(..., description="Human-readable rule description")
    source_article: str = Field(..., description="Source legislation article/section")
    source_file: str = Field(..., description="Source PDF filename")
    
    conditions: Dict[str, List[RuleCondition]] = Field(
        ..., 
        description="Rule conditions with 'all', 'any', or 'not' logic"
    )
    event: RuleEvent = Field(..., description="Event triggered when conditions are met")
    
    # Actions - Now optional to allow inference
    actions: List[RuleAction] = Field(default_factory=list, description="Actions inferred from legislative text")
    user_actions: List[UserAction] = Field(default_factory=list, description="User-specific actions inferred from legislation")
    
    priority: int = Field(default=1, description="Rule priority (1-10)")
    
    # Required fields with validation
    primary_impacted_role: Optional[DataRole] = Field(None, description="Primary role most impacted by this rule")
    secondary_impacted_role: Optional[DataRole] = Field(None, description="Secondary role impacted by this rule")
    data_category: List[DataCategory] = Field(default_factory=list, description="Categories of data this rule applies to")
    
    # Updated country metadata structure
    applicable_countries: List[str] = Field(..., description="Countries where this rule applies")
    adequacy_countries: List[str] = Field(default_factory=list, description="Adequacy countries")
    
    # Document levels processed
    source_documents: Dict[str, Optional[str]] = Field(default_factory=dict, description="Source documents by level")
    processing_metadata: Dict[str, Any] = Field(default_factory=dict, description="Processing metadata including chunking info")
    
    # Metadata
    extracted_at: datetime = Field(default_factory=datetime.utcnow)
    extraction_method: str = Field(default="llm_analysis_with_inferred_actions")
    confidence_score: float = Field(..., ge=0.0, le=1.0, description="Extraction confidence")

    @field_validator('conditions', mode='after')
    @classmethod
    def validate_conditions_structure(cls, v):
        if not isinstance(v, dict):
            raise ValueError("Conditions must be a dictionary")
        valid_keys = {'all', 'any', 'not'}
        if not any(key in valid_keys for key in v.keys()):
            raise ValueError("Conditions must contain 'all', 'any', or 'not' keys")
        return v

    # Remove the mandatory actions validation
    @field_validator('actions', mode='after')
    @classmethod
    def validate_actions_optional(cls, v):
        # Actions are now optional - they will be inferred if possible
        return v if v is not None else []

    @field_validator('primary_impacted_role', mode='before')
    @classmethod
    def validate_primary_role(cls, v):
        if v is None:
            return None
        if isinstance(v, str):
            try:
                return DataRole(v)
            except ValueError:
                return None
        elif isinstance(v, DataRole):
            return v
        return None

    @field_validator('secondary_impacted_role', mode='before')
    @classmethod
    def validate_secondary_role(cls, v):
        if v is None:
            return None
        if isinstance(v, str):
            try:
                return DataRole(v)
            except ValueError:
                return None
        elif isinstance(v, DataRole):
            return v
        return None

    @field_validator('data_category', mode='before')
    @classmethod
    def validate_data_category(cls, v):
        if not v:
            return []
        if isinstance(v, list):
            result = []
            for item in v:
                if isinstance(item, str):
                    try:
                        result.append(DataCategory(item))
                    except ValueError:
                        continue
                elif isinstance(item, DataCategory):
                    result.append(item)
            return result
        return []

# ===============================
# UPDATED METADATA STRUCTURE
# ===============================

class CountryMetadata(BaseModel):
    """Updated metadata for country configurations."""
    model_config = ConfigDict(validate_assignment=True)
    
    country: List[str] = Field(..., description="List of applicable countries")
    adequacy_country: List[str] = Field(default_factory=list, description="List of adequacy countries")
    file_level_1: Optional[str] = Field(None, description="Level 1 document (actual legislation)")
    file_level_2: Optional[str] = Field(None, description="Level 2 document (regulator guidance)")
    file_level_3: Optional[str] = Field(None, description="Level 3 document (additional guidance)")

    @field_validator('country', mode='after')
    @classmethod
    def validate_country_not_empty(cls, v):
        if not v:
            raise ValueError("At least one country must be specified")
        return v

class MetadataManager:
    """Manages legislation metadata configuration."""
    
    def __init__(self, config_file: str = Config.METADATA_CONFIG_FILE):
        self.config_file = config_file
        self.metadata: Dict[str, Any] = {}
        self.load_metadata()
    
    def load_metadata(self):
        """Load metadata from config file."""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                logger.info(f"Loaded metadata for {len(self.metadata)} configurations")
            else:
                logger.warning(f"Metadata config file not found: {self.config_file}")
                logger.warning("Please create legislation_metadata.json with your legislation configuration")
                self.metadata = {}
        except Exception as e:
            logger.error(f"Error loading metadata: {e}")
            self.metadata = {}
    
    def get_country_metadata(self, entry_id: str) -> Optional[CountryMetadata]:
        """Get metadata for a specific entry."""
        if entry_id in self.metadata:
            try:
                return CountryMetadata(**self.metadata[entry_id])
            except Exception as e:
                logger.error(f"Error parsing metadata for {entry_id}: {e}")
                return None
        return None
    
    def get_all_processing_entries(self) -> List[Tuple[str, CountryMetadata]]:
        """Get all processing entries."""
        entries = []
        for entry_id, data in self.metadata.items():
            try:
                metadata = CountryMetadata(**data)
                entries.append((entry_id, metadata))
            except Exception as e:
                logger.warning(f"Skipping invalid entry {entry_id}: {e}")
        return entries

# ===============================
# PDF PROCESSING WITH DYNAMIC CHUNKING
# ===============================

class DocumentChunk:
    """Represents a chunk of a document."""
    def __init__(self, content: str, chunk_index: int, total_chunks: int, start_pos: int, end_pos: int):
        self.content = content
        self.chunk_index = chunk_index
        self.total_chunks = total_chunks
        self.start_pos = start_pos
        self.end_pos = end_pos
        self.chunk_id = f"chunk_{chunk_index}_{total_chunks}"

class PDFProcessor:
    """Enhanced PDF processor with dynamic chunking for large files."""
    
    @staticmethod
    def get_file_size(filepath: str) -> int:
        """Get file size in bytes."""
        return os.path.getsize(filepath)
    
    @staticmethod
    def extract_text_from_pdf(pdf_path: str) -> str:
        """Extract text from PDF file."""
        if not PDF_AVAILABLE:
            raise ImportError("No PDF library available. Install PyMuPDF or pdfplumber")
        
        try:
            if 'pymupdf' in globals():
                return PDFProcessor._extract_with_pymupdf(pdf_path)
            else:
                return PDFProcessor._extract_with_pdfplumber(pdf_path)
        except Exception as e:
            logger.error(f"Error reading PDF {pdf_path}: {e}")
            raise
    
    @staticmethod
    def _extract_with_pymupdf(pdf_path: str) -> str:
        """Extract text using modern PyMuPDF."""
        text = ""
        try:
            with pymupdf.open(pdf_path) as doc:
                for page in doc:
                    page_text = page.get_text()
                    if page_text:
                        text += page_text + "\n"
        except Exception as e:
            logger.error(f"PyMuPDF extraction failed: {e}")
            raise
        return text
    
    @staticmethod
    def _extract_with_pdfplumber(pdf_path: str) -> str:
        """Extract text using pdfplumber."""
        text = ""
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        return text
    
    @staticmethod
    def chunk_text(text: str, chunk_size: int = Config.CHUNK_SIZE, overlap_size: int = Config.OVERLAP_SIZE) -> List[DocumentChunk]:
        """Dynamically chunk text based on size with overlaps."""
        if len(text) <= chunk_size:
            return [DocumentChunk(text, 0, 1, 0, len(text))]
        
        chunks = []
        start = 0
        chunk_index = 0
        
        # Calculate total chunks
        total_chunks = math.ceil(len(text) / (chunk_size - overlap_size))
        
        while start < len(text):
            # Calculate end position
            end = min(start + chunk_size, len(text))
            
            # Try to break at sentence boundaries if possible
            if end < len(text):
                # Look for sentence endings within the last 200 characters
                search_start = max(end - 200, start)
                sentence_endings = ['.', '!', '?', '\n\n']
                
                best_break = -1
                for ending in sentence_endings:
                    pos = text.rfind(ending, search_start, end)
                    if pos > best_break:
                        best_break = pos + 1
                
                if best_break > start:
                    end = best_break
            
            chunk_content = text[start:end].strip()
            if chunk_content:
                chunk = DocumentChunk(chunk_content, chunk_index, total_chunks, start, end)
                chunks.append(chunk)
                chunk_index += 1
            
            # Move start position with overlap
            if end >= len(text):
                break
            start = max(end - overlap_size, start + 1)
        
        return chunks
    
    @staticmethod
    def should_chunk_file(filepath: str) -> bool:
        """Determine if file should be chunked based on size."""
        file_size = PDFProcessor.get_file_size(filepath)
        return file_size > Config.MAX_FILE_SIZE

class MultiLevelPDFProcessor:
    """Process PDFs from multiple document levels with chunking support."""
    
    def __init__(self):
        self.pdf_processor = PDFProcessor()
    
    def process_country_documents(self, entry_id: str, metadata: CountryMetadata, base_path: str) -> Dict[str, Union[str, List[DocumentChunk]]]:
        """Process all documents for a country entry with dynamic chunking."""
        documents = {}
        
        # Process all available levels
        level_files = {
            "level_1": metadata.file_level_1,
            "level_2": metadata.file_level_2,
            "level_3": metadata.file_level_3
        }
        
        for level, filename in level_files.items():
            if filename:
                file_path = os.path.join(base_path, filename)
                if os.path.exists(file_path):
                    try:
                        text = self.pdf_processor.extract_text_from_pdf(file_path)
                        
                        # Check if chunking is needed
                        if self.pdf_processor.should_chunk_file(file_path):
                            logger.info(f"Chunking {level} document: {filename}")
                            chunks = self.pdf_processor.chunk_text(text)
                            documents[level] = chunks
                        else:
                            documents[level] = text
                            
                        logger.info(f"Processed {level} document: {filename}")
                    except Exception as e:
                        logger.error(f"Error processing {level} document {filename}: {e}")
                else:
                    logger.warning(f"{level} document not found: {file_path}")
        
        return documents

# ===============================
# ALL ORIGINAL ACTION INFERENCE TOOLS - RESTORED
# ===============================

@tool
def extract_rule_conditions(legislation_text: str, focus_area: str) -> str:
    """Extract specific rule conditions from legislation text."""
    
    prompt = f"""
    Extract rule conditions from the following legislation text, focusing on {focus_area}.
    
    Return conditions in json-rules-engine format based on explicit requirements in the text.
    
    Text: {legislation_text}
    
    Focus on identifying:
    - Specific facts that can be evaluated from the legislation
    - Comparison operators based on legal language
    - Values to compare against as stated in the text
    - Data domains and roles mentioned
    
    Return valid JSON only. Base conditions on explicit legislative language.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error extracting conditions: {str(e)}"

@tool
def analyze_data_domains(legislation_text: str) -> str:
    """Analyze and identify relevant data domains in legislation."""
    
    prompt = f"""
    Analyze the following legislation text and identify which data domains are mentioned:
    - data_transfer
    - data_usage
    - data_storage
    - data_collection
    - data_deletion
    
    Text: {legislation_text}
    
    Return a JSON object mapping each identified domain to its relevance and the specific text that indicates it.
    Include only domains that are mentioned in the legislation text.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error analyzing domains: {str(e)}"

@tool
def identify_roles_responsibilities(legislation_text: str) -> str:
    """Identify roles and responsibilities in legislation."""
    
    prompt = f"""
    Identify the roles and responsibilities mentioned in this legislation:
    - controller
    - processor 
    - joint_controller
    - data_subject
    
    Text: {legislation_text}
    
    For each role mentioned, identify their specific obligations and responsibilities as stated in the text.
    Return a JSON object with role mappings based on what is stated.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error identifying roles: {str(e)}"

# ORIGINAL TOOLS - RESTORED WITH SIMPLE ENGLISH UPDATES
@tool
def infer_data_processing_actions(legislation_text: str, data_categories: str, processing_context: str) -> str:
    """Infer specific data processing actions from legislation text."""
    
    prompt = f"""
    Based on the following legislation text, identify specific actions that must be taken regarding data processing.
    
    Legislation Text: {legislation_text}
    Data Categories Mentioned: {data_categories}
    Processing Context: {processing_context}
    
    Extract only actions that are:
    1. Explicitly required by the legislation text
    2. Related to data handling, processing, storage, transfer, or deletion
    3. Actionable by data controllers or processors
    4. Have clear data-specific outcomes
    5. Described in simple, clear English - avoid legal jargon
    
    For each action, provide:
    - action_type: Brief descriptive name (e.g., "implement_encryption", "obtain_explicit_consent")
    - title: Clear action title in simple English
    - description: What must be done with data in simple English
    - priority: Extract from legislative language (urgent/immediate/high/medium/low)
    - data_specific_steps: Concrete steps related to data handling
    - legislative_requirement: Exact requirement from legislation
    - data_impact: How this affects data processing
    - verification_method: How to confirm compliance
    - derived_from_text: Exact legislative text that requires this action
    
    Return valid JSON array. Only include actions explicitly stated or clearly implied by the legislation.
    If no actions can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring data processing actions: {str(e)}"

@tool
def infer_compliance_verification_actions(legislation_text: str, obligations: str, roles: str) -> str:
    """Infer compliance verification actions from legislation."""
    
    prompt = f"""
    Based on the legislation text and identified obligations, extract verification and compliance actions.
    
    Legislation Text: {legislation_text}
    Identified Obligations: {obligations}
    Affected Roles: {roles}
    
    Focus only on actions that:
    1. Are explicitly required for compliance verification
    2. Involve documentation, reporting, or demonstration of data handling
    3. Are mentioned in the legislation text
    4. Can be performed by the specified roles
    5. Are described in simple, clear English - avoid legal jargon
    
    For each verification action:
    - action_type: Type of verification required
    - title: What needs to be verified in simple English
    - description: How to demonstrate compliance in simple English
    - data_specific_steps: Steps involving data or data processes
    - legislative_requirement: Specific legal requirement
    - verification_method: How compliance is verified
    - derived_from_text: Exact text requiring this verification
    
    Return valid JSON array. Base all actions on explicit legislative requirements only.
    If no actions can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring compliance verification actions: {str(e)}"

@tool
def infer_data_subject_rights_actions(legislation_text: str, rights_mentioned: str, data_domains: str) -> str:
    """Infer actions required to handle data subject rights."""
    
    prompt = f"""
    Analyze the legislation for requirements related to data subject rights and extract required actions.
    
    Legislation Text: {legislation_text}
    Rights Mentioned: {rights_mentioned}
    Data Domains: {data_domains}
    
    Extract actions that:
    1. Are required to facilitate data subject rights
    2. Involve handling, processing, or responding to data subject requests
    3. Are explicitly mentioned in the legislation
    4. Have clear data-handling implications
    5. Are described in simple, clear English - avoid legal jargon
    
    For each rights-related action:
    - action_type: Type of rights handling required
    - title: Rights-related obligation in simple English
    - description: What must be done to support data subject rights in simple English
    - data_specific_steps: Specific data handling steps
    - legislative_requirement: Legal basis for the action
    - data_impact: How this affects data and data processing
    - verification_method: How to confirm rights are being respected
    - derived_from_text: Legislative text requiring this action
    
    Return valid JSON array. Only include actions with clear legislative basis.
    If no actions can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring data subject rights actions: {str(e)}"

# NEW USER ACTION INFERENCE TOOLS - RESTORED
@tool
def infer_user_actionable_tasks(legislation_text: str, data_context: str, user_roles: str) -> str:
    """Infer practical tasks that users can perform based on legislation."""
    
    prompt = f"""
    Analyze the following legislation text to identify specific tasks that individual users can perform.
    
    Legislation Text: {legislation_text}
    Data Context: {data_context}
    User Roles: {user_roles}
    
    Extract ONLY tasks that are:
    1. Explicitly required by the legislation text
    2. Actionable by individual users with commonly available tools/systems
    3. Related to data operations users can control (collect, process, store, transfer, delete, secure)
    4. Have clear compliance outcomes
    5. Can be practically implemented by users
    6. Described in simple, clear English - avoid legal jargon
    
    For each user task, provide:
    - action_type: Specific data operation (e.g., "encrypt_personal_data", "delete_user_data")
    - title: Clear task title for users in simple English
    - description: What users must do in simple English
    - priority: Based on legislative urgency
    - user_data_steps: Concrete steps for user data handling
    - affected_data_categories: Types of data involved
    - legislative_requirement: Exact requirement from legislation
    - compliance_outcome: What compliance goal this achieves
    - user_verification_steps: How users can verify completion
    - tools_needed: What users need to perform the task
    - derived_from_text: Exact text requiring this task
    
    Focus on practical, implementable data tasks. Avoid abstract concepts.
    Return valid JSON array based ONLY on explicit legislative requirements.
    If no user actions can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring user actionable tasks: {str(e)}"

@tool
def infer_user_compliance_tasks(legislation_text: str, compliance_obligations: str, data_domains: str) -> str:
    """Infer compliance-related tasks users can perform."""
    
    prompt = f"""
    Based on the legislation and compliance obligations, identify specific tasks users can perform.
    
    Legislation Text: {legislation_text}
    Compliance Obligations: {compliance_obligations}
    Data Domains: {data_domains}
    
    Extract tasks that users can perform to achieve compliance, focusing on:
    1. Documentation and record-keeping for their own data processing
    2. Implementing data protection measures they can control
    3. Handling data subject requests they receive
    4. Conducting self-assessments and audits
    5. Establishing processes and procedures within their control
    6. Described in simple, clear English - avoid legal jargon
    
    For each user compliance task:
    - action_type: Type of compliance task
    - title: What users need to accomplish in simple English
    - description: Specific compliance task for users in simple English
    - user_data_steps: Steps involving actual data
    - legislative_requirement: Legal basis for the task
    - compliance_outcome: Compliance goal achieved
    - user_verification_steps: How to confirm compliance
    - prerequisites: What must be done first
    - derived_from_text: Legislative text requiring this
    
    Return valid JSON array. Base tasks on explicit legislative requirements.
    If no user compliance tasks can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring user compliance tasks: {str(e)}"

@tool
def infer_user_rights_support_tasks(legislation_text: str, rights_context: str, processing_activities: str) -> str:
    """Infer tasks users can perform to support data subject rights."""
    
    prompt = f"""
    Analyze the legislation for tasks users can perform to facilitate data subject rights.
    
    Legislation Text: {legislation_text}
    Rights Context: {rights_context}
    Processing Activities: {processing_activities}
    
    Identify tasks users can perform to support data subject rights:
    1. Setting up systems they control to handle rights requests
    2. Implementing processes for data access, rectification, erasure they can manage
    3. Ensuring data portability capabilities within their systems
    4. Managing consent and withdrawal mechanisms
    5. Handling objections and restrictions
    6. Described in simple, clear English - avoid legal jargon
    
    For each rights-support task:
    - action_type: Type of rights support task
    - title: User-facing task title in simple English
    - description: What users must implement in simple English
    - user_data_steps: Specific data operations required
    - affected_data_categories: Data types involved
    - legislative_requirement: Rights provision requiring this
    - compliance_outcome: Rights facilitation achieved
    - tools_needed: Technical requirements users can control
    - derived_from_text: Text mandating this task
    
    Return valid JSON array. Focus on practical implementation by users.
    If no user rights support tasks can be inferred, return empty array.
    """
    
    try:
        client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        
        response = client.chat.completions.create(
            model=Config.CHAT_MODEL,
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"Error inferring user rights support tasks: {str(e)}"

# ===============================
# UPDATED DPV CONCEPTS WITH GDPR-COMPLIANT MAPPINGS
# ===============================

class DPVConcepts:
    """DPV (Data Privacy Vocabulary) concept mappings with GDPR-compliant processing purposes."""
    
    # Updated DPV Core Namespaces v2.1
    DPV = Config.DPV_NAMESPACE
    DPV_PD = Config.DPV_PD_NAMESPACE
    DPV_TECH = Config.DPV_TECH_NAMESPACE
    DPV_LEGAL = Config.DPV_LEGAL_NAMESPACE
    DPV_ACTION = Config.ACTION_NAMESPACE
    
    # GDPR-Compliant Processing Purposes
    PROCESSING_PURPOSES = {
        ProcessingPurpose.CONSENT.value: f"{DPV}Consent",
        ProcessingPurpose.CONTRACTUAL_NECESSITY.value: f"{DPV}ContractualNecessity",
        ProcessingPurpose.LEGAL_OBLIGATION.value: f"{DPV}LegalObligation",
        ProcessingPurpose.VITAL_INTERESTS.value: f"{DPV}VitalInterests",
        ProcessingPurpose.PUBLIC_TASK.value: f"{DPV}PublicTask",
        ProcessingPurpose.LEGITIMATE_INTERESTS.value: f"{DPV}LegitimateInterests"
    }
    
    # GDPR-Compliant Legal Basis
    LEGAL_BASIS = {
        LegalBasis.CONSENT.value: f"{DPV}Consent",
        LegalBasis.CONTRACTUAL_OBLIGATION.value: f"{DPV}ContractualObligation",
        LegalBasis.LEGAL_OBLIGATION.value: f"{DPV}LegalObligation",
        LegalBasis.VITAL_INTERESTS.value: f"{DPV}VitalInterests",
        LegalBasis.PUBLIC_INTEREST_OFFICIAL_AUTHORITY.value: f"{DPV}PublicInterestOfficialAuthority",
        LegalBasis.LEGITIMATE_INTERESTS.value: f"{DPV}LegitimateInterests"
    }
    
    PROCESSING_OPERATIONS = {
        "collect": f"{DPV}Collect",
        "store": f"{DPV}Store", 
        "use": f"{DPV}Use",
        "share": f"{DPV}Share",
        "transfer": f"{DPV}Transfer",
        "delete": f"{DPV}Erase",
        "process": f"{DPV}Process",
        "access": f"{DPV}Access"
    }
    
    DATA_CATEGORIES = {
        "personal_data": f"{DPV}PersonalData",
        "sensitive_data": f"{DPV}SensitivePersonalData",
        "biometric_data": f"{DPV_PD}Biometric",
        "health_data": f"{DPV_PD}Health",
        "financial_data": f"{DPV_PD}Financial",
        "location_data": f"{DPV_PD}Location",
        "behavioral_data": f"{DPV_PD}Behavioral",
        "identification_data": f"{DPV_PD}Identifying"
    }
    
    ROLES = {
        "controller": f"{DPV}DataController",
        "processor": f"{DPV}DataProcessor",
        "joint_controller": f"{DPV}JointDataControllers",
        "data_subject": f"{DPV}DataSubject"
    }
    
    # Dynamic action mapping (no hardcoded actions)
    @classmethod
    def get_action_uri(cls, action_type: str, is_user_action: bool = False) -> str:
        """Generate action URI dynamically based on action type."""
        action_prefix = "User" if is_user_action else ""
        action_name = ''.join(word.capitalize() for word in action_type.replace('_', ' ').split())
        return f"{cls.DPV_ACTION}{action_prefix}{action_name}"

# ===============================
# ENHANCED STANDARDS CONVERTER
# ===============================

class IntegratedRule(BaseModel):
    """Unified rule that combines DPV, ODRL, and ODRE elements."""
    
    id: str = Field(..., description="Unique rule identifier")
    type: str = Field(default="odre:EnforceablePolicy", description="Unified rule type")
    
    # DPV Properties - Updated for v2.1
    dpv_hasProcessing: List[str] = Field(default_factory=list, description="DPV: Processing operations")
    dpv_hasPurpose: List[str] = Field(default_factory=list, description="DPV: Purposes for processing") 
    dpv_hasPersonalData: List[str] = Field(default_factory=list, description="DPV: Personal data categories")
    dpv_hasDataController: Optional[str] = Field(None, description="DPV: Data controller")
    dpv_hasDataProcessor: Optional[str] = Field(None, description="DPV: Data processor")
    dpv_hasLegalBasis: Optional[str] = Field(None, description="DPV: Legal basis for processing")
    dpv_hasLocation: List[str] = Field(default_factory=list, description="DPV: Processing locations/countries")
    
    # DPV Actions - Dynamically inferred
    dpv_hasRuleAction: List[str] = Field(default_factory=list, description="DPV: Rule actions inferred from legislation")
    dpv_hasUserAction: List[str] = Field(default_factory=list, description="DPV: User actions inferred from legislation")
    
    # ODRL Properties
    odrl_permission: List[Dict[str, Any]] = Field(default_factory=list, description="ODRL: Permissions")
    odrl_prohibition: List[Dict[str, Any]] = Field(default_factory=list, description="ODRL: Prohibitions") 
    odrl_obligation: List[Dict[str, Any]] = Field(default_factory=list, description="ODRL: Obligations")
    
    # ODRE Properties
    odre_enforceable: bool = Field(default=True, description="ODRE: Enforceable flag")
    odre_enforcement_mode: str = Field(default="dual_action_based", description="ODRE: Enforcement mode")
    odre_action_inference: bool = Field(default=True, description="ODRE: Action inference enabled")
    odre_user_action_inference: bool = Field(default=True, description="ODRE: User action inference enabled")
    
    # Processing metadata
    source_document_levels: List[str] = Field(default_factory=list, description="Document levels processed")
    chunk_references: List[str] = Field(default_factory=list, description="Chunk references if document was chunked")
    
    # Metadata
    source_legislation: str = Field(..., description="Source legislation")
    source_article: str = Field(..., description="Source article/section")
    extracted_at: datetime = Field(default_factory=datetime.utcnow)
    confidence_score: float = Field(..., ge=0.0, le=1.0)

class StandardsConverter:
    """Converts between JSON Rules Engine and integrated DPV+ODRL+ODRE format."""
    
    def __init__(self):
        self.dpv_concepts = DPVConcepts()
    
    def json_rules_to_integrated(self, legislation_rule: LegislationRule) -> IntegratedRule:
        """Convert JSON Rules Engine rule to integrated format."""
        
        # Extract DPV elements
        dpv_elements = self._extract_dpv_elements(legislation_rule)
        
        # Extract ODRL elements  
        odrl_elements = self._extract_odrl_elements(legislation_rule)
        
        # Create integrated rule
        return self._create_integrated_rule(legislation_rule, dpv_elements, odrl_elements)
    
    def _extract_dpv_elements(self, legislation_rule: LegislationRule) -> Dict[str, Any]:
        """Extract DPV elements from legislation rule with dynamic action mapping."""
        
        dpv_personal_data = []
        for category in legislation_rule.data_category:
            category_value = category.value if hasattr(category, 'value') else str(category)
            if category_value in self.dpv_concepts.DATA_CATEGORIES:
                dpv_personal_data.append(self.dpv_concepts.DATA_CATEGORIES[category_value])
        
        dpv_processing = []
        for logic_type, conditions in legislation_rule.conditions.items():
            for condition in conditions:
                fact_lower = condition.fact.lower()
                for operation, uri in self.dpv_concepts.PROCESSING_OPERATIONS.items():
                    if operation in fact_lower:
                        dpv_processing.append(uri)
        
        # Dynamic purpose mapping based on rule content
        dpv_purposes = []
        rule_text = f"{legislation_rule.description} {legislation_rule.event.type}".lower()
        for purpose_key, purpose_uri in self.dpv_concepts.PROCESSING_PURPOSES.items():
            if purpose_key.replace("_", " ") in rule_text:
                dpv_purposes.append(purpose_uri)
        
        controller = None
        processor = None
        if legislation_rule.primary_impacted_role:
            primary_role_value = legislation_rule.primary_impacted_role.value if hasattr(legislation_rule.primary_impacted_role, 'value') else str(legislation_rule.primary_impacted_role)
            if primary_role_value in self.dpv_concepts.ROLES:
                if primary_role_value == "controller":
                    controller = self.dpv_concepts.ROLES["controller"]
                elif primary_role_value == "processor":
                    processor = self.dpv_concepts.ROLES["processor"]
        
        # Dynamic rule actions mapping
        dpv_rule_actions = []
        for action in legislation_rule.actions:
            action_uri = self.dpv_concepts.get_action_uri(action.action_type, is_user_action=False)
            dpv_rule_actions.append(action_uri)
        
        # Dynamic user actions mapping
        dpv_user_actions = []
        for action in legislation_rule.user_actions:
            action_uri = self.dpv_concepts.get_action_uri(action.action_type, is_user_action=True)
            dpv_user_actions.append(action_uri)
        
        dpv_locations = [f"dpv:Country_{country.replace(' ', '_')}" for country in legislation_rule.applicable_countries]
        
        return {
            "hasProcessing": dpv_processing,
            "hasPurpose": dpv_purposes,
            "hasPersonalData": dpv_personal_data,
            "hasDataController": controller,
            "hasDataProcessor": processor,
            "hasLocation": dpv_locations,
            "hasRuleAction": dpv_rule_actions,
            "hasUserAction": dpv_user_actions
        }
    
    def _extract_odrl_elements(self, legislation_rule: LegislationRule) -> Dict[str, Any]:
        """Extract ODRL elements from legislation rule."""
        
        permissions = []
        prohibitions = []
        obligations = []
        
        rule_description = legislation_rule.description.lower()
        event_type = legislation_rule.event.type.lower()
        
        if "prohibit" in rule_description or "forbid" in event_type:
            prohibition = self._create_odrl_rule(legislation_rule, "prohibition")
            prohibitions.append(prohibition)
        elif "require" in rule_description or "must" in rule_description:
            obligation = self._create_odrl_rule(legislation_rule, "obligation")
            obligations.append(obligation)
        else:
            permission = self._create_odrl_rule(legislation_rule, "permission")
            permissions.append(permission)
        
        return {
            "permission": permissions,
            "prohibition": prohibitions,
            "obligation": obligations
        }
    
    def _create_odrl_rule(self, legislation_rule: LegislationRule, rule_type: str) -> Dict[str, Any]:
        """Create individual ODRL rule from legislation rule."""
        
        target = f"urn:asset:{legislation_rule.source_file}:{legislation_rule.id}"
        
        actions = []
        for logic_type, conditions in legislation_rule.conditions.items():
            for condition in conditions:
                for domain in condition.data_domain:
                    domain_value = domain.value if hasattr(domain, 'value') else str(domain)
                    if domain_value == "data_transfer":
                        actions.append("transfer")
                    elif domain_value == "data_usage":
                        actions.append("use")
                    elif domain_value == "data_storage":
                        actions.append("store")
                    elif domain_value == "data_collection":
                        actions.append("collect")
                    elif domain_value == "data_deletion":
                        actions.append("delete")
        
        if not actions:
            actions = ["use"]
        
        constraints = []
        for logic_type, conditions in legislation_rule.conditions.items():
            for condition in conditions:
                operator_value = condition.operator.value if hasattr(condition.operator, 'value') else str(condition.operator)
                constraint = {
                    "leftOperand": condition.fact,
                    "operator": self._map_operator_to_odrl(operator_value),
                    "rightOperand": condition.value,
                    "comment": condition.description
                }
                constraints.append(constraint)
        
        rule = {
            "target": target,
            "action": actions[0] if len(actions) == 1 else actions,
            "constraint": constraints
        }
        
        return rule
    
    def _map_operator_to_odrl(self, operator: str) -> str:
        """Map operators to ODRL format."""
        mapping = {
            "equal": "eq",
            "notEqual": "neq",
            "greaterThan": "gt", 
            "lessThan": "lt",
            "greaterThanInclusive": "gteq",
            "lessThanInclusive": "lteq",
            "contains": "isA",
            "doesNotContain": "isNotA",
            "in": "isPartOf",
            "notIn": "isNotPartOf"
        }
        return mapping.get(operator, "eq")
    
    def _create_integrated_rule(self, legislation_rule: LegislationRule, dpv_elements: Dict[str, Any], odrl_elements: Dict[str, Any]) -> IntegratedRule:
        """Create integrated rule."""
        
        source_levels = []
        chunk_refs = []
        for logic_type, conditions in legislation_rule.conditions.items():
            for condition in conditions:
                level_value = condition.document_level.value if hasattr(condition.document_level, 'value') else str(condition.document_level)
                if level_value not in source_levels:
                    source_levels.append(level_value)
                if condition.chunk_reference and condition.chunk_reference not in chunk_refs:
                    chunk_refs.append(condition.chunk_reference)
        
        return IntegratedRule(
            id=f"integrated:{legislation_rule.id}",
            dpv_hasProcessing=dpv_elements.get("hasProcessing", []),
            dpv_hasPurpose=dpv_elements.get("hasPurpose", []),
            dpv_hasPersonalData=dpv_elements.get("hasPersonalData", []),
            dpv_hasDataController=dpv_elements.get("hasDataController"),
            dpv_hasDataProcessor=dpv_elements.get("hasDataProcessor"),
            dpv_hasLocation=dpv_elements.get("hasLocation", []),
            dpv_hasRuleAction=dpv_elements.get("hasRuleAction", []),
            dpv_hasUserAction=dpv_elements.get("hasUserAction", []),
            odrl_permission=odrl_elements.get("permission", []),
            odrl_prohibition=odrl_elements.get("prohibition", []),
            odrl_obligation=odrl_elements.get("obligation", []),
            source_document_levels=source_levels,
            chunk_references=chunk_refs,
            source_legislation=legislation_rule.source_file,
            source_article=legislation_rule.source_article,
            confidence_score=legislation_rule.confidence_score
        )

# ===============================
# EXTRACTION RESULT WITH ENHANCED METADATA AND CSV EXPORT
# ===============================

class ExtractionResult(BaseModel):
    """Complete result of legislation analysis."""
    
    rules: List[LegislationRule] = Field(..., description="Extracted rules")
    summary: str = Field(..., description="Summary of extraction")
    total_rules: int = Field(..., description="Total number of rules extracted")
    total_actions: int = Field(default=0, description="Total number of rule actions extracted")
    total_user_actions: int = Field(default=0, description="Total number of user actions extracted")
    processing_time: float = Field(..., description="Processing time in seconds")
    embeddings: Optional[List[List[float]]] = Field(None, description="Rule embeddings")
    
    # Integrated standards output
    integrated_rules: List[IntegratedRule] = Field(default_factory=list, description="Integrated standards rules")
    
    # Processing metadata
    documents_processed: Dict[str, List[str]] = Field(default_factory=dict, description="Documents processed by level")
    chunking_metadata: Dict[str, Any] = Field(default_factory=dict, description="Information about document chunking")
    
    def save_json(self, filepath: str):
        """Save rules to JSON file."""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(
                [rule.model_dump() for rule in self.rules], 
                f, 
                indent=2, 
                default=str,
                ensure_ascii=False
            )
    
    def save_integrated_json(self, filepath: str):
        """Save integrated rules to JSON file."""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(
                [rule.model_dump() for rule in self.integrated_rules],
                f,
                indent=2,
                default=str,
                ensure_ascii=False
            )
    
    def save_integrated_ttl(self, filepath: str):
        """Save integrated rules in TTL format."""
        if not RDF_AVAILABLE:
            print(f"Warning: Cannot generate TTL file - rdflib not available")
            return
            
        turtle_content = self._generate_turtle_with_rdflib()
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(turtle_content)
    
    def save_integrated_jsonld(self, filepath: str):
        """Save integrated rules in JSON-LD format."""
        jsonld_content = self._generate_jsonld()
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(jsonld_content, f, indent=2, ensure_ascii=False)
    
    def save_csv(self, base_filepath: str):
        """Save extraction results to CSV files with proper data flattening."""
        try:
            # Create separate CSV files for different data types
            base_name = base_filepath.replace('.csv', '')
            
            # 1. Main rules CSV
            rules_file = f"{base_name}_rules.csv"
            self._save_rules_csv(rules_file)
            
            # 2. Rule actions CSV
            rule_actions_file = f"{base_name}_rule_actions.csv"
            self._save_rule_actions_csv(rule_actions_file)
            
            # 3. User actions CSV
            user_actions_file = f"{base_name}_user_actions.csv"
            self._save_user_actions_csv(user_actions_file)
            
            # 4. Conditions CSV
            conditions_file = f"{base_name}_conditions.csv"
            self._save_conditions_csv(conditions_file)
            
            # 5. Summary CSV
            summary_file = f"{base_name}_summary.csv"
            self._save_summary_csv(summary_file)
            
            print(f"   CSV Rules: {rules_file}")
            print(f"   CSV Rule Actions: {rule_actions_file}")
            print(f"   CSV User Actions: {user_actions_file}")
            print(f"   CSV Conditions: {conditions_file}")
            print(f"   CSV Summary: {summary_file}")
            
        except Exception as e:
            logger.error(f"Error saving CSV files: {e}")
            print(f"   Error saving CSV files: {e}")
    
    def _generate_turtle_with_rdflib(self) -> str:
        """Generate Turtle RDF representation."""
        if not RDF_AVAILABLE:
            return "# Error: rdflib not available for TTL generation"
        
        g = Graph()
        
        # Define namespaces with updated v2.1 URIs
        DPV = Namespace(Config.DPV_NAMESPACE)
        DPV_PD = Namespace(Config.DPV_PD_NAMESPACE)
        DPV_ACTION = Namespace(Config.ACTION_NAMESPACE)
        ODRL = Namespace(Config.ODRL_NAMESPACE)
        ODRE = Namespace("https://w3id.org/def/odre#")
        
        # Bind namespaces
        g.bind("dpv", DPV)
        g.bind("dpv-pd", DPV_PD)
        g.bind("dpv-action", DPV_ACTION)
        g.bind("odrl", ODRL)
        g.bind("odre", ODRE)
        g.bind("rdf", RDF)
        g.bind("rdfs", RDFS)
        g.bind("xsd", XSD)
        
        for integrated_rule in self.integrated_rules:
            rule_id_encoded = urllib.parse.quote(integrated_rule.id, safe=':/')
            rule_uri = URIRef(f"urn:rule:{rule_id_encoded}")
            
            # Core types and properties
            g.add((rule_uri, RDF.type, ODRE.EnforceablePolicy))
            g.add((rule_uri, RDF.type, DPV.ProcessingActivity))
            g.add((rule_uri, RDFS.label, Literal(integrated_rule.source_article)))
            
            # ODRE Properties
            g.add((rule_uri, ODRE.enforceable, Literal(integrated_rule.odre_enforceable, datatype=XSD.boolean)))
            g.add((rule_uri, ODRE.enforcement_mode, Literal(integrated_rule.odre_enforcement_mode)))
            g.add((rule_uri, ODRE.action_inference, Literal(integrated_rule.odre_action_inference, datatype=XSD.boolean)))
            g.add((rule_uri, ODRE.user_action_inference, Literal(integrated_rule.odre_user_action_inference, datatype=XSD.boolean)))
            
            # DPV Properties
            for processing in integrated_rule.dpv_hasProcessing:
                g.add((rule_uri, DPV.hasProcessing, URIRef(processing)))
            
            for purpose in integrated_rule.dpv_hasPurpose:
                g.add((rule_uri, DPV.hasPurpose, URIRef(purpose)))
            
            for data in integrated_rule.dpv_hasPersonalData:
                g.add((rule_uri, DPV.hasPersonalData, URIRef(data)))
            
            # Rule actions
            for action in integrated_rule.dpv_hasRuleAction:
                g.add((rule_uri, DPV_ACTION.hasRuleAction, URIRef(action)))
            
            # User actions
            for action in integrated_rule.dpv_hasUserAction:
                g.add((rule_uri, DPV_ACTION.hasUserAction, URIRef(action)))
            
            if integrated_rule.dpv_hasDataController:
                g.add((rule_uri, DPV.hasDataController, URIRef(integrated_rule.dpv_hasDataController)))
            
            if integrated_rule.dpv_hasDataProcessor:
                g.add((rule_uri, DPV.hasDataProcessor, URIRef(integrated_rule.dpv_hasDataProcessor)))
            
            for location in integrated_rule.dpv_hasLocation:
                g.add((rule_uri, DPV.hasLocation, URIRef(location)))
            
            # Document processing metadata
            for level in integrated_rule.source_document_levels:
                g.add((rule_uri, DPV_ACTION.hasDocumentLevel, Literal(level)))
            
            for chunk_ref in integrated_rule.chunk_references:
                g.add((rule_uri, DPV_ACTION.hasChunkReference, Literal(chunk_ref)))
            
            # ODRL Properties - ensuring same content as JSON-LD
            g.add((rule_uri, ODRL.hasPermissionCount, Literal(len(integrated_rule.odrl_permission), datatype=XSD.integer)))
            g.add((rule_uri, ODRL.hasProhibitionCount, Literal(len(integrated_rule.odrl_prohibition), datatype=XSD.integer)))
            g.add((rule_uri, ODRL.hasObligationCount, Literal(len(integrated_rule.odrl_obligation), datatype=XSD.integer)))
            
            # Individual ODRL rules
            for i, permission in enumerate(integrated_rule.odrl_permission):
                perm_uri = URIRef(f"urn:rule:{rule_id_encoded}:permission:{i}")
                g.add((rule_uri, ODRL.permission, perm_uri))
                g.add((perm_uri, RDF.type, ODRL.Permission))
                if permission.get('target'):
                    g.add((perm_uri, ODRL.target, Literal(permission['target'])))
                if permission.get('action'):
                    g.add((perm_uri, ODRL.action, Literal(permission['action'])))
            
            for i, prohibition in enumerate(integrated_rule.odrl_prohibition):
                proh_uri = URIRef(f"urn:rule:{rule_id_encoded}:prohibition:{i}")
                g.add((rule_uri, ODRL.prohibition, proh_uri))
                g.add((proh_uri, RDF.type, ODRL.Prohibition))
                if prohibition.get('target'):
                    g.add((proh_uri, ODRL.target, Literal(prohibition['target'])))
                if prohibition.get('action'):
                    g.add((proh_uri, ODRL.action, Literal(prohibition['action'])))
            
            for i, obligation in enumerate(integrated_rule.odrl_obligation):
                obl_uri = URIRef(f"urn:rule:{rule_id_encoded}:obligation:{i}")
                g.add((rule_uri, ODRL.obligation, obl_uri))
                g.add((obl_uri, RDF.type, ODRL.Duty))
                if obligation.get('target'):
                    g.add((obl_uri, ODRL.target, Literal(obligation['target'])))
                if obligation.get('action'):
                    g.add((obl_uri, ODRL.action, Literal(obligation['action'])))
            
            # Metadata
            g.add((rule_uri, DPV.hasConfidenceScore, Literal(integrated_rule.confidence_score, datatype=XSD.float)))
            g.add((rule_uri, DPV.extractedAt, Literal(integrated_rule.extracted_at.isoformat(), datatype=XSD.dateTime)))
            g.add((rule_uri, DPV.sourceLegislation, Literal(integrated_rule.source_legislation)))
        
        # Serialize to Turtle format
        turtle_output = g.serialize(format='turtle')
        if isinstance(turtle_output, bytes):
            return turtle_output.decode('utf-8')
        return turtle_output
    
    def _generate_jsonld(self) -> Dict[str, Any]:
        """Generate JSON-LD representation with same content as TTL."""
        context = {
            "@context": {
                "dpv": Config.DPV_NAMESPACE,
                "dpv-pd": Config.DPV_PD_NAMESPACE,
                "dpv-action": Config.ACTION_NAMESPACE,
                "odrl": Config.ODRL_NAMESPACE,
                "odre": "https://w3id.org/def/odre#",
                "rdf": "http://www.w3.org/1999/02/22-rdf-syntax-ns#",
                "rdfs": "http://www.w3.org/2000/01/rdf-schema#",
                "xsd": "http://www.w3.org/2001/XMLSchema#"
            }
        }
        
        graph = []
        for integrated_rule in self.integrated_rules:
            rule_jsonld = {
                "@id": f"urn:rule:{integrated_rule.id}",
                "@type": ["odre:EnforceablePolicy", "dpv:ProcessingActivity"],
                "rdfs:label": integrated_rule.source_article,
                
                # ODRE Properties
                "odre:enforceable": integrated_rule.odre_enforceable,
                "odre:enforcement_mode": integrated_rule.odre_enforcement_mode,
                "odre:action_inference": integrated_rule.odre_action_inference,
                "odre:user_action_inference": integrated_rule.odre_user_action_inference,
                
                # DPV Properties
                "dpv:hasProcessing": [{"@id": uri} for uri in integrated_rule.dpv_hasProcessing],
                "dpv:hasPurpose": [{"@id": uri} for uri in integrated_rule.dpv_hasPurpose],
                "dpv:hasPersonalData": [{"@id": uri} for uri in integrated_rule.dpv_hasPersonalData],
                "dpv:hasLocation": [{"@id": uri} for uri in integrated_rule.dpv_hasLocation],
                "dpv-action:hasRuleAction": [{"@id": uri} for uri in integrated_rule.dpv_hasRuleAction],
                "dpv-action:hasUserAction": [{"@id": uri} for uri in integrated_rule.dpv_hasUserAction],
                "dpv-action:hasDocumentLevel": integrated_rule.source_document_levels,
                "dpv-action:hasChunkReference": integrated_rule.chunk_references,
                
                # ODRL Properties - matching TTL content
                "odrl:permission": integrated_rule.odrl_permission,
                "odrl:prohibition": integrated_rule.odrl_prohibition,
                "odrl:obligation": integrated_rule.odrl_obligation,
                "odrl:hasPermissionCount": {
                    "@value": len(integrated_rule.odrl_permission),
                    "@type": "xsd:integer"
                },
                "odrl:hasProhibitionCount": {
                    "@value": len(integrated_rule.odrl_prohibition),
                    "@type": "xsd:integer"
                },
                "odrl:hasObligationCount": {
                    "@value": len(integrated_rule.odrl_obligation),
                    "@type": "xsd:integer"
                },
                
                # Metadata
                "dpv:hasConfidenceScore": {
                    "@value": integrated_rule.confidence_score,
                    "@type": "xsd:float"
                },
                "dpv:extractedAt": {
                    "@value": integrated_rule.extracted_at.isoformat(),
                    "@type": "xsd:dateTime"
                },
                "dpv:sourceLegislation": integrated_rule.source_legislation
            }
            
            # Optional properties
            if integrated_rule.dpv_hasDataController:
                rule_jsonld["dpv:hasDataController"] = {"@id": integrated_rule.dpv_hasDataController}
            if integrated_rule.dpv_hasDataProcessor:
                rule_jsonld["dpv:hasDataProcessor"] = {"@id": integrated_rule.dpv_hasDataProcessor}
            
            graph.append(rule_jsonld)
        
        return {**context, "@graph": graph}

# ===============================
# SUPPORT CLASSES
# ===============================

class OpenAIService:
    """Service for OpenAI API interactions."""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """Generate embeddings."""
        try:
            response = self.client.embeddings.create(
                model=Config.EMBEDDING_MODEL,
                input=texts,
                encoding_format="float"
            )
            return [data.embedding for data in response.data]
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise
    
    async def chat_completion(self, messages: List[Union[Dict[str, str], SystemMessage, HumanMessage, AIMessage]]) -> str:
        """Generate chat completion."""
        try:
            formatted_messages = []
            for msg in messages:
                if isinstance(msg, (SystemMessage, HumanMessage, AIMessage)):
                    if isinstance(msg, SystemMessage):
                        formatted_messages.append({"role": "system", "content": msg.content})
                    elif isinstance(msg, HumanMessage):
                        formatted_messages.append({"role": "user", "content": msg.content})
                    elif isinstance(msg, AIMessage):
                        formatted_messages.append({"role": "assistant", "content": msg.content})
                elif isinstance(msg, dict):
                    formatted_messages.append(msg)
                else:
                    formatted_messages.append({"role": "user", "content": str(msg)})
            
            response = self.client.chat.completions.create(
                model=Config.CHAT_MODEL,
                messages=formatted_messages
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error in chat completion: {e}")
            raise

class SafeJsonParser:
    """Safe JSON parsing with error handling."""
    
    @staticmethod
    def parse_json_response(response: str) -> Dict[str, Any]:
        """Safely parse JSON response from LLM."""
        try:
            cleaned = response.strip()
            
            if "```json" in cleaned:
                start = cleaned.find("```json") + 7
                end = cleaned.find("```", start)
                if end != -1:
                    cleaned = cleaned[start:end].strip()
            elif "```" in cleaned:
                start = cleaned.find("```") + 3
                end = cleaned.find("```", start)
                if end != -1:
                    cleaned = cleaned[start:end].strip()
            
            parsed = json.loads(cleaned)
            return parsed
            
        except json.JSONDecodeError as e:
            logger.warning(f"JSON decode error: {e}. Attempting to fix...")
            
            try:
                import re
                fixed = re.sub(r',(\s*[}\]])', r'\1', cleaned)
                parsed = json.loads(fixed)
                return parsed
            except Exception:
                logger.error(f"Could not parse JSON response: {cleaned[:200]}...")
                return {"error": "Failed to parse JSON", "raw_response": cleaned}

class RuleManager:
    """Manages existing rules."""
    
    def __init__(self, rules_file: str = Config.EXISTING_RULES_FILE):
        self.rules_file = rules_file
        self.existing_rules: List[LegislationRule] = []
        self.load_existing_rules()
    
    def load_existing_rules(self):
        """Load existing rules from file."""
        try:
            if os.path.exists(self.rules_file):
                with open(self.rules_file, 'r', encoding='utf-8') as f:
                    rules_data = json.load(f)
                
                for rule_data in rules_data:
                    try:
                        rule = LegislationRule(**rule_data)
                        self.existing_rules.append(rule)
                    except Exception as e:
                        logger.warning(f"Skipping invalid existing rule: {e}")
                
                logger.info(f"Loaded {len(self.existing_rules)} existing rules")
            else:
                logger.info("No existing rules file found. Starting fresh.")
        except Exception as e:
            logger.error(f"Error loading existing rules: {e}")
            self.existing_rules = []
    
    def save_rules(self, new_rules: List[LegislationRule]):
        """Save new rules, appending to existing ones."""
        all_rules = self.existing_rules + new_rules
        
        unique_rules = []
        seen_ids = set()
        for rule in all_rules:
            if rule.id not in seen_ids:
                unique_rules.append(rule)
                seen_ids.add(rule.id)
        
        os.makedirs(os.path.dirname(self.rules_file), exist_ok=True)
        with open(self.rules_file, 'w', encoding='utf-8') as f:
            json.dump(
                [rule.model_dump() for rule in unique_rules], 
                f, 
                indent=2, 
                default=str,
                ensure_ascii=False
            )
        
        self.existing_rules = unique_rules
        logger.info(f"Saved {len(unique_rules)} total rules ({len(new_rules)} new)")
    
    def get_context_summary(self) -> str:
        """Get a summary of existing rules for context."""
        if not self.existing_rules:
            return "No existing rules found."
        
        summary = f"Existing Rules Context ({len(self.existing_rules)} rules):\n\n"
        
        sources = {}
        for rule in self.existing_rules:
            source = rule.source_article
            if source not in sources:
                sources[source] = []
            sources[source].append(rule)
        
        for source, rules in sources.items():
            summary += f"Source: {source} ({len(rules)} rules)\n"
            for rule in rules[:3]:
                total_actions = len(rule.actions)
                total_user_actions = len(rule.user_actions)
                summary += f"  - {rule.name}: {rule.description[:100]}... ({total_actions} rule actions, {total_user_actions} user actions)\n"
            if len(rules) > 3:
                summary += f"  ... and {len(rules) - 3} more rules\n"
            summary += "\n"
        
        return summary

# ===============================
# ENHANCED PROMPTING STRATEGIES - ALL ORIGINAL PRESERVED
# ===============================

class PromptingStrategies:
    """Anti-hallucination prompting strategies focused on dual action inference."""
    
    @staticmethod
    def focused_analysis_prompt(legislation_text: str, existing_context: str = "", level: str = "level_1", chunk_info: str = "") -> str:
        """Focused analysis prompt that minimizes hallucination."""
        context_section = f"\n\nEXISTING RULES CONTEXT:\n{existing_context}\n" if existing_context else ""
        chunk_section = f"\n\nCHUNK INFORMATION:\n{chunk_info}\n" if chunk_info else ""
        
        return f"""
        Analyze this {level} legislation text with strict adherence to what is stated.
        {context_section}{chunk_section}
        
        LEGISLATION TEXT TO ANALYZE:
        {legislation_text}
        
        ANALYSIS REQUIREMENTS:
        
        1. IDENTIFY EXPLICIT OBLIGATIONS:
        - Extract only obligations stated in the text
        - Identify who has each obligation (controller, processor, joint_controller, data_subject)
        - Note the exact text that creates each obligation
        - Use simple, clear English - avoid legal jargon
        
        2. EXTRACT CONDITIONS AND TRIGGERS:
        - Identify conditions that trigger obligations
        - Note data-related triggers (data types, processing activities, transfers)
        - Extract factual conditions that can be evaluated
        
        3. DETERMINE DATA-SPECIFIC REQUIREMENTS:
        - Identify requirements for data handling
        - Note data categories mentioned in the text
        - Extract data processing operations referenced
        
        4. INFER DUAL ACTIONS (BASED ON TEXT):
        - For each obligation, identify what rule actions must be taken (organizational/policy level)
        - For each obligation, identify what user actions can be taken (individual/practical level)
        - Focus on actions involving data processing, storage, transfer, or deletion
        - Base actions on requirements in the legislation
        - Ensure actions are practical and implementable
        - Use simple, clear English - avoid legal jargon
        
        Extract information present in the legislation text. Do not infer beyond what is directly stated.
        """
    
    @staticmethod
    def expert_verification_prompt(legislation_text: str, preliminary_analysis: str, level: str = "level_1") -> str:
        """Expert verification prompt to validate findings against source text."""
        
        return f"""
        Verify the preliminary analysis against the source legislation.
        
        SOURCE LEGISLATION ({level}):
        {legislation_text}
        
        PRELIMINARY ANALYSIS TO VERIFY:
        {preliminary_analysis}
        
        VERIFICATION TASKS:
        
        1. ACCURACY CHECK:
        - Verify each identified obligation exists in the source text
        - Confirm conditions and triggers are accurately extracted
        - Validate data categories and processing operations mentioned
        - Ensure language is simple and clear
        
        2. COMPLETENESS REVIEW:
        - Identify any explicit obligations that were missed
        - Check for data-specific requirements not captured
        - Verify all relevant roles and responsibilities are identified
        
        3. DUAL ACTION VALIDATION:
        - Confirm each proposed rule action is supported by the legislation text
        - Confirm each proposed user action is practical and based on legislation
        - Verify actions are specific to data handling requirements
        - Ensure actions can be performed by appropriate entities
        - Check that language is in simple English
        
        4. REMOVE UNSUPPORTED ELEMENTS:
        - Flag any elements not supported by the source text
        - Remove elements that cannot be traced to specific legislative language
        
        Provide corrected analysis that adheres to the source legislation text.
        Use simple, clear English throughout.
        """

# ===============================
# MAIN LEGISLATION ANALYZER - ALL ORIGINAL FEATURES RESTORED
# ===============================

class LegislationAnalyzer:
    """Main analyzer with enhanced dual action inference and chunking support."""
    
    def __init__(self):
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
        self.rule_manager = RuleManager()
        self.metadata_manager = MetadataManager()
        self.multi_level_processor = MultiLevelPDFProcessor()
        self.standards_converter = StandardsConverter()
        
        # Initialize LangChain model
        self.llm = ChatOpenAI(
            model=Config.CHAT_MODEL,
            openai_api_key=Config.API_KEY,
            openai_api_base=Config.BASE_URL
        )
        
        # Create react agent with ALL ORIGINAL TOOLS - RESTORED
        self.tools = [
            # Original tools - KEPT
            extract_rule_conditions,
            analyze_data_domains, 
            identify_roles_responsibilities,
            infer_data_processing_actions,
            infer_compliance_verification_actions,
            infer_data_subject_rights_actions,
            # NEW user action tools - ADDED
            infer_user_actionable_tasks,
            infer_user_compliance_tasks,
            infer_user_rights_support_tasks
        ]
        
        self.memory = MemorySaver()
        self.agent = create_react_agent(self.llm, self.tools, checkpointer=self.memory)
    
    async def process_legislation_folder(self, folder_path: str = None) -> ExtractionResult:
        """Process all configured legislation entries."""
        if folder_path is None:
            folder_path = Config.LEGISLATION_PDF_PATH
        
        os.makedirs(folder_path, exist_ok=True)
        
        processing_entries = self.metadata_manager.get_all_processing_entries()
        
        if not processing_entries:
            logger.warning("No processing entries found in metadata configuration")
            return ExtractionResult(
                rules=[],
                summary="No configured entries to process",
                total_rules=0,
                total_actions=0,
                total_user_actions=0,
                processing_time=0.0
            )
        
        processed_rules = {rule.id for rule in self.rule_manager.existing_rules}
        
        all_new_rules = []
        documents_processed = {}
        chunking_metadata = {}
        start_time = datetime.utcnow()
        
        for entry_id, metadata in processing_entries:
            try:
                logger.info(f"Processing entry: {entry_id}")
                
                entry_documents = self.multi_level_processor.process_country_documents(
                    entry_id, metadata, folder_path
                )
                
                if not entry_documents:
                    logger.warning(f"No documents found for entry {entry_id}")
                    continue
                
                documents_processed[entry_id] = list(entry_documents.keys())
                
                # Track chunking metadata
                for level, content in entry_documents.items():
                    if isinstance(content, list):  # Chunked document
                        chunking_metadata[f"{entry_id}_{level}"] = {
                            "chunks": len(content),
                            "chunk_size": Config.CHUNK_SIZE,
                            "overlap_size": Config.OVERLAP_SIZE
                        }
                
                result = await self.analyze_legislation_with_levels(
                    entry_documents=entry_documents,
                    entry_id=entry_id,
                    metadata=metadata
                )
                
                new_rules = [rule for rule in result.rules if rule.id not in processed_rules]
                all_new_rules.extend(new_rules)
                processed_rules.update(rule.id for rule in new_rules)
                
            except Exception as e:
                logger.error(f"Error processing entry {entry_id}: {e}")
                continue
        
        end_time = datetime.utcnow()
        total_processing_time = (end_time - start_time).total_seconds()
        total_actions = sum(len(rule.actions) for rule in all_new_rules)
        total_user_actions = sum(len(rule.user_actions) for rule in all_new_rules)
        
        if all_new_rules:
            rule_texts = [f"{rule.description} {rule.source_article}" for rule in all_new_rules]
            embeddings = await self.openai_service.get_embeddings(rule_texts)
        else:
            embeddings = []
        
        if all_new_rules:
            self.rule_manager.save_rules(all_new_rules)
        
        integrated_rules = []
        for rule in all_new_rules:
            try:
                integrated_rule = self.standards_converter.json_rules_to_integrated(rule)
                integrated_rules.append(integrated_rule)
            except Exception as e:
                logger.warning(f"Error converting rule {rule.id} to integrated format: {e}")
                continue
        
        result = ExtractionResult(
            rules=all_new_rules,
            summary=f"Processed {len(processing_entries)} entries, extracted {len(all_new_rules)} rules with {total_actions} rule actions and {total_user_actions} user actions",
            total_rules=len(all_new_rules),
            total_actions=total_actions,
            total_user_actions=total_user_actions,
            processing_time=total_processing_time,
            embeddings=embeddings,
            integrated_rules=integrated_rules,
            documents_processed=documents_processed,
            chunking_metadata=chunking_metadata
        )
        
        return result
    
    async def analyze_legislation_with_levels(
        self, 
        entry_documents: Dict[str, Union[str, List[DocumentChunk]]],
        entry_id: str,
        metadata: CountryMetadata
    ) -> ExtractionResult:
        """Analyze legislation from multiple document levels with chunking support."""
        start_time = datetime.utcnow()
        
        try:
            logger.info(f"Starting analysis for entry: {entry_id}")
            logger.info(f"Countries: {metadata.country}")
            
            existing_context = self.rule_manager.get_context_summary()
            
            metadata_context = f"""
            ENTRY METADATA:
            - Entry ID: {entry_id}
            - Applicable Countries: {', '.join(metadata.country)}
            - Adequacy Countries: {', '.join(metadata.adequacy_country) if metadata.adequacy_country else 'None specified'}
            - Document Levels Available: {', '.join(entry_documents.keys())}
            """
            
            all_rules = []
            
            for level, content in entry_documents.items():
                logger.info(f"Analyzing {level} document...")
                
                if isinstance(content, list):  # Chunked document
                    for chunk in content:
                        chunk_info = f"Chunk {chunk.chunk_index + 1} of {chunk.total_chunks} (positions {chunk.start_pos}-{chunk.end_pos})"
                        
                        # Process chunk with focused analysis
                        chunk_rules = await self._process_text_chunk(
                            text=chunk.content,
                            chunk_reference=chunk.chunk_id,
                            entry_id=entry_id,
                            level=level,
                            metadata=metadata,
                            existing_context=existing_context,
                            metadata_context=metadata_context,
                            chunk_info=chunk_info
                        )
                        
                        all_rules.extend(chunk_rules)
                        
                        logger.info(f"Processed {len(chunk_rules)} rules from chunk {chunk.chunk_index + 1}")
                
                else:  # Single document
                    level_rules = await self._process_text_chunk(
                        text=content,
                        chunk_reference=None,
                        entry_id=entry_id,
                        level=level,
                        metadata=metadata,
                        existing_context=existing_context,
                        metadata_context=metadata_context,
                        chunk_info=""
                    )
                    
                    all_rules.extend(level_rules)
                    logger.info(f"Processed {len(level_rules)} rules from {level} document")
            
            if all_rules:
                rule_texts = [f"{rule.description} {rule.source_article}" for rule in all_rules]
                embeddings = await self.openai_service.get_embeddings(rule_texts)
            else:
                embeddings = []
            
            integrated_rules = []
            for rule in all_rules:
                try:
                    integrated_rule = self.standards_converter.json_rules_to_integrated(rule)
                    integrated_rules.append(integrated_rule)
                except Exception as e:
                    logger.warning(f"Error converting rule {rule.id} to integrated format: {e}")
                    continue
            
            end_time = datetime.utcnow()
            processing_time = (end_time - start_time).total_seconds()
            total_actions = sum(len(rule.actions) for rule in all_rules)
            total_user_actions = sum(len(rule.user_actions) for rule in all_rules)
            
            result = ExtractionResult(
                rules=all_rules,
                summary=f"Extracted {len(all_rules)} rules with {total_actions} rule actions and {total_user_actions} user actions from {entry_id}",
                total_rules=len(all_rules),
                total_actions=total_actions,
                total_user_actions=total_user_actions,
                processing_time=processing_time,
                embeddings=embeddings,
                integrated_rules=integrated_rules,
                documents_processed={entry_id: list(entry_documents.keys())}
            )
            
            logger.info(f"Analysis completed: {len(all_rules)} rules with {total_actions} rule actions and {total_user_actions} user actions extracted in {processing_time:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"Error analyzing legislation with levels: {e}")
            raise
    
    async def _process_text_chunk(
        self,
        text: str,
        chunk_reference: Optional[str],
        entry_id: str,
        level: str,
        metadata: CountryMetadata,
        existing_context: str,
        metadata_context: str,
        chunk_info: str
    ) -> List[LegislationRule]:
        """Process a single text chunk (or full document)."""
        
        # Step 1: Focused analysis
        focused_analysis = await self._apply_focused_analysis(
            text, existing_context + metadata_context, level, chunk_info
        )
        
        # Step 2: Expert verification
        verified_analysis = await self._apply_expert_verification(
            text, focused_analysis, level
        )
        
        # Step 3: Use react agent for DUAL action inference (rule + user actions)
        agent_analysis = await self._run_dual_action_inference_agent(
            text, f"{entry_id} - {level}", metadata.country, chunk_reference
        )
        
        # Step 4: Synthesize into rules with DUAL actions
        rules = await self._synthesize_rules_with_dual_actions(
            legislation_text=text,
            article_reference=f"{entry_id} - {level}",
            source_files={
                "level_1": metadata.file_level_1,
                "level_2": metadata.file_level_2,
                "level_3": metadata.file_level_3
            },
            document_level=level,
            chunk_reference=chunk_reference,
            existing_context=existing_context,
            metadata_context=metadata_context,
            applicable_countries=metadata.country,
            adequacy_countries=metadata.adequacy_country,
            focused_analysis=focused_analysis,
            verified_analysis=verified_analysis,
            agent_analysis=agent_analysis
        )
        
        return rules
    
    async def _apply_focused_analysis(self, legislation_text: str, existing_context: str = "", level: str = "level_1", chunk_info: str = "") -> str:
        """Apply focused analysis to avoid hallucination."""
        prompt = PromptingStrategies.focused_analysis_prompt(legislation_text, existing_context, level, chunk_info)
        
        messages = [
            SystemMessage(content="You are a legal text analyst. Analyze only what is present in the legislation text. Use simple, clear English."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _apply_expert_verification(self, legislation_text: str, preliminary_analysis: str, level: str = "level_1") -> str:
        """Apply expert verification to validate findings."""
        prompt = PromptingStrategies.expert_verification_prompt(legislation_text, preliminary_analysis, level)
        
        messages = [
            SystemMessage(content="You are a legal compliance expert. Verify analysis accuracy against source text. Use simple, clear English."),
            HumanMessage(content=prompt)
        ]
        
        return await self.openai_service.chat_completion(messages)
    
    async def _run_dual_action_inference_agent(self, legislation_text: str, article_reference: str, countries: List[str], chunk_reference: Optional[str] = None) -> str:
        """Run react agent for DUAL action inference (rule actions + user actions)."""
        try:
            config = {"configurable": {"thread_id": f"analysis_{datetime.utcnow().timestamp()}"}}
            
            chunk_info = f" (Chunk: {chunk_reference})" if chunk_reference else ""
            
            message = f"""
            Analyze the following legislation text and infer BOTH organizational rule actions AND practical user actions.
            
            Article: {article_reference}{chunk_info}
            Countries: {', '.join(countries)}
            Text: {legislation_text}
            
            Use the available tools to:
            1. Identify specific rule conditions related to data processing
            2. Analyze data domains and categories involved
            3. Identify roles and responsibilities for data handling
            
            ORIGINAL ACTION INFERENCE (Rule Actions):
            4. Infer data processing actions required by organizations/controllers/processors
            5. Infer compliance verification actions for organizational compliance
            6. Infer actions related to data subject rights that organizations must implement
            
            NEW USER ACTION INFERENCE (User Actions):
            7. Infer user actionable tasks that individuals can perform with their data
            8. Infer user compliance tasks for individual compliance
            9. Infer user rights support tasks that individuals can implement
            
            FOCUS CONSTRAINTS:
            - RULE ACTIONS: Organizational, policy-level, systematic actions
            - USER ACTIONS: Individual, practical, implementable tasks with available tools
            - Base ALL actions on explicit legislative requirements
            - Ensure actions are practical and implementable
            - Avoid abstract concepts - focus on concrete operations
            - Use simple, clear English - avoid legal jargon
            
            Provide analysis that enables creation of machine-readable rules with BOTH organizational rule actions AND practical user actions.
            """
            
            result = self.agent.invoke(
                {"messages": [HumanMessage(content=message)]},
                config
            )
            
            if result and "messages" in result:
                last_message = result["messages"][-1]
                if hasattr(last_message, 'content'):
                    return last_message.content
                elif isinstance(last_message, dict) and 'content' in last_message:
                    return last_message['content']
            
            return "Agent analysis completed but no content returned"
            
        except Exception as e:
            logger.error(f"Error running dual action inference agent: {e}")
            return f"Error in agent analysis: {str(e)}"
    
    async def _synthesize_rules_with_dual_actions(
        self, 
        legislation_text: str,
        article_reference: str,
        source_files: Dict[str, Optional[str]],
        document_level: str,
        chunk_reference: Optional[str],
        existing_context: str,
        metadata_context: str,
        applicable_countries: List[str],
        adequacy_countries: List[str],
        focused_analysis: str,
        verified_analysis: str,
        agent_analysis: str
    ) -> List[LegislationRule]:
        """Synthesize all analyses into structured rules with BOTH rule actions and user actions."""
        
        applicable_countries_json = json.dumps(applicable_countries)
        adequacy_countries_json = json.dumps(adequacy_countries)
        source_files_json = json.dumps(source_files)
        
        chunk_context = f"\nCHUNK REFERENCE: {chunk_reference}\n" if chunk_reference else ""
        
        synthesis_prompt = f"""
        Based on the analyses below, create machine-readable rules with BOTH organizational rule actions and user actions inferred from the legislation text.
        
        EXISTING RULES CONTEXT:
        {existing_context}
        
        METADATA CONTEXT:
        {metadata_context}{chunk_context}
        
        SOURCE LEGISLATION:
        Article: {article_reference}
        Document Level: {document_level}
        Source Files: {source_files_json}
        Text: {legislation_text}
        
        ANALYSIS RESULTS:
        
        Focused Analysis:
        {focused_analysis}
        
        Expert Verification:
        {verified_analysis}
        
        Agent Dual Action Analysis:
        {agent_analysis}
        
        SYNTHESIS REQUIREMENTS:
        1. Create rules in json-rules-engine format
        2. Each condition must reference the document level: "{document_level}"
        3. Each condition must include chunk_reference if applicable: {chunk_reference}
        4. Actions are optional - only include if they can be reasonably inferred from the legislation
        5. User actions are optional - only include if they can be reasonably inferred
        6. Actions must be data-specific and based on legislative requirements
        7. Use exact enum values for all structured fields
        8. Timeline is optional - include only if mentioned in legislation
        9. Use simple, clear English - avoid legal jargon
        
        For each ORGANIZATIONAL ACTION (if inferable), provide:
        - id: unique identifier
        - action_type: organizational action (e.g., "implement_encryption", "obtain_consent")
        - title: clear action title in simple English
        - description: what organization must do in simple English
        - priority: based on legislative language
        - data_specific_steps: concrete organizational steps for data handling
        - legislative_requirement: exact requirement from legislation
        - data_impact: how this affects data processing
        - verification_method: how to verify organizational compliance
        - derived_from_text: exact legislative text requiring this action
        - confidence_score: assessment of inference accuracy (0.0-1.0)
        
        For each USER ACTION (if inferable), provide:
        - id: unique identifier
        - action_type: user action (e.g., "delete_account", "withdraw_consent")
        - title: clear task title for users in simple English
        - description: what users must do in simple English
        - priority: based on legislative context
        - user_data_steps: concrete steps for user data handling
        - affected_data_categories: types of data involved
        - legislative_requirement: exact requirement from legislation
        - compliance_outcome: what compliance goal this achieves
        - user_verification_steps: how users can verify completion
        - tools_needed: what users need to perform the task
        - derived_from_text: exact text requiring this task
        - confidence_score: assessment of inference accuracy (0.0-1.0)
        
        Only include actions that can be reasonably inferred from the legislation text.
        Return valid JSON array. If no actions can be inferred, return empty arrays for actions and user_actions.
        
        Return ONLY valid JSON array, no other text.
        """
        
        messages = [
            SystemMessage(content="You are a legal-tech expert. Create COMPLETE rules with ALL required fields. Every rule must have: id, name, description, conditions, event, priority. Use simple, clear English."),
            HumanMessage(content=synthesis_prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        
        parsed_data = self.json_parser.parse_json_response(response)
        
        if "error" in parsed_data:
            logger.error(f"Failed to parse rules JSON: {parsed_data}")
            return []
        
        rules = []
        try:
            if isinstance(parsed_data, list):
                rule_data_list = parsed_data
            elif isinstance(parsed_data, dict) and "rules" in parsed_data:
                rule_data_list = parsed_data["rules"]
            else:
                rule_data_list = [parsed_data]
            
            for rule_data in rule_data_list:
                try:
                    # Clean up any misplaced action-level fields that don't belong at rule level
                    action_level_fields = [
                        'action_type', 'data_specific_steps', 'legislative_requirement', 
                        'data_impact', 'verification_method', 'derived_from_text',
                        'responsible_role', 'timeline', 'user_data_steps', 
                        'affected_data_categories', 'user_role_context', 
                        'compliance_outcome', 'user_verification_steps', 
                        'prerequisites', 'tools_needed'
                    ]
                    
                    # Remove action-level fields from rule level if they exist
                    for field in action_level_fields:
                        if field in rule_data:
                            logger.warning(f"Removing misplaced action field '{field}' from rule level")
                            del rule_data[field]
                    
                    # Ensure ALL required fields are present with defaults
                    rule_data.setdefault("id", f"rule_{datetime.utcnow().timestamp()}")
                    rule_data.setdefault("name", "Legislative Rule")
                    rule_data.setdefault("description", "Rule extracted from legislation")
                    
                    # Ensure priority is an integer
                    priority_value = rule_data.get("priority", 1)
                    if isinstance(priority_value, str):
                        try:
                            rule_data["priority"] = int(priority_value)
                        except ValueError:
                            rule_data["priority"] = 1
                    elif not isinstance(priority_value, int):
                        rule_data["priority"] = 1
                    else:
                        rule_data["priority"] = priority_value
                    
                    # Ensure confidence_score is a float
                    confidence_value = rule_data.get("confidence_score", 0.8)
                    if isinstance(confidence_value, str):
                        try:
                            rule_data["confidence_score"] = float(confidence_value)
                        except ValueError:
                            rule_data["confidence_score"] = 0.8
                    elif not isinstance(confidence_value, (int, float)):
                        rule_data["confidence_score"] = 0.8
                    else:
                        rule_data["confidence_score"] = float(confidence_value)
                    
                    rule_data.setdefault("source_article", article_reference)
                    rule_data.setdefault("source_file", source_files.get("level_1", "unknown"))
                    rule_data.setdefault("applicable_countries", applicable_countries)
                    rule_data.setdefault("adequacy_countries", adequacy_countries)
                    rule_data.setdefault("source_documents", source_files)
                    
                    # Ensure event field exists with proper structure
                    if "event" not in rule_data or not isinstance(rule_data["event"], dict):
                        rule_data["event"] = {
                            "type": "compliance_required",
                            "params": {}
                        }
                    
                    # Fix conditions structure - ensure it's a proper dictionary
                    if "conditions" not in rule_data:
                        rule_data["conditions"] = {}
                    
                    # Convert conditions to proper format if needed
                    conditions = rule_data["conditions"]
                    if isinstance(conditions, list):
                        # If conditions is a list, wrap it in "all" logic
                        rule_data["conditions"] = {"all": conditions}
                    elif not isinstance(conditions, dict):
                        # If conditions is neither list nor dict, create default
                        rule_data["conditions"] = {"all": []}
                    
                    # Ensure conditions dictionary has at least one logic key
                    conditions = rule_data["conditions"]
                    if not any(key in conditions for key in ['all', 'any', 'not']):
                        # If no valid logic keys, create a default condition
                        rule_data["conditions"] = {
                            "all": [
                                {
                                    "fact": "data_processing_activity",
                                    "operator": "equal",
                                    "value": "data_processing",
                                    "description": "When data processing occurs as mentioned in legislation",
                                    "data_domain": ["data_usage"],
                                    "role": "controller",
                                    "reasoning": "Basic condition extracted from legislative requirements",
                                    "document_level": document_level,
                                    "chunk_reference": chunk_reference or "none"
                                }
                            ]
                        }
                    
                    # Validate and fix each condition in the conditions dictionary
                    for logic_type in list(conditions.keys()):
                        if logic_type in ['all', 'any', 'not']:
                            condition_list = conditions[logic_type]
                            if not isinstance(condition_list, list):
                                # If not a list, make it an empty list
                                conditions[logic_type] = []
                                continue
                            
                            # Fix each condition in the list
                            for i, condition in enumerate(condition_list):
                                if isinstance(condition, dict):
                                    # Ensure all required condition fields
                                    condition.setdefault("fact", "data_processing_activity")
                                    condition.setdefault("operator", "equal")
                                    condition.setdefault("value", "data_processing")
                                    condition.setdefault("description", "Legislative requirement condition")
                                    condition.setdefault("data_domain", ["data_usage"])
                                    condition.setdefault("role", "controller")
                                    condition.setdefault("reasoning", "Extracted from legislative text")
                                    condition.setdefault("document_level", document_level)
                                    condition.setdefault("chunk_reference", chunk_reference or "none")
                                else:
                                    # Replace invalid condition with default
                                    conditions[logic_type][i] = {
                                        "fact": "data_processing_activity",
                                        "operator": "equal",
                                        "value": "data_processing",
                                        "description": "Legislative requirement condition",
                                        "data_domain": ["data_usage"],
                                        "role": "controller",
                                        "reasoning": "Default condition due to parsing error",
                                        "document_level": document_level,
                                        "chunk_reference": chunk_reference or "none"
                                    }
                        else:
                            # Remove invalid logic keys
                            del conditions[logic_type]
                    
                    # Ensure at least one condition exists
                    if not any(conditions.get(key) for key in ['all', 'any', 'not']):
                        rule_data["conditions"]["all"] = [
                            {
                                "fact": "data_processing_activity",
                                "operator": "equal",
                                "value": "data_processing",
                                "description": "Default condition - data processing activity",
                                "data_domain": ["data_usage"],
                                "role": "controller",
                                "reasoning": "Fallback condition created due to missing conditions",
                                "document_level": document_level,
                                "chunk_reference": chunk_reference or "none"
                            }
                        ]
                    
                    # Add processing metadata
                    processing_metadata = {"extraction_method": "focused_analysis_with_dual_action_inference"}
                    if chunk_reference:
                        processing_metadata["chunk_reference"] = chunk_reference
                    rule_data.setdefault("processing_metadata", processing_metadata)
                    
                    # Actions and user_actions are optional
                    rule_data.setdefault("actions", [])
                    rule_data.setdefault("user_actions", [])
                    
                    # Process actions if they exist
                    if "actions" in rule_data and isinstance(rule_data["actions"], list):
                        for action in rule_data["actions"]:
                            if isinstance(action, dict):
                                action.setdefault("id", f"action_{datetime.utcnow().timestamp()}")
                                action.setdefault("action_type", "general_action")
                                action.setdefault("title", "Action Required")
                                action.setdefault("description", "Action based on legislative requirement")
                                action.setdefault("priority", "medium")
                                action.setdefault("data_specific_steps", [])
                                action.setdefault("responsible_role", "controller")
                                action.setdefault("legislative_requirement", "Legislative compliance")
                                action.setdefault("data_impact", "Affects data processing")
                                action.setdefault("verification_method", [])
                                action.setdefault("derived_from_text", legislation_text[:200])
                                action.setdefault("applicable_countries", applicable_countries)
                                action.setdefault("confidence_score", 0.8)
                    
                    # Process user_actions if they exist
                    if "user_actions" in rule_data and isinstance(rule_data["user_actions"], list):
                        for action in rule_data["user_actions"]:
                            if isinstance(action, dict):
                                action.setdefault("id", f"user_action_{datetime.utcnow().timestamp()}")
                                action.setdefault("action_type", "user_general_action")
                                action.setdefault("title", "User Action Required")
                                action.setdefault("description", "User action based on legislative requirement")
                                action.setdefault("priority", "medium")
                                action.setdefault("user_data_steps", [])
                                action.setdefault("affected_data_categories", [])
                                action.setdefault("user_role_context", "data_subject")
                                action.setdefault("legislative_requirement", "Legislative compliance")
                                action.setdefault("compliance_outcome", "Achieves compliance")
                                action.setdefault("user_verification_steps", [])
                                action.setdefault("tools_needed", [])
                                action.setdefault("derived_from_text", legislation_text[:200])
                                action.setdefault("confidence_score", 0.8)
                    
                    # Validate and create the rule using Pydantic v2
                    rule = LegislationRule.model_validate(rule_data)
                    rules.append(rule)
                    logger.info(f"Successfully created rule: {rule.name} with {len(rule.actions)} actions and {len(rule.user_actions)} user actions")
                    
                except Exception as e:
                    logger.warning(f"Skipping invalid rule due to error: {e}")
                    logger.warning(f"Rule data keys: {list(rule_data.keys()) if isinstance(rule_data, dict) else 'Not a dict'}")
                    if isinstance(rule_data, dict) and "conditions" in rule_data:
                        logger.warning(f"Conditions type: {type(rule_data['conditions'])}")
                        logger.warning(f"Conditions content: {rule_data['conditions']}")
                    continue
                    
        except Exception as e:
            logger.error(f"Error processing rule data: {e}")
            
        # If no rules were created, create a guaranteed minimal rule
        if not rules:
            logger.warning("No rules could be parsed, creating minimal rule from legislation")
            try:
                minimal_rule_data = {
                    "id": f"minimal_rule_{datetime.utcnow().timestamp()}",
                    "name": "Legislative Requirement",
                    "description": f"Requirement extracted from {article_reference}",
                    "source_article": article_reference,
                    "source_file": source_files.get("level_1", "unknown"),
                    "conditions": {
                        "all": [
                            {
                                "fact": "legislative_text_present",
                                "operator": "equal",
                                "value": True,
                                "description": "Legislative text contains requirements",
                                "data_domain": ["data_usage"],
                                "role": "controller",
                                "reasoning": "Minimal condition based on presence of legislative text",
                                "document_level": document_level,
                                "chunk_reference": chunk_reference or "none"
                            }
                        ]
                    },
                    "event": {
                        "type": "compliance_required",
                        "params": {}
                    },
                    "priority": 1,
                    "actions": [],
                    "user_actions": [],
                    "confidence_score": 0.5,
                    "applicable_countries": applicable_countries,
                    "adequacy_countries": adequacy_countries,
                    "source_documents": source_files,
                    "processing_metadata": {
                        "extraction_method": "minimal_fallback",
                        "chunk_reference": chunk_reference or "none"
                    }
                }
                
                minimal_rule = LegislationRule.model_validate(minimal_rule_data)
                rules.append(minimal_rule)
                logger.info("Created minimal fallback rule")
                
            except Exception as e:
                logger.error(f"Failed to create minimal rule: {e}")
            
        return rules

# ===============================
# MAIN EXECUTION FUNCTION
# ===============================

async def main():
    """Main execution function with enhanced processing."""
    
    analyzer = LegislationAnalyzer()
    
    try:
        print("\n=== ADVANCED LEGISLATION RULES CONVERTER WITH DUAL ACTION INFERENCE ===")
        print("Processing legislation with dynamic chunking, dual action inference (rule + user), and anti-hallucination measures...\n")
        
        # Show metadata configuration
        print("📋 METADATA CONFIGURATION:")
        processing_entries = analyzer.metadata_manager.get_all_processing_entries()
        if processing_entries:
            print(f"✅ Configured entries: {len(processing_entries)}")
            for entry_id, metadata in processing_entries:
                print(f"   📂 {entry_id}:")
                print(f"      🌍 Countries: {', '.join(metadata.country)}")
                if metadata.adequacy_country:
                    print(f"      🤝 Adequacy: {', '.join(metadata.adequacy_country)}")
                if metadata.file_level_1:
                    print(f"      📄 Level 1: {metadata.file_level_1}")
                if metadata.file_level_2:
                    print(f"      📖 Level 2: {metadata.file_level_2}")
                if metadata.file_level_3:
                    print(f"      📘 Level 3: {metadata.file_level_3}")
                print()
        else:
            print("⚠️ No configured entries found in legislation_metadata.json")
            print("Please create legislation_metadata.json with your configuration")
            return
        
        print(f"📁 Config file: {Config.METADATA_CONFIG_FILE}")
        print(f"🔧 Chunk size: {Config.CHUNK_SIZE} chars, Overlap: {Config.OVERLAP_SIZE} chars")
        print(f"📏 Chunking threshold: {Config.MAX_FILE_SIZE / (1024*1024):.1f} MB")
        print()
        
        # Check PDF processing availability
        if not PDF_AVAILABLE:
            print("⚠️ Warning: PDF processing libraries not available.")
            print("Install with: pip install PyMuPDF pdfplumber")
            return
        
        # Process configured entries
        print("🔍 Processing configured legislation entries...")
        os.makedirs(Config.LEGISLATION_PDF_PATH, exist_ok=True)
        
        result = await analyzer.process_legislation_folder()
        
        # Print results
        print(f"\n=== PROCESSING RESULTS ===")
        print(f"📊 Summary: {result.summary}")
        print(f"📈 Total Rules: {result.total_rules}")
        print(f"🎯 Total Rule Actions: {result.total_actions}")
        print(f"👤 Total User Actions: {result.total_user_actions}")
        print(f"⏱️ Processing Time: {result.processing_time:.2f} seconds")
        print(f"🔗 Integrated Rules: {len(result.integrated_rules)}")
        print(f"📚 Documents Processed: {result.documents_processed}")
        
        if result.chunking_metadata:
            print(f"🧩 Chunking Applied:")
            for doc_id, chunk_info in result.chunking_metadata.items():
                print(f"   {doc_id}: {chunk_info['chunks']} chunks")
        
        if result.rules:
            print(f"\n=== EXTRACTED RULES WITH DUAL ACTIONS ===")
            for i, rule in enumerate(result.rules, 1):
                print(f"\n🔍 Rule {i}: {rule.name}")
                print(f"   📝 Description: {rule.description}")
                print(f"   📄 Source: {rule.source_article}")
                
                # Display roles and data categories
                primary_role_display = "not_specified"
                if rule.primary_impacted_role:
                    primary_role_display = rule.primary_impacted_role.value if hasattr(rule.primary_impacted_role, 'value') else str(rule.primary_impacted_role)
                print(f"   🎯 Primary Role: {primary_role_display}")
                
                if rule.secondary_impacted_role:
                    secondary_role_display = rule.secondary_impacted_role.value if hasattr(rule.secondary_impacted_role, 'value') else str(rule.secondary_impacted_role)
                    print(f"   🎯 Secondary Role: {secondary_role_display}")
                
                data_categories_display = []
                if rule.data_category:
                    data_categories_display = [cat.value if hasattr(cat, 'value') else str(cat) for cat in rule.data_category]
                print(f"   📊 Data Categories: {', '.join(data_categories_display) if data_categories_display else 'not_specified'}")
                
                print(f"   🌍 Countries: {', '.join(rule.applicable_countries) if rule.applicable_countries else 'Not specified'}")
                print(f"   ⭐ Confidence: {rule.confidence_score}")
                
                # Show processing metadata including chunking
                if rule.processing_metadata:
                    if rule.processing_metadata.get("chunk_reference"):
                        print(f"   🧩 Chunk: {rule.processing_metadata['chunk_reference']}")
                
                print(f"   📋 Conditions:")
                for logic_type, conditions in rule.conditions.items():
                    print(f"      {logic_type.upper()}:")
                    for condition in conditions:
                        print(f"        - {condition.description}")
                        
                        operator_display = condition.operator.value if hasattr(condition.operator, 'value') else str(condition.operator)
                        role_display = "not_specified"
                        if condition.role:
                            role_display = condition.role.value if hasattr(condition.role, 'value') else str(condition.role)
                        
                        domain_displays = []
                        if condition.data_domain:
                            domain_displays = [d.value if hasattr(d, 'value') else str(d) for d in condition.data_domain]
                        
                        level_display = condition.document_level.value if hasattr(condition.document_level, 'value') else str(condition.document_level)
                        
                        print(f"          Fact: {condition.fact} | Operator: {operator_display} | Value: {condition.value}")
                        print(f"          Role: {role_display} | Domains: {', '.join(domain_displays) if domain_displays else 'not_specified'}")
                        print(f"          Level: {level_display}")
                        if condition.chunk_reference:
                            print(f"          Chunk: {condition.chunk_reference}")
                
                # Show RULE ACTIONS (Organizational)
                if rule.actions:
                    print(f"   🏢 RULE ACTIONS - Organizational ({len(rule.actions)}):")
                    for action in rule.actions:
                        print(f"      🔧 {action.title} ({action.action_type})")
                        print(f"         Priority: {action.priority}")
                        print(f"         Description: {action.description}")
                        print(f"         Legislative Requirement: {action.legislative_requirement}")
                        print(f"         Data Impact: {action.data_impact}")
                        print(f"         Data-Specific Steps: {', '.join(action.data_specific_steps)}")
                        if action.responsible_role:
                            print(f"         Responsible: {action.responsible_role}")
                        if action.timeline:
                            print(f"         Timeline: {action.timeline}")
                        print(f"         Verification: {', '.join(action.verification_method)}")
                        print(f"         Derived From: {action.derived_from_text[:100]}...")
                        print(f"         Confidence: {action.confidence_score}")
                        print()
                else:
                    print(f"   🏢 RULE ACTIONS - Organizational: None inferred")
                
                # Show USER ACTIONS (Individual)
                if rule.user_actions:
                    print(f"   👤 USER ACTIONS - Individual ({len(rule.user_actions)}):")
                    for action in rule.user_actions:
                        print(f"      🔧 {action.title} ({action.action_type})")
                        print(f"         Priority: {action.priority}")
                        print(f"         Description: {action.description}")
                        print(f"         Legislative Requirement: {action.legislative_requirement}")
                        print(f"         Compliance Outcome: {action.compliance_outcome}")
                        print(f"         User Data Steps: {', '.join(action.user_data_steps)}")
                        if action.affected_data_categories:
                            print(f"         Affected Data: {', '.join(action.affected_data_categories)}")
                        if action.user_role_context:
                            print(f"         User Role: {action.user_role_context}")
                        if action.timeline:
                            print(f"         Timeline: {action.timeline}")
                        if action.prerequisites:
                            print(f"         Prerequisites: {', '.join(action.prerequisites)}")
                        if action.tools_needed:
                            print(f"         Tools Needed: {', '.join(action.tools_needed)}")
                        print(f"         User Verification: {', '.join(action.user_verification_steps)}")
                        print(f"         Derived From: {action.derived_from_text[:100]}...")
                        print(f"         Confidence: {action.confidence_score}")
                        print()
                else:
                    print(f"   👤 USER ACTIONS - Individual: None inferred")
                
                # Show integrated alignment
                if i <= len(result.integrated_rules):
                    integrated_rule = result.integrated_rules[i-1]
                    print(f"   🔗 Integrated Standards:")
                    print(f"      DPV Processing: {[p.split('#')[-1] for p in integrated_rule.dpv_hasProcessing] if integrated_rule.dpv_hasProcessing else 'none'}")
                    print(f"      DPV Purposes: {[p.split('#')[-1] for p in integrated_rule.dpv_hasPurpose] if integrated_rule.dpv_hasPurpose else 'none'}")
                    print(f"      DPV Data Types: {[d.split('#')[-1] for d in integrated_rule.dpv_hasPersonalData] if integrated_rule.dpv_hasPersonalData else 'none'}")
                    print(f"      DPV Rule Actions: {[a.split('#')[-1] for a in integrated_rule.dpv_hasRuleAction] if integrated_rule.dpv_hasRuleAction else 'none'}")
                    print(f"      DPV User Actions: {[a.split('#')[-1] for a in integrated_rule.dpv_hasUserAction] if integrated_rule.dpv_hasUserAction else 'none'}")
                    print(f"      ODRE Dual Action Inference: Rule={integrated_rule.odre_action_inference}, User={integrated_rule.odre_user_action_inference}")
                    if integrated_rule.chunk_references:
                        print(f"      Chunk References: {integrated_rule.chunk_references}")
                
                print("-" * 80)
        
        # Save results in multiple formats
        if result.rules:
            print(f"\n=== SAVING RESULTS ===")
            
            # Ensure output directories exist
            os.makedirs(Config.RULES_OUTPUT_PATH, exist_ok=True)
            os.makedirs(Config.STANDARDS_OUTPUT_PATH, exist_ok=True)
            
            # Generate timestamp for unique filenames
            timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
            
            print("Enhanced formats with dual actions:")
            
            # Save JSON format with dual actions
            json_file = os.path.join(Config.RULES_OUTPUT_PATH, f"rules_with_dual_actions_{timestamp}.json")
            result.save_json(json_file)
            print(f"   JSON Rules with Dual Actions: {json_file}")
            
            # Save CSV format with dual actions
            csv_file = os.path.join(Config.RULES_OUTPUT_PATH, f"rules_with_dual_actions_{timestamp}.csv")
            result.save_csv(csv_file)
            
            print("\nIntegrated Standards Formats:")
            
            # Save integrated formats
            if result.integrated_rules:
                integrated_ttl_file = os.path.join(Config.STANDARDS_OUTPUT_PATH, f"integrated_standards_{timestamp}.ttl")
                result.save_integrated_ttl(integrated_ttl_file)
                print(f"   Integrated TTL: {integrated_ttl_file}")
                
                integrated_jsonld_file = os.path.join(Config.STANDARDS_OUTPUT_PATH, f"integrated_standards_{timestamp}.jsonld")
                result.save_integrated_jsonld(integrated_jsonld_file)
                print(f"   Integrated JSON-LD: {integrated_jsonld_file}")
                
                integrated_json_file = os.path.join(Config.STANDARDS_OUTPUT_PATH, f"integrated_rules_{timestamp}.json")
                result.save_integrated_json(integrated_json_file)
                print(f"   Integrated JSON: {integrated_json_file}")
            
            print(f"\nStandards Integration Summary:")
            print(f"   DPV v2.1: Processing activities with dynamic action mappings")
            print(f"   ODRL: Policy expressions with data-specific constraints") 
            print(f"   ODRE: Enforcement framework with dual action inference capability")
            print(f"   Multi-Level Processing: Legislation + guidance docs integration")
            print(f"   Dynamic Chunking: Large document processing support")
            print(f"   Anti-Hallucination: Focused analysis with verification")
            
            # Show dual action statistics
            if result.total_actions > 0 or result.total_user_actions > 0:
                rule_action_types = {}
                user_action_types = {}
                priorities = {}
                tools_needed = {}
                
                for rule in result.rules:
                    # Rule action statistics
                    for action in rule.actions:
                        rule_action_types[action.action_type] = rule_action_types.get(action.action_type, 0) + 1
                        priorities[action.priority] = priorities.get(action.priority, 0) + 1
                    
                    # User action statistics
                    for action in rule.user_actions:
                        user_action_types[action.action_type] = user_action_types.get(action.action_type, 0) + 1
                        priorities[action.priority] = priorities.get(action.priority, 0) + 1
                        for tool in action.tools_needed:
                            tools_needed[tool] = tools_needed.get(tool, 0) + 1
                
                print(f"\n🎯 DUAL ACTION INFERENCE STATISTICS:")
                print(f"   Total Rule Actions (Organizational): {result.total_actions}")
                print(f"   Total User Actions (Individual): {result.total_user_actions}")
                print(f"   Unique Rule Action Types: {len(rule_action_types)}")
                print(f"   Unique User Action Types: {len(user_action_types)}")
                if rule_action_types:
                    print(f"   Most Common Rule Types: {dict(sorted(rule_action_types.items(), key=lambda x: x[1], reverse=True)[:3])}")
                if user_action_types:
                    print(f"   Most Common User Types: {dict(sorted(user_action_types.items(), key=lambda x: x[1], reverse=True)[:3])}")
                print(f"   Priority Distribution: {dict(priorities)}")
                if tools_needed:
                    print(f"   Most Needed Tools: {dict(sorted(tools_needed.items(), key=lambda x: x[1], reverse=True)[:5])}")
                
                # Calculate average confidence for both action types
                if result.total_actions > 0:
                    total_rule_confidence = sum(action.confidence_score for rule in result.rules for action in rule.actions)
                    avg_rule_confidence = total_rule_confidence / result.total_actions
                    print(f"   Average Rule Action Confidence: {avg_rule_confidence:.2f}")
                
                if result.total_user_actions > 0:
                    total_user_confidence = sum(action.confidence_score for rule in result.rules for action in rule.user_actions)
                    avg_user_confidence = total_user_confidence / result.total_user_actions
                    print(f"   Average User Action Confidence: {avg_user_confidence:.2f}")
            
            # Show database status
            total_existing = len(analyzer.rule_manager.existing_rules)
            existing_rule_actions = sum(len(rule.actions) for rule in analyzer.rule_manager.existing_rules)
            existing_user_actions = sum(len(rule.user_actions) for rule in analyzer.rule_manager.existing_rules)
            print(f"\n=== RULE DATABASE STATUS ===")
            print(f"Total rules in database: {total_existing}")
            print(f"Total rule actions in database: {existing_rule_actions}")
            print(f"Total user actions in database: {existing_user_actions}")
            print(f"New rules added: {len(result.rules)}")
            print(f"New rule actions added: {result.total_actions}")
            print(f"New user actions added: {result.total_user_actions}")
            print(f"Database file: {Config.EXISTING_RULES_FILE}")
            
        else:
            print("\nNo rules were extracted.")
        
        print(f"\nAdvanced processing with dual action inference complete!")
        
    except Exception as e:
        logger.error(f"Error in main execution: {e}")
        raise

if __name__ == "__main__":
    # Run the enhanced main function
    asyncio.run(main())
