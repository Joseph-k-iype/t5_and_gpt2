"""
Fixed workflow implementation with error handling and proper method access.
Replace app/agents/workflow.py with this implementation.
"""

import logging
import asyncio
import re
import json
from typing import Dict, Any, List, Optional, Tuple, TypedDict, Annotated, AsyncGenerator
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
from app.core.models import (
    DataElement,
    EnhancedDataElement,
    ValidationResult,
    EnhancementResult,
    DataQualityStatus,
    Process
)
from app.utils.cache import cache_manager
from app.agents.validator_agent import ValidatorAgent # Direct import might not be used if combined call is sufficient

logger = logging.getLogger(__name__)

# Define workflow state
class WorkflowState(TypedDict):
    """State for the data enhancement workflow."""
    data_element: Dict[str, Any] # Store as dict for LangGraph state
    original_data_element_model: DataElement # Keep original model for context
    enhanced_data_model: Optional[EnhancedDataElement] # Store the Pydantic model of enhanced data
    validation_result_model: Optional[ValidationResult] # Store Pydantic model
    enhancement_result_model: Optional[EnhancementResult] # Store Pydantic model
    iterations: int
    max_iterations: int
    current_validation_feedback_str: str # String feedback for the LLM
    is_complete: bool
    error: Optional[str]


class OptimizedDataEnhancementWorkflow:
    """Optimized LangGraph workflow for enhancing data elements with reduced LLM calls."""

    def __init__(self, llm: AzureChatOpenAI):
        self.llm = llm
        # No direct validator needed if combined call handles it.
        # self.validator = ValidatorAgent(llm) # If separate validation calls were made

        self.combined_prompt = PromptTemplate(
            input_variables=["id", "name", "description", "example", "processes_info", "current_validation_feedback_str", "iteration_info"],
            template="""
            You are an expert in data governance and ISO/IEC 11179 metadata standards.
            This is iteration {iteration_info}.
            Your task is to first VALIDATE then ENHANCE the given data element based on the standards and any previous feedback.

            **ISO/IEC 11179 Standards for Data Element Names (Business-Friendly Adaptation):**
            1.  **Format:** Names MUST be in lowercase with single spaces between words.
            2.  **No Technical Casing:** Names MUST NOT use technical formatting like camelCase, snake_case, or PascalCase.
            3.  **No Special Characters:** Names MUST NOT contain underscores, hyphens, or any special characters (e.g., %, &, *, #, /). Only alphanumeric characters and spaces are allowed.
            4.  **Clarity & Unambiguity:** Names should be clear, unambiguous, and self-describing. Avoid vague terms.
            5.  **Acronyms/Abbreviations:** Avoid acronyms or abbreviations unless they are universally understood within the business context (e.g., ID, URL, SKU). If used, ensure they are common knowledge.
            6.  **Conciseness & Descriptiveness:** Names should be concise yet descriptive enough to convey meaning.
            7.  **Standard Terminology:** Use standard terminology relevant to the data element's domain.
            8.  **Business Language:** Use business language that non-technical users can easily understand.

            **ISO/IEC 11179 Standards for Data Element Descriptions:**
            1.  **Clarity of Definition:** Descriptions MUST clearly and precisely define what the data element represents.
            2.  **Completeness:** Descriptions should be complete, fully covering the concept of the data element.
            3.  **Precision:** Descriptions should be specific enough to distinguish the data element from other related concepts.
            4.  **Objectivity:** Descriptions must be objective and factual, not based on opinion.
            5.  **Grammar & Punctuation:** Descriptions MUST use complete sentences with proper grammar and punctuation. Each description should start with a capital letter and end with a period.
            6.  **Business Language:** Descriptions should be written in clear business language, avoiding technical jargon.
            7.  **Avoid Vague Language:** Do not use imprecise phrases like "etc.", "and so on", or "various".

            **Data Element to Evaluate and Enhance:**
            - ID: {id}
            - Current Name: {name}
            - Current Description: {description}
            - Example (if provided): {example}
            {processes_info}

            **Feedback from Previous Validation (if any, "{current_validation_feedback_str}" means no feedback yet or feedback was positive):**
            {current_validation_feedback_str}

            **High-Quality Examples (Target Quality: GOOD):**
            * Original Name: cust_id, Enhanced Name: customer identifier
                Original Description: Customer ID in the system
                Enhanced Description: A unique alphanumeric code assigned to identify an individual customer within the organization's systems.
            * Original Name: LN, Enhanced Name: last name
                Original Description: Last name
                Enhanced Description: The legal surname of an individual as it appears on official identification documents.

            **Task:**
            1.  **VALIDATE** the "Current Name" and "Current Description" against all listed ISO/IEC 11179 standards.
            2.  If validation is not GOOD, or if this is the first attempt, **ENHANCE** the "Current Name" and "Current Description" to fully meet all standards.
            3.  Aim for a "GOOD" quality assessment.

            **Output Format:**
            Provide your response *strictly* in the following format, with each item on a new line. Do not include any extra formatting, numbering, or markdown like asterisks:

            SECTION: VALIDATION
            Is name valid: [yes/no, based on strict adherence to all name standards]
            Name feedback: [Detailed feedback on current name quality. Explain all reasons if not valid.]
            Is description valid: [yes/no, based on strict adherence to all description standards]
            Description feedback: [Detailed feedback on current description quality. Explain all reasons if not valid.]
            Overall quality: [GOOD, NEEDS_IMPROVEMENT, or POOR. GOOD only if both name and description are fully valid according to all standards.]
            Suggested improvements for current element: [List specific improvements if not GOOD. If GOOD, state "No improvements needed for current element." Each on new line, start with "- ". ]

            SECTION: ENHANCEMENT
            Enhanced Name: [Provide the improved name as plain text here, adhering to all name standards]
            Enhanced Description: [Provide the improved description as plain text here, adhering to all description standards. Start with capital, end with period.]
            Enhancement Notes: [Explain changes made and why they improve quality and standard compliance. Be specific.]
            Confidence Score (0.0-1.0): [Provide a numerical confidence score for your enhancement, e.g., 0.9]

            Ensure both VALIDATION and ENHANCEMENT sections are present.
            If the current element is already GOOD, the Enhanced Name and Description should be identical to the Current Name and Description.
            """
        )
        self.combined_chain = self.combined_prompt | self.llm | StrOutputParser()
        self.graph = self._build_graph()

    def _convert_processes_to_model(self, processes_data: Optional[List[Any]]) -> Optional[List[Process]]:
        if not processes_data:
            return None
        processes_list = []
        for proc_item in processes_data:
            if isinstance(proc_item, Process):
                processes_list.append(proc_item)
            elif isinstance(proc_item, dict):
                try:
                    processes_list.append(Process(**proc_item))
                except Exception as e:
                    logger.warning(f"Workflow: Could not convert dict to Process: {proc_item}. Error: {e}")
            else:
                logger.warning(f"Workflow: Unknown process type: {type(proc_item)}")
        return processes_list if processes_list else None

    def _format_processes_info(self, data_element_model: DataElement) -> str:
        if not data_element_model.processes:
            return "Related Processes: None"
        
        processes_info = "Related Processes:\n"
        for i, process in enumerate(data_element_model.processes, 1):
            processes_info += f"  Process {i} ID: {process.process_id}\n"
            processes_info += f"  Process {i} Name: {process.process_name}\n"
            if process.process_description:
                processes_info += f"  Process {i} Description: {process.process_description}\n"
            processes_info += "\n"
        return processes_info.strip()


    async def _call_llm_for_enhancement(self, state: WorkflowState) -> WorkflowState:
        try:
            iteration_num = state["iterations"] + 1
            logger.info(f"Workflow: Starting LLM call for iteration {iteration_num}, element ID: {state['data_element']['id']}")
            
            # Determine current name/description to use for LLM input
            # For first iteration, use original. For subsequent, use previously enhanced.
            if iteration_num == 1:
                name_to_enhance = state["original_data_element_model"].existing_name
                desc_to_enhance = state["original_data_element_model"].existing_description
                data_element_for_context = state["original_data_element_model"]
            else:
                # Use the name/description from the *enhancement_result* of the previous iteration
                prev_enhancement = state.get("enhancement_result_model")
                if prev_enhancement:
                    name_to_enhance = prev_enhancement.enhanced_name
                    desc_to_enhance = prev_enhancement.enhanced_description
                    # Create a temporary DataElement for context if needed, or use original.
                    # For process info etc., original is fine.
                    data_element_for_context = state["original_data_element_model"]
                else: # Should not happen if workflow logic is correct
                    name_to_enhance = state["original_data_element_model"].existing_name
                    desc_to_enhance = state["original_data_element_model"].existing_description
                    data_element_for_context = state["original_data_element_model"]


            processes_info_str = self._format_processes_info(data_element_for_context)
            
            iteration_info_str = f"{iteration_num} of {state['max_iterations']}"
            if state["max_iterations"] == 1: iteration_info_str = "1 (final attempt)"


            llm_response_str = await self.combined_chain.ainvoke({
                "id": data_element_for_context.id,
                "name": name_to_enhance,
                "description": desc_to_enhance,
                "example": data_element_for_context.example or "Not provided",
                "processes_info": processes_info_str,
                "current_validation_feedback_str": state.get("current_validation_feedback_str") or "No prior feedback.",
                "iteration_info": iteration_info_str
            })

            validation_section = ""
            enhancement_section = ""
            current_section = None

            for line in llm_response_str.strip().split('\n'):
                if line.upper().startswith("SECTION: VALIDATION"):
                    current_section = "validation"
                    continue
                elif line.upper().startswith("SECTION: ENHANCEMENT"):
                    current_section = "enhancement"
                    continue
                
                if current_section == "validation":
                    validation_section += line + "\n"
                elif current_section == "enhancement":
                    enhancement_section += line + "\n"
            
            if not validation_section or not enhancement_section:
                logger.error(f"LLM output for {data_element_for_context.id} missing VALIDATION or ENHANCEMENT section. Raw: {llm_response_str[:300]}")
                state["error"] = "LLM output format error: Missing critical sections."
                state["is_complete"] = True
                # Populate with some defaults to avoid crashing later stages if possible
                state["validation_result_model"] = ValidationResult(is_valid=False, quality_status=DataQualityStatus.POOR, feedback="LLM parsing error.", suggested_improvements=["Retry"])
                state["enhancement_result_model"] = EnhancementResult(enhanced_name=name_to_enhance, enhanced_description=desc_to_enhance, feedback="LLM parsing error.", confidence=0.0)
                return state


            validation_result = self._parse_validation_result_from_combined(validation_section.strip())
            enhancement_result = self._parse_enhancement_result_from_combined(enhancement_section.strip())
            
            state["validation_result_model"] = validation_result
            state["enhancement_result_model"] = enhancement_result
            state["iterations"] = iteration_num

            # Create EnhancedDataElement model from the latest enhancement
            # The `data_element` in state is the original one as a dict.
            original_de_dict = state["data_element"]
            
            # Processes should be converted from original_data_element_model
            processes_list_of_models = state["original_data_element_model"].processes
            processes_list_of_dicts = [p.dict() for p in processes_list_of_models] if processes_list_of_models else None


            state["enhanced_data_model"] = EnhancedDataElement(
                id=original_de_dict["id"],
                existing_name=original_de_dict["existing_name"], # original name
                existing_description=original_de_dict["existing_description"], # original desc
                example=original_de_dict.get("example"),
                processes=processes_list_of_models, # Use list of Process models
                cdm=original_de_dict.get("cdm"),
                enhanced_name=enhancement_result.enhanced_name,
                enhanced_description=enhancement_result.enhanced_description,
                quality_status=validation_result.quality_status, # Quality of the *enhanced* version (implicitly from prompt)
                enhancement_iterations=iteration_num,
                validation_feedback=[validation_result.feedback], # Store feedback from this iteration
                enhancement_feedback=[enhancement_result.feedback], # Store notes from this iteration
                confidence_score=enhancement_result.confidence
            )
            
            logger.info(f"Workflow: Iteration {iteration_num} for {original_de_dict['id']} resulted in quality: {validation_result.quality_status}")
            return state

        except Exception as e:
            logger.error(f"Error in LLM call/parsing for element {state['data_element']['id']}: {e}", exc_info=True)
            state["error"] = f"LLM processing error: {str(e)}"
            state["is_complete"] = True
            # Ensure models are populated with error state to avoid None issues
            state["validation_result_model"] = ValidationResult(is_valid=False, quality_status=DataQualityStatus.POOR, feedback=f"Error: {str(e)}", suggested_improvements=["Retry"])
            current_name = state["original_data_element_model"].existing_name
            current_desc = state["original_data_element_model"].existing_description
            state["enhancement_result_model"] = EnhancementResult(enhanced_name=current_name, enhanced_description=current_desc, feedback=f"Error: {str(e)}", confidence=0.0)
            return state

    def _parse_validation_result_from_combined(self, validation_text: str) -> ValidationResult:
        lines = validation_text.strip().split("\n")
        is_name_valid_str = ""
        name_feedback_str = ""
        is_desc_valid_str = ""
        desc_feedback_str = ""
        quality_status_str = ""
        improvements_list = []

        parsing_name_feedback = False
        parsing_desc_feedback = False
        parsing_improvements = False

        for line in lines:
            line_lower = line.lower()
            
            if line_lower.startswith("is name valid:"):
                is_name_valid_str = line.split(":", 1)[1].strip().lower()
                parsing_name_feedback = False; parsing_desc_feedback = False; parsing_improvements = False
            elif line_lower.startswith("name feedback:"):
                name_feedback_str = line.split(":", 1)[1].strip()
                parsing_name_feedback = True; parsing_desc_feedback = False; parsing_improvements = False
            elif line_lower.startswith("is description valid:"):
                is_desc_valid_str = line.split(":", 1)[1].strip().lower()
                parsing_name_feedback = False; parsing_desc_feedback = False; parsing_improvements = False
            elif line_lower.startswith("description feedback:"):
                desc_feedback_str = line.split(":", 1)[1].strip()
                parsing_name_feedback = False; parsing_desc_feedback = True; parsing_improvements = False
            elif line_lower.startswith("overall quality:"):
                quality_status_str = line.split(":", 1)[1].strip().upper()
                parsing_name_feedback = False; parsing_desc_feedback = False; parsing_improvements = False
            elif line_lower.startswith("suggested improvements for current element:"):
                first_improvement_line = line.split(":", 1)[1].strip()
                if first_improvement_line and first_improvement_line.lower() not in ["no improvements needed for current element.", "no improvements needed."]:
                    improvements_list.append(first_improvement_line.lstrip("- "))
                parsing_name_feedback = False; parsing_desc_feedback = False; parsing_improvements = True
            elif parsing_name_feedback: name_feedback_str += " " + line.strip()
            elif parsing_desc_feedback: desc_feedback_str += " " + line.strip()
            elif parsing_improvements:
                if line.strip() and line.strip().lower() not in ["no improvements needed for current element.", "no improvements needed."]:
                    improvements_list.append(line.strip().lstrip("- "))
        
        is_name_valid = "yes" in is_name_valid_str
        is_desc_valid = "yes" in is_desc_valid_str
        quality_status = DataQualityStatus.NEEDS_IMPROVEMENT # Default
        if quality_status_str == "GOOD": quality_status = DataQualityStatus.GOOD
        elif quality_status_str == "POOR": quality_status = DataQualityStatus.POOR
        
        if quality_status == DataQualityStatus.GOOD and (not is_name_valid or not is_desc_valid):
            quality_status = DataQualityStatus.NEEDS_IMPROVEMENT
            if not improvements_list or improvements_list == ["No improvements needed for current element."]:
                 improvements_list = ["Review name and description for full ISO/IEC 11179 compliance as per feedback."]

        combined_feedback = f"Name Feedback: {name_feedback_str or 'Not provided.'}\nDescription Feedback: {desc_feedback_str or 'Not provided.'}"
        if len(improvements_list) == 1 and improvements_list[0].lower() in ["no improvements needed for current element.", "no improvements needed."]:
            improvements_list = []

        return ValidationResult(
            is_valid=is_name_valid and is_desc_valid,
            quality_status=quality_status,
            feedback=combined_feedback.strip(),
            suggested_improvements=improvements_list
        )

    def _parse_enhancement_result_from_combined(self, enhancement_text: str) -> EnhancementResult:
        enhanced_name = ""
        enhanced_description = ""
        feedback = "" # Enhancement Notes
        confidence = 0.5

        lines = enhancement_text.strip().split("\n")

        for line in lines:
            if line.startswith("Enhanced Name:"):
                enhanced_name = line.replace("Enhanced Name:", "").strip()
                enhanced_name = re.sub(r"^\s*[\d\W]*\s*", "", enhanced_name)
                enhanced_name = enhanced_name.strip().lower()
                break
        
        desc_lines_list = []
        in_desc_section = False
        for line in lines:
            if line.startswith("Enhanced Description:"):
                in_desc_section = True
                first_desc_line = line.replace("Enhanced Description:", "").strip()
                first_desc_line = re.sub(r"^\s*[\d\W]*\s*", "", first_desc_line)
                if first_desc_line: desc_lines_list.append(first_desc_line)
                continue
            if in_desc_section and not (line.startswith("Enhancement Notes:") or line.startswith("Confidence Score:")):
                desc_lines_list.append(line.strip())
            elif in_desc_section and (line.startswith("Enhancement Notes:") or line.startswith("Confidence Score:")):
                break # End of description section
        
        if desc_lines_list:
            enhanced_description = " ".join(desc_lines_list).strip()
            if enhanced_description: # Ensure formatting
                enhanced_description = enhanced_description[0].upper() + enhanced_description[1:]
                if not enhanced_description.endswith(('.', '!', '?')):
                    enhanced_description += "."
        
        notes_lines_list = []
        in_notes_section = False
        for line in lines:
            if line.startswith("Enhancement Notes:"):
                in_notes_section = True
                first_note_line = line.replace("Enhancement Notes:", "").strip()
                if first_note_line: notes_lines_list.append(first_note_line)
                continue
            if in_notes_section and not line.startswith("Confidence Score:"):
                notes_lines_list.append(line.strip())
            elif in_notes_section and line.startswith("Confidence Score:"):
                break # End of notes section

        if notes_lines_list:
            feedback = " ".join(notes_lines_list).strip()

        for line in lines:
            if line.startswith("Confidence Score:"):
                score_text = line.replace("Confidence Score:", "").strip()
                match = re.search(r"(\d{1}\.\d{1,})", score_text)
                if match:
                    try:
                        confidence = float(match.group(1))
                        confidence = max(0.0, min(1.0, confidence))
                    except ValueError:
                        logger.warning(f"Workflow: Failed to parse confidence from '{score_text}'")
                else:
                    logger.warning(f"Workflow: Confidence score format error in '{score_text}'")
                break
        
        # Fallback if critical fields are empty after parsing
        if not enhanced_name: enhanced_name = "parsing_failed_name"
        if not enhanced_description: enhanced_description = "Parsing failed to extract description."

        return EnhancementResult(
            enhanced_name=enhanced_name,
            enhanced_description=enhanced_description,
            feedback=feedback,
            confidence=confidence
        )

    def _should_continue_iteration(self, state: WorkflowState) -> str:
        if state.get("error"):
            logger.warning(f"Workflow: Error detected for element {state['data_element']['id']}, completing. Error: {state['error']}")
            return "complete_workflow" # Use a specific end node for errors if needed, or just complete

        validation_res = state.get("validation_result_model")
        if validation_res and validation_res.quality_status == DataQualityStatus.GOOD:
            logger.info(f"Workflow: Quality is GOOD for element {state['data_element']['id']} after {state['iterations']} iterations. Completing.")
            return "complete_workflow"

        if state["iterations"] >= state["max_iterations"]:
            logger.info(f"Workflow: Max iterations ({state['max_iterations']}) reached for element {state['data_element']['id']}. Completing.")
            return "complete_workflow"
        
        # Prepare feedback for the next iteration
        if validation_res:
            feedback_parts = [validation_res.feedback]
            if validation_res.suggested_improvements:
                feedback_parts.append("Suggestions for next attempt: " + "; ".join(validation_res.suggested_improvements))
            state["current_validation_feedback_str"] = "\n".join(filter(None, feedback_parts))
        else: # Should not happen if _call_llm_for_enhancement ran
            state["current_validation_feedback_str"] = "No validation result from previous iteration."

        logger.info(f"Workflow: Element {state['data_element']['id']} quality is {validation_res.quality_status if validation_res else 'Unknown'}. Iteration {state['iterations']}/{state['max_iterations']}. Continuing.")
        return "call_llm_node"


    async def _finalize_workflow(self, state: WorkflowState) -> WorkflowState:
        state["is_complete"] = True
        logger.info(f"Workflow: Finalizing for element {state['data_element']['id']}. Iterations: {state['iterations']}. Error: {state.get('error')}")
        
        # Ensure enhanced_data_model is populated, even on error or early exit
        if not state.get("enhanced_data_model"):
            logger.warning(f"Workflow: enhanced_data_model is missing at finalization for {state['data_element']['id']}. Using original.")
            original_model = state["original_data_element_model"]
            final_quality = DataQualityStatus.POOR if state.get("error") else DataQualityStatus.NEEDS_IMPROVEMENT
            
            val_feedback_list = []
            if state.get("validation_result_model"):
                val_feedback_list.append(state["validation_result_model"].feedback)

            enh_feedback_list = []
            if state.get("enhancement_result_model"):
                enh_feedback_list.append(state["enhancement_result_model"].feedback)


            state["enhanced_data_model"] = EnhancedDataElement(
                id=original_model.id,
                existing_name=original_model.existing_name,
                existing_description=original_model.existing_description,
                example=original_model.example,
                processes=original_model.processes,
                cdm=original_model.cdm,
                enhanced_name=original_model.existing_name, # Fallback to original
                enhanced_description=original_model.existing_description, # Fallback to original
                quality_status=final_quality,
                enhancement_iterations=state["iterations"],
                validation_feedback=val_feedback_list,
                enhancement_feedback=enh_feedback_list,
                confidence_score=0.1 # Low confidence
            )
            if state.get("error"):
                 state["enhanced_data_model"].enhancement_feedback.append(f"Workflow Error: {state['error']}")


        elif state.get("error") and state.get("enhanced_data_model"):
            # If error occurred but we have some enhanced_data_model, mark quality as POOR
            state["enhanced_data_model"].quality_status = DataQualityStatus.POOR
            state["enhanced_data_model"].enhancement_feedback.append(f"Workflow Error: {state['error']}")
            state["enhanced_data_model"].confidence_score = min(state["enhanced_data_model"].confidence_score, 0.2)


        return state

    def _build_graph(self) -> StateGraph:
        workflow = StateGraph(WorkflowState)
        workflow.add_node("call_llm_node", self._call_llm_for_enhancement)
        workflow.add_node("finalize_node", self._finalize_workflow)

        workflow.add_conditional_edges(
            "call_llm_node",
            self._should_continue_iteration,
            {
                "continue_iteration": "call_llm_node", # This was the bug, should be "call_llm_node"
                "call_llm_node": "call_llm_node", # Explicitly map if key is same as node
                "complete_workflow": "finalize_node"
            }
        )
        workflow.add_edge("finalize_node", END)
        workflow.set_entry_point("call_llm_node")
        return workflow.compile()

    @cache_manager.async_cached(ttl=3600)
    async def run(self, data_element: DataElement, max_iterations: int = 2) -> EnhancedDataElement:
        logger.info(f"Workflow run: Starting enhancement for element ID: {data_element.id}, Max iterations: {max_iterations}")

        # Ensure processes are correctly structured as list of dicts for state
        # but keep original DataElement model for context.
        element_dict_for_state = data_element.dict()
        if data_element.processes: # processes is List[Process]
             element_dict_for_state["processes"] = [p.dict() for p in data_element.processes]
        else:
            element_dict_for_state["processes"] = None


        initial_state = WorkflowState(
            data_element=element_dict_for_state,
            original_data_element_model=data_element, # Keep the Pydantic model
            enhanced_data_model=None,
            validation_result_model=None,
            enhancement_result_model=None,
            iterations=0,
            max_iterations=max_iterations,
            current_validation_feedback_str="No prior feedback for this run.",
            is_complete=False,
            error=None
        )

        final_state = await self.graph.ainvoke(initial_state)

        if final_state.get("error"):
            logger.error(f"Workflow run for {data_element.id} completed with error: {final_state['error']}")
            # Fallback to returning an EnhancedDataElement with error state if enhanced_data_model is not set
            if not final_state.get("enhanced_data_model"):
                 # This case should be handled by _finalize_workflow, but as a safeguard:
                error_enhanced_element = EnhancedDataElement(
                    **data_element.dict(), # Spread original data
                    enhanced_name=data_element.existing_name,
                    enhanced_description=data_element.existing_description,
                    quality_status=DataQualityStatus.POOR,
                    enhancement_iterations=final_state.get("iterations", 0),
                    validation_feedback=[f"Workflow error: {final_state['error']}"],
                    enhancement_feedback=[f"Workflow error: {final_state['error']}"],
                    confidence_score=0.0
                )
                return error_enhanced_element


        enhanced_result_model = final_state.get("enhanced_data_model")
        if not enhanced_result_model: # Should be set by _finalize_workflow
            logger.critical(f"Workflow for {data_element.id} ended without an enhanced_data_model. This is a bug.")
            # Construct a minimal error response
            return EnhancedDataElement(
                 **data_element.dict(),
                 enhanced_name=data_element.existing_name, 
                 enhanced_description=data_element.existing_description,
                 quality_status=DataQualityStatus.POOR,
                 enhancement_feedback=["Critical error: Workflow finished without result model."],
                 confidence_score=0.0
            )
        
        logger.info(f"Workflow run: Completed for element ID: {data_element.id}. Final quality: {enhanced_result_model.quality_status}, Confidence: {enhanced_result_model.confidence_score}")
        return enhanced_result_model


    async def stream_run(self, data_element: DataElement, max_iterations: int = 2) -> AsyncGenerator[Dict[str, Any], None]:
        logger.info(f"Workflow stream_run: Starting for element ID: {data_element.id}, Max iterations: {max_iterations}")
        
        element_dict_for_state = data_element.dict()
        if data_element.processes:
             element_dict_for_state["processes"] = [p.dict() for p in data_element.processes]
        else:
            element_dict_for_state["processes"] = None

        current_state = WorkflowState(
            data_element=element_dict_for_state,
            original_data_element_model=data_element,
            enhanced_data_model=None,
            validation_result_model=None,
            enhancement_result_model=None,
            iterations=0,
            max_iterations=max_iterations,
            current_validation_feedback_str="No prior feedback for this run.",
            is_complete=False,
            error=None
        )

        yield {
            "status": "starting",
            "message": "Workflow initialized.",
            "iteration": 0,
            "progress": 0.0,
            "element_id": data_element.id
        }

        async for event_output in self.graph.astream(current_state):
            # event_output is a dictionary where keys are node names and values are the state *after* that node executed.
            node_name = list(event_output.keys())[0]
            node_state_output = event_output[node_name] # This is the full WorkflowState *after* the node ran

            current_iterations = node_state_output.get("iterations", 0)
            progress = min(1.0, (current_iterations / max_iterations) if max_iterations > 0 else 1.0)
            
            if node_state_output.get("error"):
                yield {
                    "status": "error",
                    "message": f"Error during node '{node_name}': {node_state_output['error']}",
                    "iteration": current_iterations,
                    "progress": progress,
                    "element_id": data_element.id
                }
                return # Stop streaming on error

            if node_name == "call_llm_node": # After LLM call and parsing
                enhanced_model = node_state_output.get("enhanced_data_model")
                if enhanced_model:
                    yield {
                        "status": "in_progress",
                        "message": f"Iteration {current_iterations} completed. Quality: {enhanced_model.quality_status.value}.",
                        "iteration": current_iterations,
                        "progress": progress,
                        "current_result": {
                            "enhanced_name": enhanced_model.enhanced_name,
                            "enhanced_description": enhanced_model.enhanced_description,
                            "quality_status": enhanced_model.quality_status.value,
                            "confidence_score": enhanced_model.confidence_score
                        },
                        "element_id": data_element.id
                    }
            
            if node_name == "finalize_node" or node_state_output.get("is_complete"):
                final_enhanced_model = node_state_output.get("enhanced_data_model")
                if final_enhanced_model:
                    yield {
                        "status": "completed",
                        "message": "Workflow finalized.",
                        "iteration": current_iterations,
                        "progress": 1.0,
                        "result": final_enhanced_model.dict(), # Send full EnhancedDataElement as dict
                        "element_id": data_element.id
                    }
                else: # Should not happen if finalize_node populates it
                     yield {
                        "status": "error",
                        "message": "Workflow finalized but no enhanced data model found.",
                        "iteration": current_iterations,
                        "progress": 1.0,
                        "element_id": data_element.id
                    }
                logger.info(f"Workflow stream_run: Completed for element ID: {data_element.id}")
                return
        
        # Fallback if graph somehow finishes without hitting finalize_node (should not happen with END state)
        logger.warning(f"Workflow stream_run for {data_element.id} finished unexpectedly without explicit completion event.")
        # Try to get the last known state for a final message
        last_known_enhanced_model = current_state.get("enhanced_data_model")
        if last_known_enhanced_model:
             yield {
                "status": "completed", # Assume completed if loop finishes
                "message": "Workflow finished (fallback completion).",
                "iteration": current_state.get("iterations", max_iterations),
                "progress": 1.0,
                "result": last_known_enhanced_model.dict(),
                "element_id": data_element.id
            }
        else:
            yield {
                "status": "error",
                "message": "Workflow stream ended without final result.",
                "iteration": current_state.get("iterations", max_iterations),
                "progress": 1.0,
                 "element_id": data_element.id
            }


# For backwards compatibility, if anything still imports DataEnhancementWorkflow
DataEnhancementWorkflow = OptimizedDataEnhancementWorkflow
