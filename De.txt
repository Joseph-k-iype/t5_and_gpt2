"""
Advanced Prompting Strategies for Legal Document Analysis
COMPLETE VERSION with all methods and logic
UPDATED: Support for citations, evidence, simplified taxonomy, and condition/restriction classification

Location: src/prompting/advanced_strategies.py
"""

from typing import Optional, List, Dict, Any
from enum import Enum


class ExpertRole(str, Enum):
    """Expert roles for Mixture of Experts prompting"""
    LEGAL_EXPERT = "legal_expert"
    COMPLIANCE_OFFICER = "compliance_officer"
    DATA_PRIVACY_SPECIALIST = "data_privacy_specialist"
    REGULATORY_ANALYST = "regulatory_analyst"
    TECHNICAL_ARCHITECT = "technical_architect"
    BUSINESS_ANALYST = "business_analyst"


class ReasoningMode(str, Enum):
    """Reasoning modes for different analysis approaches"""
    CHAIN_OF_THOUGHT = "chain_of_thought"
    MIXTURE_OF_EXPERTS = "mixture_of_experts"
    TREE_OF_THOUGHT = "tree_of_thought"
    REFLECTION = "reflection"
    REACT = "react"


class AdvancedPromptingStrategies:
    """
    Advanced prompting strategies optimized for citation tracking,
    evidence collection, and simplified taxonomy
    """
    
    def __init__(self, rule_name: str, jurisdiction: str):
        self.rule_name = rule_name
        self.jurisdiction = jurisdiction
    
    # ============================================================================
    # CORE PROMPTS (UPDATED)
    # ============================================================================
    
    def get_react_agent_system_prompt(self) -> str:
        """
        UPDATED: ReAct agent system prompt with new requirements
        """
        return f"""You are a legal document analyzer using ReAct methodology.

Rule: {self.rule_name}
Jurisdiction: {self.jurisdiction}

CRITICAL REQUIREMENTS:

1. CITATIONS: For every claim, provide exact text excerpts (max 200 chars) with reasoning
2. EVIDENCE: Separate user perspective (what users do) from system perspective (what systems implement)
3. ACTION TAXONOMY: Use ONLY these three categories:
   - data_sharing_and_access (sharing, transferring, disclosing, accessing)
   - data_storage_and_hosting (storing, hosting, retaining, archiving)
   - data_usage (using, processing, analyzing, collecting)
4. CLASSIFICATION: Classify as either:
   - "condition" = Allowed under certain conditions
   - "restriction" = Prohibited or restricted
5. ENTERPRISE POLICIES: Pay special attention to Level 3 documents for enterprise-specific policies

Extract:
- Rule description with citations
- Data actions (using simplified taxonomy)
- User evidence (what users must/can/cannot do)
- System evidence (what systems must implement)
- Constraints with citations
- Classification with reasoning

Return structured JSON with all citations."""
    
    def get_chain_of_thought_prompt(
        self,
        document_text: str,
        analysis_type: str,
        context: Optional[Dict[str, Any]] = None,
        chunk_info: str = ""
    ) -> str:
        """
        UPDATED: Chain of Thought prompting with citation requirements
        """
        # Truncate document text if too long
        text_truncated = document_text[:1500] + "..." if len(document_text) > 1500 else document_text
        
        context_section = ""
        if context:
            org = context.get("organization", "")
            tools = context.get("internal_tools", [])
            if org or tools:
                context_section = f"\n\nEnterprise Context:\n- Organization: {org}\n- Tools: {', '.join(tools)}\n"
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        return f"""Analyze this text using step-by-step reasoning WITH CITATIONS:
{context_section}{chunk_section}
TEXT:
{text_truncated}

TASK: {analysis_type}

Think step-by-step:
1. What is the main requirement? → Provide citation (exact text, max 200 chars)
2. Who is affected (users vs systems)?
3. What data actions are involved? → Map to taxonomy: sharing/access, storage/hosting, or usage
4. What conditions apply? → Cite exact conditions
5. Is this a CONDITION (allowed under conditions) or RESTRICTION (prohibited)?

Provide JSON:
{{
    "description": "...",
    "citations": [
        {{"text": "exact text from document...", "reasoning": "why this supports the claim"}}
    ],
    "data_actions": [
        {{"type": "data_sharing_and_access", "description": "...", "citations": [...]}}
    ],
    "user_evidence": [
        {{"description": "what users must do", "citations": [...]}}
    ],
    "system_evidence": [
        {{"description": "what systems must implement", "citations": [...]}}
    ],
    "classification": "condition" or "restriction",
    "classification_reasoning": "why this classification"
}}"""
    
    def get_mixture_of_experts_prompt(
        self,
        document_text: str,
        expert_roles: List[ExpertRole],
        chunk_info: str = ""
    ) -> str:
        """
        UPDATED: Mixture of Experts with citation requirements
        """
        # Truncate document text
        text_truncated = document_text[:1500] + "..." if len(document_text) > 1500 else document_text
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        roles_desc = []
        for role in expert_roles:
            if role == ExpertRole.LEGAL_EXPERT:
                roles_desc.append("Legal Expert: Extract legal obligations WITH exact citations")
            elif role == ExpertRole.COMPLIANCE_OFFICER:
                roles_desc.append("Compliance Officer: Identify practical compliance steps for users and systems")
            elif role == ExpertRole.DATA_PRIVACY_SPECIALIST:
                roles_desc.append("Data Privacy Specialist: Focus on data actions (sharing/access, storage/hosting, usage)")
            elif role == ExpertRole.REGULATORY_ANALYST:
                roles_desc.append("Regulatory Analyst: Determine if CONDITION or RESTRICTION")
            elif role == ExpertRole.TECHNICAL_ARCHITECT:
                roles_desc.append("Technical Architect: Identify system-level requirements")
            elif role == ExpertRole.BUSINESS_ANALYST:
                roles_desc.append("Business Analyst: Identify user-level actions")
        
        roles_text = "\n".join(f"- {desc}" for desc in roles_desc)
        
        return f"""Analyze from multiple expert perspectives WITH CITATIONS:
{chunk_section}
TEXT:
{text_truncated}

Expert Perspectives:
{roles_text}

REQUIREMENTS:
1. Every claim must have a citation (exact text, max 200 chars)
2. Separate user evidence from system evidence
3. Use ONLY simplified taxonomy: sharing/access, storage/hosting, usage
4. Classify as "condition" or "restriction"

Provide JSON with all perspectives integrated and properly cited."""
    
    def get_dynamic_contextualized_prompt(
        self,
        document_text: str,
        previous_analyses: Optional[List[str]] = None,
        enterprise_context: Optional[Dict[str, Any]] = None,
        chunk_info: str = ""
    ) -> str:
        """
        UPDATED: Dynamic contextualized with citation requirements
        """
        # Truncate document text
        text_truncated = document_text[:1500] + "..." if len(document_text) > 1500 else document_text
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        previous_section = ""
        if previous_analyses:
            prev_summary = previous_analyses[0][:300] + "..." if len(previous_analyses[0]) > 300 else previous_analyses[0]
            previous_section = f"\n\nPrevious Analysis Summary:\n{prev_summary}\n"
        
        context_section = ""
        if enterprise_context:
            org = enterprise_context.get("organization", "")
            tools = enterprise_context.get("internal_tools", [])
            if org or tools:
                context_section = f"\n\nEnterprise Context:\n- Organization: {org}\n- Internal Tools: {', '.join(tools)}\n"
                context_section += "\nIMPORTANT: Look for enterprise-specific policies related to these tools!\n"
        
        return f"""Analyze with full context AND CITATIONS:
{chunk_section}{previous_section}{context_section}
TEXT:
{text_truncated}

CRITICAL REQUIREMENTS:
1. Provide exact text citations (max 200 chars) for every claim
2. Identify user evidence vs system evidence
3. Map actions to: sharing/access, storage/hosting, or usage ONLY
4. Classify as "condition" or "restriction"
5. If enterprise context present, look for organization-specific policies

Provide comprehensive JSON with citations."""
    
    def get_multi_level_synthesis_prompt(
        self,
        level_1_analysis: str,
        level_2_analysis: str,
        level_3_analysis: str
    ) -> str:
        """
        UPDATED: Multi-level synthesis with emphasis on Level 3 enterprise policies
        """
        # Truncate if analyses are too long
        l1_truncated = level_1_analysis[:400] + "..." if len(level_1_analysis) > 400 else level_1_analysis
        l2_truncated = level_2_analysis[:400] + "..." if len(level_2_analysis) > 400 else level_2_analysis
        l3_truncated = level_3_analysis[:400] + "..." if len(level_3_analysis) > 400 else level_3_analysis
        
        return f"""Synthesize analyses from 3 document levels for "{self.rule_name}" in {self.jurisdiction}.

LEVEL 1 (Legislation):
{l1_truncated}

LEVEL 2 (Regulatory Guidance):
{l2_truncated}

LEVEL 3 (Enterprise Policies - CRITICAL):
{l3_truncated}

SYNTHESIS REQUIREMENTS:
1. Preserve ALL citations from all levels
2. Separate user evidence from system evidence
3. Use simplified taxonomy: sharing/access, storage/hosting, usage
4. Final classification: "condition" or "restriction"
5. CRITICAL: Highlight Level 3 enterprise-specific policies

Provide JSON:
{{
    "description": "Integrated description from all levels",
    "citations": ["all citations from L1, L2, L3"],
    "data_actions": [
        {{"type": "data_sharing_and_access", "description": "...", "citations": [...], "source_level": 1}}
    ],
    "user_evidence": [
        {{"description": "...", "citations": [...], "source_level": 1}}
    ],
    "system_evidence": [
        {{"description": "...", "citations": [...], "source_level": 1}}
    ],
    "classification": "condition" or "restriction",
    "classification_reasoning": "Based on all three levels...",
    "enterprise_specific_notes": "From Level 3: ..."
}}

IMPORTANT: 
- Level 3 provides enterprise-specific implementation details
- Ensure Level 3 policies are clearly reflected in the output"""
    
    def get_reflection_prompt(self, current_analysis: str) -> str:
        """
        UPDATED: Reflection with citation validation
        """
        # Truncate analysis for prompt
        analysis_truncated = current_analysis[:800] + "..." if len(current_analysis) > 800 else current_analysis
        
        return f"""Review this analysis for "{self.rule_name}":

{analysis_truncated}

Validation checklist:
1. Citations: Does every claim have supporting citations?
2. Evidence: Are user and system perspectives clearly separated?
3. Taxonomy: Are actions mapped to sharing/access, storage/hosting, or usage?
4. Classification: Is "condition" vs "restriction" clearly determined?
5. Enterprise policies: Are Level 3 policies highlighted?

Provide:
- What's correct
- What needs improvement
- Enhanced analysis (JSON format) with all citations"""
    
    def get_chunk_analysis_prompt(
        self,
        chunk_text: str,
        chunk_context: str
    ) -> str:
        """
        UPDATED: Chunk analysis with citation requirements
        """
        return f"""Analyze this text chunk WITH CITATIONS:

CONTEXT: {chunk_context}

TEXT:
{chunk_text}

Extract JSON:
{{
    "description": "What this chunk requires",
    "citations": [
        {{"text": "exact excerpt (max 200 chars)", "reasoning": "supports description"}}
    ],
    "data_actions": [
        {{"type": "data_sharing_and_access|data_storage_and_hosting|data_usage", 
          "description": "...", 
          "citations": [...]}}
    ],
    "user_evidence": [
        {{"description": "what users do", "citations": [...]}}
    ],
    "system_evidence": [
        {{"description": "what systems do", "citations": [...]}}
    ],
    "constraints": [
        {{"type": "temporal|technical|procedural", "description": "...", "citations": [...]}}
    ],
    "classification": "condition" or "restriction",
    "classification_reasoning": "why"
}}

CRITICAL:
- Every claim must have citations
- Use ONLY the three action categories
- Clearly separate user vs system evidence"""
    
    def get_comprehensive_synthesis_prompt(
        self,
        chunk_analyses: List[Dict[str, Any]],
        total_chunks: int
    ) -> str:
        """
        UPDATED: Comprehensive synthesis with citation preservation
        """
        # Summarize chunk analyses
        summaries = []
        total_citations = 0
        
        for i, analysis in enumerate(chunk_analyses[:5]):
            desc = analysis.get("description", "")[:80]
            num_cites = len(analysis.get("citations", []))
            total_citations += num_cites
            
            if desc:
                summaries.append(f"Chunk {i+1}: {desc}... [{num_cites} citations]")
        
        if len(chunk_analyses) > 5:
            remaining_cites = sum(len(c.get("citations", [])) for c in chunk_analyses[5:])
            total_citations += remaining_cites
            summaries.append(f"... and {len(chunk_analyses) - 5} more chunks [{remaining_cites} citations]")
        
        chunks_summary = "\n".join(summaries) if summaries else "Multiple chunks analyzed"
        
        return f"""Synthesize {total_chunks} chunks into final analysis:

{chunks_summary}

Total citations available: {total_citations}

Provide comprehensive JSON:
{{
    "description": "Complete integrated description",
    "citations": ["ALL citations from all chunks"],
    "data_actions": [
        "All actions using simplified taxonomy"
    ],
    "user_evidence": ["All user-level requirements with citations"],
    "system_evidence": ["All system-level requirements with citations"],
    "constraints": ["All constraints with citations"],
    "classification": "condition or restriction",
    "classification_reasoning": "Based on full document"
}}

REQUIREMENTS:
- Preserve ALL citations
- Deduplicate while maintaining source traceability
- Use simplified taxonomy
- Clear user vs system separation"""
    
    # ============================================================================
    # NEW METHODS FOR ENHANCED FUNCTIONALITY
    # ============================================================================
    
    def get_enterprise_context_prompt(self, text: str, level: int) -> str:
        """
        NEW: Extract enterprise-specific context (especially from Level 3)
        """
        text_truncated = text[:1000] + "..." if len(text) > 1000 else text
        
        level_note = ""
        if level == 3:
            level_note = "\n\nIMPORTANT: This is a Level 3 (Enterprise Policy) document. Look for organization-specific policies, internal tools, and company-specific requirements.\n"
        
        return f"""Identify enterprise-specific context:
{level_note}
TEXT:
{text_truncated}

Extract:
- Organization name (e.g., HSBC, Acme Corp)
- Internal tools/systems (e.g., DataVisa, PrivacyHub, DataHub)
- Company-specific processes
- Business units
- Enterprise-specific data handling policies

Provide JSON:
{{
    "organization": "Organization name",
    "internal_tools": ["tool1", "tool2"],
    "processes": ["process1", "process2"],
    "business_units": ["unit1", "unit2"],
    "enterprise_policies": [
        {{"policy": "...", "applies_to": "...", "citation": "exact text"}}
    ]
}}"""
    
    def get_citation_extraction_prompt(self, text: str, claim: str) -> str:
        """
        NEW: Explicitly extract citations for a specific claim
        """
        text_truncated = text[:1500] + "..." if len(text) > 1500 else text
        
        return f"""Find supporting citations for this claim:

CLAIM: "{claim}"

DOCUMENT TEXT:
{text_truncated}

Extract exact text excerpts (max 200 chars each) that support this claim:

{{
    "citations": [
        {{"text": "exact excerpt", "reasoning": "how it supports the claim", "confidence": "high|medium|low"}}
    ]
}}

Only include citations that DIRECTLY support the claim."""
    
    def get_evidence_separation_prompt(self, text: str) -> str:
        """
        NEW: Explicitly separate user and system evidence
        """
        text_truncated = text[:1500] + "..." if len(text) > 1500 else text
        
        return f"""Separate requirements into user and system perspectives:

TEXT:
{text_truncated}

USER PERSPECTIVE (What individual users must/can/cannot do):
- Actions users take
- User obligations
- User rights
- What users need to do to comply

SYSTEM PERSPECTIVE (What systems must implement):
- Technical requirements
- System controls
- Automated processes
- System-level compliance

Provide JSON:
{{
    "user_evidence": [
        {{"description": "...", "citations": [{{"text": "..."}}]}}
    ],
    "system_evidence": [
        {{"description": "...", "citations": [{{"text": "..."}}]}}
    ]
}}"""
    
    def get_action_taxonomy_mapping_prompt(self, actions_text: str) -> str:
        """
        NEW: Map actions to simplified taxonomy
        """
        return f"""Map these actions to the simplified taxonomy:

ACTIONS:
{actions_text}

TAXONOMY (ONLY these three):
1. data_sharing_and_access - sharing, transferring, disclosing, accessing, providing
2. data_storage_and_hosting - storing, hosting, retaining, archiving, keeping
3. data_usage - using, processing, analyzing, collecting, handling

Provide JSON:
{{
    "mapped_actions": [
        {{"original": "transfer data", "mapped_type": "data_sharing_and_access", "description": "...", "reasoning": "why this mapping"}}
    ]
}}

Use ONLY the three taxonomy categories."""
    
    def get_classification_prompt(self, analysis_summary: str) -> str:
        """
        NEW: Determine condition vs restriction classification
        """
        return f"""Classify this rule as CONDITION or RESTRICTION:

ANALYSIS:
{analysis_summary}

DEFINITIONS:
- CONDITION: Actions ARE allowed but only under specific conditions
  Example: "Data transfer is allowed if adequacy decision exists"
  
- RESTRICTION: Actions are NOT allowed or heavily prohibited
  Example: "Automated decision-making is prohibited without human oversight"

Provide JSON:
{{
    "classification": "condition" or "restriction",
    "reasoning": "Why this classification based on the analysis",
    "key_indicators": ["phrases that led to this classification"],
    "confidence": "high|medium|low"
}}"""
    
    # ============================================================================
    # ADDITIONAL UTILITY PROMPTS
    # ============================================================================
    
    def get_decision_inference_prompt(self, rule_context: str) -> str:
        """
        UPDATED: Concise decision inference prompt
        """
        # Truncate context
        context_truncated = rule_context[:600] + "..." if len(rule_context) > 600 else rule_context
        
        return f"""Identify decision scenarios in this rule:

{context_truncated}

For each scenario provide:
{{
    "scenario": "When does this apply?",
    "decision_type": "yes/no/maybe",
    "conditions": ["what conditions must be met"],
    "required_actions": ["actions if YES"],
    "prohibited_actions": ["actions if NO"]
}}

Focus on practical compliance decisions."""
    
    def get_action_extraction_prompt(self, text: str) -> str:
        """
        UPDATED: Action extraction with taxonomy mapping
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract actions from text:

{text_truncated}

Standard actions - map to taxonomy:
- data_sharing_and_access (share, transfer, disclose, access)
- data_storage_and_hosting (store, host, retain, archive)
- data_usage (use, process, analyze, collect)

Provide JSON:
{{
    "user_actions": ["actions users take"],
    "system_actions": ["actions systems must do"]
}}

Map all actions to one of the three taxonomy categories."""
    
    def get_constraint_analysis_prompt(self, text: str) -> str:
        """
        UPDATED: Constraint extraction with citations
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract constraints from:

{text_truncated}

Provide JSON:
{{
    "constraints": [
        {{
            "type": "temporal|technical|procedural",
            "description": "...",
            "citations": [{{"text": "exact text"}}]
        }}
    ]
}}

Focus on conditions and limitations with supporting citations."""
    
    def get_duty_extraction_prompt(self, text: str) -> str:
        """
        UPDATED: Duty extraction (now split into user/system evidence)
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract duties and obligations from:

{text_truncated}

Separate into user and system perspectives:

Provide JSON:
{{
    "user_evidence": [
        {{"description": "what users must do", "citations": [...]}}
    ],
    "system_evidence": [
        {{"description": "what systems must do", "citations": [...]}}
    ]
}}

Focus on mandatory requirements with citations."""
    
    def get_rule_classification_prompt(self, analysis: str) -> str:
        """
        UPDATED: Rule classification (now condition/restriction)
        """
        # Truncate analysis
        analysis_truncated = analysis[:600] + "..." if len(analysis) > 600 else analysis
        
        return f"""Classify this rule:

{analysis_truncated}

Determine:
- Classification: "condition" (allowed under conditions) or "restriction" (prohibited)
- Confidence: high/medium/low
- Reasoning: Why this classification

Provide JSON:
{{
    "classification": "condition" or "restriction",
    "confidence": "high|medium|low",
    "reasoning": "...",
    "key_indicators": ["phrases that led to this classification"]
}}"""
    
    def get_data_category_prompt(self, text: str) -> str:
        """
        Data category identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify data categories mentioned:

{text_truncated}

Common categories: personal data, sensitive data, financial data, health data, biometric data, etc.

Provide JSON:
{{
    "data_categories": ["category1", "category2", ...]
}}"""
    
    def get_role_identification_prompt(self, text: str) -> str:
        """
        Role identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify roles mentioned:

{text_truncated}

Common roles: data controller, data processor, data subject, third party, joint controller, etc.

Provide JSON:
{{
    "roles": ["role1", "role2", ...]
}}"""
    
    def get_validation_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        UPDATED: Validation prompt with new requirements
        """
        # Create compact summary of analysis
        summary = f"""Classification: {analysis.get('classification', 'N/A')}
Description: {analysis.get('description', 'N/A')[:200]}
Data Actions: {len(analysis.get('data_actions', []))}
User Evidence: {len(analysis.get('user_evidence', []))}
System Evidence: {len(analysis.get('system_evidence', []))}
Citations: {len(analysis.get('citations', []))}
Constraints: {len(analysis.get('constraints', []))}"""
        
        return f"""Validate this analysis:

{summary}

Check for:
1. Citations: Are all claims properly cited?
2. Taxonomy: Are actions mapped to the 3 categories?
3. Evidence: Is user/system separation clear?
4. Classification: Is condition/restriction correct?
5. Completeness: Is anything missing?
6. Accuracy: Are citations accurate?

Provide JSON:
{{
    "is_valid": true/false,
    "issues": ["issue1", "issue2", ...],
    "suggestions": ["suggestion1", "suggestion2", ...],
    "missing_citations": ["claim without citation"],
    "taxonomy_issues": ["action not properly mapped"]
}}"""
    
    def get_merge_prompt(self, analyses: List[Dict[str, Any]]) -> str:
        """
        UPDATED: Merge multiple analyses preserving citations
        """
        # Create compact summaries
        summaries = []
        total_citations = 0
        
        for i, analysis in enumerate(analyses[:3]):
            desc = analysis.get('description', '')[:100]
            num_cites = len(analysis.get('citations', []))
            total_citations += num_cites
            summaries.append(f"Analysis {i+1}: {desc}... [{num_cites} citations]")
        
        if len(analyses) > 3:
            remaining_cites = sum(len(a.get('citations', [])) for a in analyses[3:])
            total_citations += remaining_cites
            summaries.append(f"... and {len(analyses) - 3} more [{remaining_cites} citations]")
        
        summary_text = "\n".join(summaries)
        
        return f"""Merge these analyses into one comprehensive analysis:

{summary_text}

Total citations: {total_citations}

Provide merged JSON with:
- Combined description
- ALL citations preserved
- All unique data actions (using taxonomy)
- All user evidence
- All system evidence
- All constraints
- Unified classification
- Merged reasoning

Deduplicate while preserving all citations and source traceability."""
    
    def get_refinement_prompt(self, analysis: Dict[str, Any], feedback: str) -> str:
        """
        UPDATED: Refinement prompt based on feedback
        """
        # Create compact analysis summary
        summary = f"""Current analysis:
Classification: {analysis.get('classification', 'N/A')}
Description: {analysis.get('description', '')[:200]}...
Actions: {len(analysis.get('data_actions', []))}
Evidence: {len(analysis.get('user_evidence', []))} user, {len(analysis.get('system_evidence', []))} system
Citations: {len(analysis.get('citations', []))}"""
        
        return f"""Refine this analysis based on feedback:

{summary}

FEEDBACK:
{feedback[:300]}

Apply improvements while:
1. Preserving all existing citations
2. Maintaining taxonomy compliance
3. Keeping user/system separation
4. Ensuring correct classification

Provide improved JSON with all required fields and enhanced citations."""
    
    def get_level_specific_prompt(self, text: str, level: int) -> str:
        """
        NEW: Generate prompts specific to document level
        """
        level_instructions = {
            1: """Level 1 (Legislation): Focus on legal requirements, statutory obligations, and formal rules.
            Look for: Articles, sections, statutory language, legal obligations.""",
            2: """Level 2 (Regulatory Guidance): Focus on regulatory interpretations, compliance guidance, best practices.
            Look for: Regulatory examples, compliance steps, interpretations of legislation.""",
            3: """Level 3 (Enterprise Policies): Focus on organization-specific implementations, internal tools, company policies.
            Look for: Internal systems (DataVisa, PrivacyHub), company-specific processes, organizational requirements.
            CRITICAL: Highlight enterprise-specific policies clearly."""
        }
        
        instruction = level_instructions.get(level, level_instructions[1])
        
        text_truncated = text[:1000] + "..." if len(text) > 1000 else text
        
        return f"""Analyze this Level {level} document:

{instruction}

TEXT:
{text_truncated}

Extract with level-appropriate focus and provide JSON with citations."""
    
    def get_cross_level_validation_prompt(
        self,
        level_1_findings: str,
        level_2_findings: str,
        level_3_findings: str
    ) -> str:
        """
        NEW: Validate consistency across document levels
        """
        return f"""Validate consistency across three document levels:

LEVEL 1 (Legislation):
{level_1_findings[:300]}

LEVEL 2 (Guidance):
{level_2_findings[:300]}

LEVEL 3 (Enterprise):
{level_3_findings[:300]}

Check:
1. Consistency: Do levels align or contradict?
2. Progression: Does specificity increase L1→L2→L3?
3. Enterprise: Does L3 properly implement L1 and L2?
4. Gaps: Are there requirements in L1/L2 not addressed in L3?

Provide JSON:
{{
    "is_consistent": true/false,
    "contradictions": ["..."],
    "gaps": ["L1/L2 requirements not in L3"],
    "enterprise_alignment": "good|moderate|poor",
    "recommendations": ["..."]
}}"""
    
    # ============================================================================
    # HELPER METHODS
    # ============================================================================
    
    def truncate_text(self, text: str, max_length: int = 1500) -> str:
        """
        Helper: Truncate text with ellipsis
        """
        if len(text) <= max_length:
            return text
        return text[:max_length] + "..."
    
    def format_context_section(self, context: Optional[Dict[str, Any]]) -> str:
        """
        Helper: Format enterprise context for prompts
        """
        if not context:
            return ""
        
        org = context.get("organization", "")
        tools = context.get("internal_tools", [])
        
        if not (org or tools):
            return ""
        
        section = "\n\nEnterprise Context:\n"
        if org:
            section += f"- Organization: {org}\n"
        if tools:
            section += f"- Internal Tools: {', '.join(tools)}\n"
        
        return section
    
    def create_json_schema_hint(self, required_fields: List[str]) -> str:
        """
        Helper: Create JSON schema hint for prompts
        """
        schema = "{\n"
        for field in required_fields:
            schema += f'    "{field}": "...",\n'
        schema += "}"
        return schema
