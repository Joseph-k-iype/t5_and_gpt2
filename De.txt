"""
LangGraph-based Legislation to Machine-Readable JSON Rules Converter
Bulletproof implementation - every string operation checked
Enhanced with Chain of Thought, Mixture of Thought, and Mixture of Reasoning
Focused on Data Governance Rules (Usage, Transfer, Storage, Access)
"""

import json
import re
import time
import os
from typing import List, Dict, Any, Optional, Annotated, Sequence, TypedDict, Literal, Union
from enum import Enum

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field


# ========================= Global Configuration =========================

OPENAI_MODEL = "o3-mini"
OPENAI_BASE_URL = "https://api.openai.com/v1"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
REASONING_EFFORT = "high"

def get_model():
    """Get configured o3-mini model instance"""
    return ChatOpenAI(
        model=OPENAI_MODEL,
        base_url=OPENAI_BASE_URL,
        api_key=OPENAI_API_KEY,
        model_kwargs={
            "reasoning_effort": REASONING_EFFORT,
            "max_completion_tokens": 4000
        }
    )


# ========================= Ultra-Safe Utility Functions =========================

def to_string(obj: Any) -> str:
    """Convert ANY object to string safely - no exceptions"""
    if obj is None:
        return ""
    
    # Already a string
    if isinstance(obj, str):
        return obj
    
    # Handle lists/tuples by joining elements
    if isinstance(obj, (list, tuple)):
        try:
            return " ".join(str(item) for item in obj if item is not None)
        except:
            return str(obj)
    
    # Handle dictionaries
    if isinstance(obj, dict):
        try:
            return json.dumps(obj, default=str, ensure_ascii=False)
        except:
            return str(obj)
    
    # Everything else
    try:
        return str(obj)
    except:
        return ""


def safe_get_content(message: Any) -> str:
    """Safely extract content from message - guaranteed to return string"""
    try:
        if not hasattr(message, 'content'):
            return ""
        
        content = message.content
        result = to_string(content)
        
        # Extra safety - ensure result is actually a string
        if not isinstance(result, str):
            return ""
        
        return result.strip()
    except:
        return ""


def safe_parse_json(text: Any) -> Union[Dict, List, None]:
    """Ultra-safe JSON parsing - handles any input type"""
    try:
        # Convert to string first
        if not isinstance(text, str):
            text = to_string(text)
        
        # Must be a string now
        if not isinstance(text, str):
            return None
        
        # Clean whitespace
        text = text.strip()
        if not text:
            return None
        
        # Remove markdown formatting safely
        if isinstance(text, str) and "```json" in text:
            parts = text.split("```json")
            if len(parts) > 1:
                second_part = parts[1]
                if isinstance(second_part, str) and "```" in second_part:
                    final_parts = second_part.split("```")
                    if len(final_parts) > 0:
                        text = final_parts[0].strip()
        elif isinstance(text, str) and "```" in text:
            parts = text.split("```")
            if len(parts) > 1:
                text = parts[1].strip() if len(parts) > 1 else text
        
        # Final safety check
        if not isinstance(text, str):
            return None
        
        # Check if it looks like JSON before parsing
        text = text.strip()
        if not text:
            return None
        
        # Only try to parse if it starts with { or [
        if len(text) > 0 and isinstance(text, str):
            first_char = text[0] if text else ""
            if first_char in ['{', '[']:
                return json.loads(text)
        
        return None
        
    except:
        return None


def safe_string_operation(text: Any, operation: str, *args) -> Any:
    """Safely perform string operations with type checking"""
    try:
        # Ensure we have a string
        if not isinstance(text, str):
            text = to_string(text)
        
        if not isinstance(text, str):
            return ""
        
        # Perform the operation
        if operation == "strip":
            return text.strip()
        elif operation == "split":
            return text.split(*args) if args else text.split()
        elif operation == "startswith":
            return text.startswith(*args) if args else False
        elif operation == "in":
            return args[0] in text if args else False
        else:
            return text
            
    except:
        if operation == "startswith":
            return False
        elif operation == "split":
            return []
        else:
            return ""


# ========================= State Management =========================

class AgentState(TypedDict):
    """State for the legislation processing agent"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    legislation_text: str
    current_phase: str
    analysis_count: int
    extraction_count: int
    extracted_rules: Dict[str, List[Dict[str, Any]]]
    json_rules: List[Dict[str, Any]]
    validation_results: Dict[str, Any]
    reasoning_steps: List[str]
    error_log: List[str]


# ========================= Pydantic Models =========================

class AnalyzeWithReasoningInput(BaseModel):
    legislation_text: str = Field(..., description="Legislation text")
    reasoning_pathway: str = Field(..., description="structural/semantic/logical/contextual/compliance")
    reasoning_mode: str = Field(..., description="deductive/inductive/abductive/analogical/causal")
    focus_domain: str = Field(..., description="data_usage/data_transfer/data_storage/data_access")


class ExtractDataRulesInput(BaseModel):
    legislation_text: str = Field(..., description="Legislation text")
    data_domain: str = Field(..., description="data_usage/data_transfer/data_storage/data_access")


class SynthesizeRulesInput(BaseModel):
    all_extracted_rules: str = Field(..., description="JSON string of extracted rules")


class ConvertToJsonRulesInput(BaseModel):
    synthesized_rules: str = Field(..., description="JSON string of synthesized rules")


class ValidateJsonRulesInput(BaseModel):
    json_rules: str = Field(..., description="JSON string of rules to validate")


# ========================= Tool Definitions =========================

@tool(args_schema=AnalyzeWithReasoningInput)
def analyze_with_reasoning(
    legislation_text: str,
    reasoning_pathway: str,
    reasoning_mode: str,
    focus_domain: str
) -> str:
    """
    Analyze legislation using Chain of Thought, Mixture of Thought, and Mixture of Reasoning.
    
    Mixture of Thought: Different analytical pathways
    Mixture of Reasoning: Different reasoning modes
    Chain of Thought: Step-by-step analysis
    """
    
    # Ensure all inputs are strings
    legislation_text = to_string(legislation_text)
    reasoning_pathway = to_string(reasoning_pathway)
    reasoning_mode = to_string(reasoning_mode)
    focus_domain = to_string(focus_domain)
    
    # Mixture of Thought - pathways
    pathways = {
        "structural": f"STRUCTURAL ANALYSIS for {focus_domain}: Document hierarchy, sections, cross-references",
        "semantic": f"SEMANTIC ANALYSIS for {focus_domain}: Meanings, definitions, intent, stakeholder roles",
        "logical": f"LOGICAL ANALYSIS for {focus_domain}: IF-THEN conditions, requirements, prohibitions",
        "contextual": f"CONTEXTUAL ANALYSIS for {focus_domain}: Environment, exceptions, timing",
        "compliance": f"COMPLIANCE ANALYSIS for {focus_domain}: Obligations, penalties, enforcement"
    }
    
    # Mixture of Reasoning - modes
    modes = {
        "deductive": "DEDUCTIVE: General principles to specific rules",
        "inductive": "INDUCTIVE: Specific patterns to general rules",
        "abductive": "ABDUCTIVE: Best explanation for legislative intent",
        "analogical": "ANALOGICAL: Compare with known frameworks",
        "causal": "CAUSAL: Cause-effect relationships"
    }
    
    pathway_desc = pathways.get(reasoning_pathway, pathways.get("structural", ""))
    mode_desc = modes.get(reasoning_mode, modes.get("deductive", ""))
    
    prompt = f"""
    Expert legal analysis using advanced reasoning:
    
    PATHWAY: {pathway_desc}
    MODE: {mode_desc}
    
    LEGISLATION:
    {legislation_text}
    
    Analyze {focus_domain} aspects systematically using {reasoning_pathway} pathway and {reasoning_mode} reasoning.
    Provide clear findings and insights.
    """
    
    try:
        model = get_model()
        response = model.invoke(prompt)
        content = safe_get_content(response)
        
        return f"ANALYSIS-{reasoning_pathway}-{reasoning_mode}-{focus_domain}: {content}"
        
    except Exception as e:
        return f"ANALYSIS-ERROR: {to_string(e)}"


@tool(args_schema=ExtractDataRulesInput)
def extract_data_rules(legislation_text: str, data_domain: str) -> str:
    """Extract data governance rules using Chain of Thought methodology"""
    
    # Ensure inputs are strings
    legislation_text = to_string(legislation_text)
    data_domain = to_string(data_domain)
    
    domain_prompts = {
        "data_usage": "Extract rules about data usage, consent, purpose limitation, lawful basis",
        "data_transfer": "Extract rules about data sharing, cross-border transfers, third-party restrictions",
        "data_storage": "Extract rules about retention, deletion, encryption, storage security",
        "data_access": "Extract rules about access rights, authentication, permissions, audit trails"
    }
    
    domain_prompt = domain_prompts.get(data_domain, "Extract relevant data governance rules")
    
    prompt = f"""
    {domain_prompt}
    
    LEGISLATION:
    {legislation_text}
    
    Extract {data_domain} rules using Chain of Thought:
    1. Identify relevant provisions
    2. Extract conditions and requirements
    3. Find prohibitions and restrictions
    4. Identify consequences
    
    Return ONLY a JSON array:
    [
        {{
            "rule_id": "{data_domain}_rule_1",
            "domain": "{data_domain}",
            "description": "Rule description",
            "conditions": ["condition1"],
            "requirements": ["requirement1"],
            "prohibitions": ["prohibition1"],
            "consequences": ["consequence1"],
            "confidence": 0.9
        }}
    ]
    
    Return ONLY the JSON array, no other text.
    """
    
    try:
        model = get_model()
        response = model.invoke(prompt)
        content = safe_get_content(response)
        
        # Try to parse the response
        parsed = safe_parse_json(content)
        if parsed and isinstance(parsed, list):
            return json.dumps(parsed, ensure_ascii=False)
        else:
            # Create fallback rule
            fallback = [{
                "rule_id": f"{data_domain}_rule_1",
                "domain": data_domain,
                "description": f"Extracted {data_domain} rule from legislation",
                "conditions": [],
                "requirements": [],
                "prohibitions": [],
                "consequences": [],
                "confidence": 0.7
            }]
            return json.dumps(fallback, ensure_ascii=False)
            
    except Exception as e:
        error_rule = [{
            "rule_id": f"{data_domain}_error",
            "domain": data_domain,
            "description": f"Error extracting {data_domain}: {to_string(e)}",
            "conditions": [],
            "requirements": [],
            "prohibitions": [],
            "consequences": [],
            "confidence": 0.0
        }]
        return json.dumps(error_rule, ensure_ascii=False)


@tool(args_schema=SynthesizeRulesInput)
def synthesize_rules(all_extracted_rules: str) -> str:
    """Synthesize rules using convergent reasoning"""
    
    # Ensure input is string
    all_extracted_rules = to_string(all_extracted_rules)
    
    prompt = f"""
    Synthesize these extracted rules into a coherent set:
    
    RULES:
    {all_extracted_rules}
    
    SYNTHESIS using Convergent Reasoning:
    1. Remove duplicates
    2. Merge related rules
    3. Resolve conflicts
    4. Assign priorities
    
    Return ONLY a JSON array of synthesized rules:
    [
        {{
            "rule_id": "synth_rule_1",
            "domain": "domain_name",
            "description": "Clear description",
            "conditions": ["condition1"],
            "requirements": ["requirement1"],
            "prohibitions": ["prohibition1"],
            "consequences": ["consequence1"],
            "priority": 80,
            "confidence": 0.9
        }}
    ]
    
    Return ONLY the JSON array.
    """
    
    try:
        model = get_model()
        response = model.invoke(prompt)
        content = safe_get_content(response)
        
        parsed = safe_parse_json(content)
        if parsed and isinstance(parsed, list):
            return json.dumps(parsed, ensure_ascii=False)
        else:
            # Try to parse input as fallback
            input_parsed = safe_parse_json(all_extracted_rules)
            if input_parsed:
                return json.dumps(input_parsed, ensure_ascii=False)
            else:
                return json.dumps([], ensure_ascii=False)
                
    except Exception as e:
        return json.dumps([{"error": to_string(e)}], ensure_ascii=False)


@tool(args_schema=ConvertToJsonRulesInput)
def convert_to_json_rules(synthesized_rules: str) -> str:
    """Convert to json-rules-engine format"""
    
    # Ensure input is string
    synthesized_rules = to_string(synthesized_rules)
    
    prompt = f"""
    Convert to json-rules-engine format:
    
    INPUT:
    {synthesized_rules}
    
    Use json-rules-engine structure:
    [
        {{
            "name": "data_usage_consent_rule",
            "conditions": {{
                "all": [
                    {{"fact": "dataOperation", "operator": "equal", "value": "usage"}},
                    {{"fact": "userConsent", "operator": "equal", "value": false}}
                ]
            }},
            "event": {{
                "type": "governance_violation",
                "params": {{
                    "ruleId": "usage_001",
                    "domain": "data_usage",
                    "action": "require_consent",
                    "message": "User consent required"
                }}
            }},
            "priority": 80
        }}
    ]
    
    Return ONLY the JSON array.
    """
    
    try:
        model = get_model()
        response = model.invoke(prompt)
        content = safe_get_content(response)
        
        parsed = safe_parse_json(content)
        if parsed and isinstance(parsed, list):
            return json.dumps(parsed, ensure_ascii=False)
        else:
            # Create fallback json-rules-engine rule
            fallback = [{
                "name": "fallback_governance_rule",
                "conditions": {
                    "all": [
                        {"fact": "ruleApplicable", "operator": "equal", "value": True}
                    ]
                },
                "event": {
                    "type": "governance_rule",
                    "params": {
                        "message": "Data governance rule applies"
                    }
                },
                "priority": 50
            }]
            return json.dumps(fallback, ensure_ascii=False)
            
    except Exception as e:
        error_rule = [{
            "name": "conversion_error",
            "conditions": {"all": [{"fact": "error", "operator": "equal", "value": True}]},
            "event": {"type": "error", "params": {"message": to_string(e)}},
            "priority": 1
        }]
        return json.dumps(error_rule, ensure_ascii=False)


@tool(args_schema=ValidateJsonRulesInput)
def validate_json_rules(json_rules: str) -> str:
    """Validate JSON rules"""
    
    # Ensure input is string
    json_rules = to_string(json_rules)
    
    prompt = f"""
    Validate json-rules-engine compatibility:
    
    RULES:
    {json_rules}
    
    Check: structure, operators, logic, compatibility
    
    Return validation report:
    {{
        "valid": true,
        "total_rules": 5,
        "valid_rules": 5,
        "invalid_rules": 0,
        "errors": [],
        "warnings": [],
        "quality_score": 90,
        "json_rules_engine_compatible": true
    }}
    
    Return ONLY the JSON report.
    """
    
    try:
        model = get_model()
        response = model.invoke(prompt)
        content = safe_get_content(response)
        
        parsed = safe_parse_json(content)
        if parsed and isinstance(parsed, dict):
            return json.dumps(parsed, ensure_ascii=False)
        else:
            # Simple validation fallback
            rules_parsed = safe_parse_json(json_rules)
            rule_count = len(rules_parsed) if isinstance(rules_parsed, list) else 0
            
            validation = {
                "valid": rule_count > 0,
                "total_rules": rule_count,
                "valid_rules": rule_count,
                "invalid_rules": 0,
                "errors": [],
                "warnings": [],
                "quality_score": 80 if rule_count > 0 else 0,
                "json_rules_engine_compatible": rule_count > 0
            }
            return json.dumps(validation, ensure_ascii=False)
            
    except Exception as e:
        error_validation = {
            "valid": False,
            "total_rules": 0,
            "valid_rules": 0,
            "invalid_rules": 0,
            "errors": [to_string(e)],
            "warnings": [],
            "quality_score": 0,
            "json_rules_engine_compatible": False
        }
        return json.dumps(error_validation, ensure_ascii=False)


# ========================= Agent Nodes =========================

def agent_node(state: AgentState) -> Dict[str, Any]:
    """Main agent with ultra-safe operations"""
    
    try:
        messages = state.get("messages", [])
        current_phase = state.get("current_phase", "start")
        legislation_text = state.get("legislation_text", "")
        analysis_count = state.get("analysis_count", 0)
        extraction_count = state.get("extraction_count", 0)
        
        # Ensure all are proper types
        legislation_text = to_string(legislation_text)
        current_phase = to_string(current_phase)
        
        model = get_model()
        tools = [analyze_with_reasoning, extract_data_rules, synthesize_rules, convert_to_json_rules, validate_json_rules]
        model_with_tools = model.bind_tools(tools)
        
        # Phase progression
        if current_phase == "start":
            system_msg = f"""Expert legal analyst. Process systematically:

PHASE 1: Analysis (4 calls to analyze_with_reasoning)
Call analyze_with_reasoning with:
- legislation_text="{legislation_text[:100]}..."
- reasoning_pathway="structural"
- reasoning_mode="deductive"  
- focus_domain="data_usage"

Start with first analysis."""
            
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "analysis" and analysis_count < 4:
            system_msg = f"Continue analysis {analysis_count + 1}/4. Call analyze_with_reasoning with different parameters."
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "analysis" and analysis_count >= 4:
            system_msg = f"""PHASE 2: Extraction (4 calls to extract_data_rules)
Call extract_data_rules with:
- legislation_text="{legislation_text[:100]}..."
- data_domain="data_usage"

Start first extraction."""
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "extraction" and extraction_count < 4:
            system_msg = f"Continue extraction {extraction_count + 1}/4. Call extract_data_rules with different domain."
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "extraction" and extraction_count >= 4:
            extracted_rules = state.get("extracted_rules", {})
            rules_json = json.dumps(extracted_rules, ensure_ascii=False)
            system_msg = f'PHASE 3: Call synthesize_rules(all_extracted_rules="{rules_json[:200]}...")'
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "synthesis":
            system_msg = "PHASE 4: Call convert_to_json_rules with synthesized rules"
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        elif current_phase == "conversion":
            system_msg = "PHASE 5: Call validate_json_rules with converted rules"
            new_messages = [SystemMessage(content=system_msg)] + list(messages)
            
        else:
            new_messages = list(messages)
        
        response = model_with_tools.invoke(new_messages)
        
        return {
            "messages": [response],
            "current_phase": "processing"
        }
        
    except Exception as e:
        error_msg = f"Agent error: {to_string(e)}"
        error_response = AIMessage(content=error_msg)
        
        return {
            "messages": [error_response],
            "current_phase": "error",
            "error_log": state.get("error_log", []) + [error_msg]
        }


def tool_node(state: AgentState) -> Dict[str, Any]:
    """Execute tools with bulletproof error handling"""
    
    try:
        tools = [analyze_with_reasoning, extract_data_rules, synthesize_rules, convert_to_json_rules, validate_json_rules]
        tool_node_instance = ToolNode(tools)
        result = tool_node_instance.invoke(state)
        
        # Safe updates
        updates = {"messages": result.get("messages", [])}
        extracted_rules = dict(state.get("extracted_rules", {}))  # Safe copy
        analysis_count = int(state.get("analysis_count", 0))
        extraction_count = int(state.get("extraction_count", 0))
        reasoning_steps = list(state.get("reasoning_steps", []))  # Safe copy
        error_log = list(state.get("error_log", []))  # Safe copy
        
        # Process messages ultra-safely
        messages = result.get("messages", [])
        
        for message in messages:
            try:
                if isinstance(message, ToolMessage):
                    # Ultra-safe content extraction
                    content = safe_get_content(message)
                    tool_name = to_string(getattr(message, 'name', 'unknown'))
                    
                    reasoning_steps.append(f"Executed {tool_name}")
                    
                    # Tool-specific handling
                    if tool_name == "analyze_with_reasoning":
                        analysis_count += 1
                        
                    elif tool_name == "extract_data_rules":
                        extraction_count += 1
                        parsed_rules = safe_parse_json(content)
                        if parsed_rules and isinstance(parsed_rules, list):
                            for rule in parsed_rules:
                                if isinstance(rule, dict):
                                    domain = to_string(rule.get("domain", "unknown"))
                                    if domain not in extracted_rules:
                                        extracted_rules[domain] = []
                                    extracted_rules[domain].append(rule)
                    
                    elif tool_name == "convert_to_json_rules":
                        parsed_rules = safe_parse_json(content)
                        if parsed_rules and isinstance(parsed_rules, list):
                            updates["json_rules"] = parsed_rules
                    
                    elif tool_name == "validate_json_rules":
                        parsed_validation = safe_parse_json(content)
                        if parsed_validation and isinstance(parsed_validation, dict):
                            updates["validation_results"] = parsed_validation
                
            except Exception as e:
                error_msg = f"Error processing message: {to_string(e)}"
                error_log.append(error_msg)
        
        # Update state safely
        updates.update({
            "extracted_rules": extracted_rules,
            "analysis_count": analysis_count,
            "extraction_count": extraction_count,
            "reasoning_steps": reasoning_steps,
            "error_log": error_log
        })
        
        return updates
        
    except Exception as e:
        error_msg = f"Tool node error: {to_string(e)}"
        return {
            "messages": state.get("messages", []),
            "error_log": state.get("error_log", []) + [error_msg]
        }


def should_continue(state: AgentState) -> Literal["tools", "end"]:
    """Determine continuation safely"""
    try:
        messages = state.get("messages", [])
        
        if not messages:
            return "end"
        
        last_message = messages[-1]
        
        # Check for tool calls safely
        if hasattr(last_message, "tool_calls"):
            tool_calls = getattr(last_message, "tool_calls", [])
            if tool_calls:
                return "tools"
        
        return "end"
        
    except:
        return "end"


# ========================= Create Graph =========================

def create_legislation_processing_graph():
    """Create workflow with error handling"""
    
    try:
        workflow = StateGraph(AgentState)
        workflow.add_node("agent", agent_node)
        workflow.add_node("tools", tool_node)
        workflow.set_entry_point("agent")
        workflow.add_conditional_edges("agent", should_continue, {"tools": "tools", "end": END})
        workflow.add_edge("tools", "agent")
        
        memory = MemorySaver()
        return workflow.compile(checkpointer=memory)
        
    except Exception as e:
        print(f"❌ Graph creation error: {to_string(e)}")
        return None


# ========================= Main Processing =========================

def process_legislation(legislation_text: str) -> Dict[str, Any]:
    """Process legislation with bulletproof error handling"""
    
    print("🚀 Processing with o3-mini + advanced reasoning...")
    
    try:
        legislation_text = to_string(legislation_text)
        
        graph = create_legislation_processing_graph()
        if not graph:
            return {"status": "error", "error": "Failed to create graph"}
        
        initial_state = {
            "messages": [HumanMessage(content=f"Process: {legislation_text}")],
            "legislation_text": legislation_text,
            "current_phase": "start",
            "analysis_count": 0,
            "extraction_count": 0,
            "extracted_rules": {},
            "json_rules": [],
            "validation_results": {},
            "reasoning_steps": [],
            "error_log": []
        }
        
        config = {"configurable": {"thread_id": "processing"}}
        final_state = graph.invoke(initial_state, config)
        
        return {
            "status": "completed",
            "extracted_rules": final_state.get("extracted_rules", {}),
            "json_rules": final_state.get("json_rules", []),
            "validation_results": final_state.get("validation_results", {}),
            "reasoning_steps": final_state.get("reasoning_steps", []),
            "analysis_count": final_state.get("analysis_count", 0),
            "extraction_count": final_state.get("extraction_count", 0),
            "error_log": final_state.get("error_log", [])
        }
        
    except Exception as e:
        error_msg = f"Processing failed: {to_string(e)}"
        print(f"❌ {error_msg}")
        return {"status": "error", "error": error_msg}


# ========================= Helper Functions =========================

def save_rules_to_file(rules: List[Dict[str, Any]], filename: str = "data_governance_rules.json"):
    """Save rules safely"""
    try:
        output = {
            "rules": rules,
            "metadata": {
                "created_by": "legislation_converter_o3mini",
                "model": OPENAI_MODEL,
                "reasoning_effort": REASONING_EFFORT,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "rule_count": len(rules)
            }
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)
        
        print(f"✅ Saved {len(rules)} rules to {filename}")
        
    except Exception as e:
        print(f"❌ Save error: {to_string(e)}")


def print_results_summary(results: Dict[str, Any]):
    """Print summary safely"""
    try:
        print("\n" + "="*80)
        print("📊 PROCESSING RESULTS")
        print("="*80)
        
        print(f"🧠 REASONING:")
        print(f"   • Analysis: {results.get('analysis_count', 0)}/4")
        print(f"   • Extraction: {results.get('extraction_count', 0)}/4")
        print(f"   • Steps: {len(results.get('reasoning_steps', []))}")
        
        extracted = results.get("extracted_rules", {})
        total = sum(len(rules) for rules in extracted.values())
        print(f"\n📋 EXTRACTED: {total} rules")
        for domain, rules in extracted.items():
            print(f"   • {domain}: {len(rules)}")
        
        json_rules = results.get("json_rules", [])
        print(f"\n⚙️ JSON RULES: {len(json_rules)}")
        
        validation = results.get("validation_results", {})
        if validation:
            print(f"\n✅ VALIDATION:")
            print(f"   • Valid: {validation.get('valid', False)}")
            print(f"   • Score: {validation.get('quality_score', 'N/A')}")
        
        errors = results.get("error_log", [])
        if errors:
            print(f"\n⚠️ ERRORS: {len(errors)}")
        
    except Exception as e:
        print(f"❌ Summary error: {to_string(e)}")


# ========================= Main Execution =========================

if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("⚠️ Set OPENAI_API_KEY environment variable")
        exit(1)
    
    SAMPLE_LEGISLATION = """
    DATA PROTECTION AND PRIVACY ACT
    
    Section 2. Data Usage Requirements
    2.1 Personal data shall only be used when:
        (a) The data subject has given explicit consent
        (b) Processing is necessary for contract performance
        (c) Processing is required for legal compliance
    
    2.2 Data controllers must not use personal data for incompatible purposes.
    
    Section 5. Data Transfer Regulations  
    5.1 Data controllers shall not transfer personal data to third parties unless:
        (a) A data processing agreement is in place
        (b) The third party provides security guarantees
        (c) The data subject has been informed
    
    Section 7. Storage Requirements
    7.1 Personal data shall not be stored longer than necessary.
    7.2 Data retention periods must be defined and documented.
    
    Section 10. Access Controls
    10.1 Data controllers must implement role-based access controls:
        (a) Access granted on need-to-know basis
        (b) Privileged access monitored quarterly
    """
    
    print("🚀 Data Governance Rules Extractor")
    print(f"🤖 Model: {OPENAI_MODEL} (effort: {REASONING_EFFORT})")
    print("📊 Framework: Chain of Thought + Mixture of Thought + Mixture of Reasoning")
    print("=" * 80)
    
    results = process_legislation(SAMPLE_LEGISLATION)
    
    if results["status"] == "completed":
        print_results_summary(results)
        
        json_rules = results.get("json_rules", [])
        if json_rules:
            save_rules_to_file(json_rules)
            print(f"\n✨ Generated {len(json_rules)} rules!")
        else:
            print("\n⚠️ No JSON rules generated")
    else:
        print(f"\n❌ Failed: {results.get('error', 'Unknown')}")
