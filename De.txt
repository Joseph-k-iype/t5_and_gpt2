import json
import csv

def convert_json_to_csv(data: dict):
    """
    Converts the unified legal JSON output into four separate CSV files.

    Args:
        data (dict): The dictionary loaded from the JSON file.
    """
    # --- 1. Process 'unified_simplified_rules' ---
    simplified_rules = data.get("unified_simplified_rules", [])
    if simplified_rules:
        output_filename = 'simplified_rules.csv'
        with open(output_filename, 'w', newline='', encoding='utf-8') as f:
            # Dynamically get headers from the first rule
            fieldnames = list(simplified_rules[0].keys())
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for rule in simplified_rules:
                # Join lists into semicolon-separated strings for CSV readability
                if isinstance(rule.get('conditions'), list):
                    rule['conditions'] = "; ".join(rule['conditions'])
                if isinstance(rule.get('key_phrases'), list):
                    rule['key_phrases'] = "; ".join(map(str, rule['key_phrases']))
                writer.writerow(rule)
        print(f"✅ Successfully created {output_filename}")

    # --- 2, 3, & 4. Process 'unified_decision_tables' ---
    decision_tables_data = data.get("unified_decision_tables", {}).get("decision_tables", [])
    if decision_tables_data:
        # Prepare lists to hold rows for the three related CSV files
        tables_metadata_rows = []
        table_rules_rows = []
        table_references_rows = []

        for table in decision_tables_data:
            table_id = table.get("table_id")
            
            # 2a. Prepare data for decision_tables.csv
            tables_metadata_rows.append({
                "table_id": table_id,
                "name": table.get("name"),
                "description": table.get("description"),
                # Store the conditions definition as a JSON string
                "conditions_definitions": json.dumps(table.get("conditions", {}))
            })

            # Process each rule within the table
            for rule in table.get("rules", []):
                rule_id = rule.get("rule_id")
                
                # 3a. Prepare data for decision_table_rules.csv
                table_rules_rows.append({
                    "table_id": table_id,
                    "rule_id": rule_id,
                    "priority": rule.get("priority"),
                    "source_rule": rule.get("source_rule"),
                    # Flatten rule conditions and actions into strings
                    "rule_conditions": "; ".join([f"{k}:{v}" for k, v in rule.get("conditions", {}).items()]),
                    "actions": "; ".join(rule.get("actions", []))
                })

                # 4a. Prepare data for decision_table_references.csv
                for reference in rule.get("references", []):
                    # Add table_id and rule_id to link the reference back
                    reference['table_id'] = table_id
                    reference['rule_id'] = rule_id
                    table_references_rows.append(reference)

        # 2b. Write decision_tables.csv
        if tables_metadata_rows:
            with open('decision_tables.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=tables_metadata_rows[0].keys())
                writer.writeheader()
                writer.writerows(tables_metadata_rows)
            print("✅ Successfully created decision_tables.csv")

        # 3b. Write decision_table_rules.csv
        if table_rules_rows:
            with open('decision_table_rules.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=table_rules_rows[0].keys())
                writer.writeheader()
                writer.writerows(table_rules_rows)
            print("✅ Successfully created decision_table_rules.csv")
            
        # 4b. Write decision_table_references.csv
        if table_references_rows:
            # Ensure all headers are present, even if some references miss keys
            all_headers = set()
            for row in table_references_rows:
                all_headers.update(row.keys())
            
            # Define a consistent order for headers
            fieldnames = ['table_id', 'rule_id'] + sorted([h for h in all_headers if h not in ['table_id', 'rule_id']])
            
            with open('decision_table_references.csv', 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()
                writer.writerows(table_references_rows)
            print("✅ Successfully created decision_table_references.csv")


# --- Main Execution ---
if __name__ == "__main__":
    input_filename = 'input.json'  # Your JSON file should be named this
    try:
        with open(input_filename, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        convert_json_to_csv(json_data)

    except FileNotFoundError:
        print(f"❌ Error: The file '{input_filename}' was not found. Please create it.")
    except json.JSONDecodeError:
        print(f"❌ Error: The file '{input_filename}' is not a valid JSON file.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
