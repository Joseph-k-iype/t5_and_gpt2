# backend/requirements.txt (Updated for Pydantic v2)
# FastAPI and Server
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# Async and WebSocket support
websockets==12.0
starlette==0.27.0

# Pydantic for data validation (v2 compatible)
pydantic==2.5.0
pydantic-settings==2.1.0

# CORS and middleware
python-jose[cryptography]==3.3.0

# Logging and monitoring
structlog==23.2.0

# Background tasks
celery==5.3.4
redis==5.0.1

# Original research engine dependencies (from enhanced_chatbot.py)
# Core dependencies
openai==1.3.0
elasticsearch==8.11.0
tiktoken==0.5.2
asyncio-mqtt==0.14.0

# LangChain components (optional but recommended)
langchain-core==0.1.10
langchain-elasticsearch==0.1.0
langchain-openai==0.0.2

# LangGraph (optional)
langgraph==0.0.20

# LangMem (optional)
langmem==0.1.0

# Additional ML/NLP dependencies
numpy==1.24.3
scipy==1.11.4

# Development dependencies
pytest==7.4.3
pytest-asyncio==0.21.1
httpx==0.25.2
black==23.11.0
flake8==6.1.0

# backend/app/api/chat.py (Fixed dependency injection)
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Request
from typing import List
import logging

from app.models.chat import (
    QuickChatRequest, QuickChatResponse, 
    ConversationHistory, ChatMessage
)
from app.core.session_manager import SessionManager, SessionData
from app.core.research_engine import ResearchEngineWrapper

logger = logging.getLogger(__name__)
router = APIRouter()

# These will be patched by main.py
get_session_manager = None
get_research_engine = None

@router.post("/quick", response_model=QuickChatResponse)
async def quick_chat(
    request: QuickChatRequest,
    background_tasks: BackgroundTasks,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r)),
    research_engine: ResearchEngineWrapper = Depends(lambda r: get_research_engine(r))
):
    """
    Quick chat endpoint for fast AI responses
    """
    try:
        # Get or create session
        if request.session_id:
            session = await session_manager.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="Session not found")
        else:
            session = await session_manager.create_session(request.user_id)
        
        # Add user message to conversation history
        user_message = {
            "role": "user",
            "content": request.message,
            "timestamp": session.last_activity.isoformat()
        }
        await session_manager.add_conversation_message(session.session_id, user_message)
        
        # Process with research engine
        result = await research_engine.quick_chat(
            question=request.message,
            user_id=session.user_id,
            session_id=session.session_id
        )
        
        # Add assistant response to conversation history
        assistant_message = {
            "role": "assistant", 
            "content": result.get("answer", ""),
            "metadata": {
                "confidence": result.get("confidence"),
                "approach": result.get("approach")
            }
        }
        background_tasks.add_task(
            session_manager.add_conversation_message,
            session.session_id,
            assistant_message
        )
        
        # Return structured response
        return QuickChatResponse(
            answer=result.get("answer", "No response generated"),
            confidence=result.get("confidence", "unknown"),
            approach=result.get("approach", "unknown"),
            session_id=session.session_id,
            user_id=session.user_id,
            timestamp=session.last_activity,
            metadata=result.get("metadata", {})
        )
        
    except Exception as e:
        logger.error(f"Error in quick chat: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@router.get("/conversation/{session_id}", response_model=ConversationHistory)
async def get_conversation_history(
    session_id: str,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r))
):
    """
    Get conversation history for a session
    """
    try:
        session = await session_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        messages = [
            ChatMessage(
                role=msg.get("role", "unknown"),
                content=msg.get("content", ""),
                timestamp=msg.get("timestamp"),
                metadata=msg.get("metadata", {})
            )
            for msg in session.conversation_history
        ]
        
        return ConversationHistory(
            messages=messages,
            session_id=session_id,
            total_messages=len(messages)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting conversation history: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.delete("/session/{session_id}")
async def delete_session(
    session_id: str,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r))
):
    """
    Delete a chat session
    """
    try:
        success = await session_manager.delete_session(session_id)
        if not success:
            raise HTTPException(status_code=404, detail="Session not found")
        
        return {"message": "Session deleted successfully", "session_id": session_id}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting session: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

# backend/app/api/research.py (Fixed dependency injection)
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks, Request
from fastapi.responses import StreamingResponse
from typing import Dict, Any
import asyncio
import json
import logging

from app.models.research import (
    DeepResearchRequest, ResearchResult, ResearchStatus,
    ResearchProgressUpdate, ResearchStage
)
from app.core.session_manager import SessionManager
from app.core.research_engine import ResearchEngineWrapper

logger = logging.getLogger(__name__)
router = APIRouter()

# Store active research sessions
active_research: Dict[str, Dict[str, Any]] = {}

# These will be patched by main.py
get_session_manager = None
get_research_engine = None

@router.post("/deep", response_model=ResearchResult)
async def start_deep_research(
    request: DeepResearchRequest,
    background_tasks: BackgroundTasks,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r)),
    research_engine: ResearchEngineWrapper = Depends(lambda r: get_research_engine(r))
):
    """
    Start deep research process
    """
    try:
        # Get or create session
        if request.session_id:
            session = await session_manager.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="Session not found")
        else:
            session = await session_manager.create_session(request.user_id)
        
        # Check if research is already running for this session
        if session.session_id in active_research:
            raise HTTPException(
                status_code=409, 
                detail="Research already in progress for this session"
            )
        
        # Check cache first
        cached_result = await session_manager.get_cached_research(
            session.session_id, request.topic
        )
        if cached_result:
            logger.info(f"Returning cached research result for: {request.topic}")
            return ResearchResult(**cached_result)
        
        # Mark research as active
        active_research[session.session_id] = {
            "status": "running",
            "stage": ResearchStage.INITIALIZATION,
            "progress": 0
        }
        
        try:
            # Start deep research
            result = await research_engine.deep_research(
                topic=request.topic,
                user_id=session.user_id,
                session_id=session.session_id
            )
            
            # Cache the result
            background_tasks.add_task(
                session_manager.cache_research_result,
                session.session_id,
                request.topic,
                result
            )
            
            # Return structured response
            research_result = ResearchResult(
                final_synthesis=result.get("final_synthesis", "No synthesis available"),
                overall_confidence=result.get("overall_confidence", 0.0),
                agents_used=result.get("agents_used", []),
                iterations_completed=result.get("iterations_completed", 0),
                session_id=session.session_id,
                user_id=session.user_id,
                timestamp=session.last_activity,
                processing_time=result.get("processing_time", "extended"),
                metadata=result.get("metadata", {})
            )
            
            return research_result
            
        finally:
            # Remove from active research
            active_research.pop(session.session_id, None)
        
    except HTTPException:
        # Remove from active research on HTTP errors
        active_research.pop(request.session_id or "unknown", None)
        raise
    except Exception as e:
        # Remove from active research on any error
        active_research.pop(request.session_id or "unknown", None)
        logger.error(f"Error in deep research: {e}")
        raise HTTPException(status_code=500, detail=f"Research failed: {str(e)}")

@router.get("/status/{session_id}", response_model=ResearchStatus)
async def get_research_status(
    session_id: str,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r))
):
    """
    Get research status for a session
    """
    try:
        session = await session_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        # Check if research is active
        if session_id in active_research:
            research_info = active_research[session_id]
            return ResearchStatus(
                session_id=session_id,
                is_active=True,
                current_stage=research_info.get("stage"),
                progress_percentage=research_info.get("progress", 0),
                estimated_completion=None,  # Could be calculated based on progress
                error_message=research_info.get("error")
            )
        else:
            return ResearchStatus(
                session_id=session_id,
                is_active=False,
                current_stage=None,
                progress_percentage=100,
                estimated_completion=None,
                error_message=None
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting research status: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.get("/stream/{session_id}")
async def stream_research_progress(
    session_id: str,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r)),
    research_engine: ResearchEngineWrapper = Depends(lambda r: get_research_engine(r))
):
    """
    Stream research progress updates
    """
    async def generate_progress():
        """Generate progress updates as Server-Sent Events"""
        try:
            session = await session_manager.get_session(session_id)
            if not session:
                yield f"data: {json.dumps({'error': 'Session not found'})}\n\n"
                return
            
            # Mock progress updates for demonstration
            # In real implementation, this would connect to the research engine's progress
            stages = [
                (ResearchStage.INITIALIZATION, "Initializing research system...", 10),
                (ResearchStage.PLANNING, "Creating research plan...", 25),
                (ResearchStage.RESEARCH, "Conducting research...", 70),
                (ResearchStage.SYNTHESIS, "Synthesizing findings...", 90),
                (ResearchStage.COMPLETION, "Research completed!", 100)
            ]
            
            for stage, message, progress in stages:
                if session_id not in active_research:
                    break
                
                update = ResearchProgressUpdate(
                    stage=stage,
                    message=message,
                    progress=progress,
                    details={"session_id": session_id}
                )
                
                # Update active research status
                active_research[session_id].update({
                    "stage": stage,
                    "progress": progress
                })
                
                yield f"data: {update.json()}\n\n"
                await asyncio.sleep(2)  # Simulate processing time
            
        except Exception as e:
            error_update = ResearchProgressUpdate(
                stage=ResearchStage.ERROR,
                message=f"Error: {str(e)}",
                progress=0,
                error=True
            )
            yield f"data: {error_update.json()}\n\n"
    
    return StreamingResponse(
        generate_progress(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Content-Type": "text/event-stream"
        }
    )

# backend/app/api/knowledge_graph.py (Fixed dependency injection)
from fastapi import APIRouter, HTTPException, Depends, Request
from typing import List, Dict, Any
import logging

from app.models.knowledge_graph import (
    KnowledgeGraphRequest, KnowledgeGraphResponse,
    GraphNode, GraphEdge
)
from app.core.session_manager import SessionManager
from app.utils.knowledge_extractor import KnowledgeExtractor

logger = logging.getLogger(__name__)
router = APIRouter()

# These will be patched by main.py
get_session_manager = None

@router.post("/generate", response_model=KnowledgeGraphResponse)
async def generate_knowledge_graph(
    request: KnowledgeGraphRequest,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r))
):
    """
    Generate knowledge graph from research results or conversation
    """
    try:
        # Validate session if provided
        if request.session_id:
            session = await session_manager.get_session(request.session_id)
            if not session:
                raise HTTPException(status_code=404, detail="Session not found")
        
        # Initialize knowledge extractor
        extractor = KnowledgeExtractor()
        
        # Extract concepts and relationships
        graph_data = await extractor.extract_knowledge_graph(
            text=request.content,
            context=request.context,
            max_nodes=request.max_nodes,
            max_edges=request.max_edges
        )
        
        # Convert to response model
        nodes = [
            GraphNode(
                id=node["id"],
                label=node["label"],
                type=node.get("type", "concept"),
                properties=node.get("properties", {}),
                size=node.get("size", 20),
                color=node.get("color", "#4A90E2")
            )
            for node in graph_data["nodes"]
        ]
        
        edges = [
            GraphEdge(
                id=edge["id"],
                source=edge["source"],
                target=edge["target"],
                label=edge.get("label", ""),
                type=edge.get("type", "related"),
                properties=edge.get("properties", {}),
                weight=edge.get("weight", 1.0)
            )
            for edge in graph_data["edges"]
        ]
        
        return KnowledgeGraphResponse(
            nodes=nodes,
            edges=edges,
            metadata={
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "generation_method": "nlp_extraction",
                "confidence": graph_data.get("confidence", 0.8)
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error generating knowledge graph: {e}")
        raise HTTPException(status_code=500, detail=f"Knowledge graph generation failed: {str(e)}")

@router.get("/session/{session_id}", response_model=KnowledgeGraphResponse)
async def get_session_knowledge_graph(
    session_id: str,
    session_manager: SessionManager = Depends(lambda r: get_session_manager(r))
):
    """
    Generate knowledge graph from entire session conversation
    """
    try:
        session = await session_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        # Combine all conversation content
        content_parts = []
        for message in session.conversation_history:
            if message.get("role") == "assistant":
                content_parts.append(message.get("content", ""))
        
        combined_content = " ".join(content_parts)
        
        if not combined_content.strip():
            # Return empty graph for sessions with no content
            return KnowledgeGraphResponse(
                nodes=[],
                edges=[],
                metadata={
                    "total_nodes": 0,
                    "total_edges": 0,
                    "generation_method": "session_conversation",
                    "session_id": session_id
                }
            )
        
        # Generate graph from combined content
        extractor = KnowledgeExtractor()
        graph_data = await extractor.extract_knowledge_graph(
            text=combined_content,
            context={"session_id": session_id, "type": "conversation"},
            max_nodes=30,
            max_edges=50
        )
        
        # Convert to response model
        nodes = [
            GraphNode(
                id=node["id"],
                label=node["label"],
                type=node.get("type", "concept"),
                properties=node.get("properties", {}),
                size=node.get("size", 20),
                color=node.get("color", "#4A90E2")
            )
            for node in graph_data["nodes"]
        ]
        
        edges = [
            GraphEdge(
                id=edge["id"],
                source=edge["source"],
                target=edge["target"],
                label=edge.get("label", ""),
                type=edge.get("type", "related"),
                properties=edge.get("properties", {}),
                weight=edge.get("weight", 1.0)
            )
            for edge in graph_data["edges"]
        ]
        
        return KnowledgeGraphResponse(
            nodes=nodes,
            edges=edges,
            metadata={
                "total_nodes": len(nodes),
                "total_edges": len(edges),
                "generation_method": "session_conversation",
                "session_id": session_id,
                "confidence": graph_data.get("confidence", 0.8)
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error generating session knowledge graph: {e}")
        raise HTTPException(status_code=500, detail="Knowledge graph generation failed")
