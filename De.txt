"""
Validator Agent - Validates data elements against ISO/IEC 11179 standards.
"""

from typing import Dict, Any, List, Tuple, Optional
import re
import logging
import os
import pandas as pd
import asyncio
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import AzureChatOpenAI
from app.core.models import DataElement, ValidationResult, DataQualityStatus, Process
from app.utils.iso_standards import ISO11179Validator # Assuming this utility class exists
from app.utils.cache import cache_manager

logger = logging.getLogger(__name__)

class ValidatorAgent:
    """
    Agent that validates data elements against ISO/IEC 11179 standards.
    """

    def __init__(self, llm: AzureChatOpenAI):
        """
        Initialize the validator agent.

        Args:
            llm: Language model instance
        """
        self.llm = llm
        self.iso_validator = ISO11179Validator()
        self.approved_acronyms = self._load_approved_acronyms()
        self._setup_validation_chain()

    def _load_approved_acronyms(self):
        approved_acronyms = {}
        try:
            # Try to construct path relative to this file's directory if needed
            base_dir = os.path.dirname(os.path.abspath(__file__))
            csv_path = os.path.join(base_dir, "..", "..", "data", "acronyms.csv") # Adjusted path
            csv_path = os.path.normpath(csv_path)

            if os.path.exists(csv_path):
                df = pd.read_csv(csv_path)
                if 'acronym' in df.columns and 'definition' in df.columns:
                    for _, row in df.iterrows():
                        approved_acronyms[row['acronym'].strip().upper()] = row['definition'].strip()
                logger.info(f"Loaded {len(approved_acronyms)} approved acronyms from {csv_path}")
            else:
                logger.warning(f"Acronyms file not found at {csv_path} for ValidatorAgent.")
        except Exception as e:
            logger.error(f"Error loading approved acronyms for ValidatorAgent from {csv_path}: {e}")
        return approved_acronyms


    def _format_processes_info(self, data_element: DataElement) -> str:
        if not data_element.processes:
            return "Related Processes: None"

        processes = data_element.processes
        process_list = []
        for p_data in processes:
            if isinstance(p_data, Process):
                process_list.append(p_data)
            elif isinstance(p_data, dict):
                try:
                    process_list.append(Process(**p_data))
                except Exception as e:
                    logger.warning(f"Validator: Could not convert dict to Process object: {p_data}. Error: {e}")
            else:
                logger.warning(f"Validator: Unknown process type encountered: {type(p_data)}")
        
        if not process_list:
            return "Related Processes: None available after formatting."

        processes_info = "Related Processes:\n"
        for i, process in enumerate(process_list, 1):
            processes_info += f"  Process {i} ID: {process.process_id}\n"
            processes_info += f"  Process {i} Name: {process.process_name}\n"
            if process.process_description:
                processes_info += f"  Process {i} Description: {process.process_description}\n"
            processes_info += "\n" # Add a blank line for readability
        return processes_info.strip()


    def _setup_validation_chain(self):
        """Set up the LangChain chain for validation."""
        template = """
        You are an expert in data governance and ISO/IEC 11179 metadata standards. Your task is to evaluate the
        given data element name and description against these standards to determine the quality of the metadata.

        **ISO/IEC 11179 Standards for Data Element Names (Business-Friendly Adaptation):**
        1.  **Format:** Names MUST be in lowercase with single spaces between words.
        2.  **No Technical Casing:** Names MUST NOT use technical formatting like camelCase, snake_case, or PascalCase.
        3.  **No Special Characters:** Names MUST NOT contain underscores, hyphens, or any special characters (e.g., %, &, *, #, /). Only alphanumeric characters and spaces are allowed.
        4.  **Clarity & Unambiguity:** Names should be clear, unambiguous, and self-describing. Avoid vague terms.
        5.  **Acronyms/Abbreviations:** Avoid acronyms or abbreviations unless they are universally understood within the business context (e.g., ID, URL, SKU). If used, ensure they are common knowledge.
        6.  **Conciseness & Descriptiveness:** Names should be concise yet descriptive enough to convey meaning.
        7.  **Standard Terminology:** Use standard terminology relevant to the data element's domain.
        8.  **Business Language:** Use business language that non-technical users can easily understand.

        **ISO/IEC 11179 Standards for Data Element Descriptions:**
        1.  **Clarity of Definition:** Descriptions MUST clearly and precisely define what the data element represents.
        2.  **Completeness:** Descriptions should be complete, fully covering the concept of the data element.
        3.  **Precision:** Descriptions should be specific enough to distinguish the data element from other related concepts.
        4.  **Objectivity:** Descriptions must be objective and factual, not based on opinion.
        5.  **Grammar & Punctuation:** Descriptions MUST use complete sentences with proper grammar and punctuation. Each description should start with a capital letter and end with a period.
        6.  **Business Language:** Descriptions should be written in clear business language, avoiding technical jargon.
        7.  **Avoid Vague Language:** Do not use imprecise phrases like "etc.", "and so on", or "various".

        **Data Element to Evaluate:**
        - ID: {id}
        - Current Name: {name}
        - Current Description: {description}
        - Example (if provided): {example}
        {processes_info}

        **Examples of High-Quality Data Elements (should receive "GOOD" quality):**
        * Name: customer identifier
            Description: A unique alphanumeric code assigned to identify an individual customer within the organization's systems.
            Assessment: GOOD. Name is lowercase, spaced, clear. Description is precise, complete, and well-formed.
        * Name: last name
            Description: The legal surname of an individual as it appears on official identification documents.
            Assessment: GOOD. Name is clear and simple. Description defines the term effectively.
        * Name: transaction amount
            Description: The monetary value of a financial transaction, expressed in the currency of the transaction.
            Assessment: GOOD. Name is descriptive. Description is specific and objective.

        **Based on the ISO/IEC 11179 standards, evaluate the quality of this data element.**

        **Output Format:**
        Provide your evaluation *strictly* in the following format, with each item on a new line. Do not include any extra formatting, numbering, or markdown:
        Is name valid: [yes/no, based on strict adherence to all name standards]
        Name feedback: [Detailed feedback on name quality. If not valid, explain all reasons why. If valid, state it is compliant.]
        Is description valid: [yes/no, based on strict adherence to all description standards]
        Description feedback: [Detailed feedback on description quality, including grammar, punctuation, clarity, and completeness. If not valid, explain all reasons. If valid, state it is compliant.]
        Overall quality: [GOOD, NEEDS_IMPROVEMENT, or POOR. GOOD only if both name and description are fully valid.]
        Suggested improvements: [List specific, actionable improvements for name and/or description if not GOOD. If GOOD, state "No improvements needed." Each improvement on a new line, starting with "- ". If multiple lines per improvement, indent subsequent lines.]
        """

        self.validation_prompt = PromptTemplate(
            input_variables=["id", "name", "description", "example", "processes_info"],
            template=template)
        self.validation_chain = self.validation_prompt | self.llm | StrOutputParser()

    def _perform_basic_validation(self, data_element: DataElement) -> Tuple[List[str], bool, bool]:
        basic_validation_issues = []
        name = data_element.existing_name or ""
        description = data_element.existing_description or ""

        name_valid, name_feedback = self.iso_validator.validate_name(name)
        if not name_valid:
            basic_validation_issues.append(f"Programmatic Name Check: {name_feedback}")

        desc_valid, desc_feedback = self.iso_validator.validate_description(description)
        if not desc_valid:
            basic_validation_issues.append(f"Programmatic Description Check: {desc_feedback}")
        
        # Check for unexpanded acronyms (simple check for uppercase words)
        # This is a very basic check; LLM will do more sophisticated acronym handling.
        potential_acronyms = set(re.findall(r'\b[A-Z]{2,}\b', name + " " + description))
        # Filter out universally accepted acronyms like ID, URL from this basic check
        # as the LLM prompt allows them.
        universally_ok = {"ID", "URL", "KPI", "ETA", "VAT", "SKU", "API"} # Add more if needed
        suspicious_acronyms = [acro for acro in potential_acronyms if acro not in universally_ok and acro.upper() not in self.approved_acronyms]

        if suspicious_acronyms:
             basic_validation_issues.append(f"Potential unexpanded acronyms found: {', '.join(suspicious_acronyms)}. Ensure they are either universally understood or expanded.")

        return basic_validation_issues, name_valid, desc_valid

    def _parse_validation_result(self, result: str) -> ValidationResult:
        lines = result.strip().split("\n")
        
        is_name_valid_str = ""
        name_feedback_str = ""
        is_desc_valid_str = ""
        desc_feedback_str = ""
        quality_status_str = ""
        improvements_list = []

        parsing_name_feedback = False
        parsing_desc_feedback = False
        parsing_improvements = False

        for line in lines:
            line_lower = line.lower()
            
            if line_lower.startswith("is name valid:"):
                is_name_valid_str = line.split(":", 1)[1].strip().lower()
                parsing_name_feedback = False
                parsing_desc_feedback = False
                parsing_improvements = False
            elif line_lower.startswith("name feedback:"):
                name_feedback_str = line.split(":", 1)[1].strip()
                parsing_name_feedback = True
                parsing_desc_feedback = False
                parsing_improvements = False
            elif line_lower.startswith("is description valid:"):
                is_desc_valid_str = line.split(":", 1)[1].strip().lower()
                parsing_name_feedback = False
                parsing_desc_feedback = False
                parsing_improvements = False
            elif line_lower.startswith("description feedback:"):
                desc_feedback_str = line.split(":", 1)[1].strip()
                parsing_name_feedback = False
                parsing_desc_feedback = True
                parsing_improvements = False
            elif line_lower.startswith("overall quality:"):
                quality_status_str = line.split(":", 1)[1].strip().upper()
                parsing_name_feedback = False
                parsing_desc_feedback = False
                parsing_improvements = False
            elif line_lower.startswith("suggested improvements:"):
                # Capture first line of improvements
                first_improvement_line = line.split(":", 1)[1].strip()
                if first_improvement_line and first_improvement_line.lower() != "no improvements needed.":
                    improvements_list.append(first_improvement_line.lstrip("- "))
                parsing_name_feedback = False
                parsing_desc_feedback = False
                parsing_improvements = True # Now start capturing all subsequent improvement lines
            elif parsing_name_feedback:
                name_feedback_str += " " + line.strip()
            elif parsing_desc_feedback:
                desc_feedback_str += " " + line.strip()
            elif parsing_improvements:
                if line.strip() and line.strip().lower() != "no improvements needed.":
                    improvements_list.append(line.strip().lstrip("- "))
        
        is_name_valid = "yes" in is_name_valid_str
        is_desc_valid = "yes" in is_desc_valid_str

        quality_status = DataQualityStatus.NEEDS_IMPROVEMENT # Default
        if quality_status_str == "GOOD":
            quality_status = DataQualityStatus.GOOD
        elif quality_status_str == "POOR":
            quality_status = DataQualityStatus.POOR
        
        # If LLM says GOOD, but programmatic checks failed or LLM says one part is invalid, downgrade.
        if quality_status == DataQualityStatus.GOOD and (not is_name_valid or not is_desc_valid):
            quality_status = DataQualityStatus.NEEDS_IMPROVEMENT
            if not improvements_list or improvements_list == ["No improvements needed."]:
                 improvements_list = ["Review name and description for full ISO/IEC 11179 compliance as per feedback."]


        combined_feedback = f"Name Feedback: {name_feedback_str or 'Not provided.'}\nDescription Feedback: {desc_feedback_str or 'Not provided.'}"
        
        # Filter out "No improvements needed." if it's the only item
        if len(improvements_list) == 1 and improvements_list[0].lower() == "no improvements needed.":
            improvements_list = []


        return ValidationResult(
            is_valid=is_name_valid and is_desc_valid, # Overall validity
            quality_status=quality_status,
            feedback=combined_feedback.strip(),
            suggested_improvements=improvements_list
        )


    @cache_manager.async_cached(ttl=3600)
    async def validate(self, data_element: DataElement) -> ValidationResult:
        try:
            # Perform basic programmatic validation first (can be part of context for LLM)
            basic_issues, _, _ = self._perform_basic_validation(data_element)
            
            processes_info = self._format_processes_info(data_element)
            
            # Construct additional context if basic issues were found
            additional_context_for_llm = ""
            if basic_issues:
                additional_context_for_llm = "Programmatic Pre-checks Found Issues:\n" + "\n".join(f"- {issue}" for issue in basic_issues)
                additional_context_for_llm += "\n\nPlease consider these pre-checks in your detailed evaluation.\n"

            # If additional context for LLM exists, we might prepend it to the prompt or pass it in a specific way.
            # For this template, we'll just log it and rely on the main prompt structure.
            if additional_context_for_llm:
                logger.debug(f"Additional context for LLM validation of {data_element.id}: {additional_context_for_llm}")

            result_str = await self.validation_chain.ainvoke({
                "id": data_element.id,
                "name": data_element.existing_name,
                "description": data_element.existing_description,
                "example": data_element.example or "Not provided.",
                "processes_info": processes_info
            })
            
            parsed_result = self._parse_validation_result(result_str)

            # Log the raw and parsed result for debugging if parsing seems off
            if parsed_result.quality_status == DataQualityStatus.POOR and not parsed_result.suggested_improvements:
                 logger.warning(f"Validation for {data_element.id} resulted in POOR quality with no improvements. Raw LLM: {result_str[:200]}, Parsed: {parsed_result}")


            return parsed_result

        except Exception as e:
            logger.error(f"Error validating data element {data_element.id}: {e}", exc_info=True)
            return ValidationResult(
                is_valid=False,
                quality_status=DataQualityStatus.POOR,
                feedback=f"Error during validation: {str(e)}",
                suggested_improvements=["System error during validation. Please review manually or retry."]
            )

    async def batch_validate(self, data_elements: List[DataElement]) -> List[ValidationResult]:
        tasks = [self.validate(element) for element in data_elements]
        return await asyncio.gather(*tasks)
