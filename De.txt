"""
Legal Summary Pipeline - FIXED VERSION
Ensures proper data aggregation and ONE document per rule
"""

import json
import os
from typing import Dict, List, Any, Optional
from pathlib import Path
import argparse

from src.processors.pdf_processor import PDFProcessor
from src.analyzers.legal_document_analyzer_enhanced import EnhancedLegalDocumentAnalyzer
from src.generators.legal_summary_generator_enhanced import LegalSummaryGenerator
from src.config import Config


class LegalSummaryPipeline:
    """Complete pipeline with proper data validation"""
    
    def __init__(self, metadata_file: str = "config/legislation_metadata.json",
                 output_dir: str = "output/legal_summaries",
                 config: Optional[Config] = None):
        self.metadata_file = metadata_file
        self.output_dir = output_dir
        self.config = config or Config()
        
        self.pdf_processor = PDFProcessor()
        self.analyzer = EnhancedLegalDocumentAnalyzer(config=self.config)
        self.generator = LegalSummaryGenerator(output_dir=output_dir)
        
        self.metadata = self._load_metadata()
        
        print(f"âœ“ Initialized Legal Summary Pipeline")
        print(f"âœ“ Loaded {len(self.metadata)} rules")
    
    def _load_metadata(self) -> Dict[str, Any]:
        """Load legislation metadata"""
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"Warning: Metadata file not found: {self.metadata_file}")
            return {}
        except json.JSONDecodeError as e:
            print(f"Error parsing metadata: {e}")
            return {}
    
    def _detect_enterprise_context(self, text: str) -> Optional[Dict[str, Any]]:
        """Detect enterprise context"""
        context = {}
        
        # Detect organization
        organizations = {
            "HSBC": ["HSBC", "hsbc"],
            "Acme Corp": ["Acme", "acme"],
            "Global Bank": ["Global Bank", "GlobalBank"]
        }
        
        for org_name, patterns in organizations.items():
            if any(pattern in text for pattern in patterns):
                context["organization"] = org_name
                break
        
        # Detect internal tools
        tools = []
        for tool in self.config.ENTERPRISE_TOOLS:
            if tool in text or tool.lower() in text.lower():
                tools.append(tool)
                
                if tool == "DataVisa":
                    context["datavisa_detected"] = True
                    context["tool_types"] = context.get("tool_types", [])
                    context["tool_types"].append("data_governance")
        
        if tools:
            context["internal_tools"] = tools
        
        if context.get("organization"):
            context["is_enterprise_policy"] = True
        
        return context if context else None
    
    def _extract_pdf_text(self, pdf_path: str) -> str:
        """Extract text from PDF"""
        try:
            if not os.path.exists(pdf_path):
                print(f"Warning: PDF not found: {pdf_path}")
                return ""
            
            text = self.pdf_processor.extract_text_from_pdf(pdf_path)
            return text
        except Exception as e:
            print(f"Error extracting from {pdf_path}: {e}")
            return ""
    
    def _validate_analysis(self, analysis: Dict[str, Any], rule_name: str) -> Dict[str, Any]:
        """
        Validate and log analysis data
        This helps identify where data is being lost
        """
        print(f"\n{'='*60}")
        print(f"VALIDATING ANALYSIS: {rule_name}")
        print(f"{'='*60}")
        
        # Check each required field
        required_fields = {
            'description': (str, 100),  # type, min_length
            'original_terminology': (list, 0),
            'citations': (list, 1),
            'data_actions': (list, 1),
            'user_evidence': (list, 0),
            'system_evidence': (list, 0),
            'constraints': (list, 0),
            'classification': (str, 5),
            'machine_readable_rules': (list, 0),
            'metadata': (dict, 0)
        }
        
        issues = []
        
        for field_name, (expected_type, min_count) in required_fields.items():
            if field_name not in analysis:
                issues.append(f"âŒ Missing field: {field_name}")
                continue
            
            value = analysis[field_name]
            
            # Type check
            if not isinstance(value, expected_type):
                issues.append(f"âŒ Wrong type for {field_name}: {type(value)} (expected {expected_type})")
                continue
            
            # Count/length check
            if isinstance(value, list):
                count = len(value)
                status = "âœ“" if count >= min_count else "âš "
                print(f"  {status} {field_name}: {count} items")
                if count < min_count:
                    issues.append(f"âš  {field_name} has {count} items (expected at least {min_count})")
            elif isinstance(value, str):
                length = len(value)
                status = "âœ“" if length >= min_count else "âš "
                print(f"  {status} {field_name}: {length} chars")
                if length < min_count:
                    issues.append(f"âš  {field_name} has {length} chars (expected at least {min_count})")
            elif isinstance(value, dict):
                print(f"  âœ“ {field_name}: {len(value)} keys")
        
        # Log issues
        if issues:
            print(f"\n{'='*60}")
            print(f"VALIDATION ISSUES:")
            print(f"{'='*60}")
            for issue in issues:
                print(f"  {issue}")
            print(f"{'='*60}")
        else:
            print(f"\nâœ“ All validation checks passed")
        
        return analysis
    
    def process_rule(self, rule_name: str, rule_config: Dict[str, Any],
                    generate_doc: bool = True) -> Optional[Dict[str, Any]]:
        """
        Process single rule - FIXED to generate ONE document per rule
        """
        print(f"\n{'='*80}")
        print(f"Processing Rule: {rule_name}")
        print(f"{'='*80}")
        
        countries = rule_config.get("country", [])
        adequacy_countries = rule_config.get("adequacy_country", [])
        jurisdiction = ", ".join(countries) if countries else "General"
        
        print(f"Jurisdiction: {jurisdiction}")
        if adequacy_countries:
            print(f"Adequacy Countries: {', '.join(adequacy_countries)}")
        
        level_1_file = rule_config.get("file_level_1")
        level_2_file = rule_config.get("file_level_2")
        level_3_file = rule_config.get("file_level_3")
        
        if not level_1_file:
            print(f"Error: Missing level 1 file path for '{rule_name}'")
            return None
        
        print(f"\nExtracting text from PDFs...")
        print(f"  Level 1: {level_1_file}")
        level_1_text = self._extract_pdf_text(level_1_file)
        
        if not level_1_text:
            print(f"Error: No text extracted from Level 1")
            return None
        
        print(f"  Level 1 extracted: {len(level_1_text)} characters")
        
        # Level 2 and 3 are optional
        level_2_text = ""
        level_3_text = ""
        
        if level_2_file:
            print(f"  Level 2: {level_2_file}")
            level_2_text = self._extract_pdf_text(level_2_file)
            if level_2_text:
                print(f"  Level 2 extracted: {len(level_2_text)} characters")
            else:
                print(f"  Level 2: No text extracted (continuing without)")
        else:
            print(f"  Level 2: Not provided (optional)")
        
        if level_3_file:
            print(f"  Level 3: {level_3_file}")
            level_3_text = self._extract_pdf_text(level_3_file)
            if level_3_text:
                print(f"  Level 3 extracted: {len(level_3_text)} characters")
            else:
                print(f"  Level 3: No text extracted (continuing without)")
        else:
            print(f"  Level 3: Not provided (optional)")
        
        # Detect enterprise context
        all_text = f"{level_1_text} {level_2_text} {level_3_text}"
        enterprise_context = self._detect_enterprise_context(all_text)
        
        if enterprise_context:
            print(f"\nâœ“ Enterprise context detected:")
            if enterprise_context.get("organization"):
                print(f"  Organization: {enterprise_context['organization']}")
            if enterprise_context.get("internal_tools"):
                tools_str = ", ".join(enterprise_context['internal_tools'])
                print(f"  Internal Tools: {tools_str}")
        
        print(f"\nðŸ”¬ Analyzing with advanced reasoning...")
        
        try:
            # This should return ONE analysis combining all levels
            analysis = self.analyzer.analyze_multi_level(
                rule_name=rule_name,
                jurisdiction=jurisdiction,
                level_1_text=level_1_text,
                level_2_text=level_2_text,
                level_3_text=level_3_text,
                enterprise_context=enterprise_context
            )
            
            # Ensure metadata exists
            if not analysis.get("metadata"):
                analysis["metadata"] = {}
            
            analysis["metadata"]["adequacy_countries"] = adequacy_countries
            analysis["metadata"]["countries"] = countries
            analysis["metadata"]["rule_name"] = rule_name
            analysis["metadata"]["jurisdiction"] = jurisdiction
            
            # Validate analysis data
            analysis = self._validate_analysis(analysis, rule_name)
            
            print(f"\nâœ“ Analysis complete")
            print(f"  Classification: {analysis.get('classification', 'N/A').upper()}")
            print(f"  Description: {len(analysis.get('description', ''))} chars")
            print(f"  Original Terminology: {len(analysis.get('original_terminology', []))} terms")
            print(f"  Citations: {len(analysis.get('citations', []))}")
            print(f"  Data Actions: {len(analysis.get('data_actions', []))}")
            print(f"  User Duties: {len(analysis.get('user_evidence', []))}")
            print(f"  System Duties: {len(analysis.get('system_evidence', []))}")
            print(f"  Constraints: {len(analysis.get('constraints', []))}")
            print(f"  Machine-Readable Rules: {len(analysis.get('machine_readable_rules', []))}")
            
            potential_dupes = len(analysis.get('potential_duplicates', []))
            if potential_dupes > 0:
                print(f"  âš  Potential Duplicates: {potential_dupes}")
            
        except Exception as e:
            print(f"âœ— Error during analysis: {e}")
            import traceback
            traceback.print_exc()
            return None
        
        # Generate ONE document for this rule
        if generate_doc:
            print(f"\nðŸ“„ Generating outputs...")
            try:
                # Generate Word document with all data
                doc_path = self.generator.generate_legal_summary(analysis)
                print(f"âœ“ Word document saved: {doc_path}")
                
                # Save JSON for debugging
                json_path = doc_path.replace('.docx', '.json')
                with open(json_path, 'w', encoding='utf-8') as f:
                    json.dump(analysis, f, indent=2, ensure_ascii=False)
                print(f"âœ“ JSON saved: {json_path}")
                
            except Exception as e:
                print(f"âœ— Error generating documents: {e}")
                import traceback
                traceback.print_exc()
        
        return analysis
    
    def process_all_rules(self, generate_docs: bool = True,
                         generate_index: bool = True) -> Dict[str, Dict[str, Any]]:
        """Process all rules - ONE document per rule"""
        if not self.metadata:
            print("No metadata loaded")
            return {}
        
        all_analyses = {}
        
        print(f"\n{'#'*80}")
        print(f"# Processing {len(self.metadata)} rules")
        print(f"# ONE document per rule with all levels combined")
        print(f"{'#'*80}")
        
        for i, (rule_name, rule_config) in enumerate(self.metadata.items(), 1):
            print(f"\n[{i}/{len(self.metadata)}] {rule_name}")
            
            analysis = self.process_rule(
                rule_name=rule_name,
                rule_config=rule_config,
                generate_doc=generate_docs
            )
            
            if analysis:
                all_analyses[rule_name] = analysis
            else:
                print(f"âš  Skipped {rule_name}")
        
        if generate_index and all_analyses:
            print(f"\n{'='*80}")
            print(f"Generating Index")
            print(f"{'='*80}")
            
            try:
                index_path = self.generator.create_index_document(all_analyses)
                print(f"âœ“ Index: {index_path}")
            except Exception as e:
                print(f"âœ— Index error: {e}")
        
        # Summary statistics
        print(f"\n{'#'*80}")
        print(f"# Complete")
        print(f"{'#'*80}")
        print(f"Processed: {len(all_analyses)}/{len(self.metadata)} rules")
        print(f"Output: {self.output_dir}")
        print(f"Documents generated: {len(all_analyses)} (ONE per rule)")
        
        total_citations = sum(len(a.get('citations', [])) for a in all_analyses.values())
        print(f"Total Citations: {total_citations}")
        
        total_actions = sum(len(a.get('data_actions', [])) for a in all_analyses.values())
        print(f"Total Data Actions: {total_actions}")
        
        total_machine_readable = sum(
            len(a.get('machine_readable_rules', [])) for a in all_analyses.values()
        )
        print(f"Machine-Readable Rules: {total_machine_readable}")
        
        total_duplicates = sum(
            len(a.get('potential_duplicates', [])) for a in all_analyses.values()
        )
        if total_duplicates > 0:
            print(f"âš  Potential Duplicates Detected: {total_duplicates}")
        
        return all_analyses
    
    def process_single_rule(self, rule_name: str,
                           generate_doc: bool = True) -> Optional[Dict[str, Any]]:
        """Process single rule - ONE document"""
        if rule_name not in self.metadata:
            print(f"Error: Rule '{rule_name}' not found")
            print(f"Available: {', '.join(self.metadata.keys())}")
            return None
        
        return self.process_rule(
            rule_name=rule_name,
            rule_config=self.metadata[rule_name],
            generate_doc=generate_doc
        )


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="Legal Summary Pipeline - ONE document per rule"
    )
    parser.add_argument(
        "--metadata",
        type=str,
        default="config/legislation_metadata.json",
        help="Metadata JSON file"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="output/legal_summaries",
        help="Output directory"
    )
    parser.add_argument(
        "--rule",
        type=str,
        help="Process specific rule"
    )
    parser.add_argument(
        "--no-docs",
        action="store_true",
        help="Skip document generation"
    )
    parser.add_argument(
        "--no-index",
        action="store_true",
        help="Skip index generation"
    )
    
    args = parser.parse_args()
    
    pipeline = LegalSummaryPipeline(
        metadata_file=args.metadata,
        output_dir=args.output
    )
    
    if args.rule:
        pipeline.process_single_rule(
            rule_name=args.rule,
            generate_doc=not args.no_docs
        )
    else:
        pipeline.process_all_rules(
            generate_docs=not args.no_docs,
            generate_index=not args.no_index
        )


if __name__ == "__main__":
    main()
