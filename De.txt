"""
Azure OpenAI service using the official SDK instead of direct HTTP requests.
"""

import os
import logging
import json
import time
from typing import List, Dict, Any, Optional, Union
from dotenv import dotenv_values
from openai import AzureOpenAI
from azure.identity import DefaultAzureCredential, ClientSecretCredential, get_bearer_token_provider

logger = logging.getLogger(__name__)

# Load credentials directly from file
credentials_path = os.path.join("env", "credentials.env")
config_path = os.path.join("env", "config.env")
credentials_values = {}
config_values = {}

try:
    if os.path.isfile(credentials_path):
        logger.info(f"AzureOpenAIService loading credentials from {credentials_path}")
        credentials_values = dotenv_values(credentials_path)
        logger.info(f"Loaded {len(credentials_values)} values from {credentials_path}")
    else:
        logger.warning(f"Credentials file not found: {credentials_path}")
        
    if os.path.isfile(config_path):
        logger.info(f"AzureOpenAIService loading config from {config_path}")
        config_values = dotenv_values(config_path)
        logger.info(f"Loaded {len(config_values)} values from {config_path}")
    else:
        logger.warning(f"Config file not found: {config_path}")
except Exception as e:
    logger.error(f"Error loading env files: {e}")

# Combine values, with credentials taking precedence
all_values = {**config_values, **credentials_values}

# Extract values directly
AZURE_TENANT_ID = all_values.get("AZURE_TENANT_ID", "")
AZURE_CLIENT_ID = all_values.get("AZURE_CLIENT_ID", "")
AZURE_CLIENT_SECRET = all_values.get("AZURE_CLIENT_SECRET", "")
AZURE_OPENAI_ENDPOINT = all_values.get("AZURE_OPENAI_ENDPOINT", "")
AZURE_EMBEDDING_MODEL = all_values.get("AZURE_EMBEDDING_MODEL", "text-embedding-3-large")
AZURE_EMBEDDING_DEPLOYMENT = all_values.get("AZURE_EMBEDDING_DEPLOYMENT", "text-embedding-3-large")
AZURE_LLM_MODEL = all_values.get("AZURE_LLM_MODEL", "gpt-4o-mini")
AZURE_LLM_DEPLOYMENT = all_values.get("AZURE_LLM_DEPLOYMENT", "gpt-4o-mini")

# Log values (masked for security)
if AZURE_TENANT_ID:
    masked_tenant = f"{AZURE_TENANT_ID[:4]}...{AZURE_TENANT_ID[-4:]}" if len(AZURE_TENANT_ID) > 8 else "***"
    logger.info(f"Using Azure tenant ID: {masked_tenant}")
else:
    logger.warning("AZURE_TENANT_ID is missing")

if AZURE_CLIENT_ID:
    masked_client = f"{AZURE_CLIENT_ID[:4]}...{AZURE_CLIENT_ID[-4:]}" if len(AZURE_CLIENT_ID) > 8 else "***"
    logger.info(f"Using Azure client ID: {masked_client}")
else:
    logger.warning("AZURE_CLIENT_ID is missing")

if AZURE_CLIENT_SECRET:
    logger.info(f"Azure client secret is set (length: {len(AZURE_CLIENT_SECRET)} characters)")
else:
    logger.warning("AZURE_CLIENT_SECRET is missing")

logger.info(f"Using Azure OpenAI endpoint: {AZURE_OPENAI_ENDPOINT}")
logger.info(f"Using embedding model: {AZURE_EMBEDDING_MODEL}, deployment: {AZURE_EMBEDDING_DEPLOYMENT}")
logger.info(f"Using LLM model: {AZURE_LLM_MODEL}, deployment: {AZURE_LLM_DEPLOYMENT}")

class AzureOpenAIService:
    """Service for interacting with Azure OpenAI models using the official SDK."""
    
    def __init__(self):
        """Initialize the Azure OpenAI service."""
        self.tenant_id = AZURE_TENANT_ID
        self.client_id = AZURE_CLIENT_ID
        self.client_secret = AZURE_CLIENT_SECRET
        self.endpoint = AZURE_OPENAI_ENDPOINT
        self.embedding_model = AZURE_EMBEDDING_MODEL
        self.embedding_deployment = AZURE_EMBEDDING_DEPLOYMENT
        self.llm_model = AZURE_LLM_MODEL
        self.llm_deployment = AZURE_LLM_DEPLOYMENT
        self.api_version = "2023-05-15"
        
        # Show the actual values being used (partially masked for security)
        masked_tenant = f"{self.tenant_id[:4]}...{self.tenant_id[-4:]}" if len(self.tenant_id) > 8 else "***"
        masked_client = f"{self.client_id[:4]}...{self.client_id[-4:]}" if len(self.client_id) > 8 else "***"
        logger.info(f"AzureOpenAIService initialized with:")
        logger.info(f"  - Tenant ID: {masked_tenant}")
        logger.info(f"  - Client ID: {masked_client}") 
        logger.info(f"  - Client secret length: {len(self.client_secret)} characters")
        logger.info(f"  - OpenAI endpoint: {self.endpoint}")
        
        # Initialize the Azure OpenAI client
        self._initialize_client()
        logger.info(f"AzureOpenAIService initialized successfully")
    
    def _initialize_client(self):
        """Initialize the Azure OpenAI client using Azure AD credentials."""
        try:
            # Create credentials
            credential = ClientSecretCredential(
                tenant_id=self.tenant_id,
                client_id=self.client_id,
                client_secret=self.client_secret
            )
            
            # Get token provider
            token_provider = get_bearer_token_provider(
                credential,
                "https://cognitiveservices.azure.com/.default"
            )
            
            # Initialize the client with token provider
            self.client = AzureOpenAI(
                azure_endpoint=self.endpoint,
                api_version=self.api_version,
                azure_ad_token_provider=token_provider
            )
            
            logger.info("Azure OpenAI client initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Azure OpenAI client: {e}")
            raise
    
    def refresh_tokens(self):
        """Refresh the Azure tokens by reinitializing the client."""
        try:
            logger.info("Refreshing Azure AD token by reinitializing the client...")
            self._initialize_client()
            logger.info("Azure OpenAI client reinitialized with fresh token")
            return True
        except Exception as e:
            logger.error(f"Failed to refresh Azure OpenAI token: {e}")
            return False
    
    async def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generate embeddings for a list of texts using Azure OpenAI SDK.
        
        Args:
            texts: List of texts to embed
            
        Returns:
            List of embedding vectors
        """
        try:
            # Return empty list if no texts provided
            if not texts:
                return []
                
            # Batch the requests to avoid overloading the API
            # Process in chunks of 20 texts at a time
            batch_size = 20
            all_embeddings = []
            
            for i in range(0, len(texts), batch_size):
                batch_texts = texts[i:i+batch_size]
                
                try:
                    # Generate embeddings for the batch
                    response = self.client.embeddings.create(
                        input=batch_texts,
                        model=self.embedding_deployment,
                        dimensions=3072  # Maximum dimensions for text-embedding-3-large
                    )
                    
                    # Extract embeddings from response
                    batch_embeddings = [item.embedding for item in response.data]
                    all_embeddings.extend(batch_embeddings)
                    logger.debug(f"Generated embeddings for batch of {len(batch_texts)} texts")
                    
                except Exception as e:
                    logger.error(f"Error generating embeddings for batch: {e}")
                    # Try to refresh token and retry once
                    if "authentication" in str(e).lower() or "unauthorized" in str(e).lower():
                        logger.info("Authentication error, attempting to refresh token...")
                        if self.refresh_tokens():
                            # Retry the request
                            response = self.client.embeddings.create(
                                input=batch_texts,
                                model=self.embedding_deployment,
                                dimensions=3072
                            )
                            batch_embeddings = [item.embedding for item in response.data]
                            all_embeddings.extend(batch_embeddings)
                            logger.debug(f"Generated embeddings for batch of {len(batch_texts)} texts after token refresh")
                        else:
                            raise Exception("Failed to refresh token after authentication error")
                    else:
                        raise
                
                # Add a small delay between batches to avoid rate limiting
                if i + batch_size < len(texts):
                    time.sleep(0.5)
            
            return all_embeddings
            
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            raise
    
    async def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embeddings for a single text using Azure OpenAI SDK.
        
        Args:
            text: Text to embed
            
        Returns:
            Embedding vector
        """
        try:
            # Generate embedding
            response = self.client.embeddings.create(
                input=text,
                model=self.embedding_deployment,
                dimensions=3072  # Maximum dimensions for text-embedding-3-large
            )
            
            # Extract embedding from response
            embedding = response.data[0].embedding
            return embedding
            
        except Exception as e:
            logger.error(f"Error generating single embedding: {e}")
            
            # Try to refresh token and retry once
            if "authentication" in str(e).lower() or "unauthorized" in str(e).lower():
                logger.info("Authentication error, attempting to refresh token...")
                if self.refresh_tokens():
                    # Retry the request
                    response = self.client.embeddings.create(
                        input=text,
                        model=self.embedding_deployment,
                        dimensions=3072
                    )
                    embedding = response.data[0].embedding
                    return embedding
                else:
                    raise Exception("Failed to refresh token after authentication error")
            else:
                raise
    
    async def generate_completion(self, 
                                messages: List[Dict[str, str]], 
                                temperature: float = 0.0,
                                max_tokens: int = 2000) -> str:
        """
        Generate a completion using Azure OpenAI SDK.
        
        Args:
            messages: List of messages (system, user, assistant)
            temperature: Temperature for generation
            max_tokens: Maximum tokens to generate
            
        Returns:
            Generated text
        """
        try:
            # Generate completion
            response = self.client.chat.completions.create(
                model=self.llm_deployment,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            # Extract content from response
            content = response.choices[0].message.content
            return content
            
        except Exception as e:
            logger.error(f"Error generating completion: {e}")
            
            # Try to refresh token and retry once
            if "authentication" in str(e).lower() or "unauthorized" in str(e).lower():
                logger.info("Authentication error, attempting to refresh token...")
                if self.refresh_tokens():
                    # Retry the request
                    response = self.client.chat.completions.create(
                        model=self.llm_deployment,
                        messages=messages,
                        temperature=temperature,
                        max_tokens=max_tokens
                    )
                    content = response.choices[0].message.content
                    return content
                else:
                    raise Exception("Failed to refresh token after authentication error")
            else:
                raise
