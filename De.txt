#!/usr/bin/env python3
"""
JSON-LD Ontology Schema Extractor

This script extracts ONLY the ontology schema/structure from JSON-LD files:
- Classes and their hierarchies
- Properties and their characteristics
- Domains, ranges, restrictions
- Ontology metadata

IGNORES instance data (individuals and their property values)
Focus: Extract the "TBox" (terminological knowledge) not "ABox" (assertions)
"""

import json
import sys
import os
from typing import Dict, List, Set, Any, Union
from collections import defaultdict
from datetime import datetime

# Try to import rdflib for better RDF handling
try:
    from rdflib import Graph, RDF, RDFS, OWL, URIRef
    RDFLIB_AVAILABLE = True
except ImportError:
    RDFLIB_AVAILABLE = False


class OntologySchemaExtractor:
    def __init__(self, debug=True):
        self.debug = debug
        
        # ONTOLOGY STRUCTURE ONLY (no instances)
        self.classes = set()                              # owl:Class, rdfs:Class
        self.object_properties = set()                    # owl:ObjectProperty
        self.data_properties = set()                      # owl:DatatypeProperty
        self.annotation_properties = set()               # owl:AnnotationProperty
        
        # CLASS RELATIONSHIPS
        self.subclass_relationships = []                  # rdfs:subClassOf
        self.equivalent_classes = []                      # owl:equivalentClass
        self.disjoint_classes = []                        # owl:disjointWith
        self.class_unions = []                           # owl:unionOf
        self.class_intersections = []                    # owl:intersectionOf
        
        # PROPERTY RELATIONSHIPS  
        self.subproperty_relationships = []              # rdfs:subPropertyOf
        self.equivalent_properties = []                  # owl:equivalentProperty
        self.inverse_properties = []                     # owl:inverseOf
        
        # PROPERTY CHARACTERISTICS
        self.functional_properties = set()               # owl:FunctionalProperty
        self.inverse_functional_properties = set()       # owl:InverseFunctionalProperty
        self.transitive_properties = set()              # owl:TransitiveProperty
        self.symmetric_properties = set()               # owl:SymmetricProperty
        self.asymmetric_properties = set()              # owl:AsymmetricProperty
        self.reflexive_properties = set()               # owl:ReflexiveProperty
        self.irreflexive_properties = set()             # owl:IrreflexiveProperty
        
        # PROPERTY DOMAINS AND RANGES
        self.property_domains = defaultdict(set)         # rdfs:domain
        self.property_ranges = defaultdict(set)          # rdfs:range
        
        # RESTRICTIONS AND CONSTRAINTS
        self.cardinality_restrictions = []               # owl:cardinality, owl:minCardinality, etc.
        self.value_restrictions = []                     # owl:someValuesFrom, owl:allValuesFrom
        self.has_value_restrictions = []                 # owl:hasValue
        
        # ONTOLOGY METADATA
        self.ontology_iri = None                         # Ontology IRI
        self.ontology_version = None                     # owl:versionIRI
        self.imports = []                                # owl:imports
        self.labels = {}                                 # rdfs:label
        self.comments = {}                               # rdfs:comment
        self.definitions = {}                            # Custom definition properties
        self.namespaces = {}                             # Namespace prefixes
        
        # For rdflib processing
        self.graph = None
        
        # Track what we're ignoring (for reporting)
        self.ignored_individuals = 0
        self.ignored_assertions = 0
        
    def log(self, message):
        """Debug logging"""
        if self.debug:
            print(f"[SCHEMA] {message}")
    
    def extract_schema_from_file(self, file_path: str, method: str = "auto"):
        """Extract ontology schema from JSON-LD file"""
        self.log(f"Extracting SCHEMA ONLY from: {file_path}")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # Determine method
        if method == "auto":
            method = "rdflib" if RDFLIB_AVAILABLE else "json"
        
        self.log(f"Using method: {method}")
        
        if method == "rdflib" and RDFLIB_AVAILABLE:
            return self._extract_with_rdflib(file_path)
        else:
            return self._extract_with_json(file_path)
    
    def _extract_with_rdflib(self, file_path: str):
        """Extract schema using rdflib with SPARQL queries"""
        try:
            self.log("Loading graph with rdflib...")
            self.graph = Graph()
            self.graph.parse(file_path, format='json-ld')
            
            self.log(f"Graph loaded with {len(self.graph)} triples")
            
            # Extract namespaces
            for prefix, namespace in self.graph.namespaces():
                self.namespaces[str(prefix)] = str(namespace)
            
            # Extract ontology metadata
            self._extract_ontology_metadata()
            
            # Extract schema elements using SPARQL
            self._extract_schema_with_sparql()
            
            self.log(f"Schema extraction complete - found {len(self.classes)} classes, {len(self.object_properties)} object properties")
            return True
            
        except Exception as e:
            self.log(f"rdflib extraction failed: {e}")
            return self._extract_with_json(file_path)
    
    def _extract_ontology_metadata(self):
        """Extract ontology-level metadata"""
        # Find ontology declaration
        ontology_query = """
        SELECT DISTINCT ?ontology ?version WHERE {
            { ?ontology a owl:Ontology . }
            OPTIONAL { ?ontology owl:versionIRI ?version . }
        }
        """
        try:
            results = self.graph.query(ontology_query)
            for row in results:
                self.ontology_iri = str(row.ontology) if row.ontology else None
                self.ontology_version = str(row.version) if row.version else None
                break
            
            if self.ontology_iri:
                self.log(f"Found ontology: {self.ontology_iri}")
                
                # Extract imports
                imports_query = f"""
                SELECT DISTINCT ?import WHERE {{
                    <{self.ontology_iri}> owl:imports ?import .
                }}
                """
                import_results = self.graph.query(imports_query)
                for row in import_results:
                    self.imports.append(str(row.import))
                    
        except Exception as e:
            self.log(f"Failed to extract ontology metadata: {e}")
    
    def _extract_schema_with_sparql(self):
        """Extract schema elements using SPARQL queries"""
        
        # 1. EXTRACT CLASSES
        classes_query = """
        SELECT DISTINCT ?class WHERE {
            { ?class a owl:Class } UNION { ?class a rdfs:Class }
            # Exclude blank nodes and complex class expressions for now
            FILTER(isURI(?class))
        }
        """
        results = self.graph.query(classes_query)
        for row in results:
            self.classes.add(str(row.class))
        self.log(f"Found {len(self.classes)} classes")
        
        # 2. EXTRACT PROPERTIES
        obj_props_query = """
        SELECT DISTINCT ?prop WHERE {
            ?prop a owl:ObjectProperty .
            FILTER(isURI(?prop))
        }
        """
        results = self.graph.query(obj_props_query)
        for row in results:
            self.object_properties.add(str(row.prop))
        
        data_props_query = """
        SELECT DISTINCT ?prop WHERE {
            ?prop a owl:DatatypeProperty .
            FILTER(isURI(?prop))
        }
        """
        results = self.graph.query(data_props_query)
        for row in results:
            self.data_properties.add(str(row.prop))
        
        annotation_props_query = """
        SELECT DISTINCT ?prop WHERE {
            ?prop a owl:AnnotationProperty .
            FILTER(isURI(?prop))
        }
        """
        results = self.graph.query(annotation_props_query)
        for row in results:
            self.annotation_properties.add(str(row.prop))
            
        self.log(f"Found {len(self.object_properties)} object properties, {len(self.data_properties)} data properties")
        
        # 3. EXTRACT RELATIONSHIPS
        self._extract_relationships_sparql()
        
        # 4. EXTRACT PROPERTY CHARACTERISTICS
        self._extract_property_characteristics_sparql()
        
        # 5. EXTRACT DOMAINS AND RANGES
        self._extract_domains_ranges_sparql()
        
        # 6. EXTRACT ANNOTATIONS (labels, comments)
        self._extract_schema_annotations_sparql()
        
        # 7. COUNT IGNORED INSTANCES (for reporting)
        self._count_ignored_instances()
    
    def _extract_relationships_sparql(self):
        """Extract class and property relationships"""
        
        # Subclass relationships
        subclass_query = """
        SELECT DISTINCT ?sub ?super WHERE {
            ?sub rdfs:subClassOf ?super .
            FILTER(isURI(?sub) && isURI(?super))
            FILTER(?sub != ?super)
        }
        """
        results = self.graph.query(subclass_query)
        for row in results:
            self.subclass_relationships.append((str(row.sub), str(row.super)))
        
        # Equivalent classes
        equiv_class_query = """
        SELECT DISTINCT ?class1 ?class2 WHERE {
            ?class1 owl:equivalentClass ?class2 .
            FILTER(isURI(?class1) && isURI(?class2))
        }
        """
        results = self.graph.query(equiv_class_query)
        for row in results:
            self.equivalent_classes.append((str(row.class1), str(row.class2)))
        
        # Disjoint classes
        disjoint_query = """
        SELECT DISTINCT ?class1 ?class2 WHERE {
            ?class1 owl:disjointWith ?class2 .
            FILTER(isURI(?class1) && isURI(?class2))
        }
        """
        results = self.graph.query(disjoint_query)
        for row in results:
            self.disjoint_classes.append((str(row.class1), str(row.class2)))
        
        # Subproperty relationships
        subprop_query = """
        SELECT DISTINCT ?sub ?super WHERE {
            ?sub rdfs:subPropertyOf ?super .
            FILTER(isURI(?sub) && isURI(?super))
            FILTER(?sub != ?super)
        }
        """
        results = self.graph.query(subprop_query)
        for row in results:
            self.subproperty_relationships.append((str(row.sub), str(row.super)))
        
        # Inverse properties
        inverse_query = """
        SELECT DISTINCT ?prop1 ?prop2 WHERE {
            ?prop1 owl:inverseOf ?prop2 .
            FILTER(isURI(?prop1) && isURI(?prop2))
        }
        """
        results = self.graph.query(inverse_query)
        for row in results:
            self.inverse_properties.append((str(row.prop1), str(row.prop2)))
        
        self.log(f"Found {len(self.subclass_relationships)} subclass relationships")
    
    def _extract_property_characteristics_sparql(self):
        """Extract property characteristics"""
        
        characteristics = {
            'functional': (self.functional_properties, "owl:FunctionalProperty"),
            'inverse_functional': (self.inverse_functional_properties, "owl:InverseFunctionalProperty"),
            'transitive': (self.transitive_properties, "owl:TransitiveProperty"),
            'symmetric': (self.symmetric_properties, "owl:SymmetricProperty"),
            'asymmetric': (self.asymmetric_properties, "owl:AsymmetricProperty"),
            'reflexive': (self.reflexive_properties, "owl:ReflexiveProperty"),
            'irreflexive': (self.irreflexive_properties, "owl:IrreflexiveProperty")
        }
        
        for char_name, (target_set, owl_type) in characteristics.items():
            query = f"""
            SELECT DISTINCT ?prop WHERE {{
                ?prop a {owl_type} .
                FILTER(isURI(?prop))
            }}
            """
            results = self.graph.query(query)
            for row in results:
                target_set.add(str(row.prop))
        
        total_chars = sum(len(s) for s, _ in characteristics.values())
        self.log(f"Found {total_chars} property characteristics")
    
    def _extract_domains_ranges_sparql(self):
        """Extract property domains and ranges"""
        
        # Domains
        domain_query = """
        SELECT DISTINCT ?prop ?domain WHERE {
            ?prop rdfs:domain ?domain .
            FILTER(isURI(?prop) && isURI(?domain))
        }
        """
        results = self.graph.query(domain_query)
        for row in results:
            self.property_domains[str(row.prop)].add(str(row.domain))
        
        # Ranges
        range_query = """
        SELECT DISTINCT ?prop ?range WHERE {
            ?prop rdfs:range ?range .
            FILTER(isURI(?prop))
        }
        """
        results = self.graph.query(range_query)
        for row in results:
            self.property_ranges[str(row.prop)].add(str(row.range))
        
        self.log(f"Found domains for {len(self.property_domains)} properties")
    
    def _extract_schema_annotations_sparql(self):
        """Extract labels and comments for schema elements only"""
        
        # Get all schema elements
        schema_elements = self.classes.union(self.object_properties).union(self.data_properties).union(self.annotation_properties)
        
        if schema_elements:
            # Labels
            for element in schema_elements:
                label_query = f"""
                SELECT DISTINCT ?label WHERE {{
                    <{element}> rdfs:label ?label .
                }}
                """
                results = self.graph.query(label_query)
                for row in results:
                    self.labels[element] = str(row.label)
                    break  # Take first label
            
            # Comments
            for element in schema_elements:
                comment_query = f"""
                SELECT DISTINCT ?comment WHERE {{
                    <{element}> rdfs:comment ?comment .
                }}
                """
                results = self.graph.query(comment_query)
                for row in results:
                    self.comments[element] = str(row.comment)
                    break  # Take first comment
        
        self.log(f"Found {len(self.labels)} labels and {len(self.comments)} comments for schema elements")
    
    def _count_ignored_instances(self):
        """Count how many instances we're ignoring (for reporting)"""
        
        # Count individuals (instances that are not schema elements)
        individuals_query = """
        SELECT DISTINCT ?individual WHERE {
            ?individual a ?type .
            FILTER(isURI(?individual))
            FILTER(?type != owl:Class && ?type != rdfs:Class && 
                   ?type != owl:ObjectProperty && ?type != owl:DatatypeProperty &&
                   ?type != owl:AnnotationProperty && ?type != owl:Ontology)
        }
        """
        try:
            results = self.graph.query(individuals_query)
            self.ignored_individuals = len(list(results))
        except:
            self.ignored_individuals = 0
        
        self.log(f"Ignored {self.ignored_individuals} individuals (instance data)")
    
    def _extract_with_json(self, file_path: str):
        """Extract schema using JSON parsing"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Extract context/namespaces
            if isinstance(data, dict) and '@context' in data:
                context = data['@context']
                if isinstance(context, dict):
                    self.namespaces.update({k: v for k, v in context.items() if isinstance(v, str)})
            
            # Get items to process
            items = self._get_items_from_data(data)
            self.log(f"Processing {len(items)} items for schema extraction")
            
            # Process each item - SCHEMA ONLY
            for item in items:
                self._process_schema_item(item)
            
            self.log(f"JSON schema extraction complete - {len(self.classes)} classes, {len(self.object_properties)} object properties")
            return True
            
        except Exception as e:
            self.log(f"JSON extraction failed: {e}")
            raise
    
    def _get_items_from_data(self, data):
        """Extract items from various JSON-LD structures"""
        if isinstance(data, list):
            return data
        elif isinstance(data, dict):
            if '@graph' in data:
                return data['@graph'] if isinstance(data['@graph'], list) else [data['@graph']]
            else:
                return [data]
        return []
    
    def _process_schema_item(self, item):
        """Process item - EXTRACT ONLY SCHEMA ELEMENTS"""
        if not isinstance(item, dict):
            return
        
        item_id = item.get('@id', '')
        item_types = item.get('@type', [])
        
        if isinstance(item_types, str):
            item_types = [item_types]
        
        # CHECK IF THIS IS A SCHEMA ELEMENT (not an instance)
        schema_indicators = [
            'owl:Class', 'rdfs:Class', 'Class',
            'owl:ObjectProperty', 'ObjectProperty',
            'owl:DatatypeProperty', 'DatatypeProperty', 
            'owl:AnnotationProperty', 'AnnotationProperty',
            'owl:FunctionalProperty', 'owl:TransitiveProperty', 'owl:SymmetricProperty',
            'owl:Ontology'
        ]
        
        is_schema_element = any(t in schema_indicators for t in item_types)
        
        if not is_schema_element:
            # This is likely an instance - ignore it
            self.ignored_individuals += 1
            if self.ignored_individuals <= 5:  # Log first few
                self.log(f"IGNORING individual: {item_id} (type: {item_types})")
            return
        
        # EXTRACT SCHEMA ELEMENTS
        # Classes
        if any(t in ['owl:Class', 'rdfs:Class', 'Class'] for t in item_types):
            self.classes.add(item_id)
            self.log(f"Found class: {item_id}")
        
        # Properties
        if any(t in ['owl:ObjectProperty', 'ObjectProperty'] for t in item_types):
            self.object_properties.add(item_id)
        
        if any(t in ['owl:DatatypeProperty', 'DatatypeProperty'] for t in item_types):
            self.data_properties.add(item_id)
        
        if any(t in ['owl:AnnotationProperty', 'AnnotationProperty'] for t in item_types):
            self.annotation_properties.add(item_id)
        
        # Property characteristics
        if 'owl:FunctionalProperty' in item_types:
            self.functional_properties.add(item_id)
        if 'owl:TransitiveProperty' in item_types:
            self.transitive_properties.add(item_id)
        if 'owl:SymmetricProperty' in item_types:
            self.symmetric_properties.add(item_id)
        
        # Relationships
        if 'rdfs:subClassOf' in item:
            parent = self._extract_id_from_value(item['rdfs:subClassOf'])
            if parent:
                self.subclass_relationships.append((item_id, parent))
        
        if 'rdfs:subPropertyOf' in item:
            parent = self._extract_id_from_value(item['rdfs:subPropertyOf'])
            if parent:
                self.subproperty_relationships.append((item_id, parent))
        
        # Domains and ranges
        if 'rdfs:domain' in item:
            domain = self._extract_id_from_value(item['rdfs:domain'])
            if domain:
                self.property_domains[item_id].add(domain)
        
        if 'rdfs:range' in item:
            range_val = self._extract_id_from_value(item['rdfs:range'])
            if range_val:
                self.property_ranges[item_id].add(range_val)
        
        # Annotations (for schema elements only)
        if 'rdfs:label' in item:
            label = self._extract_literal_value(item['rdfs:label'])
            if label:
                self.labels[item_id] = label
        
        if 'rdfs:comment' in item:
            comment = self._extract_literal_value(item['rdfs:comment'])
            if comment:
                self.comments[item_id] = comment
        
        # Ontology metadata
        if 'owl:Ontology' in item_types:
            self.ontology_iri = item_id
            if 'owl:imports' in item:
                imports = item['owl:imports']
                if isinstance(imports, list):
                    for imp in imports:
                        import_iri = self._extract_id_from_value(imp)
                        if import_iri:
                            self.imports.append(import_iri)
                else:
                    import_iri = self._extract_id_from_value(imports)
                    if import_iri:
                        self.imports.append(import_iri)
    
    def _extract_id_from_value(self, value):
        """Extract @id from various JSON-LD structures"""
        if isinstance(value, str):
            return value
        elif isinstance(value, dict) and '@id' in value:
            return value['@id']
        elif isinstance(value, list) and len(value) > 0:
            return self._extract_id_from_value(value[0])
        return None
    
    def _extract_literal_value(self, value):
        """Extract literal value from JSON-LD"""
        if isinstance(value, str):
            return value
        elif isinstance(value, dict):
            if '@value' in value:
                return value['@value']
            elif '@id' in value:
                return value['@id']
        elif isinstance(value, list) and len(value) > 0:
            return self._extract_literal_value(value[0])
        return None
    
    def print_schema_summary(self):
        """Print comprehensive schema summary"""
        print("=" * 70)
        print("🏗️  ONTOLOGY SCHEMA EXTRACTION RESULTS")
        print("=" * 70)
        
        # Ontology metadata
        if self.ontology_iri:
            print(f"📋 ONTOLOGY: {self.ontology_iri}")
            if self.ontology_version:
                print(f"   Version: {self.ontology_version}")
            if self.imports:
                print(f"   Imports: {len(self.imports)} ontologies")
                for imp in self.imports[:3]:  # Show first 3
                    print(f"     • {imp}")
                if len(self.imports) > 3:
                    print(f"     ... and {len(self.imports) - 3} more")
            print()
        
        # Namespaces
        if self.namespaces:
            print(f"🌐 NAMESPACES ({len(self.namespaces)}):")
            for prefix, uri in sorted(self.namespaces.items()):
                print(f"  @prefix {prefix}: <{uri}>")
            print()
        
        # Classes
        print(f"📁 CLASSES ({len(self.classes)}):")
        for cls in sorted(self.classes):
            print(f"  • {cls}")
            if cls in self.labels:
                print(f"    📝 {self.labels[cls]}")
            if cls in self.comments:
                print(f"    💭 {self.comments[cls]}")
        print()
        
        # Class hierarchy
        if self.subclass_relationships:
            print(f"🏗️  CLASS HIERARCHY ({len(self.subclass_relationships)} relationships):")
            # Group by parent
            hierarchy = defaultdict(list)
            for child, parent in self.subclass_relationships:
                hierarchy[parent].append(child)
            
            for parent in sorted(hierarchy.keys()):
                print(f"  📁 {parent}")
                for child in sorted(hierarchy[parent]):
                    print(f"    └── {child}")
            print()
        
        # Properties
        print(f"🔗 OBJECT PROPERTIES ({len(self.object_properties)}):")
        for prop in sorted(self.object_properties):
            print(f"  • {prop}")
            if prop in self.labels:
                print(f"    📝 {self.labels[prop]}")
            
            details = []
            if prop in self.property_domains:
                domains = ", ".join(sorted(self.property_domains[prop]))
                details.append(f"Domain: {domains}")
            if prop in self.property_ranges:
                ranges = ", ".join(sorted(self.property_ranges[prop]))
                details.append(f"Range: {ranges}")
            
            characteristics = []
            if prop in self.functional_properties:
                characteristics.append("Functional")
            if prop in self.transitive_properties:
                characteristics.append("Transitive")  
            if prop in self.symmetric_properties:
                characteristics.append("Symmetric")
            if characteristics:
                details.append(f"Characteristics: {', '.join(characteristics)}")
            
            for detail in details:
                print(f"    🎯 {detail}")
        print()
        
        print(f"📊 DATA PROPERTIES ({len(self.data_properties)}):")
        for prop in sorted(self.data_properties):
            print(f"  • {prop}")
            if prop in self.labels:
                print(f"    📝 {self.labels[prop]}")
            if prop in self.property_domains:
                domains = ", ".join(sorted(self.property_domains[prop]))
                print(f"    🎯 Domain: {domains}")
            if prop in self.property_ranges:
                ranges = ", ".join(sorted(self.property_ranges[prop]))
                print(f"    🎯 Range: {ranges}")
        print()
        
        # Relationships summary
        if any([self.equivalent_classes, self.disjoint_classes, self.inverse_properties]):
            print("🔄 ADDITIONAL RELATIONSHIPS:")
            if self.equivalent_classes:
                print(f"  ≡ Equivalent classes: {len(self.equivalent_classes)}")
            if self.disjoint_classes:
                print(f"  ⊥ Disjoint classes: {len(self.disjoint_classes)}")
            if self.inverse_properties:
                print(f"  ↔ Inverse properties: {len(self.inverse_properties)}")
            print()
        
        # Summary statistics
        print("📈 SCHEMA STATISTICS:")
        total_classes = len(self.classes)
        total_properties = len(self.object_properties) + len(self.data_properties) + len(self.annotation_properties)
        total_relationships = len(self.subclass_relationships) + len(self.subproperty_relationships)
        
        print(f"  • Classes: {total_classes}")
        print(f"  • Properties: {total_properties}")
        print(f"    - Object: {len(self.object_properties)}")
        print(f"    - Data: {len(self.data_properties)}")
        print(f"    - Annotation: {len(self.annotation_properties)}")
        print(f"  • Hierarchical relationships: {total_relationships}")
        print(f"  • Annotations: {len(self.labels)} labels, {len(self.comments)} comments")
        
        if self.ignored_individuals > 0:
            print(f"  • Ignored instances: {self.ignored_individuals} (not part of schema)")
        
        print()
        return total_classes + total_properties > 0
    
    def save_schema_as_ttl(self, output_file: str):
        """Save extracted schema as TTL"""
        try:
            if self.graph and RDFLIB_AVAILABLE:
                # Create a new graph with only schema elements
                schema_graph = Graph()
                
                # Copy namespaces
                for prefix, uri in self.namespaces.items():
                    schema_graph.bind(prefix, uri)
                
                # Add only schema triples
                self._add_schema_triples_to_graph(schema_graph)
                
                # Serialize
                ttl_content = schema_graph.serialize(format='turtle')
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(ttl_content)
            else:
                # Manual TTL creation
                self._create_schema_ttl_manually(output_file)
            
            self.log(f"✅ Schema TTL saved to: {output_file}")
            return True
            
        except Exception as e:
            self.log(f"❌ Failed to save schema TTL: {e}")
            return False
    
    def _add_schema_triples_to_graph(self, schema_graph):
        """Add only schema triples to the new graph"""
        if not self.graph:
            return
        
        # Add all triples for schema elements
        schema_elements = self.classes.union(self.object_properties).union(self.data_properties).union(self.annotation_properties)
        
        if self.ontology_iri:
            schema_elements.add(self.ontology_iri)
        
        for element in schema_elements:
            element_uri = URIRef(element)
            # Add all triples where this element is the subject
            for p, o in self.graph.predicate_objects(element_uri):
                schema_graph.add((element_uri, p, o))
    
    def _create_schema_ttl_manually(self, output_file: str):
        """Create schema TTL manually"""
        with open(output_file, 'w', encoding='utf-8') as f:
            # Header
            f.write(f"# Ontology Schema extracted on {datetime.now().isoformat()}\n")
            f.write("# Contains ONLY schema elements (classes, properties, relationships)\n")
            f.write("# Instance data has been excluded\n\n")
            
            # Prefixes
            f.write("@prefix owl: <http://www.w3.org/2002/07/owl#> .\n")
            f.write("@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n")
            f.write("@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n")
            f.write("@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n")
            
            for prefix, uri in self.namespaces.items():
                if prefix not in ['owl', 'rdf', 'rdfs', 'xsd']:
                    f.write(f"@prefix {prefix}: <{uri}> .\n")
            f.write("\n")
            
            # Ontology declaration
            if self.ontology_iri:
                f.write("# === ONTOLOGY METADATA ===\n")
                f.write(f"<{self.ontology_iri}> rdf:type owl:Ontology .\n")
                if self.ontology_version:
                    f.write(f"<{self.ontology_iri}> owl:versionIRI <{self.ontology_version}> .\n")
                for imp in self.imports:
                    f.write(f"<{self.ontology_iri}> owl:imports <{imp}> .\n")
                f.write("\n")
            
            # Classes
            if self.classes:
                f.write("# === CLASSES ===\n")
                for cls in sorted(self.classes):
                    f.write(f"<{cls}> rdf:type owl:Class .\n")
                    if cls in self.labels:
                        f.write(f"<{cls}> rdfs:label \"{self._escape_literal(self.labels[cls])}\" .\n")
                    if cls in self.comments:
                        f.write(f"<{cls}> rdfs:comment \"{self._escape_literal(self.comments[cls])}\" .\n")
                    f.write("\n")
            
            # Class relationships
            if self.subclass_relationships:
                f.write("# === CLASS HIERARCHY ===\n")
                for child, parent in sorted(self.subclass_relationships):
                    f.write(f"<{child}> rdfs:subClassOf <{parent}> .\n")
                f.write("\n")
            
            # Object properties
            if self.object_properties:
                f.write("# === OBJECT PROPERTIES ===\n")
                for prop in sorted(self.object_properties):
                    f.write(f"<{prop}> rdf:type owl:ObjectProperty .\n")
                    self._write_property_schema_ttl(f, prop)
                f.write("\n")
            
            # Data properties
            if self.data_properties:
                f.write("# === DATA PROPERTIES ===\n")
                for prop in sorted(self.data_properties):
                    f.write(f"<{prop}> rdf:type owl:DatatypeProperty .\n")
                    self._write_property_schema_ttl(f, prop)
                f.write("\n")
    
    def _write_property_schema_ttl(self, f, prop):
        """Write property schema details to TTL"""
        if prop in self.labels:
            f.write(f"<{prop}> rdfs:label \"{self._escape_literal(self.labels[prop])}\" .\n")
        if prop in self.comments:
            f.write(f"<{prop}> rdfs:comment \"{self._escape_literal(self.comments[prop])}\" .\n")
        
        for domain in sorted(self.property_domains.get(prop, [])):
            f.write(f"<{prop}> rdfs:domain <{domain}> .\n")
        for range_val in sorted(self.property_ranges.get(prop, [])):
            f.write(f"<{prop}> rdfs:range <{range_val}> .\n")
        
        # Property characteristics
        if prop in self.functional_properties:
            f.write(f"<{prop}> rdf:type owl:FunctionalProperty .\n")
        if prop in self.transitive_properties:
            f.write(f"<{prop}> rdf:type owl:TransitiveProperty .\n")
        if prop in self.symmetric_properties:
            f.write(f"<{prop}> rdf:type owl:SymmetricProperty .\n")
        
        f.write("\n")
    
    def _escape_literal(self, literal):
        """Escape literal values for TTL"""
        return literal.replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n')


def main():
    """Main CLI function"""
    if len(sys.argv) < 2:
        print("Usage: python schema_extractor.py <jsonld_file> [options]")
        print("\nOntology Schema Extractor - extracts ONLY schema/structure, ignores instance data")
        print("\nOptions:")
        print("  --ttl <file>       Save schema as TTL file")
        print("  --json <file>      Save schema as JSON file")
        print("  --method <method>  Use 'rdflib' or 'json' (default: auto)")
        print("  --quiet            Suppress debug output")
        print("  --no-summary       Don't print schema summary")
        print("\nExample:")
        print("  python schema_extractor.py ontology.jsonld --ttl schema.ttl")
        sys.exit(1)
    
    # Parse arguments
    file_path = sys.argv[1]
    ttl_output = None
    json_output = None
    method = "auto"
    quiet = False
    show_summary = True
    
    i = 2
    while i < len(sys.argv):
        arg = sys.argv[i]
        if arg == '--ttl' and i + 1 < len(sys.argv):
            ttl_output = sys.argv[i + 1]
            i += 2
        elif arg == '--json' and i + 1 < len(sys.argv):
            json_output = sys.argv[i + 1]
            i += 2
        elif arg == '--method' and i + 1 < len(sys.argv):
            method = sys.argv[i + 1]
            i += 2
        elif arg == '--quiet':
            quiet = True
            i += 1
        elif arg == '--no-summary':
            show_summary = False
            i += 1
        else:
            i += 1
    
    # Run schema extraction
    try:
        extractor = OntologySchemaExtractor(debug=not quiet)
        
        print(f"🏗️  Extracting SCHEMA ONLY from: {file_path}")
        print("   (ignoring instance data)")
        
        success = extractor.extract_schema_from_file(file_path, method)
        
        if not success:
            print("❌ Schema extraction failed")
            sys.exit(1)
        
        # Print schema summary
        if show_summary:
            found_schema = extractor.print_schema_summary()
            if not found_schema:
                print("⚠️  Warning: No schema elements found!")
        
        # Save outputs
        if ttl_output:
            if extractor.save_schema_as_ttl(ttl_output):
                print(f"✅ Schema TTL saved to: {ttl_output}")
            else:
                print("❌ Failed to save schema TTL")
        
        if json_output:
            # Save schema as JSON (implement if needed)
            print("JSON export not yet implemented for schema")
        
        if not ttl_output and not json_output:
            print("💡 Add --ttl <file> to save the extracted schema")
            
    except Exception as e:
        print(f"❌ Error: {e}")
        if not quiet:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
