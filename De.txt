"""
LangGraph-based Legislation to Machine-Readable JSON Rules Converter
Enhanced with Chain of Thought, Mixture of Thought, and Mixture of Reasoning
Focused on Data Governance Rules (Usage, Transfer, Storage, Access)
"""

import json
import re
import asyncio
from typing import List, Dict, Any, Optional, Annotated, Sequence, TypedDict, Literal
from enum import Enum

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field


# ========================= State Management =========================

class AgentState(TypedDict):
    """Comprehensive state for the legislation processing agent with reasoning traces"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    legislation_text: str
    # Mixture of Thought - Multiple reasoning pathways
    reasoning_pathways: List[Dict[str, Any]]
    # Chain of Thought - Step-by-step reasoning
    reasoning_steps: List[Dict[str, Any]]
    # Mixture of Reasoning - Different reasoning modes
    reasoning_modes: List[str]
    # Extracted data governance rules
    data_usage_rules: List[Dict[str, Any]]
    data_transfer_rules: List[Dict[str, Any]]
    data_storage_rules: List[Dict[str, Any]]
    data_access_rules: List[Dict[str, Any]]
    # Final outputs
    all_extracted_rules: List[Dict[str, Any]]
    json_rules: List[Dict[str, Any]]
    validation_results: Dict[str, Any]
    current_phase: str


# ========================= Enums for Reasoning Framework =========================

class ReasoningPathway(Enum):
    """Mixture of Thought - Different pathways to analyze legislation"""
    STRUCTURAL = "structural"  # Analyze document structure and hierarchy
    SEMANTIC = "semantic"  # Understand meaning and intent
    LOGICAL = "logical"  # Extract logical relationships and conditions
    CONTEXTUAL = "contextual"  # Understand context and domain specifics
    COMPLIANCE = "compliance"  # Focus on compliance requirements


class ReasoningMode(Enum):
    """Mixture of Reasoning - Different reasoning approaches"""
    DEDUCTIVE = "deductive"  # General principles to specific rules
    INDUCTIVE = "inductive"  # Specific examples to general patterns
    ABDUCTIVE = "abductive"  # Best explanation for observations
    ANALOGICAL = "analogical"  # Compare with known patterns
    CAUSAL = "causal"  # Cause-effect relationships


class DataDomain(Enum):
    """Data governance domains to focus on"""
    USAGE = "data_usage"
    TRANSFER = "data_transfer"
    STORAGE = "data_storage"
    ACCESS = "data_access"


# ========================= Pydantic Models for Tools =========================

class AnalyzeWithReasoningInput(BaseModel):
    legislation_text: str = Field(..., description="Legislation text to analyze")
    reasoning_pathway: str = Field(..., description="Reasoning pathway to use (structural/semantic/logical/contextual/compliance)")
    reasoning_mode: str = Field(..., description="Reasoning mode to apply (deductive/inductive/abductive/analogical/causal)")
    focus_domain: str = Field(..., description="Data domain to focus on (data_usage/data_transfer/data_storage/data_access)")


class ExtractDataRulesInput(BaseModel):
    analyzed_text: str = Field(..., description="Analyzed text with reasoning context")
    data_domain: str = Field(..., description="Data domain to extract rules for")
    reasoning_context: Dict[str, Any] = Field(default={}, description="Context from reasoning analysis")


class SynthesizeRulesInput(BaseModel):
    rules_by_domain: Dict[str, List[Dict[str, Any]]] = Field(..., description="Rules organized by data domain")
    reasoning_pathways: List[Dict[str, Any]] = Field(default=[], description="All reasoning pathways used")


class ConvertToJsonRulesInput(BaseModel):
    synthesized_rules: List[Dict[str, Any]] = Field(..., description="Synthesized rules to convert")


class ValidateJsonRulesInput(BaseModel):
    json_rules: List[Dict[str, Any]] = Field(..., description="JSON rules to validate")


# ========================= Advanced Reasoning Tools =========================

@tool(args_schema=AnalyzeWithReasoningInput)
def analyze_with_reasoning(
    legislation_text: str,
    reasoning_pathway: str,
    reasoning_mode: str,
    focus_domain: str
) -> Dict[str, Any]:
    """
    Analyze legislation using specified reasoning pathway and mode.
    Uses LLM capabilities for deep understanding rather than regex.
    
    This implements:
    - Mixture of Thought: Different analytical pathways
    - Mixture of Reasoning: Different reasoning modes
    - Chain of Thought: Step-by-step analysis
    """
    
    # Create focused prompts based on pathway and mode
    pathway_prompts = {
        "structural": """
        Analyze the STRUCTURE of this legislation:
        1. Identify main sections and subsections
        2. Map the hierarchical organization
        3. Find cross-references and dependencies
        4. Identify how data governance rules are organized
        Focus on: {focus_domain}
        """,
        
        "semantic": """
        Analyze the MEANING and INTENT:
        1. Identify key definitions related to data
        2. Understand the purpose of each provision
        3. Extract implied meanings and interpretations
        4. Identify stakeholders and their obligations
        Focus on: {focus_domain}
        """,
        
        "logical": """
        Extract LOGICAL RELATIONSHIPS:
        1. Identify IF-THEN conditions
        2. Find requirements (MUST/SHALL statements)
        3. Find prohibitions (MUST NOT/SHALL NOT)
        4. Map cause-effect relationships
        Focus on: {focus_domain}
        """,
        
        "contextual": """
        Understand the CONTEXT:
        1. Identify the regulatory environment
        2. Understand industry-specific requirements
        3. Find temporal conditions and deadlines
        4. Identify exceptions and special cases
        Focus on: {focus_domain}
        """,
        
        "compliance": """
        Extract COMPLIANCE REQUIREMENTS:
        1. Identify mandatory obligations
        2. Find penalties for non-compliance
        3. Extract audit and reporting requirements
        4. Identify enforcement mechanisms
        Focus on: {focus_domain}
        """
    }
    
    mode_prompts = {
        "deductive": "Apply top-down reasoning: Start from general principles and derive specific rules.",
        "inductive": "Apply bottom-up reasoning: Identify specific patterns and infer general rules.",
        "abductive": "Find the best explanation: What rules best explain the legislative intent?",
        "analogical": "Compare with known patterns: How do these rules compare to standard data governance frameworks?",
        "causal": "Identify cause-effect chains: What triggers lead to what consequences?"
    }
    
    # Build the analysis prompt
    analysis_prompt = f"""
    {pathway_prompts.get(reasoning_pathway, pathway_prompts["structural"])}
    
    Reasoning Mode: {mode_prompts.get(reasoning_mode, mode_prompts["deductive"])}
    
    Legislation Text:
    {legislation_text}
    
    Provide a detailed analysis focusing on {focus_domain} rules.
    Include:
    - Key findings
    - Identified patterns
    - Relevant sections
    - Logical relationships
    - Compliance requirements
    """
    
    # Initialize the model for analysis
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2
    )
    
    # Get LLM analysis
    response = model.invoke(analysis_prompt)
    
    # Structure the analysis results
    analysis_results = {
        "pathway": reasoning_pathway,
        "mode": reasoning_mode,
        "domain_focus": focus_domain,
        "analysis": response.content,
        "reasoning_trace": [
            f"Applied {reasoning_pathway} pathway",
            f"Used {reasoning_mode} reasoning",
            f"Focused on {focus_domain}",
            "LLM-based deep analysis completed"
        ],
        "text_length": len(legislation_text),
        "timestamp": asyncio.get_event_loop().time()
    }
    
    return analysis_results


@tool(args_schema=ExtractDataRulesInput)
def extract_data_rules(
    analyzed_text: str,
    data_domain: str,
    reasoning_context: Dict[str, Any] = {}
) -> List[Dict[str, Any]]:
    """
    Extract specific data governance rules using LLM capabilities.
    Implements Chain of Thought for step-by-step extraction.
    """
    
    # Domain-specific extraction prompts
    domain_prompts = {
        "data_usage": """
        Extract ALL rules about DATA USAGE from this text:
        
        Chain of Thought Steps:
        1. First, identify all mentions of how data can be used
        2. Next, find restrictions on data usage
        3. Then, identify purposes for which data can/cannot be used
        4. Extract conditions that must be met for data usage
        5. Find any consent requirements for data usage
        6. Identify data usage retention limits
        
        For each rule, provide:
        - Rule description
        - Subject (who must comply)
        - Conditions (when it applies)
        - Requirements (what must be done)
        - Prohibitions (what must not be done)
        - Consequences (what happens if violated)
        """,
        
        "data_transfer": """
        Extract ALL rules about DATA TRANSFER from this text:
        
        Chain of Thought Steps:
        1. First, identify all mentions of data sharing, transmission, or transfer
        2. Next, find cross-border data transfer rules
        3. Then, identify third-party sharing restrictions
        4. Extract conditions for legitimate data transfers
        5. Find security requirements for data in transit
        6. Identify notification requirements for data transfers
        
        For each rule, provide:
        - Rule description
        - Transfer type (internal/external/cross-border)
        - Allowed recipients
        - Prohibited recipients
        - Required safeguards
        - Approval requirements
        """,
        
        "data_storage": """
        Extract ALL rules about DATA STORAGE from this text:
        
        Chain of Thought Steps:
        1. First, identify all data retention requirements
        2. Next, find data deletion/destruction requirements
        3. Then, identify storage location restrictions
        4. Extract encryption and security requirements
        5. Find backup and recovery obligations
        6. Identify data minimization principles
        
        For each rule, provide:
        - Rule description
        - Storage duration requirements
        - Storage location restrictions
        - Security measures required
        - Deletion requirements
        - Access control requirements
        """,
        
        "data_access": """
        Extract ALL rules about DATA ACCESS from this text:
        
        Chain of Thought Steps:
        1. First, identify who can access what data
        2. Next, find authentication requirements
        3. Then, identify access control mechanisms
        4. Extract audit trail requirements
        5. Find data subject access rights
        6. Identify breach notification requirements
        
        For each rule, provide:
        - Rule description
        - Authorized parties
        - Access conditions
        - Authentication requirements
        - Audit requirements
        - Rights and remedies
        """
    }
    
    extraction_prompt = f"""
    {domain_prompts.get(data_domain, domain_prompts["data_usage"])}
    
    Context from reasoning analysis:
    {json.dumps(reasoning_context, indent=2) if reasoning_context else "No prior context"}
    
    Text to analyze:
    {analyzed_text}
    
    Extract rules as structured JSON objects with logical conditions.
    Each rule should have:
    {{
        "rule_id": "unique_identifier",
        "domain": "{data_domain}",
        "description": "clear description",
        "conditions": ["condition1", "condition2"],
        "requirements": ["requirement1", "requirement2"],
        "prohibitions": ["prohibition1", "prohibition2"],
        "consequences": ["consequence1", "consequence2"],
        "confidence": 0.0-1.0
    }}
    
    Return a JSON array of rules.
    """
    
    # Initialize model for extraction
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1,
        model_kwargs={"response_format": {"type": "json_object"}}
    )
    
    # Get extraction
    response = model.invoke(extraction_prompt)
    
    # Parse the extracted rules
    try:
        content = response.content
        # Try to parse as JSON
        if isinstance(content, str):
            # Look for JSON array in the content
            if content.strip().startswith('['):
                rules = json.loads(content)
            elif content.strip().startswith('{'):
                # Might be wrapped in an object
                parsed = json.loads(content)
                if 'rules' in parsed:
                    rules = parsed['rules']
                else:
                    rules = [parsed]
            else:
                # Try to extract JSON from text
                import re
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    rules = json.loads(json_match.group())
                else:
                    rules = []
        else:
            rules = []
            
        # Ensure each rule has the domain
        for rule in rules:
            rule['domain'] = data_domain
            
        return rules
        
    except Exception as e:
        # Fallback: create a simple rule from the response
        return [{
            "rule_id": f"{data_domain}_extracted",
            "domain": data_domain,
            "description": str(response.content)[:200],
            "conditions": [],
            "requirements": [],
            "prohibitions": [],
            "consequences": [],
            "confidence": 0.5,
            "extraction_error": str(e)
        }]


@tool(args_schema=SynthesizeRulesInput)
def synthesize_rules(
    rules_by_domain: Dict[str, List[Dict[str, Any]]],
    reasoning_pathways: List[Dict[str, Any]] = []
) -> List[Dict[str, Any]]:
    """
    Synthesize rules from multiple domains and reasoning pathways.
    Implements convergent synthesis from divergent analysis.
    """
    
    synthesis_prompt = """
    Synthesize the following data governance rules into a coherent set:
    
    Rules by Domain:
    {rules_json}
    
    Reasoning Pathways Used:
    {pathways_summary}
    
    Synthesis Requirements:
    1. Remove duplicates while preserving unique conditions
    2. Merge related rules that address the same topic
    3. Ensure logical consistency between rules
    4. Resolve any conflicts between rules
    5. Prioritize rules based on:
       - Clarity and specificity
       - Regulatory importance
       - Practical enforceability
    
    For each synthesized rule, provide:
    - Unique ID
    - Clear description
    - Complete conditions (merged from all sources)
    - Priority level (1-100)
    - Source domains
    - Confidence score
    
    Return as JSON array of synthesized rules.
    """
    
    # Prepare data for synthesis
    rules_json = json.dumps(rules_by_domain, indent=2)
    pathways_summary = "\n".join([
        f"- {p.get('pathway', 'unknown')} pathway with {p.get('mode', 'unknown')} reasoning"
        for p in reasoning_pathways
    ])
    
    # Initialize model
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.1
    )
    
    # Get synthesis
    response = model.invoke(
        synthesis_prompt.format(
            rules_json=rules_json,
            pathways_summary=pathways_summary
        )
    )
    
    # Parse synthesized rules
    try:
        content = response.content
        if isinstance(content, str):
            # Extract JSON from response
            import re
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                synthesized = json.loads(json_match.group())
            else:
                # Fallback: combine all rules
                synthesized = []
                for domain_rules in rules_by_domain.values():
                    synthesized.extend(domain_rules)
        else:
            synthesized = []
            
        return synthesized
        
    except Exception as e:
        # Fallback: return flattened rules
        synthesized = []
        for domain, domain_rules in rules_by_domain.items():
            for rule in domain_rules:
                rule['synthesis_error'] = str(e)
                synthesized.append(rule)
        return synthesized


@tool(args_schema=ConvertToJsonRulesInput)
def convert_to_json_rules(synthesized_rules: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Convert synthesized rules to json-rules-engine format.
    Creates complex, multi-condition rules that make logical sense.
    """
    
    json_rules = []
    
    for rule in synthesized_rules:
        rule_id = rule.get('rule_id', f"rule_{len(json_rules) + 1}")
        domain = rule.get('domain', 'data_governance')
        
        # Build conditions based on rule type and domain
        conditions_all = []
        
        # Add domain-specific fact checks
        if domain == "data_usage":
            conditions_all.append({
                "fact": "dataOperation",
                "operator": "equal",
                "value": "usage"
            })
        elif domain == "data_transfer":
            conditions_all.append({
                "fact": "dataOperation",
                "operator": "equal",
                "value": "transfer"
            })
        elif domain == "data_storage":
            conditions_all.append({
                "fact": "dataOperation",
                "operator": "equal",
                "value": "storage"
            })
        elif domain == "data_access":
            conditions_all.append({
                "fact": "dataOperation",
                "operator": "equal",
                "value": "access"
            })
        
        # Add specific conditions from the rule
        for condition in rule.get('conditions', []):
            if isinstance(condition, str):
                # Parse condition string into fact/operator/value
                if 'must' in condition.lower():
                    conditions_all.append({
                        "fact": "complianceCheck",
                        "operator": "equal",
                        "value": True,
                        "path": f"$.requirements.{rule_id}"
                    })
                elif 'consent' in condition.lower():
                    conditions_all.append({
                        "fact": "userConsent",
                        "operator": "equal",
                        "value": True
                    })
                elif 'encrypted' in condition.lower():
                    conditions_all.append({
                        "fact": "dataEncrypted",
                        "operator": "equal",
                        "value": True
                    })
                elif 'authorized' in condition.lower():
                    conditions_all.append({
                        "fact": "userAuthorized",
                        "operator": "equal",
                        "value": True
                    })
                elif 'cross-border' in condition.lower():
                    conditions_all.append({
                        "fact": "crossBorderTransfer",
                        "operator": "equal",
                        "value": True
                    })
        
        # Build the json-rules-engine rule
        json_rule = {
            "name": rule_id,
            "conditions": {
                "all": conditions_all if conditions_all else [
                    {
                        "fact": "alwaysApplicable",
                        "operator": "equal",
                        "value": True
                    }
                ]
            },
            "event": {
                "type": f"{domain}_rule_triggered",
                "params": {
                    "ruleId": rule_id,
                    "domain": domain,
                    "description": rule.get('description', ''),
                    "requirements": rule.get('requirements', []),
                    "prohibitions": rule.get('prohibitions', []),
                    "consequences": rule.get('consequences', [])
                }
            },
            "priority": rule.get('priority', 50),
            "onSuccess": {
                "type": "rule_applied",
                "params": {
                    "message": f"Data governance rule {rule_id} has been applied",
                    "domain": domain
                }
            },
            "onFailure": {
                "type": "rule_skipped",
                "params": {
                    "message": f"Conditions not met for rule {rule_id}",
                    "domain": domain
                }
            }
        }
        
        # Add additional conditions for complex rules
        if rule.get('requirements'):
            for req in rule.get('requirements', []):
                if isinstance(req, str):
                    if 'retention' in req.lower():
                        json_rule["conditions"]["all"].append({
                            "fact": "dataRetentionPeriod",
                            "operator": "lessThanInclusive",
                            "value": 365,
                            "path": "$.days"
                        })
                    elif 'audit' in req.lower():
                        json_rule["conditions"]["all"].append({
                            "fact": "auditLogEnabled",
                            "operator": "equal",
                            "value": True
                        })
        
        # Add prohibition checks
        if rule.get('prohibitions'):
            any_conditions = []
            for prohibition in rule.get('prohibitions', []):
                if isinstance(prohibition, str):
                    if 'third party' in prohibition.lower():
                        any_conditions.append({
                            "fact": "recipientType",
                            "operator": "notEqual",
                            "value": "third_party"
                        })
                    elif 'unencrypted' in prohibition.lower():
                        any_conditions.append({
                            "fact": "dataEncrypted",
                            "operator": "equal",
                            "value": True
                        })
            
            if any_conditions:
                # Add an 'any' condition group for prohibitions
                if "any" not in json_rule["conditions"]:
                    # Convert to nested conditions
                    original_conditions = json_rule["conditions"]["all"]
                    json_rule["conditions"] = {
                        "all": [
                            {"all": original_conditions},
                            {"any": any_conditions}
                        ]
                    }
        
        json_rules.append(json_rule)
    
    return json_rules


@tool(args_schema=ValidateJsonRulesInput)
def validate_json_rules(json_rules: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Validate JSON rules for json-rules-engine compatibility and logical consistency.
    """
    
    validation_report = {
        "valid": True,
        "total_rules": len(json_rules),
        "valid_rules": 0,
        "invalid_rules": 0,
        "errors": [],
        "warnings": [],
        "domain_coverage": {
            "data_usage": 0,
            "data_transfer": 0,
            "data_storage": 0,
            "data_access": 0
        },
        "complexity_analysis": {
            "simple_rules": 0,
            "complex_rules": 0,
            "average_conditions": 0
        }
    }
    
    required_fields = ["name", "conditions", "event"]
    valid_operators = [
        "equal", "notEqual", "lessThan", "lessThanInclusive",
        "greaterThan", "greaterThanInclusive", "in", "notIn",
        "contains", "doesNotContain"
    ]
    
    total_conditions = 0
    
    for i, rule in enumerate(json_rules):
        rule_errors = []
        rule_warnings = []
        
        # Check required fields
        for field in required_fields:
            if field not in rule:
                rule_errors.append(f"Rule {i}: Missing required field '{field}'")
        
        # Check conditions structure
        if "conditions" in rule:
            conditions = rule["conditions"]
            if not isinstance(conditions, dict):
                rule_errors.append(f"Rule {i}: Conditions must be an object")
            else:
                # Count conditions
                condition_count = 0
                if "all" in conditions:
                    condition_count += len(conditions["all"]) if isinstance(conditions["all"], list) else 1
                if "any" in conditions:
                    condition_count += len(conditions["any"]) if isinstance(conditions["any"], list) else 1
                
                total_conditions += condition_count
                
                if condition_count > 3:
                    validation_report["complexity_analysis"]["complex_rules"] += 1
                else:
                    validation_report["complexity_analysis"]["simple_rules"] += 1
                
                # Validate operators
                for logical_op in ["all", "any"]:
                    if logical_op in conditions and isinstance(conditions[logical_op], list):
                        for cond in conditions[logical_op]:
                            if isinstance(cond, dict) and "operator" in cond:
                                if cond["operator"] not in valid_operators:
                                    rule_warnings.append(f"Rule {i}: Unknown operator '{cond['operator']}'")
        
        # Check event structure
        if "event" in rule:
            event = rule["event"]
            if not isinstance(event, dict):
                rule_errors.append(f"Rule {i}: Event must be an object")
            elif "type" not in event:
                rule_errors.append(f"Rule {i}: Event missing 'type' field")
            else:
                # Track domain coverage
                event_type = event.get("type", "")
                for domain in ["data_usage", "data_transfer", "data_storage", "data_access"]:
                    if domain in event_type:
                        validation_report["domain_coverage"][domain] += 1
        
        # Check priority
        if "priority" in rule:
            priority = rule["priority"]
            if not isinstance(priority, (int, float)):
                rule_warnings.append(f"Rule {i}: Priority should be a number")
            elif priority < 0 or priority > 100:
                rule_warnings.append(f"Rule {i}: Priority should be between 0 and 100")
        
        # Update counts
        if rule_errors:
            validation_report["invalid_rules"] += 1
            validation_report["valid"] = False
        else:
            validation_report["valid_rules"] += 1
        
        validation_report["errors"].extend(rule_errors)
        validation_report["warnings"].extend(rule_warnings)
    
    # Calculate average conditions
    if validation_report["total_rules"] > 0:
        validation_report["complexity_analysis"]["average_conditions"] = (
            total_conditions / validation_report["total_rules"]
        )
    
    # Add quality score
    quality_score = 0
    if validation_report["total_rules"] > 0:
        quality_score += (validation_report["valid_rules"] / validation_report["total_rules"]) * 50
        
        # Check domain coverage
        domains_covered = sum(1 for count in validation_report["domain_coverage"].values() if count > 0)
        quality_score += (domains_covered / 4) * 30
        
        # Check complexity distribution
        if validation_report["complexity_analysis"]["complex_rules"] > 0:
            quality_score += 20
    
    validation_report["quality_score"] = round(quality_score, 2)
    
    return validation_report


# ========================= Agent Node Functions =========================

def reasoning_agent_node(state: AgentState) -> Dict[str, Any]:
    """
    Main agent node that implements Chain of Thought with tool calling.
    Orchestrates the reasoning process and tool execution.
    """
    messages = state["messages"]
    
    # Initialize model with tools
    model = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2
    )
    
    # Bind all tools
    tools = [
        analyze_with_reasoning,
        extract_data_rules,
        synthesize_rules,
        convert_to_json_rules,
        validate_json_rules
    ]
    
    model_with_tools = model.bind_tools(tools)
    
    # Add Chain of Thought system message
    cot_system_message = SystemMessage(content="""
    You are an expert legal analyst specializing in data governance and privacy regulations.
    
    Use Chain of Thought reasoning to process legislation:
    1. Think step-by-step through each analysis
    2. Explain your reasoning before each tool call
    3. Build upon previous findings
    4. Ensure comprehensive coverage of all data domains
    
    Your goal is to extract and convert data governance rules into machine-readable JSON format.
    Focus on: data usage, data transfer, data storage, and data access rules.
    """)
    
    # Prepend system message if not present
    if not any(isinstance(m, SystemMessage) for m in messages):
        messages = [cot_system_message] + list(messages)
    
    # Get response with reasoning
    response = model_with_tools.invoke(messages)
    
    # Track reasoning step
    reasoning_step = {
        "timestamp": asyncio.get_event_loop().time() if asyncio.get_event_loop().is_running() else 0,
        "phase": state.get("current_phase", "unknown"),
        "message": response.content if hasattr(response, 'content') else "",
        "tool_calls": len(response.tool_calls) if hasattr(response, 'tool_calls') else 0
    }
    
    # Update state with reasoning
    new_reasoning_steps = state.get("reasoning_steps", []) + [reasoning_step]
    
    return {
        "messages": [response],
        "reasoning_steps": new_reasoning_steps
    }


def tool_execution_node(state: AgentState) -> Dict[str, Any]:
    """Execute tools and update state with results"""
    tools_map = {
        "analyze_with_reasoning": analyze_with_reasoning,
        "extract_data_rules": extract_data_rules,
        "synthesize_rules": synthesize_rules,
        "convert_to_json_rules": convert_to_json_rules,
        "validate_json_rules": validate_json_rules
    }
    
    tool_node_instance = ToolNode(list(tools_map.values()))
    result = tool_node_instance.invoke(state)
    
    # Extract and organize results based on tool outputs
    messages = result.get("messages", [])
    
    # Update domain-specific rules if extraction was performed
    for message in messages:
        if isinstance(message, ToolMessage):
            try:
                if hasattr(message, 'content'):
                    content = message.content
                    if isinstance(content, str) and content.strip().startswith('['):
                        rules = json.loads(content)
                        # Organize by domain
                        for rule in rules:
                            domain = rule.get('domain', '')
                            if domain == 'data_usage':
                                state.setdefault('data_usage_rules', []).append(rule)
                            elif domain == 'data_transfer':
                                state.setdefault('data_transfer_rules', []).append(rule)
                            elif domain == 'data_storage':
                                state.setdefault('data_storage_rules', []).append(rule)
                            elif domain == 'data_access':
                                state.setdefault('data_access_rules', []).append(rule)
            except:
                pass
    
    return result


def should_continue(state: AgentState) -> Literal["tools", "end"]:
    """Determine whether to continue to tools or end"""
    messages = state["messages"]
    last_message = messages[-1]
    
    # Check if there are tool calls
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"
    
    return "end"


# ========================= Create Advanced Agent Graph =========================

def create_advanced_reasoning_agent():
    """
    Create LangGraph agent with Chain of Thought, Mixture of Thought, and Mixture of Reasoning.
    """
    
    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("agent", reasoning_agent_node)
    workflow.add_node("tools", tool_execution_node)
    
    # Set entry point
    workflow.set_entry_point("agent")
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "tools": "tools",
            "end": END
        }
    )
    
    # Add edge from tools back to agent
    workflow.add_edge("tools", "agent")
    
    # Compile with memory
    memory = MemorySaver()
    graph = workflow.compile(checkpointer=memory)
    
    return graph


# ========================= Main Processing Function =========================

async def process_legislation_advanced(legislation_text: str) -> Dict[str, Any]:
    """
    Process legislation using advanced reasoning techniques.
    Implements Chain of Thought, Mixture of Thought, and Mixture of Reasoning.
    """
    
    # Create the advanced agent
    agent = create_advanced_reasoning_agent()
    
    # Build comprehensive prompt with reasoning instructions
    prompt = f"""
    Process this legislation using our advanced reasoning framework to extract data governance rules.
    
    ## REASONING FRAMEWORK:
    
    ### Phase 1: DIVERGENT ANALYSIS (Mixture of Thought)
    Analyze the legislation through multiple pathways:
    
    1. **Structural Analysis with Deductive Reasoning**
       - Call: analyze_with_reasoning(reasoning_pathway="structural", reasoning_mode="deductive", focus_domain="data_usage")
       - Purpose: Understand document structure and derive usage rules from general principles
    
    2. **Semantic Analysis with Inductive Reasoning**
       - Call: analyze_with_reasoning(reasoning_pathway="semantic", reasoning_mode="inductive", focus_domain="data_transfer")
       - Purpose: Extract meaning and infer transfer rules from specific examples
    
    3. **Logical Analysis with Abductive Reasoning**
       - Call: analyze_with_reasoning(reasoning_pathway="logical", reasoning_mode="abductive", focus_domain="data_storage")
       - Purpose: Find best explanations for storage requirements
    
    4. **Contextual Analysis with Analogical Reasoning**
       - Call: analyze_with_reasoning(reasoning_pathway="contextual", reasoning_mode="analogical", focus_domain="data_access")
       - Purpose: Compare with known access control patterns
    
    5. **Compliance Analysis with Causal Reasoning**
       - Call: analyze_with_reasoning(reasoning_pathway="compliance", reasoning_mode="causal", focus_domain="data_usage")
       - Purpose: Identify cause-effect chains in compliance requirements
    
    ### Phase 2: FOCUSED EXTRACTION (Chain of Thought)
    Extract rules for each data domain step-by-step:
    
    1. **Data Usage Rules**
       - Think: What are the permitted and prohibited uses of data?
       - Call: extract_data_rules(data_domain="data_usage")
    
    2. **Data Transfer Rules**
       - Think: How can data be shared or transmitted?
       - Call: extract_data_rules(data_domain="data_transfer")
    
    3. **Data Storage Rules**  
       - Think: How must data be stored and retained?
       - Call: extract_data_rules(data_domain="data_storage")
    
    4. **Data Access Rules**
       - Think: Who can access data and under what conditions?
       - Call: extract_data_rules(data_domain="data_access")
    
    ### Phase 3: CONVERGENT SYNTHESIS
    Combine all extracted rules:
    - Call: synthesize_rules() with all domain rules and reasoning pathways
    
    ### Phase 4: CONVERSION TO JSON
    Convert to machine-readable format:
    - Call: convert_to_json_rules() with synthesized rules
    
    ### Phase 5: VALIDATION
    Ensure quality and consistency:
    - Call: validate_json_rules() with the JSON rules
    
    ## LEGISLATION TEXT TO PROCESS:
    {legislation_text}
    
    ## IMPORTANT INSTRUCTIONS:
    - Use Chain of Thought: Explain your reasoning before each step
    - Apply Mixture of Thought: Use different analytical pathways
    - Implement Mixture of Reasoning: Apply various reasoning modes
    - Focus on data governance: usage, transfer, storage, and access
    - Create complex, multi-condition rules that are logically sound
    - Ensure comprehensive coverage of all data-related provisions
    
    Begin by explaining your analysis approach, then proceed with the tool calls.
    """
    
    # Initialize state
    initial_state = {
        "messages": [HumanMessage(content=prompt)],
        "legislation_text": legislation_text,
        "reasoning_pathways": [],
        "reasoning_steps": [],
        "reasoning_modes": ["deductive", "inductive", "abductive", "analogical", "causal"],
        "data_usage_rules": [],
        "data_transfer_rules": [],
        "data_storage_rules": [],
        "data_access_rules": [],
        "all_extracted_rules": [],
        "json_rules": [],
        "validation_results": {},
        "current_phase": "initialization"
    }
    
    # Configuration
    config = {"configurable": {"thread_id": "advanced_reasoning_session"}}
    
    # Execute the agent
    result = await agent.ainvoke(initial_state, config)
    
    # Extract final JSON rules
    json_rules = extract_json_rules_from_messages(result["messages"])
    
    # Compile comprehensive results
    return {
        "status": "completed",
        "json_rules": json_rules,
        "reasoning_summary": {
            "pathways_used": len(result.get("reasoning_pathways", [])),
            "reasoning_steps": len(result.get("reasoning_steps", [])),
            "modes_applied": result.get("reasoning_modes", [])
        },
        "domain_coverage": {
            "data_usage": len(result.get("data_usage_rules", [])),
            "data_transfer": len(result.get("data_transfer_rules", [])),
            "data_storage": len(result.get("data_storage_rules", [])),
            "data_access": len(result.get("data_access_rules", []))
        },
        "validation": result.get("validation_results", {}),
        "messages": result["messages"]
    }


def process_legislation_sync(legislation_text: str) -> Dict[str, Any]:
    """Synchronous wrapper for async processing"""
    return asyncio.run(process_legislation_advanced(legislation_text))


# ========================= Helper Functions =========================

def extract_json_rules_from_messages(messages: List[BaseMessage]) -> List[Dict[str, Any]]:
    """Extract JSON rules from agent messages"""
    json_rules = []
    
    for message in messages:
        if isinstance(message, ToolMessage):
            try:
                if hasattr(message, 'content'):
                    content = message.content
                    if isinstance(content, str):
                        # Try to parse as JSON
                        import re
                        # Look for JSON arrays
                        json_matches = re.findall(r'\[[\s\S]*?\]', content)
                        for match in json_matches:
                            try:
                                parsed = json.loads(match)
                                if isinstance(parsed, list):
                                    for item in parsed:
                                        if isinstance(item, dict) and "conditions" in item:
                                            json_rules.append(item)
                            except:
                                pass
                    elif isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict) and "conditions" in item:
                                json_rules.append(item)
            except:
                pass
    
    # Remove duplicates by name
    seen = set()
    unique_rules = []
    for rule in json_rules:
        name = rule.get("name", "")
        if name and name not in seen:
            seen.add(name)
            unique_rules.append(rule)
    
    return unique_rules


def save_rules_to_file(rules: List[Dict[str, Any]], filename: str = "data_governance_rules.json"):
    """Save JSON rules to file"""
    output = {
        "rules": rules,
        "metadata": {
            "created_by": "advanced_reasoning_agent",
            "reasoning_framework": "CoT + MoT + MoR",
            "focus": "data_governance",
            "domains": ["data_usage", "data_transfer", "data_storage", "data_access"],
            "engine": "json-rules-engine",
            "rule_count": len(rules)
        }
    }
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… Saved {len(rules)} rules to {filename}")


def print_reasoning_summary(result: Dict[str, Any]):
    """Print a summary of the reasoning process"""
    print("\nðŸ§  REASONING PROCESS SUMMARY")
    print("=" * 60)
    
    # Reasoning framework usage
    reasoning = result.get("reasoning_summary", {})
    print(f"Reasoning Pathways Used: {reasoning.get('pathways_used', 0)}")
    print(f"Chain of Thought Steps: {reasoning.get('reasoning_steps', 0)}")
    print(f"Reasoning Modes Applied: {', '.join(reasoning.get('modes_applied', []))}")
    
    # Domain coverage
    print(f"\nðŸ“Š DOMAIN COVERAGE")
    print("-" * 40)
    coverage = result.get("domain_coverage", {})
    for domain, count in coverage.items():
        print(f"  {domain.replace('_', ' ').title()}: {count} rules")
    
    # Validation results
    validation = result.get("validation", {})
    if validation:
        print(f"\nâœ”ï¸ VALIDATION RESULTS")
        print("-" * 40)
        print(f"  Valid Rules: {validation.get('valid_rules', 0)}/{validation.get('total_rules', 0)}")
        print(f"  Quality Score: {validation.get('quality_score', 0)}%")
        
        # Domain coverage from validation
        if 'domain_coverage' in validation:
            print(f"  Domains Covered:")
            for domain, count in validation['domain_coverage'].items():
                if count > 0:
                    print(f"    - {domain.replace('_', ' ').title()}: {count}")
    
    # Rules summary
    rules = result.get("json_rules", [])
    if rules:
        print(f"\nðŸ“‹ GENERATED RULES")
        print("-" * 40)
        print(f"  Total JSON Rules: {len(rules)}")
        
        # Show complexity
        simple = sum(1 for r in rules if len(r.get('conditions', {}).get('all', [])) <= 2)
        complex = len(rules) - simple
        print(f"  Simple Rules: {simple}")
        print(f"  Complex Rules: {complex}")
        
        # Sample rule
        print(f"\n  Sample Rule:")
        sample = rules[0] if rules else {}
        print(f"    Name: {sample.get('name', 'N/A')}")
        print(f"    Priority: {sample.get('priority', 'N/A')}")
        print(f"    Event Type: {sample.get('event', {}).get('type', 'N/A')}")


# ========================= Main Execution =========================

if __name__ == "__main__":
    # Example data governance legislation
    SAMPLE_LEGISLATION = """
    DATA PROTECTION AND PRIVACY ACT
    
    PART I - GENERAL PROVISIONS
    
    Section 1. Definitions
    For the purposes of this Act:
    (a) "Personal Data" means any information relating to an identified or identifiable natural person.
    (b) "Data Controller" means the entity that determines the purposes and means of processing personal data.
    (c) "Data Processor" means an entity that processes personal data on behalf of the controller.
    (d) "Data Subject" means the individual to whom personal data relates.
    (e) "Cross-border Transfer" means any transfer of personal data to a recipient in a different jurisdiction.
    (f) "Sensitive Data" means personal data revealing racial origin, political opinions, religious beliefs, health data, or biometric data.
    
    PART II - DATA USAGE REQUIREMENTS
    
    Section 2. Lawful Basis for Data Usage
    2.1 Personal data shall only be used when there is a lawful basis, including:
        (a) The data subject has given explicit consent
        (b) Processing is necessary for contract performance
        (c) Processing is required for legal compliance
        (d) Processing is necessary to protect vital interests
    
    2.2 Data controllers must not use personal data for purposes incompatible with those for which it was originally collected.
    
    2.3 Sensitive data shall not be processed unless:
        (a) The data subject has given explicit written consent
        (b) Processing is necessary for employment law obligations
        (c) Processing is necessary for healthcare purposes
    
    Section 3. Data Minimization and Purpose Limitation
    3.1 Data controllers must ensure that personal data usage is:
        (a) Adequate, relevant, and limited to what is necessary
        (b) Collected for specified, explicit, and legitimate purposes
        (c) Not further processed in a manner incompatible with those purposes
    
    PART III - DATA TRANSFER REGULATIONS
    
    Section 4. Intra-organizational Transfers
    4.1 Personal data may be transferred within an organization provided that:
        (a) Appropriate access controls are in place
        (b) The transfer is logged and auditable
        (c) Receiving departments have a legitimate need
    
    Section 5. Third-Party Data Transfers
    5.1 Data controllers shall not transfer personal data to third parties unless:
        (a) A data processing agreement is in place
        (b) The third party provides appropriate security guarantees
        (c) The data subject has been informed of the transfer
    
    5.2 Cross-border transfers of personal data are prohibited unless:
        (a) The recipient country ensures adequate protection
        (b) Appropriate safeguards are implemented, including:
            - Standard contractual clauses
            - Binding corporate rules
            - Approved certification mechanisms
        (c) The data subject has explicitly consented to the transfer
    
    Section 6. Data Transfer Security
    6.1 All data transfers must be encrypted using industry-standard encryption.
    6.2 Data controllers must maintain logs of all data transfers for at least 3 years.
    
    PART IV - DATA STORAGE REQUIREMENTS
    
    Section 7. Storage Duration and Retention
    7.1 Personal data shall not be stored longer than necessary for the purposes for which it was collected.
    7.2 Data retention periods must be defined and documented for each category of personal data.
    7.3 Upon expiration of the retention period, personal data must be securely deleted or anonymized.
    
    Section 8. Storage Security Requirements
    8.1 Data controllers must implement appropriate technical measures including:
        (a) Encryption of personal data at rest
        (b) Regular backups with tested recovery procedures
        (c) Physical security controls for data storage facilities
        (d) Logical access controls and authentication mechanisms
    
    8.2 Sensitive data must be stored:
        (a) In encrypted form using AES-256 or stronger encryption
        (b) With additional access controls and audit logging
        (c) Segregated from other personal data
    
    Section 9. Data Localization
    9.1 Health data and financial data must be stored within national borders.
    9.2 Backup copies may be stored internationally if encrypted and access-controlled.
    
    PART V - DATA ACCESS CONTROLS
    
    Section 10. Access Rights and Permissions
    10.1 Data controllers must implement role-based access controls ensuring:
        (a) Access is granted on a need-to-know basis
        (b) Privileged access is monitored and reviewed quarterly
        (c) Access permissions are revoked upon role change or termination
    
    10.2 Authentication requirements:
        (a) Multi-factor authentication for accessing sensitive data
        (b) Strong password policies enforced
        (c) Session timeouts after 15 minutes of inactivity
    
    Section 11. Data Subject Access Rights
    11.1 Data subjects have the right to:
        (a) Access their personal data within 30 days of request
        (b) Rectify inaccurate personal data
        (c) Request deletion of their personal data
        (d) Object to processing of their personal data
        (e) Request data portability in machine-readable format
    
    Section 12. Audit and Monitoring
    12.1 All access to personal data must be logged including:
        (a) User identity
        (b) Timestamp of access
        (c) Data accessed
        (d) Actions performed
    
    12.2 Access logs must be:
        (a) Retained for minimum 2 years
        (b) Protected from unauthorized modification
        (c) Regularly reviewed for anomalies
    
    PART VI - BREACH NOTIFICATION
    
    Section 13. Breach Response Requirements
    13.1 In case of a data breach, the data controller must:
        (a) Notify the supervisory authority within 72 hours
        (b) Notify affected data subjects without undue delay
        (c) Document the breach and remediation measures
    
    PART VII - PENALTIES
    
    Section 14. Administrative Penalties
    14.1 Violation of data usage requirements: Fine up to $1 million or 2% of annual revenue
    14.2 Unauthorized data transfer: Fine up to $2 million or 4% of annual revenue
    14.3 Inadequate storage security: Fine up to $500,000 per incident
    14.4 Access control violations: Fine up to $750,000 per violation
    14.5 Failure to notify breach: Fine up to $1.5 million
    """
    
    print("ðŸš€ Advanced Data Governance Rules Extractor")
    print("ðŸ“Š Using Chain of Thought + Mixture of Thought + Mixture of Reasoning")
    print("=" * 60)
    print()
    
    try:
        print("ðŸ”„ Processing legislation with advanced reasoning...")
        print("   This may take a few moments as the agent thinks through multiple pathways...\n")
        
        # Process the legislation
        result = process_legislation_sync(SAMPLE_LEGISLATION)
        
        # Print reasoning summary
        print_reasoning_summary(result)
        
        # Extract and save rules
        json_rules = result.get("json_rules", [])
        
        if json_rules:
            save_rules_to_file(json_rules)
            
            print(f"\nâœ¨ Successfully generated {len(json_rules)} data governance rules!")
            print("\nðŸ“„ Sample JSON Rule:")
            print(json.dumps(json_rules[0], indent=2)[:800] + "..." if len(json.dumps(json_rules[0])) > 800 else json.dumps(json_rules[0], indent=2))
        else:
            print("\nâš ï¸ No rules were generated. Check the agent messages for details.")
            
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
