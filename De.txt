#!/usr/bin/env python
"""
PBT Import Script - Import Preferred Business Terms (PBTs) from a CSV file.

This script imports PBTs from a CSV file into the vector database (ChromaDB or PostgreSQL).
It uses the BusinessTermManager to handle the data import and vector embedding generation.
"""

import os
import sys
import logging
import argparse
import time
import uuid
import chardet
from typing import Optional

# Add parent directory to path for module imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.core.business_terms import BusinessTermManager
from app.config.environment import get_os_env
from app.config.settings import get_vector_store

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] [%(name)s:%(lineno)d] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)
logger = logging.getLogger(__name__)

def detect_encoding(file_path: str) -> str:
    """
    Detect the encoding of a file.
    
    Args:
        file_path: Path to the file
        
    Returns:
        Detected encoding (defaults to utf-8)
    """
    try:
        # Read a sample of the file
        with open(file_path, 'rb') as f:
            sample = f.read(min(1024 * 1024, os.path.getsize(file_path)))
        
        # Detect encoding
        result = chardet.detect(sample)
        encoding = result['encoding']
        confidence = result['confidence']
        
        logger.info(f"Detected encoding: {encoding} with confidence {confidence:.2f}")
        
        if encoding and confidence > 0.7:
            return encoding
        else:
            logger.warning(f"Encoding detection uncertain. Using UTF-8.")
            return 'utf-8'
    
    except Exception as e:
        logger.error(f"Error detecting encoding: {e}")
        return 'utf-8'

def main():
    """Main function to import PBTs from a CSV file."""
    parser = argparse.ArgumentParser(description="Import Preferred Business Terms (PBTs) from a CSV file")
    parser.add_argument("csv_file", help="Path to the CSV file containing PBTs")
    parser.add_argument("--encoding", help="Encoding of the CSV file", default=None)
    parser.add_argument("--batch-size", type=int, default=100, help="Batch size for import")
    parser.add_argument("--vector-db-type", help="Type of vector database to use: chroma or postgresql", default="chroma")
    parser.add_argument("--chroma-dir", help="Directory for ChromaDB persistent storage", default="./data/chroma_db")
    parser.add_argument("--chroma-collection", help="Collection name for ChromaDB", default="business_terms")
    parser.add_argument("--embedding-model", help="OpenAI embedding model to use", default="text-embedding-3-large")
    
    args = parser.parse_args()
    
    # Ensure CSV file exists
    if not os.path.exists(args.csv_file):
        logger.error(f"CSV file not found: {args.csv_file}")
        sys.exit(1)
    
    # Set environment variables
    if args.vector_db_type:
        os.environ["VECTOR_DB_TYPE"] = args.vector_db_type
    if args.chroma_dir:
        os.environ["CHROMA_PERSIST_DIR"] = args.chroma_dir
    if args.chroma_collection:
        os.environ["CHROMA_COLLECTION"] = args.chroma_collection
    if args.embedding_model:
        os.environ["EMBEDDING_MODEL"] = args.embedding_model
    
    # Auto-detect encoding if not provided
    encoding = args.encoding
    if not encoding:
        encoding = detect_encoding(args.csv_file)
    
    logger.info(f"Starting PBT import from {args.csv_file} with encoding {encoding}")
    logger.info(f"Using vector database type: {os.environ.get('VECTOR_DB_TYPE', 'chroma')}")
    logger.info(f"Using embedding model: {os.environ.get('EMBEDDING_MODEL', 'text-embedding-3-large')}")
    
    # Initialize the environment settings
    env = get_os_env()
    
    # Initialize the BusinessTermManager
    try:
        logger.info("Initializing BusinessTermManager...")
        term_manager = BusinessTermManager()
        
        # Get initial term count
        initial_count = term_manager.get_term_count()
        logger.info(f"Initial term count: {initial_count}")
        
        # Import terms from CSV
        logger.info(f"Importing terms from {args.csv_file} with batch size {args.batch_size}...")
        start_time = time.time()
        
        count = term_manager.import_terms_from_csv(
            csv_path=args.csv_file,
            encoding=encoding,
            batch_size=args.batch_size
        )
        
        end_time = time.time()
        
        # Get final term count
        final_count = term_manager.get_term_count()
        
        logger.info(f"Import complete. Elapsed time: {end_time - start_time:.2f} seconds")
        logger.info(f"Imported {count} terms")
        logger.info(f"Initial term count: {initial_count}, Final term count: {final_count}")
        logger.info(f"Terms added/updated: {final_count - initial_count}")
        
    except Exception as e:
        logger.error(f"Error importing terms: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
