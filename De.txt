"""
LangGraph-based Legislation to Machine-Readable JSON Rules Converter
Using React Agent Pattern with o3-mini reasoning model and custom defined tools

This system converts legislation text into JSON rules compatible with json-rules-engine
"""

import json
import re
import asyncio
from typing import List, Dict, Any, Optional, Annotated, Sequence
from dataclasses import dataclass
from enum import Enum

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition, create_react_agent
from langgraph.checkpoint.memory import MemorySaver
from pydantic import BaseModel, Field


# State Management
class AgentState(BaseModel):
    """State for the legislation processing agent"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    legislation_text: str = ""
    extracted_rules: List[Dict[str, Any]] = []
    json_rules: List[Dict[str, Any]] = []
    processing_step: str = "initial"
    metadata: Dict[str, Any] = {}


class RuleType(Enum):
    """Types of rules that can be extracted from legislation"""
    CONDITIONAL = "conditional"
    REQUIREMENT = "requirement"
    PROHIBITION = "prohibition"
    DEFINITION = "definition"
    PROCEDURE = "procedure"
    PENALTY = "penalty"
    EXCEPTION = "exception"


@dataclass
class LegislationRule:
    """Structured representation of a rule extracted from legislation"""
    rule_id: str
    rule_type: RuleType
    title: str
    description: str
    conditions: List[str]
    actions: List[str]
    references: List[str]
    keywords: List[str]
    confidence: float


# Pydantic Input Models for Strict Tool Definitions

class LegislationStructureInput(BaseModel):
    """Input model for parsing legislation structure"""
    legislation_text: str = Field(..., description="Raw legislation text to parse")


class LegalEntitiesInput(BaseModel):
    """Input model for extracting legal entities"""
    text: str = Field(..., description="Legislation text to analyze for legal entities")


class RulePatternsInput(BaseModel):
    """Input model for identifying rule patterns"""
    text: str = Field(..., description="Legislation text to analyze for rule patterns")


class ConvertRulesInput(BaseModel):
    """Input model for converting rules to JSON format"""
    rules: List[Dict[str, Any]] = Field(..., description="List of extracted legal rules")
    entities: Dict[str, Any] = Field(..., description="Dictionary of legal entities and definitions")


class ValidateRulesInput(BaseModel):
    """Input model for validating JSON rules"""
    json_rules: List[Dict[str, Any]] = Field(..., description="List of JSON rules to validate")


# Custom Tools with Strict Pydantic Schemas

@tool(args_schema=LegislationStructureInput)
def parse_legislation_structure(legislation_text: str) -> Dict[str, Any]:
    """
    Parse the structure of legislation text to identify sections, subsections, and articles.
    
    Args:
        legislation_text: Raw legislation text
        
    Returns:
        Dictionary containing structured legislation with sections and subsections
    """
    # Pattern matching for common legislation structures
    patterns = {
        'section': r'(?:Section|Sec\.?)\s+(\d+(?:\.\d+)*)[:\.\s]+(.*?)(?=(?:Section|Sec\.?)\s+\d+|$)',
        'article': r'(?:Article|Art\.?)\s+(\d+(?:\.\d+)*)[:\.\s]+(.*?)(?=(?:Article|Art\.?)\s+\d+|$)',
        'subsection': r'(?:^|\n)\s*\(([a-z]|\d+)\)\s+(.*?)(?=\n\s*\([a-z]|\d+\)|$)',
        'paragraph': r'(?:^|\n)\s*(\d+)\.\s+(.*?)(?=\n\s*\d+\.|$)',
        'clause': r'(?:^|\n)\s*\(i+\)\s+(.*?)(?=\n\s*\(i+\)|$)'
    }
    
    structure = {
        'title': '',
        'sections': [],
        'articles': [],
        'definitions': [],
        'raw_text': legislation_text
    }
    
    # Extract title (usually first few lines)
    lines = legislation_text.split('\n')
    title_lines = []
    for line in lines[:5]:
        if line.strip() and not re.match(r'(?:Section|Article)', line):
            title_lines.append(line.strip())
    structure['title'] = ' '.join(title_lines)
    
    # Extract sections
    sections = re.findall(patterns['section'], legislation_text, re.DOTALL | re.MULTILINE)
    for section_num, section_text in sections:
        section_obj = {
            'number': section_num,
            'text': section_text.strip(),
            'subsections': []
        }
        
        # Extract subsections within this section
        subsections = re.findall(patterns['subsection'], section_text, re.DOTALL | re.MULTILINE)
        for subsec_id, subsec_text in subsections:
            section_obj['subsections'].append({
                'id': subsec_id,
                'text': subsec_text.strip()
            })
        
        structure['sections'].append(section_obj)
    
    # Extract articles if no sections found
    if not structure['sections']:
        articles = re.findall(patterns['article'], legislation_text, re.DOTALL | re.MULTILINE)
        for article_num, article_text in articles:
            structure['articles'].append({
                'number': article_num,
                'text': article_text.strip()
            })
    
    return structure


@tool(args_schema=LegalEntitiesInput)
def extract_legal_entities(text: str) -> Dict[str, List[str]]:
    """
    Extract legal entities, definitions, and key terms from legislation text.
    
    Args:
        text: Legislation text to analyze
        
    Returns:
        Dictionary containing categorized legal entities
    """
    entities = {
        'definitions': [],
        'actors': [],
        'obligations': [],
        'rights': [],
        'penalties': [],
        'timeframes': [],
        'amounts': []
    }
    
    # Definition patterns
    definition_patterns = [
        r'"([^"]+)"\s+means\s+([^.]+)',
        r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+means\s+([^.]+)',
        r'(?:For the purposes of this|In this)\s+[^,]*,\s*"([^"]+)"\s+([^.]+)'
    ]
    
    for pattern in definition_patterns:
        matches = re.findall(pattern, text, re.MULTILINE)
        for match in matches:
            entities['definitions'].append({
                'term': match[0].strip(),
                'definition': match[1].strip()
            })
    
    # Extract actors (who/what the law applies to)
    actor_patterns = [
        r'\b(?:person|individual|entity|organization|company|corporation|agency|department|officer|employee|citizen|resident)\b',
        r'\b(?:applicant|licensee|registrant|holder|owner|operator|provider|contractor)\b'
    ]
    
    for pattern in actor_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        entities['actors'].extend(list(set(matches)))
    
    # Extract obligation keywords
    obligation_patterns = [
        r'\b(?:shall|must|required|mandatory|obligated|duty|responsible)\b',
        r'\b(?:ensure|provide|maintain|submit|comply|notify|report)\b'
    ]
    
    for pattern in obligation_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        entities['obligations'].extend(list(set(matches)))
    
    # Extract rights keywords
    rights_patterns = [
        r'\b(?:may|entitled|authorized|permitted|allowed|right|privilege)\b'
    ]
    
    for pattern in rights_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        entities['rights'].extend(list(set(matches)))
    
    # Extract penalties/sanctions
    penalty_patterns = [
        r'\b(?:fine|penalty|sanction|imprisonment|suspension|revocation|violation)\b',
        r'\$[\d,]+(?:\.\d{2})?',
        r'\b\d+\s+(?:days|months|years)\b'
    ]
    
    for pattern in penalty_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        entities['penalties'].extend(matches)
    
    # Extract timeframes
    timeframe_patterns = [
        r'\b(?:within|before|after|by|no later than)\s+\d+\s+(?:days|weeks|months|years)\b',
        r'\b\d+\s+(?:day|week|month|year)s?\b',
        r'\b(?:immediately|promptly|forthwith|annually|monthly|quarterly)\b'
    ]
    
    for pattern in timeframe_patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        entities['timeframes'].extend(matches)
    
    # Clean up and deduplicate
    for key in entities:
        if isinstance(entities[key], list) and entities[key] and isinstance(entities[key][0], str):
            entities[key] = list(set([item.lower() for item in entities[key]]))
    
    return entities


@tool(args_schema=RulePatternsInput)
def identify_rule_patterns(text: str) -> List[Dict[str, Any]]:
    """
    Identify common legal rule patterns in legislation text.
    
    Args:
        text: Legislation text to analyze
        
    Returns:
        List of identified rule patterns with metadata
    """
    patterns = []
    
    # If-then patterns (conditional rules)
    if_then_pattern = r'(?:If|When|Where)\s+([^,]+),\s*(?:then\s+)?([^.]+)'
    matches = re.findall(if_then_pattern, text, re.IGNORECASE | re.DOTALL)
    for condition, action in matches:
        patterns.append({
            'type': 'conditional',
            'pattern': 'if-then',
            'condition': condition.strip(),
            'action': action.strip(),
            'confidence': 0.8
        })
    
    # Shall/Must patterns (requirements)
    requirement_pattern = r'([^.]+?)\s+(?:shall|must)\s+([^.]+)'
    matches = re.findall(requirement_pattern, text, re.IGNORECASE)
    for subject, requirement in matches:
        patterns.append({
            'type': 'requirement',
            'pattern': 'shall-must',
            'subject': subject.strip(),
            'requirement': requirement.strip(),
            'confidence': 0.9
        })
    
    # Prohibition patterns
    prohibition_pattern = r'([^.]+?)\s+(?:shall not|must not|may not|prohibited from)\s+([^.]+)'
    matches = re.findall(prohibition_pattern, text, re.IGNORECASE)
    for subject, prohibition in matches:
        patterns.append({
            'type': 'prohibition',
            'pattern': 'shall-not',
            'subject': subject.strip(),
            'prohibition': prohibition.strip(),
            'confidence': 0.9
        })
    
    # Exception patterns
    exception_pattern = r'(?:except|unless|provided that|notwithstanding)\s+([^,]+),\s*([^.]+)'
    matches = re.findall(exception_pattern, text, re.IGNORECASE | re.DOTALL)
    for exception_condition, exception_action in matches:
        patterns.append({
            'type': 'exception',
            'pattern': 'except-unless',
            'condition': exception_condition.strip(),
            'action': exception_action.strip(),
            'confidence': 0.7
        })
    
    # Penalty patterns
    penalty_pattern = r'(?:violation|breach|failure to comply)[^.]*?(?:shall result in|subject to|punishable by)\s+([^.]+)'
    matches = re.findall(penalty_pattern, text, re.IGNORECASE | re.DOTALL)
    for penalty in matches:
        patterns.append({
            'type': 'penalty',
            'pattern': 'violation-penalty',
            'penalty': penalty.strip(),
            'confidence': 0.8
        })
    
    return patterns


@tool(args_schema=ConvertRulesInput)
def convert_to_json_rules(rules: List[Dict[str, Any]], entities: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Convert extracted legal rules into json-rules-engine compatible format.
    
    Args:
        rules: List of extracted legal rules
        entities: Dictionary of legal entities and definitions
        
    Returns:
        List of JSON rules compatible with json-rules-engine
    """
    json_rules = []
    
    for i, rule in enumerate(rules):
        rule_id = f"rule_{i+1}"
        
        if rule['type'] == 'conditional':
            # Convert if-then rules
            json_rule = {
                "conditions": {
                    "all": [
                        {
                            "fact": "legislation_context",
                            "operator": "contains",
                            "value": rule['condition'].lower(),
                            "path": "$.conditions"
                        }
                    ]
                },
                "event": {
                    "type": "conditional_rule",
                    "params": {
                        "rule_id": rule_id,
                        "action": rule['action'],
                        "condition": rule['condition'],
                        "confidence": rule.get('confidence', 0.5)
                    }
                }
            }
            
        elif rule['type'] == 'requirement':
            # Convert shall/must requirements
            json_rule = {
                "conditions": {
                    "all": [
                        {
                            "fact": "subject_context",
                            "operator": "equal",
                            "value": rule['subject'].lower(),
                            "path": "$.subject"
                        },
                        {
                            "fact": "action_required",
                            "operator": "equal",
                            "value": True
                        }
                    ]
                },
                "event": {
                    "type": "requirement_rule",
                    "params": {
                        "rule_id": rule_id,
                        "subject": rule['subject'],
                        "requirement": rule['requirement'],
                        "mandatory": True,
                        "confidence": rule.get('confidence', 0.9)
                    }
                }
            }
            
        elif rule['type'] == 'prohibition':
            # Convert prohibition rules
            json_rule = {
                "conditions": {
                    "all": [
                        {
                            "fact": "subject_context",
                            "operator": "equal",
                            "value": rule['subject'].lower(),
                            "path": "$.subject"
                        },
                        {
                            "fact": "action_prohibited",
                            "operator": "equal",
                            "value": True
                        }
                    ]
                },
                "event": {
                    "type": "prohibition_rule",
                    "params": {
                        "rule_id": rule_id,
                        "subject": rule['subject'],
                        "prohibition": rule['prohibition'],
                        "mandatory": True,
                        "confidence": rule.get('confidence', 0.9)
                    }
                }
            }
            
        elif rule['type'] == 'exception':
            # Convert exception rules
            json_rule = {
                "conditions": {
                    "any": [
                        {
                            "fact": "exception_context",
                            "operator": "contains",
                            "value": rule['condition'].lower(),
                            "path": "$.conditions"
                        }
                    ]
                },
                "event": {
                    "type": "exception_rule",
                    "params": {
                        "rule_id": rule_id,
                        "condition": rule['condition'],
                        "action": rule['action'],
                        "overrides": True,
                        "confidence": rule.get('confidence', 0.7)
                    }
                }
            }
            
        elif rule['type'] == 'penalty':
            # Convert penalty rules
            json_rule = {
                "conditions": {
                    "all": [
                        {
                            "fact": "violation_detected",
                            "operator": "equal",
                            "value": True
                        },
                        {
                            "fact": "compliance_status",
                            "operator": "equal",
                            "value": "non_compliant"
                        }
                    ]
                },
                "event": {
                    "type": "penalty_rule",
                    "params": {
                        "rule_id": rule_id,
                        "penalty": rule['penalty'],
                        "severity": "high",
                        "confidence": rule.get('confidence', 0.8)
                    }
                }
            }
        
        # Add metadata and priority
        json_rule["priority"] = rule.get('priority', 50)
        json_rule["metadata"] = {
            "source": "legislation",
            "rule_type": rule['type'],
            "extracted_by": "langgraph_o3_mini_agent",
            "entities": entities
        }
        
        json_rules.append(json_rule)
    
    return json_rules


@tool(args_schema=ValidateRulesInput)
def validate_json_rules(json_rules: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Validate the generated JSON rules for compatibility with json-rules-engine.
    
    Args:
        json_rules: List of JSON rules to validate
        
    Returns:
        Validation report with errors and warnings
    """
    validation_report = {
        "valid": True,
        "errors": [],
        "warnings": [],
        "rule_count": len(json_rules),
        "validated_rules": []
    }
    
    required_fields = ["conditions", "event"]
    valid_operators = [
        "equal", "notEqual", "lessThan", "lessThanInclusive", 
        "greaterThan", "greaterThanInclusive", "in", "notIn", 
        "contains", "doesNotContain", "regex"
    ]
    
    for i, rule in enumerate(json_rules):
        rule_errors = []
        rule_warnings = []
        
        # Check required fields
        for field in required_fields:
            if field not in rule:
                rule_errors.append(f"Missing required field: {field}")
        
        # Validate conditions structure
        if "conditions" in rule:
            conditions = rule["conditions"]
            if not isinstance(conditions, dict):
                rule_errors.append("Conditions must be an object")
            else:
                # Check for valid logical operators
                logical_ops = ["all", "any", "not"]
                if not any(op in conditions for op in logical_ops):
                    rule_errors.append("Conditions must contain 'all', 'any', or 'not' operator")
                
                # Validate individual conditions
                for logical_op in logical_ops:
                    if logical_op in conditions:
                        condition_list = conditions[logical_op]
                        if logical_op == "not":
                            # 'not' should contain a single condition
                            if not isinstance(condition_list, dict):
                                rule_errors.append("'not' operator must contain a single condition object")
                        else:
                            # 'all' and 'any' should contain arrays
                            if not isinstance(condition_list, list):
                                rule_errors.append(f"'{logical_op}' operator must contain an array of conditions")
                            else:
                                for j, condition in enumerate(condition_list):
                                    if not isinstance(condition, dict):
                                        rule_errors.append(f"Condition {j} must be an object")
                                        continue
                                    
                                    # Check required condition fields
                                    if "fact" not in condition:
                                        rule_errors.append(f"Condition {j} missing 'fact' field")
                                    if "operator" not in condition:
                                        rule_errors.append(f"Condition {j} missing 'operator' field")
                                    elif condition["operator"] not in valid_operators:
                                        rule_warnings.append(f"Condition {j} uses unknown operator: {condition['operator']}")
                                    if "value" not in condition:
                                        rule_warnings.append(f"Condition {j} missing 'value' field")
        
        # Validate event structure
        if "event" in rule:
            event = rule["event"]
            if not isinstance(event, dict):
                rule_errors.append("Event must be an object")
            elif "type" not in event:
                rule_warnings.append("Event missing 'type' field")
        
        # Validate priority
        if "priority" in rule:
            if not isinstance(rule["priority"], (int, float)):
                rule_errors.append("Priority must be a number")
            elif rule["priority"] < 0 or rule["priority"] > 100:
                rule_warnings.append("Priority should be between 0 and 100")
        
        # Add rule validation results
        rule_validation = {
            "rule_index": i,
            "valid": len(rule_errors) == 0,
            "errors": rule_errors,
            "warnings": rule_warnings
        }
        
        validation_report["validated_rules"].append(rule_validation)
        validation_report["errors"].extend(rule_errors)
        validation_report["warnings"].extend(rule_warnings)
        
        if rule_errors:
            validation_report["valid"] = False
    
    return validation_report


# o3-mini Agent Setup

def create_o3_mini_agent():
    """Create a LangGraph agent specifically configured for o3-mini reasoning model"""
    
    # Initialize o3-mini model with optimized reasoning configuration
    model = ChatOpenAI(
        model="o3-mini",
        temperature=0,
        model_kwargs={
            "reasoning_effort": "medium"  # Balance between speed and accuracy
        }
    )
    
    # Available tools for the agent
    tools = [
        parse_legislation_structure,
        extract_legal_entities,
        identify_rule_patterns,
        convert_to_json_rules,
        validate_json_rules
    ]
    
    # Define system message optimized for o3-mini reasoning
    system_message = """You are an expert legal analyst and rules engineer with advanced reasoning capabilities. Your specialty is converting legislation into precise, machine-readable JSON rules.

REASONING APPROACH:
Use your enhanced reasoning to:
1. Carefully parse complex legal language and nested structures
2. Identify implicit rules and relationships between legal concepts
3. Resolve ambiguities through contextual analysis
4. Ensure accurate semantic translation to machine format

TASK WORKFLOW:
1. Parse legislation structure (sections, articles, subsections)
2. Extract all legal entities and definitions
3. Identify rule patterns (requirements, prohibitions, conditions, exceptions, penalties)
4. Convert patterns into json-rules-engine compatible format
5. Validate generated rules for correctness

QUALITY STANDARDS:
- Each rule must be unambiguous and executable
- Maintain legal precision while ensuring machine readability
- Preserve the intent and scope of original legislation
- Generate comprehensive validation reports

Use the provided tools systematically and leverage your reasoning capabilities to produce high-quality, validated JSON rules."""
    
    # Create memory for conversation state
    memory = MemorySaver()
    
    # Create the react agent with o3-mini
    agent = create_react_agent(
        model=model,
        tools=tools,
        checkpointer=memory,
        prompt=system_message
    )
    
    return agent


# Main Processing Functions

async def process_legislation_with_o3_mini(
    legislation_text: str,
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Process legislation text using o3-mini reasoning model and convert to JSON rules.
    
    Args:
        legislation_text: The legislation text to process
        config: Optional configuration for the agent
        
    Returns:
        Dictionary containing the processed results
    """
    
    # Create the o3-mini agent
    agent = create_o3_mini_agent()
    
    # Default config
    if config is None:
        config = {"configurable": {"thread_id": "o3_mini_legislation_session"}}
    
    # Create optimized prompt for o3-mini reasoning
    prompt = f"""Analyze and convert the following legislation into machine-readable JSON rules using your advanced reasoning capabilities:

LEGISLATION TEXT:
{legislation_text}

REASONING INSTRUCTIONS:
Think step by step through the legal structure and requirements. Consider:
- What are the explicit rules and requirements?
- What are the implicit conditions and exceptions?
- How do different sections relate to each other?
- What are the enforcement mechanisms and penalties?

PROCESSING STEPS:
1. Parse the complete structure to understand the legislative framework
2. Extract all legal entities, definitions, and key terms
3. Identify all rule patterns using pattern recognition
4. Convert each pattern into precise json-rules-engine format
5. Validate the generated rules for completeness and correctness

Provide comprehensive JSON rules that accurately represent the legislation's requirements in a format directly compatible with json-rules-engine."""

    # Process with o3-mini reasoning
    response = await agent.ainvoke(
        {"messages": [HumanMessage(content=prompt)]},
        config=config
    )
    
    return {
        "status": "completed",
        "model_used": "o3-mini",
        "original_text": legislation_text,
        "messages": response["messages"],
        "processing_method": "o3_mini_agent"
    }


def process_legislation_sync(
    legislation_text: str,
    config: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Synchronous wrapper for o3-mini legislation processing.
    
    Args:
        legislation_text: The legislation text to process
        config: Optional configuration for the agent
        
    Returns:
        Dictionary containing the processed results
    """
    
    async def _process_async():
        return await process_legislation_with_o3_mini(legislation_text, config)
    
    # Handle event loop management
    try:
        loop = asyncio.get_running_loop()
        # Use thread pool for existing event loop
        import concurrent.futures
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future = executor.submit(asyncio.run, _process_async())
            return future.result()
    except RuntimeError:
        # No running event loop, use asyncio.run()
        return asyncio.run(_process_async())


# Demo and Testing Functions

def test_o3_mini_demo():
    """Test o3-mini processing with sample legislation"""
    
    sample_legislation = """
    SECTION 1. DEFINITIONS
    
    For the purposes of this Act:
    (a) "Vehicle" means any motorized conveyance designed for transportation on public roads.
    (b) "Driver" means any person operating a vehicle on a public road.
    (c) "Speed limit" means the maximum lawful speed for vehicles on a particular road segment.
    
    SECTION 2. SPEED REGULATIONS
    
    (a) No person shall operate a vehicle at a speed greater than the posted speed limit.
    (b) If weather conditions are hazardous, drivers must reduce speed to maintain safe operation.
    (c) Emergency vehicles may exceed speed limits when responding to emergencies, provided warning signals are activated.
    
    SECTION 3. PENALTIES
    
    (a) Any person who violates Section 2(a) shall be subject to a fine of not less than $100 and not more than $500.
    (b) Repeat violations within 12 months shall result in license suspension for 30 days.
    """
    
    print("ðŸ¤– Testing o3-mini legislation processing...")
    print(f"ðŸ“„ Processing {len(sample_legislation)} characters of legislation text")
    
    try:
        result = process_legislation_sync(sample_legislation)
        
        print(f"âœ… o3-mini processing completed successfully!")
        print(f"ðŸ“Š Status: {result['status']}")
        print(f"ðŸ§  Model: {result['model_used']}")
        print(f"ðŸ’¬ Messages exchanged: {len(result['messages'])}")
        
        # Extract JSON rules from the conversation
        json_rules = []
        for msg in result['messages']:
            if hasattr(msg, 'content') and 'json' in msg.content.lower():
                print("ðŸ“‹ Found JSON rules in conversation")
                break
        
        print("\nðŸ” Sample conversation excerpt:")
        if result['messages']:
            last_msg = result['messages'][-1]
            if hasattr(last_msg, 'content'):
                print(f"Agent: {last_msg.content[:300]}...")
        
        return result
        
    except Exception as e:
        print(f"âŒ o3-mini processing failed: {e}")
        print(f"ðŸ”§ Error type: {type(e).__name__}")
        raise


# File Processing

def process_file(file_path: str, output_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Process legislation from a text file using o3-mini.
    
    Args:
        file_path: Path to the legislation text file
        output_path: Optional path to save the JSON rules
        
    Returns:
        Dictionary containing the processed results
    """
    try:
        # Read the legislation file
        with open(file_path, 'r', encoding='utf-8') as f:
            legislation_text = f.read()
        
        print(f"ðŸ“– Reading legislation from: {file_path}")
        print(f"ðŸ“ Text length: {len(legislation_text)} characters")
        
        # Process with o3-mini
        result = process_legislation_sync(legislation_text)
        
        # Save results if output path provided
        if output_path and result.get('json_rules'):
            with open(output_path, 'w') as f:
                json.dump(result['json_rules'], f, indent=2)
            print(f"ðŸ’¾ Rules saved to: {output_path}")
        
        return result
        
    except FileNotFoundError:
        print(f"âŒ File not found: {file_path}")
        return {"status": "error", "message": "File not found"}
    except Exception as e:
        print(f"âŒ Error processing file: {e}")
        return {"status": "error", "message": str(e)}


# Main execution
if __name__ == "__main__":
    print("ðŸš€ o3-mini Legislation Processing Demo")
    print("="*50)
    test_o3_mini_demo()


# Usage Documentation
"""
FOCUSED o3-mini LEGISLATION PROCESSOR

This system is specifically designed to work with OpenAI's o3-mini reasoning model
for converting legislation into machine-readable JSON rules.

REQUIREMENTS:
- OpenAI API key with o3-mini access
- pip install langgraph langchain-openai langchain-core

SETUP:
export OPENAI_API_KEY="your-openai-api-key"

USAGE:

1. Quick Demo:
   >>> test_o3_mini_demo()

2. Process Text:
   >>> result = process_legislation_sync("Your legislation text...")

3. Process File:
   >>> result = process_file("law.txt", "rules.json")

4. Async Processing (Jupyter):
   >>> result = await process_legislation_with_o3_mini("Your text...")

FEATURES:
- o3-mini reasoning model with medium reasoning effort
- Strict Pydantic tool schemas for compatibility
- Comprehensive legal pattern recognition
- json-rules-engine compatible output
- Advanced reasoning for complex legal structures

OUTPUT:
The system generates JSON rules compatible with json-rules-engine,
validated for correctness and ready for production use.
"""
