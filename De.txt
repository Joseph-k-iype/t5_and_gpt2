"""
Advanced ELDM Field Mapping System with Full Hierarchical Graph RAG
Multiple Search Methods: Keyword, BM25, TF-IDF, Fuzzy, Vector, Fulltext, Hybrid, Graph RAG
Ensures complete ELDM ingestion: Name (with Description) -> Entity -> Conceptual Entity
"""

import os
import json
import re
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, TypedDict, Annotated, Tuple, Set
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
from scipy.stats import zscore
import operator
from collections import Counter
import math

# OpenAI and LangChain imports
import openai
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# FalkorDB
from falkordb import FalkorDB

# Additional search libraries
from rapidfuzz import fuzz, process
from sklearn.feature_extraction.text import TfidfVectorizer
from rank_bm25 import BM25Okapi

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

# OpenAI API Configuration
BASE_URL = "https://your-openai-gateway.company.com/v1"
API_KEY = "your-api-key-here"
REASONING_MODEL = "o3-mini"
EMBEDDING_MODEL = "text-embedding-3-large"
EMBEDDING_DIMENSIONS = 3072

# FalkorDB Configuration
FALKORDB_HOST = "localhost"
FALKORDB_PORT = 6379
GRAPH_NAME = "ELDM_MAPPING"

# File Paths
TRANSACTION_FILE = "transaction_fields.xlsx"
ELDM_FILE = "eldm_attributes.xlsx"
OUTPUT_FILE = "eldm_mapping_results.xlsx"

# Search Configuration
HYBRID_SEARCH_ALPHA = 0.6  # Weight for vector vs full-text
FUZZY_THRESHOLD = 70  # Minimum fuzzy match score (0-100)

# Confidence Thresholds
HIGH_CONFIDENCE_THRESHOLD = 0.85
MEDIUM_CONFIDENCE_THRESHOLD = 0.70
LOW_CONFIDENCE_THRESHOLD = 0.50

# Processing Configuration
BATCH_SIZE = 50
TOP_K_CANDIDATES = 5


# ============================================================================
# UTILITY FUNCTIONS
# ============================================================================

def sanitize_fulltext_query(query: str, max_length: int = 200) -> str:
    """Sanitize text for RediSearch full-text queries"""
    if not query or not isinstance(query, str):
        return ""
    
    query = query.strip()
    
    # Replace problematic characters
    replacements = {
        '(': ' ', ')': ' ', '[': ' ', ']': ' ', '{': ' ', '}': ' ',
        '"': ' ', "'": ' ', '`': ' ', '\\': ' ', '/': ' ', '|': ' ',
        '&': ' ', '^': ' ', '~': ' ', '*': ' ', ':': ' ', ';': ' ',
        ',': ' ', '.': ' ', '!': ' ', '?': ' ', '<': ' ', '>': ' ',
        '=': ' ', '+': ' ', '%': ' ', '$': ' ', '#': ' ', '@': ' ',
    }
    
    for char, replacement in replacements.items():
        query = query.replace(char, replacement)
    
    query = re.sub(r'\s+', ' ', query)
    words = query.split()
    words = [word.strip('-_') for word in words if word.strip('-_')]
    query = ' '.join(words)
    
    if len(query) > max_length:
        query = query[:max_length]
    
    query = query.strip()
    
    if len(query) < 2:
        return ""
    
    return query


def extract_keywords(text: str, max_keywords: int = 10) -> str:
    """Extract meaningful keywords from text"""
    if not text or not isinstance(text, str):
        return ""
    
    stop_words = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
        'should', 'could', 'may', 'might', 'must', 'can', 'this', 'that',
        'these', 'those', 'it', 'its', 'their', 'there', 'where', 'when'
    }
    
    words = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]{1,}\b', text.lower())
    keywords = [w for w in words if w not in stop_words and len(w) >= 3]
    
    seen = set()
    unique_keywords = []
    for kw in keywords:
        if kw not in seen:
            seen.add(kw)
            unique_keywords.append(kw)
    
    unique_keywords = unique_keywords[:max_keywords]
    return ' '.join(unique_keywords)


def tokenize(text: str) -> List[str]:
    """Tokenize text for BM25 and TF-IDF"""
    if not text:
        return []
    words = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]{2,}\b', text.lower())
    return words


# ============================================================================
# DATA MODELS
# ============================================================================

@dataclass
class TransactionField:
    """Represents a field from the transaction file"""
    tt_file_name: str
    tt_column_name: str
    standardised_name: str
    is_primary_key: bool
    comment: str
    data_type: str
    creation_sql: str
    transformation_sql: str

    def get_context(self) -> str:
        """Get rich context for this field"""
        context = f"""
Field: {self.tt_column_name}
Standardised Name: {self.standardised_name}
File: {self.tt_file_name}
Data Type: {self.data_type}
Primary Key: {self.is_primary_key}
Description: {self.comment}

SQL Context:
Creation: {self.creation_sql}
Transformation: {self.transformation_sql}
"""
        return context.strip()

    def get_searchable_text(self) -> str:
        """Get text for embedding"""
        parts = [
            self.tt_column_name,
            self.standardised_name,
            self.comment,
            self.data_type,
            f"primary_key_{self.is_primary_key}"
        ]
        return " ".join([p for p in parts if p and str(p).strip()])
    
    def get_fulltext_keywords(self) -> str:
        """Get sanitized keywords for full-text search"""
        important_text = f"{self.tt_column_name} {self.standardised_name} {self.comment} {self.data_type}"
        keywords = extract_keywords(important_text, max_keywords=8)
        return sanitize_fulltext_query(keywords)


@dataclass
class ELDMAttribute:
    """Represents an ELDM Attribute (Name with Description)"""
    name: str
    description: str
    entity: Optional[str]
    conceptual_entity: Optional[str]
    full_path: str
    embedding: Optional[np.ndarray] = None

    def get_searchable_text(self) -> str:
        """Get text representation for embedding and search"""
        parts = [self.name, self.description, self.entity or '', self.conceptual_entity or '']
        return " ".join([p for p in parts if p and str(p).strip()])


@dataclass
class ELDMEntity:
    """Represents an ELDM Entity with all its attributes"""
    name: str
    conceptual_entity: Optional[str]
    attributes: List[str]
    embedding: Optional[np.ndarray] = None

    def get_searchable_text(self) -> str:
        """Get text representation"""
        parts = [
            self.name,
            self.conceptual_entity or '',
            ' '.join(self.attributes)
        ]
        return " ".join([p for p in parts if p and str(p).strip()])


@dataclass
class ELDMConceptualEntity:
    """Represents an ELDM Conceptual Entity with all its entities"""
    name: str
    entities: List[str]
    embedding: Optional[np.ndarray] = None

    def get_searchable_text(self) -> str:
        """Get text representation"""
        parts = [self.name] + self.entities
        return " ".join([p for p in parts if p and str(p).strip()])


@dataclass
class MappingResult:
    """Represents a mapping result with confidence scores"""
    transaction_field: str
    mapped_node_name: str
    mapped_node_type: str
    eldm_attribute_name: str
    eldm_entity: str
    eldm_conceptual_entity: str
    eldm_description: str
    confidence_score: float
    vector_similarity: float
    fulltext_score: float
    keyword_score: float
    bm25_score: float
    tfidf_score: float
    fuzzy_score: float
    hybrid_score: float
    graph_rag_score: float
    reasoning_confidence: float
    validation_score: float
    reasoning_explanation: str
    validation_notes: str
    statistical_metrics: Dict[str, float]
    confidence_level: str
    retrieval_method: str
    hierarchy_path: str
    timestamp: str


class GraphState(TypedDict):
    """State for the LangGraph workflow"""
    transaction_field: TransactionField
    keyword_candidates: List[Dict[str, Any]]
    bm25_candidates: List[Dict[str, Any]]
    tfidf_candidates: List[Dict[str, Any]]
    fuzzy_candidates: List[Dict[str, Any]]
    vector_candidates: List[Dict[str, Any]]
    fulltext_candidates: List[Dict[str, Any]]
    hybrid_candidates: List[Dict[str, Any]]
    graph_rag_candidates: List[Dict[str, Any]]
    final_candidates: List[Dict[str, Any]]
    mapping_proposals: List[Dict[str, Any]]
    validation_results: List[Dict[str, Any]]
    final_mapping: Optional[MappingResult]
    messages: Annotated[List, operator.add]
    iteration_count: int
    memory_context: Dict[str, Any]


# ============================================================================
# EMBEDDING SERVICE
# ============================================================================

class EmbeddingService:
    """Direct OpenAI API embedding service"""

    def __init__(self):
        self.client = openai.OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY
        )
        logger.info(f"Initialized EmbeddingService with model: {EMBEDDING_MODEL}")

    def create_embedding(self, text: str) -> np.ndarray:
        """Create embedding for a single text"""
        try:
            response = self.client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text,
                dimensions=EMBEDDING_DIMENSIONS
            )
            embedding = np.array(response.data[0].embedding)
            return embedding
        except Exception as e:
            logger.error(f"Error creating embedding: {e}")
            raise

    def create_embeddings_batch(self, texts: List[str]) -> List[np.ndarray]:
        """Create embeddings for multiple texts"""
        try:
            response = self.client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=texts,
                dimensions=EMBEDDING_DIMENSIONS
            )
            embeddings = [np.array(item.embedding) for item in response.data]
            logger.info(f"Created {len(embeddings)} embeddings in batch")
            return embeddings
        except Exception as e:
            logger.error(f"Error creating batch embeddings: {e}")
            raise


# ============================================================================
# MULTI-METHOD SEARCH ENGINE
# ============================================================================

class MultiMethodSearchEngine:
    """
    Combines multiple search methods:
    1. Keyword (exact/partial matching)
    2. BM25 (ranking algorithm)
    3. TF-IDF (term frequency)
    4. Fuzzy (Levenshtein distance)
    """
    
    def __init__(self):
        self.corpus_data: List[Dict[str, Any]] = []
        self.bm25: Optional[BM25Okapi] = None
        self.tfidf_vectorizer: Optional[TfidfVectorizer] = None
        self.tfidf_matrix = None
        logger.info("Initialized MultiMethodSearchEngine")
    
    def index_corpus(self, attributes: List[ELDMAttribute], 
                     entities: List[ELDMEntity], 
                     conceptuals: List[ELDMConceptualEntity]):
        """Index all ELDM data for search"""
        self.corpus_data = []
        
        # Index attributes
        for attr in attributes:
            self.corpus_data.append({
                'node_type': 'ATTRIBUTE',
                'name': attr.name,
                'description': attr.description,
                'entity': attr.entity or '',
                'conceptual_entity': attr.conceptual_entity or '',
                'full_path': attr.full_path,
                'searchable_text': attr.get_searchable_text()
            })
        
        # Index entities
        for entity in entities:
            self.corpus_data.append({
                'node_type': 'ENTITY',
                'name': entity.name,
                'description': f"Entity with {len(entity.attributes)} attributes",
                'entity': entity.name,
                'conceptual_entity': entity.conceptual_entity or '',
                'full_path': entity.name,
                'searchable_text': entity.get_searchable_text()
            })
        
        # Index conceptual entities
        for conceptual in conceptuals:
            self.corpus_data.append({
                'node_type': 'CONCEPTUAL_ENTITY',
                'name': conceptual.name,
                'description': f"Conceptual entity with {len(conceptual.entities)} entities",
                'entity': '',
                'conceptual_entity': conceptual.name,
                'full_path': conceptual.name,
                'searchable_text': conceptual.get_searchable_text()
            })
        
        logger.info(f"Indexed {len(self.corpus_data)} items in corpus")
        
        # Build BM25 index
        tokenized_corpus = [tokenize(item['searchable_text']) for item in self.corpus_data]
        self.bm25 = BM25Okapi(tokenized_corpus)
        logger.info("Built BM25 index")
        
        # Build TF-IDF index
        corpus_texts = [item['searchable_text'] for item in self.corpus_data]
        self.tfidf_vectorizer = TfidfVectorizer(
            tokenizer=tokenize,
            lowercase=True,
            max_features=1000
        )
        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(corpus_texts)
        logger.info("Built TF-IDF index")
    
    def keyword_search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Simple keyword matching (exact and partial)"""
        if not query:
            return []
        
        query_lower = query.lower()
        query_tokens = set(tokenize(query))
        
        results = []
        for item in self.corpus_data:
            score = 0.0
            name_lower = item['name'].lower()
            desc_lower = item['description'].lower()
            
            # Exact name match
            if query_lower == name_lower:
                score += 10.0
            # Partial name match
            elif query_lower in name_lower:
                score += 5.0
            elif name_lower in query_lower:
                score += 3.0
            
            # Description match
            if query_lower in desc_lower:
                score += 2.0
            
            # Token overlap
            item_tokens = set(tokenize(item['searchable_text']))
            overlap = len(query_tokens & item_tokens)
            if overlap > 0:
                score += overlap * 0.5
            
            if score > 0:
                results.append({
                    'node_type': item['node_type'],
                    'name': item['name'],
                    'description': item['description'],
                    'full_path': item['full_path'],
                    'entity': item['entity'],
                    'conceptual_entity': item['conceptual_entity'],
                    'similarity': min(score / 10.0, 1.0),  # Normalize
                    'method': 'KEYWORD'
                })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"Keyword search returned {len(results[:top_k])} candidates")
        return results[:top_k]
    
    def bm25_search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """BM25 ranking search"""
        if not self.bm25 or not query:
            return []
        
        query_tokens = tokenize(query)
        if not query_tokens:
            return []
        
        scores = self.bm25.get_scores(query_tokens)
        
        # Get top-k indices
        top_indices = np.argsort(scores)[::-1][:top_k * 2]
        
        results = []
        max_score = max(scores) if len(scores) > 0 else 1.0
        
        for idx in top_indices:
            if scores[idx] > 0:
                item = self.corpus_data[idx]
                results.append({
                    'node_type': item['node_type'],
                    'name': item['name'],
                    'description': item['description'],
                    'full_path': item['full_path'],
                    'entity': item['entity'],
                    'conceptual_entity': item['conceptual_entity'],
                    'similarity': scores[idx] / max_score if max_score > 0 else 0.0,
                    'method': 'BM25'
                })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"BM25 search returned {len(results[:top_k])} candidates")
        return results[:top_k]
    
    def tfidf_search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """TF-IDF cosine similarity search"""
        if not self.tfidf_vectorizer or self.tfidf_matrix is None or not query:
            return []
        
        try:
            query_vec = self.tfidf_vectorizer.transform([query])
            cosine_similarities = (self.tfidf_matrix * query_vec.T).toarray().flatten()
            
            top_indices = np.argsort(cosine_similarities)[::-1][:top_k * 2]
            
            results = []
            for idx in top_indices:
                if cosine_similarities[idx] > 0:
                    item = self.corpus_data[idx]
                    results.append({
                        'node_type': item['node_type'],
                        'name': item['name'],
                        'description': item['description'],
                        'full_path': item['full_path'],
                        'entity': item['entity'],
                        'conceptual_entity': item['conceptual_entity'],
                        'similarity': float(cosine_similarities[idx]),
                        'method': 'TFIDF'
                    })
            
            results.sort(key=lambda x: x['similarity'], reverse=True)
            logger.info(f"TF-IDF search returned {len(results[:top_k])} candidates")
            return results[:top_k]
        except Exception as e:
            logger.warning(f"TF-IDF search error: {e}")
            return []
    
    def fuzzy_search(self, query: str, top_k: int = 5, threshold: int = FUZZY_THRESHOLD) -> List[Dict[str, Any]]:
        """Fuzzy string matching using RapidFuzz"""
        if not query:
            return []
        
        results = []
        
        for item in self.corpus_data:
            # Check name similarity
            name_score = fuzz.ratio(query.lower(), item['name'].lower())
            
            # Check partial ratio
            partial_score = fuzz.partial_ratio(query.lower(), item['name'].lower())
            
            # Check token sort ratio
            token_score = fuzz.token_sort_ratio(query.lower(), item['searchable_text'].lower())
            
            # Take best score
            max_score = max(name_score, partial_score, token_score * 0.8)
            
            if max_score >= threshold:
                results.append({
                    'node_type': item['node_type'],
                    'name': item['name'],
                    'description': item['description'],
                    'full_path': item['full_path'],
                    'entity': item['entity'],
                    'conceptual_entity': item['conceptual_entity'],
                    'similarity': max_score / 100.0,  # Normalize to 0-1
                    'method': 'FUZZY'
                })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"Fuzzy search returned {len(results[:top_k])} candidates")
        return results[:top_k]


# ============================================================================
# FALKORDB FULL HIERARCHICAL GRAPH RAG
# ============================================================================

class ELDMFullHierarchicalGraphRAG:
    """FalkorDB-based Graph RAG with complete hierarchy support"""

    def __init__(self):
        self.db = FalkorDB(
            host=FALKORDB_HOST,
            port=FALKORDB_PORT
        )
        self.graph = self.db.select_graph(GRAPH_NAME)
        logger.info(f"Connected to FalkorDB graph: {GRAPH_NAME}")

    def clear_graph(self):
        """Clear all data from the graph"""
        self.graph.query("MATCH (n) DETACH DELETE n")
        logger.info("Cleared FalkorDB graph")

    def create_indexes(self):
        """Create vector and full-text indexes for ALL node types"""
        try:
            attr_vector_query = f"""
            CREATE VECTOR INDEX FOR (a:Attribute) ON (a.embedding) 
            OPTIONS {{
                dimension: {EMBEDDING_DIMENSIONS}, 
                similarityFunction: 'cosine',
                M: 32,
                efConstruction: 200,
                efRuntime: 10
            }}
            """
            self.graph.query(attr_vector_query)
            logger.info("✅ Created vector index for Attributes")
        except Exception as e:
            logger.warning(f"Attribute vector index note: {e}")

        try:
            entity_vector_query = f"""
            CREATE VECTOR INDEX FOR (e:Entity) ON (e.embedding) 
            OPTIONS {{
                dimension: {EMBEDDING_DIMENSIONS}, 
                similarityFunction: 'cosine',
                M: 32,
                efConstruction: 200,
                efRuntime: 10
            }}
            """
            self.graph.query(entity_vector_query)
            logger.info("✅ Created vector index for Entities")
        except Exception as e:
            logger.warning(f"Entity vector index note: {e}")

        try:
            conceptual_vector_query = f"""
            CREATE VECTOR INDEX FOR (c:ConceptualEntity) ON (c.embedding) 
            OPTIONS {{
                dimension: {EMBEDDING_DIMENSIONS}, 
                similarityFunction: 'cosine',
                M: 32,
                efConstruction: 200,
                efRuntime: 10
            }}
            """
            self.graph.query(conceptual_vector_query)
            logger.info("✅ Created vector index for Conceptual Entities")
        except Exception as e:
            logger.warning(f"Conceptual Entity vector index note: {e}")

        try:
            attr_ft_query = "CALL db.idx.fulltext.createNodeIndex('Attribute', 'name', 'description', 'searchable_text')"
            self.graph.query(attr_ft_query)
            logger.info("✅ Created full-text index for Attributes")
        except Exception as e:
            logger.warning(f"Attribute full-text index note: {e}")

        try:
            entity_ft_query = "CALL db.idx.fulltext.createNodeIndex('Entity', 'name', 'searchable_text')"
            self.graph.query(entity_ft_query)
            logger.info("✅ Created full-text index for Entities")
        except Exception as e:
            logger.warning(f"Entity full-text index note: {e}")

        try:
            conceptual_ft_query = "CALL db.idx.fulltext.createNodeIndex('ConceptualEntity', 'name', 'searchable_text')"
            self.graph.query(conceptual_ft_query)
            logger.info("✅ Created full-text index for Conceptual Entities")
        except Exception as e:
            logger.warning(f"Conceptual Entity full-text index note: {e}")

        try:
            self.graph.query("CREATE INDEX FOR (a:Attribute) ON (a.name)")
            self.graph.query("CREATE INDEX FOR (e:Entity) ON (e.name)")
            self.graph.query("CREATE INDEX FOR (c:ConceptualEntity) ON (c.name)")
            self.graph.query("CREATE INDEX FOR (t:TransactionField) ON (t.name)")
            self.graph.query("CREATE INDEX FOR (t:TransactionField) ON (t.data_type)")
            logger.info("✅ Created property indexes")
        except Exception as e:
            logger.warning(f"Property index note: {e}")
        
        logger.info("✅ Index creation completed for full hierarchy")

    def store_full_hierarchy(self, attributes: List[ELDMAttribute], 
                            entities: List[ELDMEntity], 
                            conceptuals: List[ELDMConceptualEntity]):
        """Store complete ELDM hierarchy with ALL data"""
        
        logger.info(f"Starting to store {len(attributes)} Attributes...")
        stored_attributes = 0
        
        # Store Attributes with ALL fields (Name + Description)
        for i, attr in enumerate(attributes, 1):
            try:
                embedding_list = attr.embedding.tolist()
                searchable_text = sanitize_fulltext_query(attr.get_searchable_text())
                
                query = """
                CREATE (a:Attribute {
                    name: $name,
                    description: $description,
                    entity_name: $entity_name,
                    conceptual_entity_name: $conceptual_entity_name,
                    full_path: $full_path,
                    searchable_text: $searchable_text,
                    embedding: vecf32($embedding),
                    created_at: $created_at
                })
                """
                self.graph.query(query, {
                    'name': attr.name,
                    'description': attr.description,
                    'entity_name': attr.entity or '',
                    'conceptual_entity_name': attr.conceptual_entity or '',
                    'full_path': attr.full_path,
                    'searchable_text': searchable_text,
                    'embedding': embedding_list,
                    'created_at': datetime.now().isoformat()
                })
                stored_attributes += 1
                
                if i % 100 == 0:
                    logger.info(f"Stored {i}/{len(attributes)} attributes...")
            except Exception as e:
                logger.error(f"Error storing attribute {attr.name}: {e}")

        logger.info(f"✅ Created {stored_attributes}/{len(attributes)} Attribute nodes with embeddings")

        # Store Entities
        logger.info(f"Starting to store {len(entities)} Entities...")
        stored_entities = 0
        
        for entity in entities:
            try:
                embedding_list = entity.embedding.tolist()
                searchable_text = sanitize_fulltext_query(entity.get_searchable_text())
                
                query = """
                CREATE (e:Entity {
                    name: $name,
                    conceptual_entity_name: $conceptual_entity_name,
                    searchable_text: $searchable_text,
                    embedding: vecf32($embedding),
                    attribute_count: $attribute_count,
                    created_at: $created_at
                })
                """
                self.graph.query(query, {
                    'name': entity.name,
                    'conceptual_entity_name': entity.conceptual_entity or '',
                    'searchable_text': searchable_text,
                    'embedding': embedding_list,
                    'attribute_count': len(entity.attributes),
                    'created_at': datetime.now().isoformat()
                })
                stored_entities += 1
            except Exception as e:
                logger.error(f"Error storing entity {entity.name}: {e}")

        logger.info(f"✅ Created {stored_entities}/{len(entities)} Entity nodes with embeddings")

        # Store Conceptual Entities
        logger.info(f"Starting to store {len(conceptuals)} Conceptual Entities...")
        stored_conceptuals = 0
        
        for conceptual in conceptuals:
            try:
                embedding_list = conceptual.embedding.tolist()
                searchable_text = sanitize_fulltext_query(conceptual.get_searchable_text())
                
                query = """
                CREATE (c:ConceptualEntity {
                    name: $name,
                    searchable_text: $searchable_text,
                    embedding: vecf32($embedding),
                    entity_count: $entity_count,
                    created_at: $created_at
                })
                """
                self.graph.query(query, {
                    'name': conceptual.name,
                    'searchable_text': searchable_text,
                    'embedding': embedding_list,
                    'entity_count': len(conceptual.entities),
                    'created_at': datetime.now().isoformat()
                })
                stored_conceptuals += 1
            except Exception as e:
                logger.error(f"Error storing conceptual entity {conceptual.name}: {e}")

        logger.info(f"✅ Created {stored_conceptuals}/{len(conceptuals)} Conceptual Entity nodes with embeddings")

        # Create relationships
        entity_rel_query = """
        MATCH (a:Attribute)
        WHERE a.entity_name <> ''
        MATCH (e:Entity {name: a.entity_name})
        MERGE (a)-[:BELONGS_TO]->(e)
        MERGE (e)-[:HAS_ATTRIBUTE]->(a)
        """
        result = self.graph.query(entity_rel_query)
        logger.info(f"✅ Created Attribute -> Entity relationships")

        conceptual_rel_query = """
        MATCH (e:Entity)
        WHERE e.conceptual_entity_name <> ''
        MATCH (c:ConceptualEntity {name: e.conceptual_entity_name})
        MERGE (e)-[:BELONGS_TO]->(c)
        MERGE (c)-[:HAS_ENTITY]->(e)
        """
        result = self.graph.query(conceptual_rel_query)
        logger.info(f"✅ Created Entity -> Conceptual Entity relationships")

        # Verify ingestion
        verify_query = """
        MATCH (a:Attribute) WITH count(a) as attr_count
        MATCH (e:Entity) WITH attr_count, count(e) as entity_count
        MATCH (c:ConceptualEntity) WITH attr_count, entity_count, count(c) as conceptual_count
        RETURN attr_count, entity_count, conceptual_count
        """
        result = self.graph.query(verify_query)
        if result.result_set:
            counts = result.result_set[0]
            logger.info(f"✅ VERIFICATION: {counts[0]} Attributes, {counts[1]} Entities, {counts[2]} Conceptual Entities in graph")

    def multi_level_vector_search(self, query_embedding: np.ndarray, top_k: int = 5) -> List[Dict[str, Any]]:
        """Vector search across ALL hierarchy levels"""
        candidates = []

        # Search Attributes
        attr_query = f"""
        CALL db.idx.vector.queryNodes('Attribute', 'embedding', {top_k}, vecf32($embedding))
        YIELD node, score
        OPTIONAL MATCH (node)-[:BELONGS_TO]->(e:Entity)
        OPTIONAL MATCH (e)-[:BELONGS_TO]->(c:ConceptualEntity)
        RETURN 'ATTRIBUTE' as node_type,
               node.name as name,
               node.description as description,
               node.full_path as full_path,
               e.name as entity,
               c.name as conceptual_entity,
               score
        ORDER BY score DESC
        """

        result = self.graph.query(attr_query, {'embedding': query_embedding.tolist()})
        for record in result.result_set:
            candidates.append({
                'node_type': str(record[0]),
                'name': str(record[1]),
                'description': str(record[2] or ''),
                'full_path': str(record[3]),
                'entity': str(record[4] or ''),
                'conceptual_entity': str(record[5] or ''),
                'similarity': float(record[6]),  # Convert to native Python float
                'method': 'VECTOR',
                'level_boost': 1.0
            })

        # Search Entities
        entity_query = f"""
        CALL db.idx.vector.queryNodes('Entity', 'embedding', {top_k}, vecf32($embedding))
        YIELD node, score
        OPTIONAL MATCH (node)-[:BELONGS_TO]->(c:ConceptualEntity)
        OPTIONAL MATCH (node)-[:HAS_ATTRIBUTE]->(a:Attribute)
        WITH node, score, c, COLLECT(a.name) as attributes
        RETURN 'ENTITY' as node_type,
               node.name as name,
               attributes as description,
               node.name as full_path,
               node.name as entity,
               c.name as conceptual_entity,
               score
        ORDER BY score DESC
        """

        result = self.graph.query(entity_query, {'embedding': query_embedding.tolist()})
        for record in result.result_set:
            attr_list = record[2] if record[2] else []
            candidates.append({
                'node_type': str(record[0]),
                'name': str(record[1]),
                'description': f"Entity with {len(attr_list)} attributes",
                'full_path': str(record[3]),
                'entity': str(record[4] or ''),
                'conceptual_entity': str(record[5] or ''),
                'similarity': float(record[6]),  # Convert to native Python float
                'method': 'VECTOR',
                'level_boost': 0.8
            })

        # Search Conceptual Entities
        conceptual_query = f"""
        CALL db.idx.vector.queryNodes('ConceptualEntity', 'embedding', {top_k}, vecf32($embedding))
        YIELD node, score
        OPTIONAL MATCH (node)-[:HAS_ENTITY]->(e:Entity)
        WITH node, score, COLLECT(e.name) as entities
        RETURN 'CONCEPTUAL_ENTITY' as node_type,
               node.name as name,
               entities as description,
               node.name as full_path,
               '' as entity,
               node.name as conceptual_entity,
               score
        ORDER BY score DESC
        """

        result = self.graph.query(conceptual_query, {'embedding': query_embedding.tolist()})
        for record in result.result_set:
            entity_list = record[2] if record[2] else []
            candidates.append({
                'node_type': str(record[0]),
                'name': str(record[1]),
                'description': f"Conceptual entity with {len(entity_list)} entities",
                'full_path': str(record[3]),
                'entity': str(record[4] or ''),
                'conceptual_entity': str(record[5] or ''),
                'similarity': float(record[6]),  # Convert to native Python float
                'method': 'VECTOR',
                'level_boost': 0.6
            })

        for candidate in candidates:
            candidate['similarity'] = float(candidate['similarity'] * candidate['level_boost'])

        candidates.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"Vector search returned {len(candidates[:top_k*2])} candidates")
        return candidates[:top_k * 2]

    def multi_level_fulltext_search(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Full-text search across ALL hierarchy levels"""
        candidates = []
        
        sanitized_query = sanitize_fulltext_query(query_text, max_length=150)
        
        if len(sanitized_query) < 3:
            sanitized_query = extract_keywords(query_text, max_keywords=6)
            sanitized_query = sanitize_fulltext_query(sanitized_query)
        
        if len(sanitized_query) < 2:
            logger.info("Query too short after sanitization, skipping full-text search")
            return []
        
        logger.info(f"Full-text search with query: '{sanitized_query}'")

        # Search Attributes
        try:
            attr_query = f"""
            CALL db.idx.fulltext.queryNodes('Attribute', $query_text)
            YIELD node, score
            OPTIONAL MATCH (node)-[:BELONGS_TO]->(e:Entity)
            OPTIONAL MATCH (e)-[:BELONGS_TO]->(c:ConceptualEntity)
            RETURN 'ATTRIBUTE' as node_type,
                   node.name as name,
                   node.description as description,
                   node.full_path as full_path,
                   e.name as entity,
                   c.name as conceptual_entity,
                   score
            ORDER BY score DESC
            LIMIT {top_k}
            """
            
            result = self.graph.query(attr_query, {'query_text': sanitized_query})
            for record in result.result_set:
                candidates.append({
                    'node_type': str(record[0]),
                    'name': str(record[1]),
                    'description': str(record[2] or ''),
                    'full_path': str(record[3]),
                    'entity': str(record[4] or ''),
                    'conceptual_entity': str(record[5] or ''),
                    'similarity': float(record[6]),  # Convert to native Python float
                    'method': 'FULLTEXT',
                    'level_boost': 1.0
                })
        except Exception as e:
            logger.warning(f"Attribute full-text search error: {e}")

        # Search Entities
        try:
            entity_query = f"""
            CALL db.idx.fulltext.queryNodes('Entity', $query_text)
            YIELD node, score
            OPTIONAL MATCH (node)-[:BELONGS_TO]->(c:ConceptualEntity)
            RETURN 'ENTITY' as node_type,
                   node.name as name,
                   node.searchable_text as description,
                   node.name as full_path,
                   node.name as entity,
                   c.name as conceptual_entity,
                   score
            ORDER BY score DESC
            LIMIT {top_k}
            """
            
            result = self.graph.query(entity_query, {'query_text': sanitized_query})
            for record in result.result_set:
                candidates.append({
                    'node_type': str(record[0]),
                    'name': str(record[1]),
                    'description': str(record[2] or ''),
                    'full_path': str(record[3]),
                    'entity': str(record[4] or ''),
                    'conceptual_entity': str(record[5] or ''),
                    'similarity': float(record[6]),  # Convert to native Python float
                    'method': 'FULLTEXT',
                    'level_boost': 0.8
                })
        except Exception as e:
            logger.warning(f"Entity full-text search error: {e}")

        # Search Conceptual Entities
        try:
            conceptual_query = f"""
            CALL db.idx.fulltext.queryNodes('ConceptualEntity', $query_text)
            YIELD node, score
            RETURN 'CONCEPTUAL_ENTITY' as node_type,
                   node.name as name,
                   node.searchable_text as description,
                   node.name as full_path,
                   '' as entity,
                   node.name as conceptual_entity,
                   score
            ORDER BY score DESC
            LIMIT {top_k}
            """
            
            result = self.graph.query(conceptual_query, {'query_text': sanitized_query})
            for record in result.result_set:
                candidates.append({
                    'node_type': str(record[0]),
                    'name': str(record[1]),
                    'description': str(record[2] or ''),
                    'full_path': str(record[3]),
                    'entity': str(record[4] or ''),
                    'conceptual_entity': str(record[5] or ''),
                    'similarity': float(record[6]),  # Convert to native Python float
                    'method': 'FULLTEXT',
                    'level_boost': 0.6
                })
        except Exception as e:
            logger.warning(f"Conceptual Entity full-text search error: {e}")

        if not candidates:
            return []

        for candidate in candidates:
            candidate['similarity'] = float(candidate['similarity'] * candidate['level_boost'])

        candidates.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"Full-text search returned {len(candidates[:top_k*2])} candidates")
        return candidates[:top_k * 2]

    def hybrid_search(self, query_embedding: np.ndarray, query_text: str, 
                     top_k: int = 5, alpha: float = HYBRID_SEARCH_ALPHA) -> List[Dict[str, Any]]:
        """Hybrid search combining vector and full-text"""
        vector_results = self.multi_level_vector_search(query_embedding, top_k * 2)
        fulltext_results = self.multi_level_fulltext_search(query_text, top_k * 2)

        if not fulltext_results:
            return vector_results[:top_k]
        
        combined_scores = {}
        metadata = {}

        vector_scores = {r['name']: r['similarity'] for r in vector_results}
        max_vector = max(vector_scores.values()) if vector_scores else 1.0

        fulltext_scores = {r['name']: r['similarity'] for r in fulltext_results}
        max_fulltext = max(fulltext_scores.values()) if fulltext_scores else 1.0

        for r in vector_results + fulltext_results:
            if r['name'] not in metadata:
                metadata[r['name']] = r

        for name in metadata.keys():
            v_score = vector_scores.get(name, 0.0) / max_vector if max_vector > 0 else 0.0
            f_score = fulltext_scores.get(name, 0.0) / max_fulltext if max_fulltext > 0 else 0.0
            combined_scores[name] = alpha * v_score + (1 - alpha) * f_score

        sorted_names = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]

        candidates = []
        for name, hybrid_score in sorted_names:
            record = metadata[name]
            candidates.append({
                'node_type': record['node_type'],
                'name': record['name'],
                'description': record['description'],
                'full_path': record['full_path'],
                'entity': record['entity'],
                'conceptual_entity': record['conceptual_entity'],
                'similarity': hybrid_score,
                'vector_score': vector_scores.get(name, 0.0),
                'fulltext_score': fulltext_scores.get(name, 0.0),
                'method': 'HYBRID'
            })

        logger.info(f"Hybrid search returned {len(candidates)} candidates")
        return candidates

    def graph_rag_search(self, query_embedding: np.ndarray, query_text: str, 
                        transaction_field: TransactionField, top_k: int = 5) -> List[Dict[str, Any]]:
        """Graph RAG with historical patterns"""
        candidates = self.hybrid_search(query_embedding, query_text, top_k * 2)

        similar_mappings_query = """
        MATCH (t:TransactionField)-[r:MAPPED_TO]->(n)
        WHERE t.data_type = $data_type 
           OR t.file_name = $file_name
           OR t.standardised_name CONTAINS $partial_name
        WITH n, labels(n) as node_labels, COUNT(r) as mapping_frequency, AVG(r.confidence_score) as avg_confidence
        OPTIONAL MATCH (n)-[:BELONGS_TO*]->(parent)
        RETURN n.name as name,
               node_labels[0] as node_type,
               mapping_frequency,
               avg_confidence,
               COLLECT(DISTINCT parent.name) as ancestors
        ORDER BY mapping_frequency DESC, avg_confidence DESC
        LIMIT $top_k
        """

        params = {
            'data_type': transaction_field.data_type,
            'file_name': transaction_field.tt_file_name,
            'partial_name': transaction_field.standardised_name[:10] if transaction_field.standardised_name else "",
            'top_k': top_k * 2
        }

        result = self.graph.query(similar_mappings_query, params)

        historical_boost = {}
        for record in result.result_set:
            name = record[0]
            mapping_freq = record[2]
            avg_conf = record[3]
            historical_boost[name] = {
                'boost': mapping_freq * avg_conf * 0.2,
                'frequency': mapping_freq,
                'avg_confidence': avg_conf
            }

        enhanced_candidates = []
        for candidate in candidates:
            name = candidate['name']
            base_score = candidate['similarity']

            hist_boost = 0.0
            mapping_freq = 0
            if name in historical_boost:
                hist_boost = historical_boost[name]['boost']
                mapping_freq = historical_boost[name]['frequency']

            enhanced_score = min(base_score + hist_boost, 1.0)

            candidate['similarity'] = enhanced_score
            candidate['graph_rag_score'] = hist_boost
            candidate['mapping_frequency'] = mapping_freq
            candidate['method'] = 'GRAPH_RAG'

            enhanced_candidates.append(candidate)

        enhanced_candidates.sort(key=lambda x: x['similarity'], reverse=True)
        logger.info(f"Graph RAG returned {len(enhanced_candidates[:top_k])} candidates")
        return enhanced_candidates[:top_k]

    def store_mapping_result(self, result: MappingResult, transaction_field: TransactionField):
        """Store mapping result"""
        query = """
        MATCH (n {name: $node_name})
        WHERE n:Attribute OR n:Entity OR n:ConceptualEntity
        MERGE (t:TransactionField {
            name: $transaction_field,
            file_name: $file_name,
            data_type: $data_type,
            standardised_name: $standardised_name
        })
        MERGE (t)-[r:MAPPED_TO]->(n)
        SET r.confidence_score = $confidence_score,
            r.vector_similarity = $vector_similarity,
            r.hybrid_score = $hybrid_score,
            r.mapped_node_type = $mapped_node_type,
            r.reasoning_confidence = $reasoning_confidence,
            r.validation_score = $validation_score,
            r.confidence_level = $confidence_level,
            r.retrieval_method = $retrieval_method,
            r.reasoning_explanation = $reasoning_explanation,
            r.timestamp = $timestamp
        """

        params = {
            'node_name': result.mapped_node_name,
            'transaction_field': result.transaction_field,
            'file_name': transaction_field.tt_file_name,
            'data_type': transaction_field.data_type,
            'standardised_name': transaction_field.standardised_name,
            'confidence_score': result.confidence_score,
            'vector_similarity': result.vector_similarity,
            'hybrid_score': result.hybrid_score,
            'mapped_node_type': result.mapped_node_type,
            'reasoning_confidence': result.reasoning_confidence,
            'validation_score': result.validation_score,
            'confidence_level': result.confidence_level,
            'retrieval_method': result.retrieval_method,
            'reasoning_explanation': result.reasoning_explanation,
            'timestamp': result.timestamp
        }
        self.graph.query(query, params)


# ============================================================================
# AGENT PROMPTS
# ============================================================================

MAPPING_AGENT_SYSTEM_PROMPT = """You are a data mapping aggregation specialist.

Your task is to review candidates from multiple search methods and identify the TOP candidates for detailed evaluation.

You receive candidates from 8 different search methods:
1. Keyword Search - exact/partial matching
2. BM25 - ranking algorithm
3. TF-IDF - term frequency
4. Fuzzy - string similarity
5. Vector - semantic embeddings
6. Fulltext - RediSearch
7. Hybrid - vector + fulltext
8. Graph RAG - historical patterns

Consolidate and rank the candidates. Return the top 10 candidates sorted by confidence.

Response must be JSON:
{{
    "top_candidates": [
        {{
            "name": "candidate name",
            "node_type": "ATTRIBUTE/ENTITY/CONCEPTUAL_ENTITY",
            "description": "description",
            "aggregate_score": 0.0-1.0,
            "supporting_methods": ["method1", "method2"],
            "reasoning": "why this is a strong candidate"
        }}
    ]
}}
"""

VALIDATION_AGENT_SYSTEM_PROMPT = """You are a senior data mapping validator and decision maker.

Your critical task is to:
1. EVALUATE ALL candidates from all search methods
2. SELECT THE BEST MATCH based on semantic correctness, granularity, and evidence
3. Provide detailed reasoning for your selection

ELDM HIERARCHY:
- Name (Attribute) - MOST GRANULAR (strongly preferred)
- Entity - Parent grouping (use if no suitable attribute)
- Conceptual Entity - High-level (last resort)

You receive candidates with scores from 8 different search methods.

SELECTION CRITERIA:
1. Semantic correctness (most important)
2. Granularity (prefer Attribute > Entity > Conceptual Entity)
3. Consistency across multiple search methods (high confidence)
4. Historical usage patterns (if available)

Response must be JSON:
{{
    "selected_candidate": {{
        "name": "exact name of selected candidate",
        "node_type": "ATTRIBUTE or ENTITY or CONCEPTUAL_ENTITY"
    }},
    "confidence_score": 0.0-1.0,
    "detailed_reasoning": "comprehensive explanation of why this is the best match",
    "supporting_evidence": [
        "evidence point 1",
        "evidence point 2"
    ],
    "alternative_candidates": [
        {{
            "name": "alternative name",
            "why_not_selected": "reason"
        }}
    ],
    "concerns": ["any concerns or caveats"]
}}
"""

SUPERVISOR_AGENT_SYSTEM_PROMPT = """You are the chief data architect making final approval decisions.

Review the validator's selection and either APPROVE or REJECT it.

APPROVAL CRITERIA:
- Semantic correctness is clear
- Confidence score meets thresholds
- Evidence is compelling
- No major concerns

CONFIDENCE LEVELS:
- HIGH: ≥ 0.85 (strong match, multiple methods agree)
- MEDIUM: 0.70-0.84 (good match, some uncertainty)
- LOW: 0.50-0.69 (weak match, needs review)
- REJECT: < 0.50 (insufficient confidence)

Response must be JSON:
{{
    "final_decision": "APPROVE or REJECT",
    "confidence_level": "HIGH or MEDIUM or LOW or REJECTED",
    "overall_confidence_score": 0.0-1.0,
    "final_reasoning": "concise justification",
    "action_required": "any follow-up actions"
}}
"""


# ============================================================================
# MULTI-AGENT SYSTEM
# ============================================================================

class MappingAgent:
    """Agent for aggregating candidates from all search methods"""

    def __init__(self):
        self.llm = ChatOpenAI(model=REASONING_MODEL, base_url=BASE_URL, api_key=API_KEY)
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", MAPPING_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])

    def aggregate_candidates(self, state: GraphState) -> GraphState:
        field = state['transaction_field']
        
        # Collect ALL candidates from ALL methods
        all_candidates = []
        
        for method_key in ['keyword_candidates', 'bm25_candidates', 'tfidf_candidates', 
                          'fuzzy_candidates', 'vector_candidates', 'fulltext_candidates', 
                          'hybrid_candidates', 'graph_rag_candidates']:
            candidates = state.get(method_key, [])
            for c in candidates:
                # Ensure all values are native Python types
                all_candidates.append({
                    'name': str(c['name']),
                    'node_type': str(c.get('node_type', 'UNKNOWN')),
                    'description': str(c.get('description', '')),
                    'full_path': str(c.get('full_path', '')),
                    'entity': str(c.get('entity', '')),
                    'conceptual_entity': str(c.get('conceptual_entity', '')),
                    'similarity': float(c.get('similarity', 0.0)),
                    'method': str(c.get('method', 'UNKNOWN'))
                })
        
        # Aggregate by name
        name_aggregates = {}
        for c in all_candidates:
            name = c['name']
            if name not in name_aggregates:
                name_aggregates[name] = {
                    'candidate': c,
                    'methods': [],
                    'scores': []
                }
            name_aggregates[name]['methods'].append(c['method'])
            name_aggregates[name]['scores'].append(c['similarity'])
        
        # Calculate aggregate scores
        aggregated = []
        for name, data in name_aggregates.items():
            avg_score = float(np.mean(data['scores']))
            max_score = float(np.max(data['scores']))
            method_count = len(set(data['methods']))
            
            # Boost for multiple methods agreeing
            aggregate_score = float((avg_score * 0.7 + max_score * 0.3) * (1 + 0.05 * method_count))
            aggregate_score = float(min(aggregate_score, 1.0))
            
            aggregated.append({
                'name': str(name),
                'node_type': str(data['candidate']['node_type']),
                'description': str(data['candidate']['description']),
                'full_path': str(data['candidate']['full_path']),
                'entity': str(data['candidate']['entity']),
                'conceptual_entity': str(data['candidate']['conceptual_entity']),
                'aggregate_score': aggregate_score,
                'avg_score': avg_score,
                'max_score': max_score,
                'methods': data['methods'],
                'method_count': int(method_count)
            })
        
        aggregated.sort(key=lambda x: x['aggregate_score'], reverse=True)
        top_candidates = aggregated[:15]
        
        input_text = f"""
Transaction Field:
{field.get_context()}

Aggregated Candidates from ALL search methods:
"""
        for i, cand in enumerate(top_candidates, 1):
            input_text += f"""
{i}. Name: {cand['name']}
   Type: {cand['node_type']}
   Description: {cand['description']}
   Aggregate Score: {cand['aggregate_score']:.4f}
   Supporting Methods ({cand['method_count']}): {', '.join(set(cand['methods']))}
   Path: {cand['full_path']}
"""

        try:
            messages = state.get('messages', [])
            response = (self.prompt | self.llm).invoke({"messages": messages, "input": input_text})
            
            state['final_candidates'] = top_candidates
            state['messages'].extend([HumanMessage(content=input_text), AIMessage(content=response.content)])
            
            logger.info(f"Aggregated {len(aggregated)} unique candidates from {len(all_candidates)} total results")
            
        except Exception as e:
            logger.error(f"Error in aggregate_candidates: {e}")
            state['final_candidates'] = top_candidates

        return state


class ValidationAgent:
    """Agent for evaluating ALL candidates and SELECTING the best match"""

    def __init__(self):
        self.llm = ChatOpenAI(model=REASONING_MODEL, base_url=BASE_URL, api_key=API_KEY)
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", VALIDATION_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])

    def select_best_mapping(self, state: GraphState) -> GraphState:
        field = state['transaction_field']
        candidates = state.get('final_candidates', [])
        
        if not candidates:
            logger.warning("No candidates available for validation")
            return state

        input_text = f"""
Transaction Field to Map:
Name: {field.tt_column_name}
Standardised: {field.standardised_name}
Description: {field.comment}
Data Type: {field.data_type}
File: {field.tt_file_name}

ALL CANDIDATES (evaluate each carefully):
"""
        for i, cand in enumerate(candidates[:10], 1):
            input_text += f"""
{i}. Name: {cand['name']}
   Type: {cand['node_type']}
   Description: {cand['description']}
   Hierarchy: {cand['full_path']}
   Aggregate Score: {cand['aggregate_score']:.4f}
   Avg Score: {cand['avg_score']:.4f}
   Max Score: {cand['max_score']:.4f}
   Supporting Methods ({cand['method_count']}): {', '.join(set(cand['methods']))}
"""

        input_text += """
TASK: Evaluate ALL candidates and SELECT THE BEST MATCH.
Consider semantic correctness, granularity (prefer Attribute level), and consistency across methods.
"""

        try:
            messages = state.get('messages', [])
            response = (self.prompt | self.llm).invoke({"messages": messages, "input": input_text})

            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            selection = json.loads(content)
            state['mapping_proposals'].append(selection)
            state['messages'].extend([HumanMessage(content=input_text), AIMessage(content=response.content)])

            selected_name = selection['selected_candidate']['name']
            confidence = float(selection['confidence_score'])
            logger.info(f"Validator selected: {selected_name} (confidence: {confidence:.3f})")

        except Exception as e:
            logger.error(f"Error in select_best_mapping: {e}")
            # Fallback to top candidate
            if candidates:
                selection = {
                    'selected_candidate': {
                        'name': candidates[0]['name'],
                        'node_type': candidates[0]['node_type']
                    },
                    'confidence_score': float(candidates[0]['aggregate_score']),
                    'detailed_reasoning': f"Fallback selection: {str(e)}",
                    'supporting_evidence': ['Top aggregate score'],
                    'alternative_candidates': [],
                    'concerns': ['Error in validation']
                }
                state['mapping_proposals'].append(selection)

        return state


class SupervisorAgent:
    """Agent for final approval decisions"""

    def __init__(self):
        self.llm = ChatOpenAI(model=REASONING_MODEL, base_url=BASE_URL, api_key=API_KEY)
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", SUPERVISOR_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])

    def make_final_decision(self, state: GraphState) -> GraphState:
        field = state['transaction_field']
        proposals = state['mapping_proposals']
        candidates = state.get('final_candidates', [])

        if not proposals:
            logger.warning("No proposals for supervisor to review")
            return state

        selection = proposals[-1]
        selected_name = selection['selected_candidate']['name']
        selected_type = selection['selected_candidate']['node_type']
        
        # Find the selected candidate in the list
        selected_candidate = next((c for c in candidates if c['name'] == selected_name), 
                                  candidates[0] if candidates else None)

        if not selected_candidate:
            logger.warning(f"Could not find selected candidate: {selected_name}")
            return state

        input_text = f"""
Transaction Field: {field.tt_column_name}

Validator's Selection:
- Name: {selected_name}
- Type: {selected_type}
- Confidence: {selection['confidence_score']:.3f}

Reasoning:
{selection['detailed_reasoning']}

Supporting Evidence:
{', '.join(selection['supporting_evidence'])}

Concerns:
{', '.join(selection.get('concerns', ['None']))}

Candidate Details:
- Aggregate Score: {selected_candidate['aggregate_score']:.4f}
- Supporting Methods: {', '.join(set(selected_candidate['methods']))}

Make final APPROVE/REJECT decision.
"""

        try:
            messages = state.get('messages', [])
            response = (self.prompt | self.llm).invoke({"messages": messages, "input": input_text})

            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            decision = json.loads(content)

            if decision['final_decision'] == 'APPROVE':
                # Determine hierarchy details
                if selected_type == 'ATTRIBUTE':
                    attr_name = str(selected_candidate['name'])
                    entity_name = str(selected_candidate.get('entity', ''))
                    conceptual_name = str(selected_candidate.get('conceptual_entity', ''))
                elif selected_type == 'ENTITY':
                    attr_name = ''
                    entity_name = str(selected_candidate['name'])
                    conceptual_name = str(selected_candidate.get('conceptual_entity', ''))
                else:
                    attr_name = ''
                    entity_name = ''
                    conceptual_name = str(selected_candidate['name'])

                # Calculate statistical metrics
                all_similarities = [float(c['aggregate_score']) for c in candidates]
                z_scores = zscore(all_similarities) if len(all_similarities) > 1 else [0.0]
                top_similarity = float(selected_candidate['aggregate_score'])
                top_z_score = float(z_scores[0]) if all_similarities and all_similarities[0] == top_similarity else 0.0
                gap_to_second = float(top_similarity - all_similarities[1]) if len(all_similarities) > 1 else float(top_similarity)

                result = MappingResult(
                    transaction_field=str(field.tt_column_name),
                    mapped_node_name=str(selected_name),
                    mapped_node_type=str(selected_type),
                    eldm_attribute_name=attr_name,
                    eldm_entity=entity_name,
                    eldm_conceptual_entity=conceptual_name,
                    eldm_description=str(selected_candidate.get('description', '')),
                    confidence_score=float(decision['overall_confidence_score']),
                    vector_similarity=float(selected_candidate.get('max_score', 0.0)),
                    fulltext_score=0.0,
                    keyword_score=0.0,
                    bm25_score=0.0,
                    tfidf_score=0.0,
                    fuzzy_score=0.0,
                    hybrid_score=float(selected_candidate.get('avg_score', 0.0)),
                    graph_rag_score=float(selected_candidate.get('aggregate_score', 0.0)),
                    reasoning_confidence=float(selection['confidence_score']),
                    validation_score=float(selection['confidence_score']),
                    reasoning_explanation=str(selection['detailed_reasoning']),
                    validation_notes=str(decision['final_reasoning']),
                    statistical_metrics={
                        'semantic_similarity': float(top_similarity),
                        'z_score': float(top_z_score),
                        'gap_to_second_best': float(gap_to_second)
                    },
                    confidence_level=str(decision['confidence_level']),
                    retrieval_method=f"MULTI_METHOD({selected_candidate['method_count']})",
                    hierarchy_path=str(selected_candidate.get('full_path', selected_name)),
                    timestamp=str(datetime.now().isoformat())
                )
                state['final_mapping'] = result
                logger.info(f"✅ APPROVED: {result.mapped_node_name} ({result.mapped_node_type}) - {result.confidence_level}")
            else:
                logger.info(f"❌ REJECTED: {selected_name}")

            state['messages'].extend([HumanMessage(content=input_text), AIMessage(content=response.content)])

        except Exception as e:
            logger.error(f"Error in final_decision: {e}")

        return state


# ============================================================================
# WORKFLOW & MAIN SYSTEM
# ============================================================================

def create_mapping_workflow() -> StateGraph:
    """Create the mapping workflow with proper agent orchestration"""
    workflow = StateGraph(GraphState)
    workflow.add_node("aggregate_candidates", MappingAgent().aggregate_candidates)
    workflow.add_node("select_best_mapping", ValidationAgent().select_best_mapping)
    workflow.add_node("final_decision", SupervisorAgent().make_final_decision)
    workflow.set_entry_point("aggregate_candidates")
    workflow.add_edge("aggregate_candidates", "select_best_mapping")
    workflow.add_edge("select_best_mapping", "final_decision")
    workflow.add_edge("final_decision", END)
    return workflow.compile(checkpointer=MemorySaver())


class ELDMMappingSystem:
    """Complete ELDM mapping system with multiple search methods"""

    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.graph_rag = ELDMFullHierarchicalGraphRAG()
        self.multi_search = MultiMethodSearchEngine()
        self.workflow = create_mapping_workflow()
        logger.info("✅ Initialized Complete ELDM Mapping System with Multiple Search Methods")

    def load_transaction_data(self) -> List[TransactionField]:
        df = pd.read_excel(TRANSACTION_FILE)
        fields = [TransactionField(
            tt_file_name=str(row['TT File name']),
            tt_column_name=str(row['TT COLUMN/FIELD Name']),
            standardised_name=str(row.get('Standardised Name', '')),
            is_primary_key=bool(row.get('PK', False)),
            comment=str(row.get('Comment', '')),
            data_type=str(row.get('DataType', '')),
            creation_sql=str(row.get('Creation', '')),
            transformation_sql=str(row.get('Transformation', ''))
        ) for _, row in df.iterrows()]
        logger.info(f"✅ Loaded {len(fields)} transaction fields")
        return fields

    def load_eldm_full_hierarchy(self) -> Tuple[List[ELDMAttribute], List[ELDMEntity], List[ELDMConceptualEntity]]:
        """Load and create embeddings for ALL hierarchy levels - ENSURING COMPLETE INGESTION"""
        df = pd.read_excel(ELDM_FILE)
        
        logger.info(f"📊 ELDM File has {len(df)} rows")

        # Collect data with validation
        attributes = []
        entities_data = {}
        conceptuals_data = {}

        for idx, row in df.iterrows():
            try:
                name = str(row['Name']) if pd.notna(row.get('Name')) else None
                if not name or name == 'nan':
                    logger.warning(f"Row {idx}: Skipping - no Name")
                    continue
                
                description = str(row.get('Description', '')) if pd.notna(row.get('Description')) else ''
                entity = str(row.get('Entity', '')) if pd.notna(row.get('Entity')) else None
                conceptual = str(row.get('Conceptual Entity', '')) if pd.notna(row.get('Conceptual Entity')) else None

                path_parts = [p for p in [conceptual, entity, name] if p]
                full_path = ' > '.join(path_parts)

                attr = ELDMAttribute(
                    name=name,
                    description=description,
                    entity=entity,
                    conceptual_entity=conceptual,
                    full_path=full_path
                )
                attributes.append(attr)

                if entity:
                    if entity not in entities_data:
                        entities_data[entity] = {'conceptual': conceptual, 'attributes': []}
                    entities_data[entity]['attributes'].append(name)

                if conceptual:
                    if conceptual not in conceptuals_data:
                        conceptuals_data[conceptual] = {'entities': set()}
                    if entity:
                        conceptuals_data[conceptual]['entities'].add(entity)
                        
            except Exception as e:
                logger.error(f"Error processing row {idx}: {e}")

        entities = [ELDMEntity(name=name, conceptual_entity=data['conceptual'], attributes=data['attributes']) 
                   for name, data in entities_data.items()]
        conceptuals = [ELDMConceptualEntity(name=name, entities=list(data['entities'])) 
                      for name, data in conceptuals_data.items()]

        logger.info(f"✅ Loaded {len(attributes)} Attributes, {len(entities)} Entities, {len(conceptuals)} Conceptual Entities")

        # Create embeddings for ALL levels
        logger.info("🔄 Creating embeddings for Attributes...")
        attr_texts = [attr.get_searchable_text() for attr in attributes]
        for i in range(0, len(attr_texts), BATCH_SIZE):
            batch_embeddings = self.embedding_service.create_embeddings_batch(attr_texts[i:i+BATCH_SIZE])
            for j, emb in enumerate(batch_embeddings):
                attributes[i+j].embedding = emb
            if (i + BATCH_SIZE) % 200 == 0:
                logger.info(f"   Created embeddings for {min(i+BATCH_SIZE, len(attr_texts))}/{len(attr_texts)} attributes")

        logger.info("🔄 Creating embeddings for Entities...")
        entity_texts = [ent.get_searchable_text() for ent in entities]
        for i in range(0, len(entity_texts), BATCH_SIZE):
            batch_embeddings = self.embedding_service.create_embeddings_batch(entity_texts[i:i+BATCH_SIZE])
            for j, emb in enumerate(batch_embeddings):
                entities[i+j].embedding = emb

        logger.info("🔄 Creating embeddings for Conceptual Entities...")
        conceptual_texts = [con.get_searchable_text() for con in conceptuals]
        for i in range(0, len(conceptual_texts), BATCH_SIZE):
            batch_embeddings = self.embedding_service.create_embeddings_batch(conceptual_texts[i:i+BATCH_SIZE])
            for j, emb in enumerate(batch_embeddings):
                conceptuals[i+j].embedding = emb

        logger.info("✅ Created embeddings for ALL hierarchy levels")
        return attributes, entities, conceptuals

    def initialize_knowledge_graph(self):
        logger.info("🔄 Initializing full hierarchical knowledge graph...")
        self.graph_rag.clear_graph()
        attributes, entities, conceptuals = self.load_eldm_full_hierarchy()
        
        # Store in graph
        self.graph_rag.store_full_hierarchy(attributes, entities, conceptuals)
        
        # Create indexes
        self.graph_rag.create_indexes()
        
        # Index for multi-method search
        self.multi_search.index_corpus(attributes, entities, conceptuals)
        
        logger.info("✅ Full hierarchical knowledge graph initialized with ALL search methods")

    def map_single_field(self, field: TransactionField) -> Optional[MappingResult]:
        field_text = field.get_searchable_text()
        field_keywords = field.get_fulltext_keywords()
        field_embedding = self.embedding_service.create_embedding(field_text)

        # Run ALL search methods
        keyword_candidates = self.multi_search.keyword_search(field_text, TOP_K_CANDIDATES)
        bm25_candidates = self.multi_search.bm25_search(field_text, TOP_K_CANDIDATES)
        tfidf_candidates = self.multi_search.tfidf_search(field_text, TOP_K_CANDIDATES)
        fuzzy_candidates = self.multi_search.fuzzy_search(field.tt_column_name, TOP_K_CANDIDATES)
        
        vector_candidates = self.graph_rag.multi_level_vector_search(field_embedding, TOP_K_CANDIDATES)
        fulltext_candidates = self.graph_rag.multi_level_fulltext_search(field_keywords, TOP_K_CANDIDATES)
        hybrid_candidates = self.graph_rag.hybrid_search(field_embedding, field_keywords, TOP_K_CANDIDATES)
        graph_rag_candidates = self.graph_rag.graph_rag_search(field_embedding, field_keywords, field, TOP_K_CANDIDATES)

        initial_state = {
            'transaction_field': field,
            'keyword_candidates': keyword_candidates,
            'bm25_candidates': bm25_candidates,
            'tfidf_candidates': tfidf_candidates,
            'fuzzy_candidates': fuzzy_candidates,
            'vector_candidates': vector_candidates,
            'fulltext_candidates': fulltext_candidates,
            'hybrid_candidates': hybrid_candidates,
            'graph_rag_candidates': graph_rag_candidates,
            'final_candidates': graph_rag_candidates,
            'mapping_proposals': [],
            'validation_results': [],
            'final_mapping': None,
            'messages': [],
            'iteration_count': 0,
            'memory_context': {}
        }

        try:
            result = self.workflow.invoke(initial_state, {"configurable": {"thread_id": field.tt_column_name}})
            final_mapping = result.get('final_mapping')

            if final_mapping:
                self.graph_rag.store_mapping_result(final_mapping, field)
                logger.info(f"✅ Mapped: {field.tt_column_name} -> {final_mapping.mapped_node_name} ({final_mapping.mapped_node_type})")
                return final_mapping
            else:
                logger.warning(f"❌ No mapping for: {field.tt_column_name}")

        except Exception as e:
            logger.error(f"❌ Error mapping {field.tt_column_name}: {e}")

        return None

    def map_all_fields(self) -> List[MappingResult]:
        fields = self.load_transaction_data()
        results = []

        for i, field in enumerate(fields, 1):
            logger.info(f"🔄 Processing {i}/{len(fields)}: {field.tt_column_name}")
            result = self.map_single_field(field)
            if result:
                results.append(result)
            if i % 10 == 0:
                logger.info(f"📊 Progress: {i}/{len(fields)} processed, {len(results)} mapped ({len(results)/i*100:.1f}%)")

        logger.info(f"✅ Complete: {len(results)}/{len(fields)} successful mappings ({len(results)/len(fields)*100:.1f}%)")
        return results

    def export_results(self, results: List[MappingResult]):
        data = [{
            'Transaction Field': r.transaction_field,
            'Mapped To': r.mapped_node_name,
            'Mapping Level': r.mapped_node_type,
            'ELDM Attribute': r.eldm_attribute_name,
            'ELDM Entity': r.eldm_entity,
            'ELDM Conceptual Entity': r.eldm_conceptual_entity,
            'Description': r.eldm_description,
            'Hierarchy Path': r.hierarchy_path,
            'Confidence Score': r.confidence_score,
            'Confidence Level': r.confidence_level,
            'Retrieval Method': r.retrieval_method,
            'Keyword Score': r.keyword_score,
            'BM25 Score': r.bm25_score,
            'TF-IDF Score': r.tfidf_score,
            'Fuzzy Score': r.fuzzy_score,
            'Vector Score': r.vector_similarity,
            'Fulltext Score': r.fulltext_score,
            'Graph RAG Score': r.graph_rag_score,
            'Reasoning': r.reasoning_explanation,
            'Validation': r.validation_notes,
            'Timestamp': r.timestamp
        } for r in results]

        df = pd.DataFrame(data)

        with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Mapping Results', index=False)

            summary = {
                'Total Mappings': len(results),
                'ATTRIBUTE Level': len([r for r in results if r.mapped_node_type == 'ATTRIBUTE']),
                'ENTITY Level': len([r for r in results if r.mapped_node_type == 'ENTITY']),
                'CONCEPTUAL_ENTITY Level': len([r for r in results if r.mapped_node_type == 'CONCEPTUAL_ENTITY']),
                'HIGH Confidence': len([r for r in results if r.confidence_level == 'HIGH']),
                'MEDIUM Confidence': len([r for r in results if r.confidence_level == 'MEDIUM']),
                'LOW Confidence': len([r for r in results if r.confidence_level == 'LOW']),
                'Avg Confidence': np.mean([r.confidence_score for r in results]),
                'Avg Keyword Score': np.mean([r.keyword_score for r in results]),
                'Avg BM25 Score': np.mean([r.bm25_score for r in results]),
                'Avg TF-IDF Score': np.mean([r.tfidf_score for r in results]),
                'Avg Fuzzy Score': np.mean([r.fuzzy_score for r in results])
            }
            pd.DataFrame([summary]).to_excel(writer, sheet_name='Summary', index=False)

        logger.info(f"✅ Results exported to {OUTPUT_FILE}")

    def run(self):
        logger.info("=" * 80)
        logger.info("🚀 COMPLETE ELDM MAPPING SYSTEM - STARTING")
        logger.info("📋 8 Search Methods: Keyword, BM25, TF-IDF, Fuzzy, Vector, Fulltext, Hybrid, Graph RAG")
        logger.info("🌳 Full Hierarchy: Name (Attribute with Description) -> Entity -> Conceptual Entity")
        logger.info("🤖 3-Agent Workflow:")
        logger.info("   1. Mapping Agent - Aggregates candidates from all search methods")
        logger.info("   2. Validation Agent - Evaluates ALL candidates and SELECTS best match")
        logger.info("   3. Supervisor Agent - Makes final approval/rejection decision")
        logger.info("=" * 80)

        try:
            self.initialize_knowledge_graph()
            results = self.map_all_fields()
            if results:
                self.export_results(results)
            logger.info("=" * 80)
            logger.info("✅ COMPLETED SUCCESSFULLY")
            logger.info(f"✅ Mapped {len(results)} fields")
            logger.info("=" * 80)
            return results
        except Exception as e:
            logger.error(f"❌ Error: {e}")
            raise


if __name__ == "__main__":
    system = ELDMMappingSystem()
    results = system.run()

    if results:
        print(f"\n✅ Mapping completed: {len(results)} fields mapped")
        print(f"📊 Results: {OUTPUT_FILE}")

        by_level = {}
        for r in results:
            by_level[r.mapped_node_type] = by_level.get(r.mapped_node_type, 0) + 1

        print("\n🎯 Mapping Level Distribution:")
        for level, count in by_level.items():
            print(f"   {level}: {count} ({count/len(results)*100:.1f}%)")
    else:
        print("\n❌ No mappings completed")
