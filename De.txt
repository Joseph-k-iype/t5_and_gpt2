import os
import sys
import uuid
import json
import logging
import chardet
import pandas as pd
import networkx as nx
import numpy as np
from typing import Optional, Any, Dict, List, Union, Tuple, Callable, Sequence, Annotated, TypedDict, cast
from pathlib import Path
from dotenv import dotenv_values
from azure.identity import DefaultAzureCredential, get_bearer_token_provider, ClientSecretCredential
from openai import AzureOpenAI
from pydantic import BaseModel, Field, field_validator  # Updated for Pydantic v2
from langchain_openai import AzureChatOpenAI  # Updated import path
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, ToolMessage, AIMessage
from langchain_core.tools import tool, BaseTool
from langchain_core.documents import Document  # Updated import path
from langchain_core.runnables import RunnableConfig
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain, LLMChain
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from collections import namedtuple
import re
import json
from langgraph.graph import StateGraph, END  # For LangGraph
from langgraph.graph.message import add_messages  # For LangGraph message handling
from langgraph.prebuilt import create_react_agent  # For creating the React agent
from langgraph.checkpoint.memory import MemorySaver  # For persistent memory
from sklearn.metrics.pairwise import cosine_similarity

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

ENV_DIR = "env"
CONFIG_PATH = f"{ENV_DIR}/config.env"
CREDS_PATH = f"{ENV_DIR}/credentials.env"
CERT_PATH = f"{ENV_DIR}/cacert.pem"

Triple = namedtuple("Triple", ["subject", "predicate", "object"])

## Helper Functions
def is_file_readable(filepath: str)->bool:
    """Check if a file is readable."""
    if not os.path.isfile(filepath) or not os.access(filepath, os.R_OK):
        raise FileNotFoundError(f"The file '{filepath}' does not exist or is not readable")
    return True

def str_to_bool(s: str)->bool:
    """Convert a string to a boolean."""
    if s== 'True':
        return True
    elif s== 'False':
        return False
    else:
        raise ValueError(f"Invalid boolean value: {s}")

def serialize_message(message):
    """Serialize a LangChain message object to a JSON-serializable dict."""
    if isinstance(message, BaseMessage):
        return {
            "type": message.type,
            "content": message.content,
            "additional_kwargs": message.additional_kwargs
        }
    elif isinstance(message, list):
        return [serialize_message(m) for m in message]
    elif isinstance(message, dict):
        return {k: serialize_message(v) for k, v in message.items()}
    return message

## Agent State for LangGraph
class AgentState(TypedDict):
    """The state of the agent."""
    messages: List[BaseMessage]
    context: Dict[str, Any]

## OSEnv class
class OSEnv:
    def __init__(self, config_file: str, creds_file: str, certificate_path: str):
        self.var_list = []
        self.bulk_set(config_file, True)
        self.bulk_set(creds_file, False)
        self.set_certificate_path(certificate_path)
        if str_to_bool(self.get("PROXY_ENABLED", "False")):
            self.set_proxy()
        
        if str_to_bool(self.get("SECURED_ENDPOINTS", "False")):
            self.token = self.get_azure_token()
        else:
            self.token = None
        
        self.credential = self._get_credential()
        
    def _get_credential(self):
        if str_to_bool(self.get("USE_MANAGED_IDENTITY", "False")):
            return DefaultAzureCredential()
        else:
            return ClientSecretCredential(tenant_id=self.get("AZURE_TENANT_ID"), client_id=self.get("AZURE_CLIENT_ID"), client_secret=self.get("AZURE_CLIENT_SECRET"))
    
    def set_certificate_path(self, path: str):
        try:
            if not os.path.isabs(path):
                path = os.path.abspath(path)
            if not is_file_readable(path):
                raise FileNotFoundError(f"The file '{path}' does not exist or is not readable")
            
            self.set("REQUESTS_CA_BUNDLE", path)
            self.set("SSL_CERT_FILE", path)
            self.set("CURL_CA_BUNDLE", path)
        except Exception as e:
            logger.error(f"Error setting certificate path: {e}")
            raise
    
    def bulk_set(self, dotenvfile: str, print_val: bool = False)->None:
        try:
            if not os.path.isabs(dotenvfile):
                dotenvfile = os.path.abspath(dotenvfile)
            if not is_file_readable(dotenvfile):
                raise FileNotFoundError(f"The file '{dotenvfile}' does not exist or is not readable")
            temp_dict = dotenv_values(dotenvfile)
            for key, value in temp_dict.items():
                self.set(key, value, print_val)
            del temp_dict
        except Exception as e:
            logger.error(f"Error loading environment variables from {dotenvfile}: {e}")
            raise
    
    def set(self, key: str, value: str, print_val: bool = False)->None:
        try:
            os.environ[key] = value
            if key not in self.var_list:
                self.var_list.append(key)
            if print_val:
                logger.info(f"{key}: {value}")
        except Exception as e:
            logger.error(f"Error setting environment variable {key}: {e}")
            raise
    
    def get(self, key: str, default: Optional[str] = None)->str:
        try:
            return os.environ.get(key, default)
        except Exception as e:
            logger.error(f"Error getting environment variable {key}: {e}")
            raise
    
    def set_proxy(self) -> None:
        try:
            ad_username = self.get("AD_USERNAME")
            ad_password = self.get("AD_USER_PW")
            proxy_domain = self.get("HTTPS_PROXY_DOMAIN")
            if not all([ad_username, ad_password, proxy_domain]):
                raise ValueError("Proxy settings are incomplete")
            proxy_url = f"https://{ad_username}:{ad_password}@{proxy_domain}"
            self.set("HTTP_PROXY", proxy_url, print_val=False)
            self.set("HTTPS_PROXY", proxy_url, print_val=False)
            no_proxy_domains = [
                'cognitiveservices.azure.com',
                'search.windows.net',
                'openai.azure.com',
                'core.windows.net',
                'azurewebsites.net'
            ]
            self.set("NO_PROXY", ",".join(no_proxy_domains), print_val=False)
        except Exception as e:
            logger.error(f"Error setting proxy: {e}")
            raise
    
    def get_azure_token(self) -> str:
        try:
            credential = ClientSecretCredential(
                tenant_id=self.get("AZURE_TENANT_ID"),
                client_id=self.get("AZURE_CLIENT_ID"),
                client_secret=self.get("AZURE_CLIENT_SECRET")
            )
            token = credential.get_token("https://cognitiveservices.azure.com/.default")
            self.set("AZURE_TOKEN", token.token, print_val=False)
            logger.info("Azure token set")
            return token.token
        except Exception as e:
            logger.error(f"Error retrieving Azure token: {e}")
            return None
    
    def list_env_vars(self)->None:
        for var in self.var_list:
            if var in {'AZURE_TOKEN', 'AD_USER_PW', 'AZURE_CLIENT_SECRET'}:
                logger.info(f"{var}: [REDACTED]")
            else:
                logger.info(f"{var}: {os.getenv(var)}")


## embedding class + Document class
class MyDocument(BaseModel):
    id: str = ""
    text: str = ""
    embedding: List[float] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)

class EmbeddingClient:
    def __init__(self, env: OSEnv, azure_api_version: str = "2024-05-01-preview", embeddings_model: str = "text-embedding-3-large"):
        self.env = env
        self.azure_api_version = azure_api_version
        self.embeddings_model = embeddings_model
        self.direct_azure_client = self._get_direct_azure_client()
        # Deployment name may be different from model name
        self.deployment_name = self.env.get("EMBEDDING_DEPLOYMENT_NAME", embeddings_model)
    
    def _get_direct_azure_client(self):
        token_provider = get_bearer_token_provider(
            self.env.credential,
            "https://cognitiveservices.azure.com/.default"
        )
        return AzureOpenAI(
            azure_endpoint=self.env.get("AZURE_ENDPOINT", ""),
            api_version=self.azure_api_version,
            azure_ad_token_provider=token_provider
        )
    
    def generate_embeddings(self, doc: MyDocument)->MyDocument:
        try:
            response = self.direct_azure_client.embeddings.create(
                model=self.deployment_name,  # Use deployment name instead of model name
                input=doc.text,
                encoding_format="float"  # Explicitly specify the format
            ).data[0].embedding
            doc.embedding = response
            return doc
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            return doc
    
    def batch_generate_embeddings(self, docs: List[MyDocument]) -> List[MyDocument]:
        """Generate embeddings for a batch of documents."""
        try:
            # Process in batches of 16 to avoid limits
            batch_size = 16
            batched_docs = []
            
            for i in range(0, len(docs), batch_size):
                batch = docs[i:i + batch_size]
                texts = [doc.text for doc in batch]
                
                response = self.direct_azure_client.embeddings.create(
                    model=self.deployment_name,  # Use deployment name instead of model name
                    input=texts,
                    encoding_format="float"  # Explicitly specify the format
                )
                
                for j, embedding_data in enumerate(response.data):
                    batch[j].embedding = embedding_data.embedding
                
                batched_docs.extend(batch)
                logger.info(f"Generated embeddings for batch {i//batch_size + 1} of {(len(docs) - 1)//batch_size + 1}")
            
            return batched_docs
        except Exception as e:
            logger.error(f"Error generating batch embeddings: {e}")
            raise

## AzureChatbot components
class AzureChatbot:
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self._setup_chat_model()
        self.memory = ConversationBufferMemory()
        self.conversation = ConversationChain(llm=self.llm, memory=self.memory, verbose=True)
    
    def _setup_chat_model(self):
        try:
            token_provider = get_bearer_token_provider(
                self.env.credential,
                "https://cognitiveservices.azure.com/.default"
            )
            model_name = self.env.get("MODEL_NAME", "gpt-4o")
            temperature = float(self.env.get("TEMPERATURE", "0.7"))
            max_tokens = int(self.env.get("MAX_TOKENS", "800"))
            api_version = self.env.get("API_VERSION", "2024-05-01-preview")
            azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
            
            self.llm = AzureChatOpenAI(
                model_name=model_name,
                temperature=temperature,
                max_tokens=max_tokens,
                api_version=api_version,
                azure_endpoint=azure_endpoint,
                azure_ad_token_provider=token_provider
            )
        except Exception as e:
            logger.error(f"Error setting up chatbot: {e}")
            raise
    
    def classify_with_llm(self, user_input: str, pbt_options: List[Dict]) -> Dict:
        """Use the LLM to classify the user input against the PBT options."""
        try:
            # Create a prompt for the classification
            prompt_template = """
            You are an expert in data classification. You need to map a user input to the most relevant category in a database.

            User Input: {user_input}

            Available Categories:
            {pbt_options}

            Please analyze the user input and determine which category is the most contextually relevant match.
            Return only the ID of the best matching category. Do not include any explanations or additional text.
            """
            
            # Format the PBT options
            formatted_options = "\n".join([
                f"ID: {option['id']}, Name: {option['name']}, Definition: {option['definition']}" 
                for option in pbt_options
            ])
            
            # Create a prompt message
            prompt = prompt_template.format(
                user_input=user_input,
                pbt_options=formatted_options
            )
            
            # Get the classification from the LLM
            response = self.llm.invoke(prompt)
            
            # Extract the ID from the response
            result_id = response.content.strip()
            
            # Find the matching option
            for option in pbt_options:
                if str(option['id']) == result_id:
                    return option
            
            # If no exact match is found
            logger.warning(f"No exact match found for ID: {result_id}. Returning best guess.")
            return pbt_options[0]  # Return the first option as a fallback
            
        except Exception as e:
            logger.error(f"Error in LLM classification: {e}")
            return None

## PBT Data Manager Class
class PBTDataManager:
    def __init__(self, embedding_client: EmbeddingClient):
        self.embedding_client = embedding_client
        self.pbt_data = []
        self.pbt_embeddings = []
    
    def load_csv(self, csv_path: str) -> None:
        """Load PBT data from CSV file."""
        try:
            df = pd.read_csv(csv_path)
            if not all(col in df.columns for col in ['id', 'PBT_NAME', 'PBT_DEFINITION']):
                raise ValueError("CSV file must contain columns: id, PBT_NAME, PBT_DEFINITION")
            
            # Convert DataFrame to list of dictionaries
            self.pbt_data = df.to_dict('records')
            
            # Create documents for embedding
            docs = []
            for item in self.pbt_data:
                combined_text = f"{item['PBT_NAME']} - {item['PBT_DEFINITION']}"
                doc = MyDocument(
                    id=str(item['id']),
                    text=combined_text,
                    metadata={
                        'name': item['PBT_NAME'],
                        'definition': item['PBT_DEFINITION']
                    }
                )
                docs.append(doc)
            
            # Generate embeddings for all PBT items
            embedded_docs = self.embedding_client.batch_generate_embeddings(docs)
            
            # Store the embeddings
            self.pbt_embeddings = [doc.embedding for doc in embedded_docs]
            
            logger.info(f"Loaded {len(self.pbt_data)} PBT records from CSV")
        except Exception as e:
            logger.error(f"Error loading CSV: {e}")
            raise
    
    def find_similar_items(self, query_text: str, top_n: int = 5) -> List[Dict]:
        """Find the most similar PBT items to the query text."""
        try:
            # Create a document for the query
            query_doc = MyDocument(
                id="query",
                text=query_text
            )
            
            # Generate embedding for the query
            query_doc = self.embedding_client.generate_embeddings(query_doc)
            
            # Calculate similarity scores
            similarity_scores = []
            for i, embedding in enumerate(self.pbt_embeddings):
                # Calculate cosine similarity
                similarity = cosine_similarity(
                    [query_doc.embedding], 
                    [embedding]
                )[0][0]
                
                similarity_scores.append((i, similarity))
            
            # Sort by similarity (descending)
            similarity_scores.sort(key=lambda x: x[1], reverse=True)
            
            # Get the top N results
            top_results = []
            for idx, score in similarity_scores[:top_n]:
                result = self.pbt_data[idx].copy()
                result['similarity_score'] = float(score)  # Convert numpy.float to Python float
                top_results.append(result)
            
            return top_results
        except Exception as e:
            logger.error(f"Error finding similar items: {e}")
            return []

## LangGraph React Agent Tool
class PBTClassifierTool(BaseTool):
    name: str = Field("pbt_classifier")
    description: str = Field("Classifies user input against PBT (Purpose-Built Technology) database entries")
    pbt_manager: PBTDataManager = Field(exclude=True)
    
    def __init__(self, pbt_manager: PBTDataManager):
        # Initialize with proper field values
        super().__init__(name="pbt_classifier", 
                        description="Classifies user input against PBT (Purpose-Built Technology) database entries",
                        pbt_manager=pbt_manager)
        
    def _run(self, name: str, description: str) -> dict:
        """Classify the input against the PBT data."""
        combined_input = f"{name} - {description}"
        similar_items = self.pbt_manager.find_similar_items(combined_input, top_n=5)
        
        if not similar_items:
            return {"status": "error", "message": "No similar items found"}
        
        return {
            "status": "success",
            "best_match": similar_items[0],
            "similar_items": similar_items
        }

## LangGraph React Agent Class
class ReactAgent:
    def __init__(self, env: OSEnv, pbt_manager: PBTDataManager):
        self.env = env
        self.pbt_manager = pbt_manager
        self.memory_saver = MemorySaver()
        self.model = self._setup_llm()
        self.tools = self._setup_tools()
        self.agent = self._create_agent()
    
    def _setup_llm(self):
        token_provider = get_bearer_token_provider(
            self.env.credential,
            "https://cognitiveservices.azure.com/.default"
        )
        model_name = self.env.get("MODEL_NAME", "gpt-4o")
        temperature = float(self.env.get("TEMPERATURE", "0.3"))
        api_version = self.env.get("API_VERSION", "2024-05-01-preview")
        azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
        
        return AzureChatOpenAI(
            model_name=model_name,
            temperature=temperature,
            api_version=api_version,
            azure_endpoint=azure_endpoint,
            azure_ad_token_provider=token_provider
        )
    
    def _setup_tools(self):
        return [PBTClassifierTool(pbt_manager=self.pbt_manager)]
    
    def _create_agent(self):
        # Define custom system message
        system_message = """
        You are an expert business terminology standardization system. Your task is to map user-provided terms 
        and descriptions to the organization's Preferred Business Terms (PBT).

        When a user provides a name and description, use the pbt_classifier tool to find the most appropriate 
        standard business term from the database. Provide a brief explanation of why this standard term 
        matches the user's input, focusing on conceptual alignment rather than just keyword matching.
        """
        
        # Create the React agent
        return create_react_agent(
            self.model,
            self.tools,
            prompt=system_message,
            checkpointer=self.memory_saver
        )
    
    def classify(self, name: str, description: str) -> Dict:
        """Use the agent to classify the input."""
        try:
            # Generate a unique ID for this classification session
            session_id = str(uuid.uuid4())
            
            input_message = f"Please map the following to a standard Preferred Business Term: Name: {name}, Description: {description}"
            
            # Create a config with thread_id for the checkpointer
            config = {"configurable": {"thread_id": session_id}}
            
            result = self.agent.invoke(
                {"messages": [HumanMessage(content=input_message)]},
                config=config
            )
            
            # The last message contains the final response
            final_message = result["messages"][-1]
            
            # Serialize the messages for JSON compatibility
            serialized_result = {
                "messages": serialize_message(result["messages"])
            }
            
            return {
                "status": "success",
                "agent_response": final_message.content,
                "full_trace": serialized_result
            }
        except Exception as e:
            logger.error(f"Error in agent classification: {e}")
            return {"status": "error", "message": str(e)}

## Confidence Evaluator Agent Class
class ConfidenceEvaluatorAgent:
    def __init__(self, env: OSEnv):
        self.env = env
        self.model = self._setup_llm()
        self.chain = self._create_confidence_chain()
    
    def _setup_llm(self):
        token_provider = get_bearer_token_provider(
            self.env.credential,
            "https://cognitiveservices.azure.com/.default"
        )
        model_name = self.env.get("MODEL_NAME", "gpt-4o")
        temperature = float(self.env.get("TEMPERATURE", "0.2"))  # Lower temperature for more deterministic confidence scores
        api_version = self.env.get("API_VERSION", "2024-05-01-preview")
        azure_endpoint = self.env.get("AZURE_ENDPOINT", "")
        
        return AzureChatOpenAI(
            model_name=model_name,
            temperature=temperature,
            api_version=api_version,
            azure_endpoint=azure_endpoint,
            azure_ad_token_provider=token_provider
        )
    
    def _create_confidence_chain(self):
        # Define prompt for confidence evaluation
        prompt = ChatPromptTemplate.from_messages([
            SystemMessage(content="""
            You are an expert system that evaluates the confidence of matches between user-provided terms and standard
            Preferred Business Terms (PBT). Analyze the semantic similarity, contextual relevance, and overall 
            appropriateness of the match.
            
            Provide a confidence score between 0 and 100, where:
            - 0-20: Very low confidence. The match seems arbitrary or incorrect.
            - 21-40: Low confidence. There's a vague relationship but likely not the best match.
            - 41-60: Moderate confidence. There's a reasonable connection but potentially better alternatives.
            - 61-80: High confidence. The match is strong and likely appropriate.
            - 81-100: Very high confidence. The match is excellent and almost certainly correct.
            
            Return your evaluation as a JSON object with the following fields:
            - confidence_score: (number between 0-100)
            - explanation: (string explaining your reasoning)
            """),
            HumanMessage(content="""
            User Input: {user_input}
            
            Matched PBT: 
            ID: {pbt_id}
            Name: {pbt_name}
            Definition: {pbt_definition}
            
            Evaluate the confidence of this match.
            """)
        ])
        
        # Create the chain
        return prompt | self.model | JsonOutputParser()
    
    def evaluate_confidence(self, user_input: str, pbt_match: Dict) -> Dict:
        """Evaluate the confidence of a match between user input and a PBT."""
        try:
            result = self.chain.invoke({
                "user_input": user_input,
                "pbt_id": pbt_match.get("id", ""),
                "pbt_name": pbt_match.get("PBT_NAME", ""),
                "pbt_definition": pbt_match.get("PBT_DEFINITION", "")
            })
            
            return {
                "confidence_score": result.get("confidence_score", 0),
                "explanation": result.get("explanation", "No explanation provided")
            }
        except Exception as e:
            logger.error(f"Error in confidence evaluation: {e}")
            return {
                "confidence_score": 0,
                "explanation": f"Error evaluating confidence: {str(e)}"
            }

## Data Classifier Class
class DataClassifier:
    def __init__(self, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.env = OSEnv(config_file, creds_file, cert_file)
        self.embedding_client = EmbeddingClient(self.env)
        self.pbt_manager = PBTDataManager(self.embedding_client)
        self.chatbot = AzureChatbot(config_file, creds_file, cert_file)
        self.react_agent = None  # Will be initialized after loading data
        self.confidence_agent = ConfidenceEvaluatorAgent(self.env)
    
    def load_data(self, csv_path: str) -> None:
        """Load the PBT data from CSV."""
        self.pbt_manager.load_csv(csv_path)
        # Initialize the React agent after data is loaded
        self.react_agent = ReactAgent(self.env, self.pbt_manager)
    
    def classify_with_embeddings(self, name: str, description: str, top_n: int = 5) -> Dict:
        """Classify using embedding similarity."""
        combined_input = f"{name} - {description}"
        similar_items = self.pbt_manager.find_similar_items(combined_input, top_n=top_n)
        
        if not similar_items:
            logger.warning("No similar items found")
            return {"status": "error", "message": "No similar items found"}
        
        # Evaluate confidence
        confidence_result = self.confidence_agent.evaluate_confidence(
            combined_input, 
            similar_items[0]
        )
        
        return {
            "status": "success",
            "best_match": similar_items[0],
            "similar_items": similar_items,
            "confidence": confidence_result
        }
    
    def classify_with_llm(self, name: str, description: str, top_n: int = 5) -> Dict:
        """Classify using LLM."""
        # First get similar items with embeddings
        combined_input = f"{name} - {description}"
        similar_items = self.pbt_manager.find_similar_items(combined_input, top_n=top_n)
        
        if not similar_items:
            logger.warning("No similar items found")
            return {"status": "error", "message": "No similar items found"}
        
        # Use LLM for final classification among top candidates
        best_match = self.chatbot.classify_with_llm(combined_input, [
            {
                'id': item['id'],
                'name': item['PBT_NAME'],
                'definition': item['PBT_DEFINITION']
            } for item in similar_items
        ])
        
        if best_match:
            # Evaluate confidence
            confidence_result = self.confidence_agent.evaluate_confidence(
                combined_input, 
                best_match
            )
            
            return {
                "status": "success",
                "best_match": best_match,
                "similar_items": similar_items,
                "confidence": confidence_result
            }
        
        # Fallback to embedding similarity
        confidence_result = self.confidence_agent.evaluate_confidence(
            combined_input, 
            similar_items[0]
        )
        
        return {
            "status": "success",
            "best_match": similar_items[0],
            "similar_items": similar_items,
            "confidence": confidence_result
        }
    
    def classify_with_agent(self, name: str, description: str) -> Dict:
        """Classify using the LangGraph React agent."""
        if not self.react_agent:
            logger.error("React agent not initialized. Call load_data() first.")
            return {"status": "error", "message": "React agent not initialized"}
        
        agent_result = self.react_agent.classify(name, description)
        
        if agent_result.get("status") == "error":
            return agent_result
        
        # Extract the best match from the agent's result
        # This assumes the agent's tool returns a result with similar format to other methods
        # We'll get this from the "full_trace" which contains all messages including tool outputs
        full_trace = agent_result.get("full_trace", {})
        messages = full_trace.get("messages", [])
        
        # Find the tool message with the classification result
        best_match = None
        for message in messages:
            if message.get("type") == "tool" and message.get("additional_kwargs", {}).get("name") == "pbt_classifier":
                try:
                    tool_content = json.loads(message.get("content", "{}"))
                    if tool_content.get("status") == "success":
                        best_match = tool_content.get("best_match")
                        break
                except:
                    pass
        
        # If we couldn't find a best match in the tool results, fall back to embedding similarity
        if best_match is None:
            logger.warning("Could not extract best match from agent result, falling back to embedding similarity")
            combined_input = f"{name} - {description}"
            similar_items = self.pbt_manager.find_similar_items(combined_input, top_n=5)
            
            if not similar_items:
                return {"status": "error", "message": "No similar items found"}
            
            best_match = similar_items[0]
        
        # Evaluate confidence
        combined_input = f"{name} - {description}"
        confidence_result = self.confidence_agent.evaluate_confidence(
            combined_input, 
            best_match
        )
        
        # Add confidence to the agent's result
        agent_result["confidence"] = confidence_result
        
        return agent_result
    
    def classify(self, name: str, description: str, method: str = "agent") -> Dict:
        """Classify using the specified method."""
        if method == "embeddings":
            return self.classify_with_embeddings(name, description)
        elif method == "llm":
            return self.classify_with_llm(name, description)
        elif method == "agent":
            return self.classify_with_agent(name, description)
        else:
            logger.error(f"Unknown classification method: {method}")
            return {"status": "error", "message": f"Unknown classification method: {method}"}

## Main Application Class
class AIClassificationApp:
    def __init__(self, csv_path: str, config_file=CONFIG_PATH, creds_file=CREDS_PATH, cert_file=CERT_PATH):
        self.classifier = DataClassifier(config_file, creds_file, cert_file)
        self.classifier.load_data(csv_path)
        logger.info("AI Classification App initialized")
    
    def classify_input(self, name: str, description: str, method: str = "agent") -> Dict:
        """Classify user input against PBT data using the specified method."""
        result = self.classifier.classify(name, description, method)
        return result
    
    def batch_classify(self, inputs: List[Dict], method: str = "agent") -> List[Dict]:
        """Batch classify multiple inputs."""
        results = []
        for input_item in inputs:
            result = self.classify_input(
                input_item.get('name', ''),
                input_item.get('description', ''),
                method
            )
            results.append({
                "input": input_item,
                "classification": result
            })
        return results

# Example usage
def main():
    # Example configuration
    csv_path = "path/to/your/pbt_data.csv"
    
    # Initialize the app
    app = AIClassificationApp(csv_path)
    
    # Example classification using React agent
    result = app.classify_input(
        "Machine Learning Algorithm", 
        "A computational method that uses statistical techniques to enable machines to improve through experience"
    )
    
    print(json.dumps(result, indent=2))
    
    # Example batch classification
    batch_results = app.batch_classify([
        {
            "name": "Neural Network",
            "description": "A computing system inspired by biological neural networks that can learn from examples"
        },
        {
            "name": "Decision Tree",
            "description": "A tree-like model of decisions where each internal node represents a test on an attribute"
        }
    ])
    
    print(json.dumps(batch_results, indent=2))

if __name__ == "__main__":
    main()
