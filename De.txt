"""
Advanced Prompting Strategies for Legal Document Analysis
Optimized for token efficiency while maintaining quality

Location: src/prompting/advanced_strategies.py
"""

from typing import Optional, List, Dict, Any
from enum import Enum


class ExpertRole(str, Enum):
    """Expert roles for Mixture of Experts prompting"""
    LEGAL_EXPERT = "legal_expert"
    COMPLIANCE_OFFICER = "compliance_officer"
    DATA_PRIVACY_SPECIALIST = "data_privacy_specialist"
    REGULATORY_ANALYST = "regulatory_analyst"
    TECHNICAL_ARCHITECT = "technical_architect"
    BUSINESS_ANALYST = "business_analyst"


class ReasoningMode(str, Enum):
    """Reasoning modes for different analysis approaches"""
    CHAIN_OF_THOUGHT = "chain_of_thought"
    MIXTURE_OF_EXPERTS = "mixture_of_experts"
    TREE_OF_THOUGHT = "tree_of_thought"
    REFLECTION = "reflection"
    REACT = "react"


class AdvancedPromptingStrategies:
    """
    Advanced prompting strategies with token optimization
    """
    
    def __init__(self, rule_name: str, jurisdiction: str):
        self.rule_name = rule_name
        self.jurisdiction = jurisdiction
    
    def get_react_agent_system_prompt(self) -> str:
        """
        OPTIMIZED: Concise ReAct agent system prompt
        """
        return f"""You are a legal document analyzer using ReAct methodology.

Rule: {self.rule_name}
Jurisdiction: {self.jurisdiction}

For each chunk:
1. THINK: What legal requirements are present?
2. ACT: Extract specific obligations, permissions, actions
3. OBSERVE: Structure findings as JSON

Extract:
- Description (what the rule requires)
- User actions (what users can/must/cannot do)
- System actions (what systems must implement)
- Duties (obligations for users/systems)
- Constraints (conditions, limitations)
- Rule type (permission/prohibition/obligation/combination)

Be concise and precise. Use plain English."""
    
    def get_chain_of_thought_prompt(
        self,
        document_text: str,
        analysis_type: str,
        context: Optional[Dict[str, Any]] = None,
        chunk_info: str = ""
    ) -> str:
        """
        OPTIMIZED: Chain of Thought prompting with token efficiency
        """
        # Truncate document text if too long
        text_truncated = document_text[:1000] + "..." if len(document_text) > 1000 else document_text
        
        context_section = ""
        if context:
            org = context.get("organization", "")
            tools = context.get("internal_tools", [])
            if org or tools:
                context_section = f"\n\nEnterprise Context:\n- Organization: {org}\n- Tools: {', '.join(tools)}\n"
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        return f"""Analyze this legal text using step-by-step reasoning:
{context_section}{chunk_section}
TEXT:
{text_truncated}

TASK: {analysis_type}

Think step-by-step:
1. What is the main requirement?
2. Who is affected?
3. What actions are required?
4. What conditions apply?
5. What are the implications?

Provide detailed analysis with reasoning."""
    
    def get_mixture_of_experts_prompt(
        self,
        document_text: str,
        expert_roles: List[ExpertRole],
        chunk_info: str = ""
    ) -> str:
        """
        OPTIMIZED: Mixture of Experts prompting
        """
        # Truncate document text
        text_truncated = document_text[:1000] + "..." if len(document_text) > 1000 else document_text
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        roles_desc = []
        for role in expert_roles:
            if role == ExpertRole.LEGAL_EXPERT:
                roles_desc.append("Legal Expert: Analyze legal obligations and compliance requirements")
            elif role == ExpertRole.COMPLIANCE_OFFICER:
                roles_desc.append("Compliance Officer: Identify practical compliance steps and controls")
            elif role == ExpertRole.DATA_PRIVACY_SPECIALIST:
                roles_desc.append("Data Privacy Specialist: Focus on data protection and privacy requirements")
            elif role == ExpertRole.REGULATORY_ANALYST:
                roles_desc.append("Regulatory Analyst: Interpret regulatory intent and implications")
            elif role == ExpertRole.TECHNICAL_ARCHITECT:
                roles_desc.append("Technical Architect: Identify technical implementation requirements")
            elif role == ExpertRole.BUSINESS_ANALYST:
                roles_desc.append("Business Analyst: Assess business process impacts")
        
        roles_text = "\n".join(f"- {desc}" for desc in roles_desc)
        
        return f"""Analyze this text from multiple expert perspectives:
{chunk_section}
TEXT:
{text_truncated}

Expert Perspectives:
{roles_text}

Provide comprehensive analysis incorporating all expert viewpoints."""
    
    def get_dynamic_contextualized_prompt(
        self,
        document_text: str,
        previous_analyses: Optional[List[str]] = None,
        enterprise_context: Optional[Dict[str, Any]] = None,
        chunk_info: str = ""
    ) -> str:
        """
        OPTIMIZED: Dynamic contextualized prompting
        """
        # Truncate document text
        text_truncated = document_text[:1000] + "..." if len(document_text) > 1000 else document_text
        
        chunk_section = f"\n\nChunk Context: {chunk_info}\n" if chunk_info else ""
        
        previous_section = ""
        if previous_analyses:
            prev_summary = previous_analyses[0][:300] + "..." if len(previous_analyses[0]) > 300 else previous_analyses[0]
            previous_section = f"\n\nPrevious Analysis Summary:\n{prev_summary}\n"
        
        context_section = ""
        if enterprise_context:
            org = enterprise_context.get("organization", "")
            if org:
                context_section = f"\n\nOrganization: {org}\n"
        
        return f"""Analyze this text with full context:
{chunk_section}{previous_section}{context_section}
TEXT:
{text_truncated}

Provide analysis that builds on previous findings and considers organizational context."""
    
    def get_multi_level_synthesis_prompt(
        self,
        level_1_analysis: str,
        level_2_analysis: str,
        level_3_analysis: str
    ) -> str:
        """
        OPTIMIZED: Concise multi-level synthesis prompt
        NOTE: Input analyses should be summaries, not full JSON
        """
        # Truncate if analyses are too long
        l1_truncated = level_1_analysis[:500] + "..." if len(level_1_analysis) > 500 else level_1_analysis
        l2_truncated = level_2_analysis[:500] + "..." if len(level_2_analysis) > 500 else level_2_analysis
        l3_truncated = level_3_analysis[:500] + "..." if len(level_3_analysis) > 500 else level_3_analysis
        
        return f"""Synthesize analyses from 3 document levels for "{self.rule_name}" in {self.jurisdiction}.

LEVEL 1 (Overview):
{l1_truncated}

LEVEL 2 (Details):
{l2_truncated}

LEVEL 3 (Technical):
{l3_truncated}

Integrate all insights into comprehensive JSON:
{{
    "description": "Complete description from all levels",
    "user_actions": ["all user actions"],
    "system_actions": ["all system actions"],
    "user_duties": ["all user obligations"],
    "system_duties": ["all system obligations"],
    "constraints": [{{"type": "...", "description": "..."}}],
    "rule_type": "permission/prohibition/obligation/combination",
    "confidence": "high/medium/low"
}}

Ensure:
- No contradictions between levels
- Progressively detailed (L1→L2→L3)
- Practical and implementable
- Complete coverage"""
    
    def get_reflection_prompt(self, current_analysis: str) -> str:
        """
        OPTIMIZED: Concise reflection prompt
        """
        # Truncate analysis for prompt
        analysis_truncated = current_analysis[:800] + "..." if len(current_analysis) > 800 else current_analysis
        
        return f"""Review this analysis for "{self.rule_name}":

{analysis_truncated}

Check:
1. Completeness - all requirements captured?
2. Accuracy - legally sound?
3. Clarity - understandable?
4. Actionability - implementable?

Provide:
- What's correct
- What needs improvement
- Enhanced final analysis (JSON format)

Be concise."""
    
    def get_chunk_analysis_prompt(
        self,
        chunk_text: str,
        chunk_context: str
    ) -> str:
        """
        OPTIMIZED: Concise chunk analysis prompt
        """
        return f"""Analyze this legal text chunk:

CONTEXT: {chunk_context}

TEXT:
{chunk_text}

Extract JSON:
{{
    "description": "What this chunk requires",
    "user_actions": ["specific actions"],
    "system_actions": ["system requirements"],
    "user_duties": ["user obligations"],
    "system_duties": ["system obligations"],
    "constraints": [{{"type": "...", "description": "..."}}],
    "rule_type": "type if determinable"
}}

Focus on this chunk only. Be precise."""
    
    def get_comprehensive_synthesis_prompt(
        self,
        chunk_analyses: List[Dict[str, Any]],
        total_chunks: int
    ) -> str:
        """
        OPTIMIZED: Concise comprehensive synthesis
        """
        # Summarize chunk analyses
        summaries = []
        for i, analysis in enumerate(chunk_analyses[:5]):  # Limit to first 5 for brevity
            desc = analysis.get("description", "")[:100]
            if desc:
                summaries.append(f"Chunk {i+1}: {desc}...")
        
        if len(chunk_analyses) > 5:
            summaries.append(f"... and {len(chunk_analyses) - 5} more chunks")
        
        chunks_summary = "\n".join(summaries) if summaries else "Multiple chunks analyzed"
        
        return f"""Synthesize {total_chunks} chunk analyses into final analysis:

{chunks_summary}

Provide comprehensive JSON with:
- Complete description
- All user/system actions
- All duties and constraints
- Rule type and confidence

Merge and deduplicate. Ensure completeness."""
    
    def get_decision_inference_prompt(self, rule_context: str) -> str:
        """
        OPTIMIZED: Concise decision inference prompt
        """
        # Truncate context
        context_truncated = rule_context[:600] + "..." if len(rule_context) > 600 else rule_context
        
        return f"""Identify decision scenarios in this rule:

{context_truncated}

For each scenario provide:
{{
    "scenario": "When does this apply?",
    "decision_type": "yes/no/maybe",
    "conditions": ["what conditions must be met"],
    "required_actions": ["actions if YES"],
    "prohibited_actions": ["actions if NO"]
}}

Focus on practical compliance decisions."""
    
    def get_action_extraction_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise action extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract actions from text:

{text_truncated}

Standard actions only: share, store, process, update, create

Provide JSON:
{{
    "user_actions": ["actions users take"],
    "system_actions": ["actions systems must do"]
}}

Map synonyms to standard actions."""
    
    def get_constraint_analysis_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise constraint extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract constraints from:

{text_truncated}

Provide JSON:
{{
    "constraints": [
        {{"type": "temporal/technical/procedural", "description": "..."}}
    ]
}}

Focus on conditions and limitations."""
    
    def get_duty_extraction_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise duty extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract duties and obligations from:

{text_truncated}

Provide JSON:
{{
    "user_duties": ["what users must do"],
    "system_duties": ["what systems must do"]
}}

Focus on mandatory requirements."""
    
    def get_rule_classification_prompt(self, analysis: str) -> str:
        """
        OPTIMIZED: Concise rule classification
        """
        # Truncate analysis
        analysis_truncated = analysis[:600] + "..." if len(analysis) > 600 else analysis
        
        return f"""Classify this rule:

{analysis_truncated}

Determine:
- Rule type: permission/prohibition/obligation/combination
- Confidence: high/medium/low
- Reasoning: Brief justification

Provide JSON:
{{
    "rule_type": "...",
    "confidence": "...",
    "reasoning": "..."
}}"""
    
    def get_enterprise_context_prompt(self, text: str) -> str:
        """
        Extract enterprise-specific context
        """
        # Truncate text
        text_truncated = text[:800] + "..." if len(text) > 800 else text
        
        return f"""Identify enterprise-specific context from:

{text_truncated}

Extract:
- Organization name
- Internal tools/systems
- Specific processes
- Business units

Provide JSON:
{{
    "organization": "...",
    "tools": ["..."],
    "processes": ["..."],
    "business_units": ["..."]
}}"""
    
    def get_data_category_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Data category identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify data categories mentioned:

{text_truncated}

Common categories: personal data, sensitive data, financial data, health data, etc.

Provide JSON:
{{
    "data_categories": ["category1", "category2", ...]
}}"""
    
    def get_role_identification_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Role identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify roles mentioned:

{text_truncated}

Common roles: data controller, data processor, data subject, third party, etc.

Provide JSON:
{{
    "roles": ["role1", "role2", ...]
}}"""
    
    def get_validation_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Validation prompt
        """
        # Create compact summary of analysis
        summary = f"""Rule: {analysis.get('description', 'N/A')[:200]}
User Actions: {len(analysis.get('user_actions', []))}
System Actions: {len(analysis.get('system_actions', []))}
Constraints: {len(analysis.get('constraints', []))}
Type: {analysis.get('rule_type', 'N/A')}"""
        
        return f"""Validate this analysis:

{summary}

Check for:
1. Logical consistency
2. Completeness
3. Accuracy
4. Missing information

Provide JSON:
{{
    "is_valid": true/false,
    "issues": ["issue1", "issue2", ...],
    "suggestions": ["suggestion1", "suggestion2", ...]
}}"""
    
    def get_merge_prompt(self, analyses: List[Dict[str, Any]]) -> str:
        """
        OPTIMIZED: Merge multiple analyses
        """
        # Create compact summaries
        summaries = []
        for i, analysis in enumerate(analyses[:3]):
            desc = analysis.get('description', '')[:100]
            summaries.append(f"Analysis {i+1}: {desc}...")
        
        if len(analyses) > 3:
            summaries.append(f"... and {len(analyses) - 3} more analyses")
        
        summary_text = "\n".join(summaries)
        
        return f"""Merge these analyses into one comprehensive analysis:

{summary_text}

Provide merged JSON with:
- Combined description
- All unique actions
- All unique constraints
- Unified rule type

Deduplicate and synthesize."""
    
    def get_refinement_prompt(self, analysis: Dict[str, Any], feedback: str) -> str:
        """
        OPTIMIZED: Refinement prompt based on feedback
        """
        # Create compact analysis summary
        summary = f"""Current analysis:
Description: {analysis.get('description', '')[:200]}...
Actions: {len(analysis.get('user_actions', []))} user, {len(analysis.get('system_actions', []))} system
Type: {analysis.get('rule_type', 'N/A')}"""
        
        return f"""Refine this analysis based on feedback:

{summary}

FEEDBACK:
{feedback[:300]}

Provide improved JSON with all required fields."""
