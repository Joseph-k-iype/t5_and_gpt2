"""
Advanced Privacy Q&A Chatbot with Deep Research and Multi-Agent ReAct Architecture
Complete implementation with LangChain's Open Deep Research patterns

Features:
- Multi-jurisdiction support (GDPR, CCPA, LGPD, PIPEDA, etc.)
- Deep iterative research with knowledge gap analysis
- AI-powered query analysis and intent detection
- Adaptive search strategies based on content analysis
- Cross-jurisdiction comparison capabilities
- LangChain Elasticsearch integration
- O3-mini reasoning model for intelligent analysis
- Business-friendly response formatting

Requirements:
- OpenAI API access with o3-mini model
- Elasticsearch with pre-indexed privacy data
- Python 3.9+
- pip install langchain-elasticsearch langchain langchain-openai langchain-core elasticsearch langgraph

Environment Variables:
- OPENAI_API_KEY: Your OpenAI API key
- ES_USERNAME: Elasticsearch username
- ES_PASSWORD: Elasticsearch password
- ES_HOST: Elasticsearch host (default: localhost)
- ES_PORT: Elasticsearch port (default: 9200)
"""

import asyncio
import json
import logging
import os
import ssl
import uuid
import time
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional, TypedDict, Annotated, Sequence, Tuple, Union, Callable
from dataclasses import dataclass, field
import re
from collections import defaultdict, Counter

# Core imports
import openai
from elasticsearch import Elasticsearch

# LangChain Elasticsearch integration
try:
    from langchain_elasticsearch import ElasticsearchStore, ElasticsearchRetriever
    from langchain_elasticsearch.vectorstores import DenseVectorStrategy, BM25Strategy
except ImportError:
    print("Error: langchain-elasticsearch not found. Install with: pip install langchain-elasticsearch")
    sys.exit(1)

# LangChain core
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langchain_core.retrievers import BaseRetriever
from langchain_core.embeddings import Embeddings
from langchain_core.prompts import ChatPromptTemplate

# LangChain OpenAI
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    print("Error: langchain-openai not found. Install with: pip install langchain-openai")
    sys.exit(1)

# LangChain QA chains
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# LangGraph
try:
    from langgraph.graph import StateGraph, MessagesState, START, END
    from langgraph.checkpoint.memory import MemorySaver
    from langgraph.store.memory import InMemoryStore
    from langgraph.prebuilt import ToolNode, create_react_agent
except ImportError:
    print("Error: langgraph not found. Install with: pip install langgraph")
    sys.exit(1)

# Pydantic
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration
class Config:
    """Configuration class with validation"""
    
    def __init__(self):
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        self.OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.ES_USERNAME = os.getenv("ES_USERNAME", "elastic")
        self.ES_PASSWORD = os.getenv("ES_PASSWORD")
        self.ES_HOST = os.getenv("ES_HOST", "localhost")
        
        # Validate required environment variables
        if not self.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        if not self.ES_PASSWORD:
            raise ValueError("ES_PASSWORD environment variable is required")
        
        try:
            self.ES_PORT = int(os.getenv("ES_PORT", "9200"))
        except ValueError:
            self.ES_PORT = 9200
            
        self.ES_CACERT_PATH = os.getenv("ES_CACERT_PATH", "cacert.crt")
        
        # Model configurations
        self.REASONING_MODEL = "o3-mini-2025-01-31"
        self.EMBEDDING_MODEL = "text-embedding-3-large"
        self.EMBEDDING_DIMENSIONS = 3072
        self.REASONING_EFFORT = "high"
        
        # Search configurations
        self.MAX_SEARCH_RESULTS = 15
        self.SIMILARITY_THRESHOLD = 0.6
        self.MAX_CONTEXT_LENGTH = 8000

# Global config instance
try:
    config = Config()
except Exception as e:
    print(f"Configuration error: {e}")
    sys.exit(1)

# Enhanced Data Models for Deep Research
@dataclass
class SearchResult:
    """Enhanced search result with metadata"""
    content: str
    title: str
    document_type: str
    jurisdiction: str
    framework_type: str
    article_number: Optional[str]
    chapter_number: str
    score: float
    chunk_id: Optional[str] = None
    article_id: Optional[str] = None
    page_number: Optional[int] = None
    key_concepts: Optional[List[str]] = field(default_factory=list)
    supporting_references: Optional[List[Dict]] = field(default_factory=list)

@dataclass
class ResearchPlan:
    """Structured research plan following Open Deep Research patterns"""
    main_topic: str
    research_objectives: List[str]
    sections: List[Dict[str, str]]
    sub_queries: List[str]
    expected_jurisdictions: List[str]
    complexity_level: str
    estimated_depth: int

@dataclass
class ResearchIteration:
    """Single iteration of deep research"""
    iteration_number: int
    queries: List[str]
    search_results: List[SearchResult]
    findings: List[str]
    knowledge_gaps: List[str]
    confidence_score: float
    next_queries: List[str]
    should_continue: bool

@dataclass
class ResearchState:
    """State management for iterative deep research"""
    original_query: str
    research_plan: Optional[ResearchPlan]
    iterations: List[ResearchIteration]
    accumulated_knowledge: Dict[str, List[str]]
    knowledge_gaps: List[str]
    current_iteration: int
    max_iterations: int
    confidence_threshold: float
    final_report: str = ""
    is_complete: bool = False

@dataclass
class ConversationContext:
    """Conversation context and memory"""
    thread_id: str
    query: str
    intent: str = ""
    entities: List[str] = field(default_factory=list)
    previous_searches: List[Dict] = field(default_factory=list)
    conversation_history: List[BaseMessage] = field(default_factory=list)
    current_analysis: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DynamicConcepts:
    """Dynamically discovered concepts from documents"""
    terms: List[str] = field(default_factory=list)
    definitions: Dict[str, str] = field(default_factory=dict)
    relationships: Dict[str, List[str]] = field(default_factory=dict)
    importance_scores: Dict[str, float] = field(default_factory=dict)
    contexts: Dict[str, List[str]] = field(default_factory=dict)

class ChatbotState(TypedDict):
    """State for the chatbot workflow"""
    messages: Annotated[Sequence[BaseMessage], "The conversation messages"]
    current_query: str
    conversation_context: ConversationContext
    search_results: List[SearchResult]
    analysis_results: Dict[str, Any]
    final_answer: str
    citations: List[Dict]
    processing_stage: str

# Utility Functions
def safe_json_parse(json_string: str, fallback_value: Any = None) -> Any:
    """Safely parse JSON with fallback handling"""
    if not json_string or not isinstance(json_string, str):
        logger.warning(f"Invalid JSON input: {type(json_string)}")
        return fallback_value
    
    json_string = json_string.strip()
    
    # Try to extract JSON from markdown code blocks
    if "```json" in json_string:
        try:
            start_idx = json_string.find("```json") + 7
            end_idx = json_string.find("```", start_idx)
            if end_idx > start_idx:
                json_string = json_string[start_idx:end_idx].strip()
        except Exception:
            pass
    elif "```" in json_string:
        try:
            start_idx = json_string.find("```") + 3
            end_idx = json_string.find("```", start_idx)
            if end_idx > start_idx:
                json_string = json_string[start_idx:end_idx].strip()
        except Exception:
            pass
    
    # Multiple parsing attempts
    parse_attempts = [
        lambda: json.loads(json_string),
        lambda: json.loads(json_string.replace("'", '"')),
        lambda: json.loads(re.sub(r'(\w+):', r'"\1":', json_string)),
    ]
    
    for attempt in parse_attempts:
        try:
            result = attempt()
            if result is not None:
                return result
        except Exception:
            continue
    
    logger.error(f"Failed to parse JSON: {json_string[:200]}...")
    return fallback_value

def get_event_loop() -> asyncio.AbstractEventLoop:
    """Get or create event loop safely"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_closed():
            raise RuntimeError("Event loop is closed")
        return loop
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop

async def run_async_safe(coro):
    """Run async function safely in any context"""
    try:
        return await coro
    except Exception as e:
        logger.error(f"Error in async execution: {e}")
        raise

# Data Privacy Filter
class DataPrivacyFilter:
    """Filter to ensure responses are related to data privacy topics"""
    
    PRIVACY_KEYWORDS = [
        "gdpr", "data protection", "privacy", "personal data", "data controller",
        "data processor", "consent", "data subject", "data breach", "compliance",
        "regulation", "legal basis", "legitimate interest", "data rights",
        "erasure", "portability", "rectification", "processing", "security",
        "confidentiality", "integrity", "availability", "pseudonymization",
        "encryption", "data minimization", "purpose limitation", "accuracy",
        "storage limitation", "accountability", "privacy by design", "dpia",
        "data protection officer", "dpo", "supervisory authority", "cross-border",
        "transfer", "adequacy decision", "binding corporate rules", "bcr",
        "standard contractual clauses", "scc", "privacy policy", "cookie",
        "legitimate interests assessment", "lia", "records of processing",
        "data inventory", "privacy notice", "retention", "deletion", "anonymization",
        "special categories", "sensitive data", "children", "minors", "opt-in",
        "opt-out", "withdrawal", "transparency", "fairness", "lawfulness",
        "data sharing", "third party", "vendor", "sub-processor", "audit",
        "assessment", "impact", "risk", "mitigation", "breach notification",
        "72 hours", "penalty", "fine", "enforcement", "compliance framework",
        "iso 27001", "iso 27701", "soc 2", "privacy shield", "ccpa", "cpra",
        "lgpd", "pipeda", "data localization", "residency", "sovereignty",
        "pdpa", "pipl", "dpa", "nist", "pci dss", "jurisdiction", "framework"
    ]
    
    NON_PRIVACY_REJECTION_PHRASES = [
        "I'm designed to help with data privacy and protection questions across multiple jurisdictions.",
        "My expertise is focused on global data protection regulations and privacy matters.",
        "I specialize in privacy topics across GDPR, CCPA, LGPD, and other frameworks. Please ask questions related to data protection or privacy compliance.",
        "I can assist with questions about data privacy regulations from various jurisdictions worldwide.",
        "My knowledge covers global data protection laws and privacy regulations. How can I help with your privacy compliance questions?"
    ]
    
    @classmethod
    def is_privacy_related(cls, query: str) -> bool:
        """Check if query is related to data privacy"""
        if not query:
            return False
        
        query_lower = query.lower()
        
        # Check for privacy keywords
        for keyword in cls.PRIVACY_KEYWORDS:
            if keyword in query_lower:
                return True
        
        # Check for privacy-related patterns
        privacy_patterns = [
            r'\bdata\s+(?:protection|privacy|security|breach)\b',
            r'\b(?:personal|sensitive|confidential)\s+(?:data|information)\b',
            r'\b(?:privacy|protection|compliance)\s+(?:law|regulation|requirement)\b',
            r'\b(?:user|customer|employee)\s+(?:data|information|privacy)\b',
            r'\b(?:collect|process|store|transfer|share)\s+(?:data|information)\b',
            r'\b(?:consent|permission|authorization|agreement)\b',
            r'\b(?:right|rights)\s+(?:to|of)\s+(?:access|erasure|portability|rectification)\b'
        ]
        
        for pattern in privacy_patterns:
            if re.search(pattern, query_lower):
                return True
        
        return False
    
    @classmethod
    def get_rejection_message(cls) -> str:
        """Get a polite rejection message for non-privacy queries"""
        import random
        return random.choice(cls.NON_PRIVACY_REJECTION_PHRASES)

# Enhanced OpenAI Manager
class AdvancedOpenAIManager:
    """Advanced OpenAI manager with direct API integration"""
    
    def __init__(self):
        try:
            self.client = openai.OpenAI(
                api_key=config.OPENAI_API_KEY,
                base_url=config.OPENAI_BASE_URL
            )
            # Test connection
            self._test_connection()
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            raise
    
    def _test_connection(self):
        """Test OpenAI connection"""
        try:
            # Test with a simple completion instead of listing models
            test_response = self.client.chat.completions.create(
                model=config.REASONING_MODEL,
                messages=[{"role": "user", "content": "test"}],
                reasoning_effort=config.REASONING_EFFORT
            )
            logger.info("OpenAI connection successful")
        except Exception as e:
            logger.error(f"OpenAI connection test failed: {e}")
            raise
    
    async def create_embedding(self, text: str) -> List[float]:
        """Create embedding using direct OpenAI API"""
        if not text or not isinstance(text, str):
            logger.warning("Empty or invalid text for embedding")
            return [0.0] * config.EMBEDDING_DIMENSIONS
        
        try:
            # Clean and truncate text for embedding
            clean_text = text.strip()[:8000]  # Limit text length
            
            response = self.client.embeddings.create(
                model=config.EMBEDDING_MODEL,
                input=clean_text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Error creating embedding: {e}")
            raise
    
    async def reasoning_completion(self, messages: List[Dict], system_prompt: str = None) -> str:
        """Create completion using o3-mini with high reasoning effort"""
        if not messages:
            raise ValueError("Messages cannot be empty")
        
        try:
            formatted_messages = []
            
            if system_prompt:
                formatted_messages.append({"role": "developer", "content": system_prompt})
            
            formatted_messages.extend(messages)
            
            response = self.client.chat.completions.create(
                model=config.REASONING_MODEL,
                messages=formatted_messages,
                reasoning_effort=config.REASONING_EFFORT
            )
            
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error in reasoning completion: {e}")
            raise

# Deep Research Planner (inspired by LangChain's Open Deep Research)
class DeepResearchPlanner:
    """Creates structured research plans following Open Deep Research patterns"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.name = "DeepResearchPlanner"
    
    async def create_research_plan(self, query: str, context: ConversationContext) -> ResearchPlan:
        """Create a comprehensive research plan for deep investigation"""
        system_prompt = """
        You are a research planning expert specializing in data privacy and protection regulations.
        Create a structured research plan that will guide deep, iterative investigation.
        
        Analyze the query and create a plan that includes:
        1. Main research topic and scope
        2. Specific research objectives
        3. Logical sections for investigation
        4. Initial sub-queries for exploration
        5. Relevant jurisdictions to investigate
        6. Complexity assessment and estimated research depth
        
        Return JSON in this exact format:
        {
            "main_topic": "Clear topic statement",
            "research_objectives": ["objective1", "objective2", "objective3"],
            "sections": [
                {"title": "Section 1", "description": "What this section covers"},
                {"title": "Section 2", "description": "What this section covers"}
            ],
            "sub_queries": ["query1", "query2", "query3"],
            "expected_jurisdictions": ["EU", "US", "CANADA"],
            "complexity_level": "simple|moderate|complex",
            "estimated_depth": 3
        }
        """
        
        try:
            messages = [{"role": "user", "content": f"Create research plan for: {query}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            plan_data = safe_json_parse(response, {})
            
            return ResearchPlan(
                main_topic=plan_data.get("main_topic", query),
                research_objectives=plan_data.get("research_objectives", []),
                sections=plan_data.get("sections", []),
                sub_queries=plan_data.get("sub_queries", [query]),
                expected_jurisdictions=plan_data.get("expected_jurisdictions", []),
                complexity_level=plan_data.get("complexity_level", "moderate"),
                estimated_depth=plan_data.get("estimated_depth", 3)
            )
            
        except Exception as e:
            logger.error(f"Error creating research plan: {e}")
            return ResearchPlan(
                main_topic=query,
                research_objectives=["Investigate the topic"],
                sections=[{"title": "Main Investigation", "description": "Primary research"}],
                sub_queries=[query],
                expected_jurisdictions=["EU", "US"],
                complexity_level="moderate",
                estimated_depth=2
            )

# Deep Research Reflection Agent
class DeepResearchReflector:
    """Analyzes research findings and identifies knowledge gaps for next iteration"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.name = "DeepResearchReflector"
    
    async def analyze_iteration(self, iteration: ResearchIteration, research_state: ResearchState) -> Dict[str, Any]:
        """Analyze current iteration and determine next steps"""
        system_prompt = """
        You are a research analysis expert. Analyze the findings from this research iteration
        and determine what knowledge gaps remain and what should be investigated next.
        
        Evaluate:
        1. Quality and completeness of current findings
        2. Identified knowledge gaps
        3. Confidence in current understanding
        4. Whether more research is needed
        5. Specific queries for next iteration
        
        Return JSON:
        {
            "findings_summary": ["key finding 1", "key finding 2"],
            "knowledge_gaps": ["gap 1", "gap 2"],
            "confidence_score": 0.75,
            "should_continue": true,
            "next_queries": ["next query 1", "next query 2"],
            "reasoning": "Why continue or stop research"
        }
        """
        
        try:
            # Prepare context for analysis
            context = f"""
            Research Topic: {research_state.original_query}
            Current Iteration: {iteration.iteration_number}
            
            Current Findings:
            {chr(10).join(iteration.findings)}
            
            Search Results Summary:
            {len(iteration.search_results)} results from {len(set(r.jurisdiction for r in iteration.search_results))} jurisdictions
            
            Accumulated Knowledge So Far:
            {dict(list(research_state.accumulated_knowledge.items())[:3])}
            """
            
            messages = [{"role": "user", "content": context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            analysis = safe_json_parse(response, {})
            
            return {
                "findings_summary": analysis.get("findings_summary", []),
                "knowledge_gaps": analysis.get("knowledge_gaps", []),
                "confidence_score": analysis.get("confidence_score", 0.5),
                "should_continue": analysis.get("should_continue", False),
                "next_queries": analysis.get("next_queries", []),
                "reasoning": analysis.get("reasoning", "Analysis completed")
            }
            
        except Exception as e:
            logger.error(f"Error in research reflection: {e}")
            return {
                "findings_summary": ["Research iteration completed"],
                "knowledge_gaps": ["More investigation needed"],
                "confidence_score": 0.5,
                "should_continue": False,
                "next_queries": [],
                "reasoning": f"Error in analysis: {str(e)}"
            }
    
    async def synthesize_findings(self, research_state: ResearchState) -> str:
        """Synthesize all research iterations into a comprehensive report"""
        system_prompt = """
        Synthesize all research findings into a comprehensive, well-structured report.
        Create a detailed analysis that covers all aspects investigated.
        
        Structure the report with:
        1. Executive Summary
        2. Main Findings by Topic/Jurisdiction
        3. Detailed Analysis
        4. Conclusions and Implications
        5. Sources and Citations
        
        Make it comprehensive yet readable, focusing on data privacy regulations.
        """
        
        try:
            # Compile all findings
            all_findings = []
            all_sources = []
            
            for iteration in research_state.iterations:
                all_findings.extend(iteration.findings)
                all_sources.extend([f"{r.jurisdiction} - {r.title}" for r in iteration.search_results])
            
            context = f"""
            Research Topic: {research_state.original_query}
            Total Iterations: {len(research_state.iterations)}
            
            All Findings:
            {chr(10).join(all_findings)}
            
            Knowledge Areas Covered:
            {research_state.accumulated_knowledge}
            
            Sources Used:
            {chr(10).join(set(all_sources))}
            """
            
            messages = [{"role": "user", "content": context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            return response
            
        except Exception as e:
            logger.error(f"Error synthesizing findings: {e}")
            return f"Research completed with findings from {len(research_state.iterations)} iterations."

# Custom Embeddings Wrapper for Direct OpenAI API
class DirectOpenAIEmbeddings(Embeddings):
    """Custom embeddings class that uses direct OpenAI API calls"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
        super().__init__()
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs synchronously"""
        try:
            loop = get_event_loop()
            if loop.is_running():
                # If we're in an async context, create a task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self._aembed_documents(texts))
                    return future.result()
            else:
                return asyncio.run(self._aembed_documents(texts))
        except Exception as e:
            logger.error(f"Error in embed_documents: {e}")
            return [[0.0] * config.EMBEDDING_DIMENSIONS for _ in texts]
    
    def embed_query(self, text: str) -> List[float]:
        """Embed query text synchronously"""
        try:
            loop = get_event_loop()
            if loop.is_running():
                # If we're in an async context, create a task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self.openai_manager.create_embedding(text))
                    return future.result()
            else:
                return asyncio.run(self.openai_manager.create_embedding(text))
        except Exception as e:
            logger.error(f"Error in embed_query: {e}")
            return [0.0] * config.EMBEDDING_DIMENSIONS
    
    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs asynchronously"""
        return await self._aembed_documents(texts)
    
    async def aembed_query(self, text: str) -> List[float]:
        """Embed query text asynchronously"""
        return await self.openai_manager.create_embedding(text)
    
    async def _aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Internal method to embed multiple documents"""
        embeddings = []
        for text in texts:
            try:
                embedding = await self.openai_manager.create_embedding(text)
                embeddings.append(embedding)
            except Exception as e:
                logger.error(f"Error embedding document: {e}")
                # Return zero vector as fallback
                embeddings.append([0.0] * config.EMBEDDING_DIMENSIONS)
        return embeddings

# Dynamic Concept Discovery Engine
class DynamicConceptEngine:
    """Engine for dynamically discovering concepts, terms, and patterns from documents"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
        self.concept_cache: Dict[str, Any] = {}
        self.pattern_cache: Dict[str, List[str]] = {}
        self.relationship_cache: Dict[str, Dict] = {}
    
    async def extract_key_terms_from_query(self, query: str) -> List[str]:
        """Dynamically extract key terms from a query using AI"""
        if not query or not isinstance(query, str):
            return []
        
        # Check cache first
        cache_key = f"terms_{hash(query)}"
        if cache_key in self.concept_cache:
            return self.concept_cache[cache_key]
        
        system_prompt = """
        Analyze the given query and extract key terms, concepts, and entities that would be important 
        for searching legal/regulatory documents about data privacy and protection. Focus on:
        1. Data privacy terms and acronyms
        2. Legal concepts across jurisdictions
        3. Regulatory terms
        4. Compliance processes
        5. Roles and responsibilities
        6. Jurisdiction-specific terms
        
        Return only a JSON array of terms:
        ["term1", "term2", "term3"]
        """
        
        try:
            messages = [{"role": "user", "content": f"Extract key terms from: {query}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Parse JSON response
            terms = safe_json_parse(response, [])
            if not isinstance(terms, list):
                terms = []
            
            # Fallback if no terms found
            if not terms:
                terms = await self._fallback_term_extraction(query)
            
            # Cache result
            self.concept_cache[cache_key] = terms
            return terms
                
        except Exception as e:
            logger.error(f"Error in dynamic term extraction: {e}")
            return await self._fallback_term_extraction(query)
    
    async def _fallback_term_extraction(self, query: str) -> List[str]:
        """Fallback term extraction using basic NLP"""
        try:
            # Remove common words and extract potential terms
            words = re.findall(r'\b[A-Za-z]{3,}\b', query)
            
            # Common stop words to exclude
            stop_words = {
                'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 
                'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 
                'how', 'man', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 
                'did', 'its', 'let', 'put', 'say', 'she', 'too', 'use', 'what', 'when',
                'where', 'why', 'with', 'this', 'that', 'they', 'them', 'than', 'then'
            }
            
            # Filter for meaningful terms
            meaningful_terms = []
            for word in words:
                if (len(word) >= 3 and 
                    word.lower() not in stop_words):
                    meaningful_terms.append(word.lower())
            
            return list(set(meaningful_terms))[:10]  # Limit to 10 terms
            
        except Exception as e:
            logger.error(f"Error in fallback term extraction: {e}")
            return []

# Dynamic Elasticsearch Manager for Multi-Jurisdiction System
class DynamicElasticsearchManager:
    """Dynamic Elasticsearch manager that works with the multi-jurisdiction privacy indices"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.concept_engine = DynamicConceptEngine(openai_manager)
        self.client = self._create_client()
        self.embeddings = DirectOpenAIEmbeddings(openai_manager)
        
        # Initialize LangChain Elasticsearch stores
        self._setup_langchain_stores()
    
    def _create_client(self) -> Elasticsearch:
        """Create Elasticsearch client with SSL configuration"""
        try:
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            if os.path.exists(config.ES_CACERT_PATH):
                ssl_context.load_verify_locations(config.ES_CACERT_PATH)
            
            client = Elasticsearch(
                [{"host": config.ES_HOST, "port": config.ES_PORT, "scheme": "https"}],
                basic_auth=(config.ES_USERNAME, config.ES_PASSWORD),
                ssl_context=ssl_context,
                verify_certs=True,
                request_timeout=30,
                max_retries=3,
                retry_on_timeout=True
            )
            
            # Test connection
            info = client.info()
            logger.info(f"Connected to Elasticsearch: {info.get('version', {}).get('number', 'unknown')}")
            return client
            
        except Exception as e:
            logger.error(f"Failed to create Elasticsearch client: {e}")
            raise
    
    def _setup_langchain_stores(self):
        """Setup LangChain Elasticsearch stores for the privacy indices"""
        try:
            # Articles store for privacy_articles index
            self.articles_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="privacy_articles",
                embedding=self.embeddings,
                vector_query_field="full_article_embedding",
                query_field="full_content",
                strategy=DenseVectorStrategy(
                    hybrid=False
                ),
                distance_strategy="COSINE"
            )
            logger.info("✓ Privacy articles store initialized")
            
            # Chunks store for privacy_chunks index
            self.chunks_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="privacy_chunks",
                embedding=self.embeddings,
                vector_query_field="chunk_embedding",
                query_field="content",
                strategy=DenseVectorStrategy(
                    hybrid=False
                ),
                distance_strategy="COSINE"
            )
            logger.info("✓ Privacy chunks store initialized")
            
            # Create retrievers
            self.articles_retriever = self.articles_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 8}
            )
            
            self.chunks_retriever = self.chunks_store.as_retriever(
                search_type="similarity", 
                search_kwargs={"k": 15}
            )
            
            logger.info("✓ Dynamic LangChain Elasticsearch stores initialized successfully")
            
        except Exception as e:
            logger.error(f"Error setting up LangChain stores: {e}")
            raise
    
    async def dynamic_search_articles(self, query: str, k: int = 8, filters: Dict = None) -> List[Document]:
        """Dynamic search that adapts based on query analysis"""
        if not query:
            return []
        
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            # Use native Elasticsearch search with filters
            return await self._elasticsearch_filtered_search(
                "privacy_articles", enhanced_query, k, filters, "full_article_embedding"
            )
        except Exception as e:
            logger.error(f"Error in dynamic article search: {e}")
            return []
    
    async def dynamic_search_chunks(self, query: str, k: int = 15, filters: Dict = None) -> List[Document]:
        """Dynamic chunk search with adaptive strategies"""
        if not query:
            return []
        
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            # Use native Elasticsearch search with filters
            return await self._elasticsearch_filtered_search(
                "privacy_chunks", enhanced_query, k, filters, "chunk_embedding"
            )
        except Exception as e:
            logger.error(f"Error in dynamic chunk search: {e}")
            return []
    
    async def _elasticsearch_filtered_search(self, index_name: str, query: str, k: int, 
                                          filters: Dict, vector_field: str) -> List[Document]:
        """Perform filtered search using native Elasticsearch"""
        try:
            # Create embedding for the query
            query_embedding = await self.openai_manager.create_embedding(query)
            
            # Build filter query
            filter_queries = []
            if filters:
                for field, values in filters.items():
                    if isinstance(values, list):
                        filter_queries.append({"terms": {field: values}})
                    else:
                        filter_queries.append({"term": {field: values}})
            
            # Build the search query
            body = {
                "size": k,
                "query": {
                    "bool": {
                        "must": [
                            {
                                "script_score": {
                                    "query": {"match_all": {}},
                                    "script": {
                                        "source": f"cosineSimilarity(params.query_vector, '{vector_field}') + 1.0",
                                        "params": {"query_vector": query_embedding}
                                    }
                                }
                            }
                        ],
                        "filter": filter_queries
                    }
                }
            }
            
            # Execute search
            response = self.client.search(index=index_name, body=body)
            
            # Convert to Documents
            docs = []
            for hit in response['hits']['hits']:
                source = hit['_source']
                
                # Get the appropriate content field
                if index_name == "privacy_articles":
                    content = source.get('full_content', '')
                else:
                    content = source.get('content', '')
                
                doc = Document(
                    page_content=content,
                    metadata={
                        **source,
                        '_score': hit['_score'],
                        '_id': hit['_id']
                    }
                )
                docs.append(doc)
            
            return docs
            
        except Exception as e:
            logger.error(f"Error in filtered Elasticsearch search: {e}")
            return []
    
    async def search_across_jurisdictions(self, query: str, jurisdictions: List[str] = None) -> Dict[str, List[Document]]:
        """Search across multiple jurisdictions"""
        try:
            results = {
                "articles": [],
                "chunks": []
            }
            
            # Create filters if jurisdictions specified
            filters = None
            if jurisdictions:
                filters = {"jurisdiction": jurisdictions}
            
            # Search both articles and chunks
            articles = await self.dynamic_search_articles(query, k=8, filters=filters)
            chunks = await self.dynamic_search_chunks(query, k=15, filters=filters)
            
            results["articles"] = articles
            results["chunks"] = chunks
            
            return results
            
        except Exception as e:
            logger.error(f"Error in cross-jurisdiction search: {e}")
            return {"articles": [], "chunks": []}
    
    async def get_jurisdiction_summary(self) -> Dict[str, Any]:
        """Get summary of all jurisdictions and frameworks in the system"""
        try:
            aggs_query = {
                "size": 0,
                "aggs": {
                    "jurisdictions": {
                        "terms": {"field": "jurisdiction", "size": 50}
                    },
                    "document_types": {
                        "terms": {"field": "document_type", "size": 50}
                    },
                    "framework_types": {
                        "terms": {"field": "framework_type", "size": 20}
                    }
                }
            }
            
            response = self.client.search(index="privacy_chunks", body=aggs_query)
            
            return {
                "total_documents": response["hits"]["total"]["value"],
                "jurisdictions": [bucket["key"] for bucket in response["aggregations"]["jurisdictions"]["buckets"]],
                "document_types": [bucket["key"] for bucket in response["aggregations"]["document_types"]["buckets"]],
                "framework_types": [bucket["key"] for bucket in response["aggregations"]["framework_types"]["buckets"]]
            }
            
        except Exception as e:
            logger.error(f"Error getting jurisdiction summary: {e}")
            return {}
    
    async def _enhance_query_with_terms(self, original_query: str, key_terms: List[str]) -> str:
        """Enhance query with dynamically discovered terms"""
        if not key_terms or not original_query:
            return original_query
        
        # Use AI to intelligently combine query with terms
        system_prompt = """
        Enhance the original query by incorporating the key terms in a natural way 
        that would improve search results in privacy/data protection documents.
        
        Return only the enhanced query string.
        """
        
        try:
            context = f"Original query: {original_query}\nKey terms: {', '.join(key_terms[:5])}"
            messages = [{"role": "user", "content": context}]
            enhanced_query = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Clean the response
            enhanced_query = enhanced_query.strip().strip('"\'')
            
            return enhanced_query if enhanced_query else original_query
            
        except Exception as e:
            logger.error(f"Error enhancing query: {e}")
            # Fallback: simple concatenation
            return f"{original_query} {' '.join(key_terms[:3])}"
    
    def get_diagnostics(self) -> Dict[str, Any]:
        """Get diagnostic information about the Elasticsearch configuration"""
        diagnostics = {
            "elasticsearch": {
                "connected": False,
                "version": "unknown",
                "indices": {}
            },
            "errors": []
        }
        
        try:
            # Check ES connection
            info = self.client.info()
            diagnostics["elasticsearch"]["connected"] = True
            diagnostics["elasticsearch"]["version"] = info.get('version', {}).get('number', 'unknown')
            
            # Check each index
            for index_name in ["privacy_articles", "privacy_chunks", "privacy_links", "agent_memories"]:
                try:
                    if self.client.indices.exists(index=index_name):
                        stats = self.client.indices.stats(index=index_name)
                        doc_count = stats['indices'][index_name]['primaries']['docs']['count']
                        diagnostics["elasticsearch"]["indices"][index_name] = {
                            "exists": True,
                            "document_count": doc_count
                        }
                    else:
                        diagnostics["elasticsearch"]["indices"][index_name] = {
                            "exists": False
                        }
                except Exception as e:
                    diagnostics["errors"].append(f"Error checking {index_name}: {str(e)}")
                    
        except Exception as e:
            diagnostics["errors"].append(f"Error getting diagnostics: {str(e)}")
            
        return diagnostics

# Deep Research Iterator
class DeepResearchIterator:
    """Manages the iterative research process following Open Deep Research patterns"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager, openai_manager: AdvancedOpenAIManager):
        self.es_manager = es_manager
        self.openai_manager = openai_manager
        self.planner = DeepResearchPlanner(openai_manager)
        self.reflector = DeepResearchReflector(openai_manager)
        self.name = "DeepResearchIterator"
    
    async def conduct_deep_research(self, query: str, max_iterations: int = 3, 
                                  confidence_threshold: float = 0.8) -> ResearchState:
        """Conduct comprehensive iterative research following Open Deep Research patterns"""
        logger.info(f"Starting deep research for: {query}")
        
        # Initialize research state
        context = ConversationContext(
            thread_id=str(uuid.uuid4()),
            query=query
        )
        
        research_plan = await self.planner.create_research_plan(query, context)
        logger.info(f"Created research plan with {len(research_plan.sections)} sections")
        
        research_state = ResearchState(
            original_query=query,
            research_plan=research_plan,
            iterations=[],
            accumulated_knowledge={},
            knowledge_gaps=[],
            current_iteration=0,
            max_iterations=max_iterations,
            confidence_threshold=confidence_threshold
        )
        
        # Iterative research loop (Open Deep Research pattern)
        for iteration_num in range(max_iterations):
            logger.info(f"Starting research iteration {iteration_num + 1}/{max_iterations}")
            
            # Determine queries for this iteration
            if iteration_num == 0:
                queries = research_plan.sub_queries
            else:
                # Use queries from previous reflection
                prev_iteration = research_state.iterations[-1]
                queries = prev_iteration.next_queries if prev_iteration.next_queries else [query]
            
            # Conduct research for this iteration
            iteration = await self._conduct_single_iteration(
                iteration_num + 1, queries, research_state
            )
            
            # Reflect on findings and determine next steps
            reflection = await self.reflector.analyze_iteration(iteration, research_state)
            
            # Update iteration with reflection results
            iteration.findings.extend(reflection["findings_summary"])
            iteration.knowledge_gaps = reflection["knowledge_gaps"]
            iteration.confidence_score = reflection["confidence_score"]
            iteration.next_queries = reflection["next_queries"]
            iteration.should_continue = reflection["should_continue"]
            
            # Add to research state
            research_state.iterations.append(iteration)
            research_state.current_iteration = iteration_num + 1
            
            # Update accumulated knowledge
            self._update_knowledge_state(research_state, iteration)
            
            logger.info(f"Iteration {iteration_num + 1} completed. Confidence: {iteration.confidence_score:.2f}")
            
            # Check if we should continue
            if (iteration.confidence_score >= confidence_threshold or 
                not iteration.should_continue or
                not iteration.next_queries):
                logger.info("Research convergence achieved or stopping criteria met")
                break
        
        # Synthesize final report
        research_state.final_report = await self.reflector.synthesize_findings(research_state)
        research_state.is_complete = True
        
        logger.info(f"Deep research completed after {len(research_state.iterations)} iterations")
        return research_state
    
    async def _conduct_single_iteration(self, iteration_num: int, queries: List[str], 
                                      research_state: ResearchState) -> ResearchIteration:
        """Conduct a single research iteration"""
        all_results = []
        findings = []
        
        for query in queries:
            try:
                # Search across jurisdictions
                search_results = await self.es_manager.search_across_jurisdictions(query)
                
                # Convert to SearchResult objects
                for doc in search_results.get("articles", [])[:3]:
                    result = self._document_to_search_result(doc, "article")
                    if result:
                        all_results.append(result)
                
                for doc in search_results.get("chunks", [])[:5]:
                    result = self._document_to_search_result(doc, "chunk")
                    if result:
                        all_results.append(result)
                
                # Extract findings from this query
                query_findings = await self._extract_findings_from_results(
                    query, all_results[-8:]
                )
                findings.extend(query_findings)
                
            except Exception as e:
                logger.error(f"Error in query '{query}': {e}")
                continue
        
        return ResearchIteration(
            iteration_number=iteration_num,
            queries=queries,
            search_results=all_results,
            findings=findings,
            knowledge_gaps=[],
            confidence_score=0.0,
            next_queries=[],
            should_continue=True
        )
    
    async def _extract_findings_from_results(self, query: str, results: List[SearchResult]) -> List[str]:
        """Extract key findings from search results"""
        if not results:
            return []
        
        system_prompt = """
        Analyze the search results and extract 2-3 key findings that directly answer 
        or relate to the research query. Focus on:
        1. Specific regulatory requirements
        2. Jurisdictional differences
        3. Compliance obligations
        4. Practical implications
        
        Return JSON array: ["finding 1", "finding 2", "finding 3"]
        """
        
        try:
            context = f"Query: {query}\n\nSearch Results:\n"
            for result in results[:5]:
                context += f"- {result.jurisdiction}: {result.content[:200]}...\n"
            
            messages = [{"role": "user", "content": context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            findings = safe_json_parse(response, [])
            return findings if isinstance(findings, list) else []
            
        except Exception as e:
            logger.error(f"Error extracting findings: {e}")
            return [f"Results found for query: {query}"]
    
    def _document_to_search_result(self, doc: Document, doc_type: str) -> Optional[SearchResult]:
        """Convert LangChain Document to SearchResult"""
        try:
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            
            return SearchResult(
                content=doc.page_content,
                title=metadata.get('title', f'{doc_type.title()} Document'),
                document_type=metadata.get('document_type', 'Unknown'),
                jurisdiction=metadata.get('jurisdiction', 'Unknown'),
                framework_type=metadata.get('framework_type', 'Unknown'),
                article_number=metadata.get('article_number'),
                chapter_number=metadata.get('chapter_number', 'Unknown'),
                score=float(metadata.get('_score', 0.8)),
                chunk_id=metadata.get('chunk_id'),
                article_id=metadata.get('article_id'),
                page_number=metadata.get('page_number'),
                key_concepts=metadata.get('key_concepts', []),
                supporting_references=metadata.get('supporting_references', [])
            )
            
        except Exception as e:
            logger.error(f"Error converting document: {e}")
            return None
    
    def _update_knowledge_state(self, research_state: ResearchState, iteration: ResearchIteration):
        """Update accumulated knowledge state"""
        for finding in iteration.findings:
            # Categorize findings by topic
            topic_key = "general"
            if any(word in finding.lower() for word in ['gdpr', 'european']):
                topic_key = "gdpr"
            elif any(word in finding.lower() for word in ['ccpa', 'california']):
                topic_key = "ccpa"
            elif any(word in finding.lower() for word in ['consent']):
                topic_key = "consent"
            elif any(word in finding.lower() for word in ['breach', 'notification']):
                topic_key = "breach"
            
            if topic_key not in research_state.accumulated_knowledge:
                research_state.accumulated_knowledge[topic_key] = []
            
            research_state.accumulated_knowledge[topic_key].append(finding)

# Dynamic Analysis Agent
class DynamicAnalysisAgent:
    """Agent that performs adaptive query and content analysis"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.name = "DynamicAnalysisAgent"
    
    async def analyze_query_dynamically(self, query: str, context: ConversationContext) -> Dict[str, Any]:
        """Perform dynamic, adaptive query analysis"""
        if not query:
            return {
                "intent": "unknown",
                "complexity": "simple",
                "entities": [],
                "domain_focus": "general",
                "requires_cross_analysis": False,
                "optimal_approach": "business",
                "response_format": "simple",
                "reasoning": "Empty query provided"
            }
        
        system_prompt = """
        Perform a comprehensive analysis of the user's data privacy query. Consider:
        
        1. Primary intent and secondary objectives
        2. Complexity level and required expertise
        3. Key entities, concepts, and relationships
        4. Context clues and domain indicators
        5. Optimal response format and approach
        6. Cross-jurisdiction analysis requirements
        7. Business vs technical vs legal focus
        
        Adapt your analysis to the specific query characteristics.
        
        Return JSON:
        {
            "intent": "primary intent",
            "complexity": "simple|moderate|complex",
            "entities": ["entity1", "entity2"],
            "domain_focus": "business|technical|legal|mixed",
            "requires_cross_analysis": boolean,
            "optimal_approach": "approach_type",
            "response_format": "format_type",
            "reasoning": "analysis reasoning"
        }
        """
        
        try:
            analysis_context = f"Query: {query}\nPrevious context: {context.current_analysis}"
            messages = [{"role": "user", "content": analysis_context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            analysis = safe_json_parse(response, {})
            if not isinstance(analysis, dict):
                analysis = {}
            
            # Ensure all required fields are present
            return {
                "intent": analysis.get("intent", "explanation"),
                "complexity": analysis.get("complexity", "moderate"),
                "entities": analysis.get("entities", []),
                "domain_focus": analysis.get("domain_focus", "mixed"),
                "requires_cross_analysis": analysis.get("requires_cross_analysis", False),
                "optimal_approach": analysis.get("optimal_approach", "business"),
                "response_format": analysis.get("response_format", "structured"),
                "reasoning": analysis.get("reasoning", "Analysis completed")
            }
                
        except Exception as e:
            logger.error(f"Error in dynamic query analysis: {e}")
            return {
                "intent": "explanation",
                "complexity": "moderate",
                "entities": [],
                "domain_focus": "mixed",
                "requires_cross_analysis": False,
                "optimal_approach": "business",
                "response_format": "structured",
                "reasoning": f"Fallback analysis due to error: {str(e)}"
            }

# Dynamic QA Chain Manager
class DynamicQAChainManager:
    """Dynamic QA Chain Manager that adapts chain selection based on query analysis"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        self.es_manager = es_manager
        
        # Create LLM without temperature/token limits
        self.llm = ChatOpenAI(
            model=config.REASONING_MODEL,
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        )
        
        self._setup_dynamic_chains()
    
    def _setup_dynamic_chains(self):
        """Setup QA chains with dynamic prompts"""
        try:
            # Create a simple retriever for the chains
            from langchain_core.retrievers import BaseRetriever
            
            class SimpleRetriever(BaseRetriever):
                def __init__(self, es_manager):
                    super().__init__()
                    self.es_manager = es_manager
                
                def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:
                    try:
                        # Synchronous search
                        loop = get_event_loop()
                        if loop.is_running():
                            import concurrent.futures
                            with concurrent.futures.ThreadPoolExecutor() as executor:
                                future = executor.submit(asyncio.run, self._async_search(query))
                                return future.result()
                        else:
                            return asyncio.run(self._async_search(query))
                    except Exception as e:
                        logger.error(f"Error in retriever: {e}")
                        return []
                
                async def _async_search(self, query: str) -> List[Document]:
                    results = await self.es_manager.search_across_jurisdictions(query)
                    return results.get("chunks", [])[:10]
            
            self.retriever = SimpleRetriever(self.es_manager)
            
            # Basic RetrievalQA Chain
            self.retrieval_qa = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.retriever,
                return_source_documents=True
            )
            
            logger.info("✓ Dynamic QA chains initialized")
            
        except Exception as e:
            logger.error(f"Error setting up dynamic chains: {e}")
            raise
    
    async def answer_with_dynamic_chain(self, query: str, context: ConversationContext, 
                                      chain_type: str = None) -> Dict[str, Any]:
        """Answer using dynamically selected QA chain"""
        if not query:
            return {
                "answer": "Please provide a question.",
                "source_documents": [],
                "chain_type": "error"
            }
        
        try:
            # Use the basic retrieval chain
            result = self.retrieval_qa.invoke({"query": query})
            return {
                "answer": result["result"],
                "source_documents": result.get("source_documents", []),
                "chain_type": "retrieval"
            }
                
        except Exception as e:
            logger.error(f"Error in dynamic QA chain: {e}")
            return {
                "answer": f"I apologize, but I encountered an error processing your question: {str(e)}",
                "source_documents": [],
                "chain_type": "error"
            }

# Deep Research Tools for ReAct Agent
@tool
async def deep_research_tool(query: str, max_iterations: int = 3, config: RunnableConfig = None) -> str:
    """
    Conduct deep iterative research following Open Deep Research patterns.
    
    Args:
        query: The research topic/question
        max_iterations: Maximum number of research iterations (default: 3)
    
    Returns:
        Comprehensive research report with iterative findings
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        es_manager = config["configurable"]["es_manager"]
        openai_manager = config["configurable"]["openai_manager"]
        
        # Create deep research iterator
        iterator = DeepResearchIterator(es_manager, openai_manager)
        
        # Conduct deep research
        research_state = await iterator.conduct_deep_research(
            query, max_iterations=max_iterations, confidence_threshold=0.75
        )
        
        # Format comprehensive response
        response = f"# Deep Research Report: {research_state.original_query}\n\n"
        
        if research_state.research_plan:
            response += f"**Research Scope:** {research_state.research_plan.main_topic}\n"
            response += f"**Complexity:** {research_state.research_plan.complexity_level}\n"
            response += f"**Iterations Completed:** {len(research_state.iterations)}\n\n"
        
        # Add iteration summary
        response += "## Research Process Summary\n\n"
        for i, iteration in enumerate(research_state.iterations, 1):
            response += f"**Iteration {i}:**\n"
            response += f"- Queries: {', '.join(iteration.queries)}\n"
            response += f"- Results: {len(iteration.search_results)} documents\n"
            response += f"- Findings: {len(iteration.findings)} key insights\n"
            response += f"- Confidence: {iteration.confidence_score:.1%}\n\n"
        
        # Add final report
        response += "## Comprehensive Analysis\n\n"
        response += research_state.final_report
        
        # Add knowledge areas covered
        if research_state.accumulated_knowledge:
            response += "\n\n## Knowledge Areas Covered\n\n"
            for topic, findings in research_state.accumulated_knowledge.items():
                response += f"**{topic.upper()}:** {len(findings)} insights\n"
        
        return response
        
    except Exception as e:
        logger.error(f"Error in deep research tool: {e}")
        return f"Error conducting deep research: {str(e)}"

@tool
async def adaptive_qa_chain_tool(query: str, chain_type: str = "auto", config: RunnableConfig = None) -> str:
    """
    Use adaptive QA chains that dynamically select optimal approach.
    
    Args:
        query: The question to answer
        chain_type: Chain type ("auto", "definition", "compliance", "business", "comparison", "conversational")
    
    Returns:
        Comprehensive answer from adaptive QA chain
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        qa_manager = config["configurable"]["qa_manager"]
        context = config["configurable"]["context"]
        
        result = await qa_manager.answer_with_dynamic_chain(query, context, chain_type)
        
        answer = result["answer"]
        chain_used = result["chain_type"]
        num_sources = len(result.get("source_documents", []))
        
        formatted_response = f"**Answer (using {chain_used} chain with {num_sources} sources):**\n\n{answer}"
        
        # Add source information
        if result.get("source_documents"):
            formatted_response += "\n\n**Sources:**\n"
            for i, doc in enumerate(result["source_documents"][:3]):
                metadata = getattr(doc, 'metadata', {})
                formatted_response += (
                    f"{i+1}. {metadata.get('jurisdiction', 'Unknown')} - "
                    f"{metadata.get('document_type', 'Unknown')} - "
                    f"{metadata.get('title', 'Unknown')}\n"
                )
        
        return formatted_response
        
    except Exception as e:
        logger.error(f"Error in adaptive QA chain tool: {e}")
        return f"Error in adaptive QA chain: {str(e)}"

@tool
async def dynamic_search_tool(query: str, search_strategy: str = "adaptive", 
                            jurisdiction: str = None, k: int = 10, config: RunnableConfig = None) -> str:
    """
    Perform dynamic search that adapts its strategy based on query analysis.
    
    Args:
        query: The search query
        search_strategy: Strategy type ("adaptive", "articles", "chunks", "cross_jurisdiction")
        jurisdiction: Optional filter for specific jurisdiction
        k: Maximum number of results
    
    Returns:
        Formatted search results
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        es_manager = config["configurable"]["es_manager"]
        
        filters = None
        if jurisdiction:
            filters = {"jurisdiction": [jurisdiction.upper()]}
        
        if search_strategy == "articles":
            docs = await es_manager.dynamic_search_articles(query, k=k, filters=filters)
        elif search_strategy == "chunks":
            docs = await es_manager.dynamic_search_chunks(query, k=k, filters=filters)
        elif search_strategy == "cross_jurisdiction":
            results = await es_manager.search_across_jurisdictions(query)
            docs = results.get("articles", []) + results.get("chunks", [])
        else:  # adaptive
            results = await es_manager.search_across_jurisdictions(query, jurisdictions=[jurisdiction] if jurisdiction else None)
            docs = results.get("articles", [])[:k//2] + results.get("chunks", [])[:k//2]
        
        if not docs:
            return f"No relevant results found for query: {query}"
        
        formatted_results = []
        for i, doc in enumerate(docs):
            metadata = getattr(doc, 'metadata', {})
            score = metadata.get('_score', 0.0)
            
            formatted_results.append(
                f"Result {i+1} (Score: {score:.3f}):\n"
                f"Jurisdiction: {metadata.get('jurisdiction', 'N/A')}\n"
                f"Document: {metadata.get('document_type', 'N/A')}\n"
                f"Framework: {metadata.get('framework_type', 'N/A')}\n"
                f"Title: {metadata.get('title', 'N/A')}\n"
                f"Content: {doc.page_content[:400]}...\n"
            )
        
        return "\n---\n".join(formatted_results)
        
    except Exception as e:
        logger.error(f"Error in dynamic search tool: {e}")
        return f"Error in dynamic search: {str(e)}"

@tool
async def jurisdiction_summary_tool(config: RunnableConfig = None) -> str:
    """
    Get a summary of all jurisdictions and frameworks available in the system.
    
    Returns:
        Summary of system coverage
    """
    try:
        es_manager = config["configurable"]["es_manager"]
        
        summary_data = await es_manager.get_jurisdiction_summary()
        
        if not summary_data:
            return "No jurisdiction data available"
        
        summary = []
        summary.append("=== PRIVACY FRAMEWORK COVERAGE ===\n")
        
        summary.append(f"Total Documents: {summary_data.get('total_documents', 0):,}")
        
        if summary_data.get('jurisdictions'):
            summary.append(f"\nJurisdictions ({len(summary_data['jurisdictions'])}):")
            for jurisdiction in sorted(summary_data['jurisdictions']):
                summary.append(f"• {jurisdiction}")
        
        if summary_data.get('document_types'):
            summary.append(f"\nDocument Types ({len(summary_data['document_types'])}):")
            for doc_type in sorted(summary_data['document_types']):
                summary.append(f"• {doc_type}")
        
        if summary_data.get('framework_types'):
            summary.append(f"\nFramework Types:")
            for framework_type in sorted(summary_data['framework_types']):
                summary.append(f"• {framework_type.title()}")
        
        return "\n".join(summary)
        
    except Exception as e:
        logger.error(f"Error getting jurisdiction summary: {str(e)}")
        return f"Error getting jurisdiction summary: {str(e)}"

# Main Dynamic Privacy Chatbot with Deep Research
class DynamicPrivacyChatbot:
    """Main Privacy Q&A Chatbot with deep research capabilities"""
    
    def __init__(self):
        try:
            logger.info("Initializing Dynamic Privacy Chatbot with Deep Research capabilities...")
            
            # Initialize core managers
            self.openai_manager = AdvancedOpenAIManager()
            logger.info("✓ OpenAI manager initialized")
            
            self.es_manager = DynamicElasticsearchManager(self.openai_manager)
            logger.info("✓ Elasticsearch manager initialized")
            
            # Initialize specialized agents
            self.analysis_agent = DynamicAnalysisAgent(self.openai_manager)
            logger.info("✓ Dynamic analysis agent initialized")
            
            self.qa_manager = DynamicQAChainManager(self.es_manager)
            logger.info("✓ Dynamic QA manager initialized")
            
            # Initialize deep research components
            self.deep_research_iterator = DeepResearchIterator(self.es_manager, self.openai_manager)
            logger.info("✓ Deep research iterator initialized")
            
            self.memory_store = InMemoryStore()
            logger.info("✓ Memory store initialized")
            
            # Create ReAct agent with deep research capabilities
            self.react_agent = None
            self._create_dynamic_react_agent()
            logger.info("✓ Enhanced Deep Research ReAct agent initialized")
            
        except Exception as e:
            logger.error(f"Error initializing Dynamic Privacy Chatbot with Deep Research: {e}")
            raise
    
    def _create_dynamic_react_agent(self):
        """Create ReAct agent with dynamic, adaptive tools including deep research"""
        try:
            # Create comprehensive tool set including deep research
            tools = [
                deep_research_tool,
                adaptive_qa_chain_tool,
                dynamic_search_tool,
                jurisdiction_summary_tool
            ]
            
            # Create chat model
            chat_model = ChatOpenAI(
                model=config.REASONING_MODEL,
                api_key=config.OPENAI_API_KEY,
                base_url=config.OPENAI_BASE_URL
            )
            
            # Enhanced system prompt with deep research capabilities
            system_prompt = """
            You are an expert consultant specializing in global data privacy and protection compliance.
            You ONLY answer questions related to data privacy, data protection regulations, and related topics.
            
            Your expertise covers multiple jurisdictions including:
            - GDPR (EU), UK GDPR, CCPA (California), PIPEDA (Canada)
            - LGPD (Brazil), PDPA (Singapore), Privacy Act (Australia)
            - ISO 27001, SOC 2, NIST, and other privacy frameworks
            
            Your Advanced Capabilities:
            1. **Deep Iterative Research**: Conduct multi-iteration research following Open Deep Research patterns
            2. **Adaptive Search**: Dynamically discover and use the most relevant search strategies
            3. **Intelligent QA**: Select optimal response approaches based on query analysis
            4. **Cross-Jurisdiction Analysis**: Compare requirements across different frameworks
            
            Your Research Approach (following Open Deep Research patterns):
            1. **Plan**: Create structured research plans for complex queries
            2. **Research**: Conduct iterative research with multiple cycles
            3. **Reflect**: Analyze findings and identify knowledge gaps
            4. **Refine**: Generate new queries to fill identified gaps
            5. **Synthesize**: Combine findings into comprehensive answers
            
            When to Use Deep Research:
            - Complex, multi-faceted questions requiring comprehensive investigation
            - Cross-jurisdictional comparisons with multiple regulations
            - Questions requiring understanding of relationships between concepts
            - Topics where initial search results suggest deeper investigation needed
            
            When to Use Standard Tools:
            - Simple, direct questions with clear scope
            - Quick fact-checking or definitions
            - Single-jurisdiction specific queries
            
            Key Principles:
            - Only answer questions about data privacy and related regulations
            - For complex topics, default to deep research for comprehensive coverage
            - Consider multi-jurisdiction implications when relevant
            - Provide practical, actionable guidance
            - Cite specific regulations and requirements
            - Use iterative research to build comprehensive understanding
            
            You have access to powerful research tools that can conduct multiple iterations
            of investigation and synthesize comprehensive reports.
            Use them intelligently to provide the most thorough and accurate responses.
            """
            
            # Create ReAct agent
            self.react_agent = create_react_agent(
                model=chat_model,
                tools=tools,
                state_modifier=system_prompt
            )
            
            logger.info("Enhanced Deep Research ReAct Privacy chatbot created successfully")
            
        except Exception as e:
            logger.error(f"Error creating deep research ReAct agent: {e}")
            raise
    
    async def chat(self, user_query: str, thread_id: str = None) -> Dict[str, Any]:
        """Main chat interface with deep research processing"""
        try:
            if not user_query or len(user_query.strip()) < 3:
                return {
                    "answer": "Please provide a more detailed question about data privacy.",
                    "confidence": "low",
                    "thread_id": thread_id or "unknown"
                }
            
            # Check if query is privacy-related
            if not DataPrivacyFilter.is_privacy_related(user_query):
                return {
                    "answer": DataPrivacyFilter.get_rejection_message(),
                    "confidence": "high",
                    "thread_id": thread_id or str(uuid.uuid4()),
                    "intent": "non_privacy",
                    "complexity": "simple",
                    "approach": "rejection"
                }
            
            if not thread_id:
                thread_id = f"privacy_chat_{uuid.uuid4().hex[:8]}"
            
            # Create conversation context
            context = ConversationContext(
                thread_id=thread_id,
                query=user_query,
                intent="",
                entities=[],
                previous_searches=[],
                conversation_history=[],
                current_analysis={}
            )
            
            # Dynamic query analysis
            try:
                intent_analysis = await self.analysis_agent.analyze_query_dynamically(user_query, context)
                context.current_analysis = intent_analysis
                logger.info(f"Dynamic analysis - Intent: {intent_analysis.get('intent')}, Approach: {intent_analysis.get('optimal_approach')}")
            except Exception as e:
                logger.warning(f"Dynamic analysis failed: {e}")
                intent_analysis = {}
            
            # Configure ReAct agent with deep research capabilities
            config_dict = RunnableConfig(
                configurable={
                    "thread_id": thread_id,
                    "es_manager": self.es_manager,
                    "openai_manager": self.openai_manager,
                    "qa_manager": self.qa_manager,
                    "context": context
                }
            )
            
            # Run dynamic ReAct agent
            logger.info(f"Processing with deep research ReAct agent: {user_query[:100]}...")
            
            messages = [HumanMessage(content=user_query)]
            
            try:
                response = await self.react_agent.ainvoke(
                    {"messages": messages},
                    config=config_dict
                )
            except Exception as e:
                logger.error(f"ReAct agent failed: {e}")
                # Fallback to direct QA chain
                try:
                    qa_result = await self.qa_manager.answer_with_dynamic_chain(user_query, context)
                    return {
                        "answer": qa_result["answer"],
                        "confidence": "medium",
                        "thread_id": thread_id,
                        "intent": intent_analysis.get('intent', 'unknown'),
                        "complexity": intent_analysis.get('complexity', 'unknown'),
                        "approach": "fallback_qa"
                    }
                except Exception as e2:
                    logger.error(f"Fallback QA also failed: {e2}")
                    return {
                        "answer": "I apologize, but I encountered an error processing your data privacy question. Please try rephrasing it.",
                        "confidence": "low",
                        "thread_id": thread_id,
                        "intent": "error",
                        "complexity": "unknown",
                        "approach": "error"
                    }
            
            # Extract final answer
            final_answer = ""
            if response and "messages" in response:
                for message in reversed(response["messages"]):
                    if hasattr(message, 'content') and message.content:
                        content = str(message.content).strip()
                        if (content and 
                            not content.startswith('{"') and 
                            not content.startswith('Error:') and
                            len(content) > 50):
                            final_answer = content
                            break
            
            if not final_answer:
                # Fallback to dynamic QA chain
                logger.info("ReAct didn't provide answer, using dynamic QA chain fallback")
                try:
                    qa_result = await self.qa_manager.answer_with_dynamic_chain(user_query, context)
                    final_answer = qa_result["answer"]
                except Exception as e:
                    final_answer = "I apologize, but I couldn't generate a comprehensive answer about this data privacy topic. Please try rephrasing your question."
            
            # Dynamic answer quality assessment
            confidence = self._assess_answer_quality(final_answer, intent_analysis)
            
            return {
                "answer": final_answer,
                "confidence": confidence,
                "thread_id": thread_id,
                "intent": intent_analysis.get('intent', 'unknown'),
                "complexity": intent_analysis.get('complexity', 'unknown'),
                "approach": intent_analysis.get('optimal_approach', 'adaptive')
            }
            
        except Exception as e:
            logger.error(f"Error in dynamic chat processing: {e}")
            return {
                "answer": f"I apologize, but I encountered an error processing your data privacy question: {str(e)}",
                "confidence": "low",
                "thread_id": thread_id or "error"
            }
    
    def _assess_answer_quality(self, answer: str, intent_analysis: Dict) -> str:
        """Assess answer quality based on multiple factors"""
        if not answer or len(answer) < 50:
            return "low"
        
        try:
            base_score = 0
            
            # Length-based scoring
            if len(answer) > 200:
                base_score += 1
            if len(answer) > 500:
                base_score += 1
            
            # Structure-based scoring
            if "**" in answer or "###" in answer:
                base_score += 1
            
            # Content relevance scoring
            intent = intent_analysis.get('intent', 'unknown')
            if intent == "definition" and any(word in answer.lower() for word in ['means', 'refers to', 'defined as']):
                base_score += 1
            elif intent == "compliance" and any(word in answer.lower() for word in ['requirement', 'must', 'obligation']):
                base_score += 1
            
            return "high" if base_score >= 3 else "medium" if base_score >= 2 else "low"
                
        except Exception as e:
            logger.error(f"Error in quality assessment: {e}")
            return "medium"
    
    async def conduct_deep_research(self, query: str, max_iterations: int = 3) -> Dict[str, Any]:
        """Conduct standalone deep research for complex topics"""
        try:
            logger.info(f"Starting standalone deep research for: {query}")
            
            research_state = await self.deep_research_iterator.conduct_deep_research(
                query, max_iterations=max_iterations, confidence_threshold=0.75
            )
            
            return {
                "query": query,
                "iterations_completed": len(research_state.iterations),
                "research_plan": research_state.research_plan,
                "final_report": research_state.final_report,
                "accumulated_knowledge": research_state.accumulated_knowledge,
                "confidence": "high" if research_state.iterations and 
                             research_state.iterations[-1].confidence_score > 0.7 else "medium"
            }
            
        except Exception as e:
            logger.error(f"Error in standalone deep research: {e}")
            return {
                "query": query,
                "error": str(e),
                "final_report": "Deep research failed to complete.",
                "confidence": "low"
            }
    
    def get_diagnostics(self) -> Dict[str, Any]:
        """Get diagnostic information about the chatbot configuration"""
        try:
            diagnostics = self.es_manager.get_diagnostics()
            
            # Add deep research capabilities info
            diagnostics["deep_research"] = {
                "iterator_available": hasattr(self, 'deep_research_iterator'),
                "max_iterations_supported": 5,
                "research_planning": True,
                "iterative_refinement": True,
                "knowledge_gap_analysis": True
            }
            
            return diagnostics
        except Exception as e:
            return {"error": f"Failed to get diagnostics: {str(e)}"}

# Interface classes
class DynamicPrivacyChatbotInterface:
    """Dynamic interface for Privacy chatbot with Deep Research capabilities"""
    
    def __init__(self):
        self.chatbot = None
    
    async def initialize(self):
        """Initialize the dynamic chatbot with deep research"""
        try:
            logger.info("Initializing Dynamic Privacy Chatbot with Deep Research...")
            
            # Check if already initialized
            if self.chatbot is not None:
                logger.info("Chatbot already initialized")
                return True
            
            # Initialize the chatbot
            self.chatbot = DynamicPrivacyChatbot()
            
            # Validate initialization including deep research components
            if (hasattr(self.chatbot, 'openai_manager') and 
                hasattr(self.chatbot, 'es_manager') and 
                hasattr(self.chatbot, 'deep_research_iterator') and
                hasattr(self.chatbot, 'react_agent') and
                self.chatbot.react_agent is not None):
                logger.info("Dynamic Privacy Chatbot with Deep Research initialized successfully!")
                return True
            else:
                logger.error("Chatbot initialization incomplete - missing components")
                return False
                
        except Exception as e:
            logger.error(f"Failed to initialize dynamic chatbot with deep research: {e}")
            self.chatbot = None
            return False
    
    async def ask_question(self, question: str, thread_id: str = None) -> Dict[str, Any]:
        """Ask a question to the dynamic chatbot with deep research capabilities"""
        if not self.chatbot:
            if not await self.initialize():
                return {
                    "answer": "Chatbot failed to initialize. Please check your configuration.",
                    "confidence": "low",
                    "thread_id": thread_id or "error"
                }
        
        return await self.chatbot.chat(question, thread_id)
    
    async def conduct_deep_research(self, topic: str, max_iterations: int = 3) -> Dict[str, Any]:
        """Conduct deep research on a topic"""
        if not self.chatbot:
            if not await self.initialize():
                return {
                    "error": "Chatbot failed to initialize",
                    "final_report": "Unable to conduct research"
                }
        
        return await self.chatbot.conduct_deep_research(topic, max_iterations)

# Main execution functions
async def interactive_loop():
    """Interactive loop for the chatbot with deep research capabilities"""
    interface = DynamicPrivacyChatbotInterface()
    
    print("="*80)
    print("Dynamic Privacy Q&A Chatbot - Global Privacy Expert with Deep Research")
    print("="*80)
    print("Features:")
    print("• Multi-jurisdiction support with Dynamic Term Discovery")
    print("• Deep Iterative Research following Open Deep Research patterns")
    print("• Research Planning and Knowledge Gap Analysis") 
    print("• Adaptive Search with Query Refinement")
    print("• Cross-jurisdictional Analysis and Synthesis")
    print()
    print("Specializes in: GDPR, CCPA, LGPD, PIPEDA, and other privacy frameworks")
    print("Ask any questions about data privacy - the system adapts and conducts deep research.")
    print("Type 'exit' to quit, 'help' for examples")
    print("="*80)
    
    if not await interface.initialize():
        print("❌ Failed to initialize dynamic chatbot.")
        return
    
    thread_id = f"privacy_{uuid.uuid4().hex[:8]}"
    print(f"✅ Dynamic Privacy Chatbot ready! (Thread ID: {thread_id})")
    
    while True:
        try:
            question = input("\n💬 Your question: ").strip()
            
            if question.lower() in ['exit', 'quit', 'bye']:
                print("👋 Goodbye!")
                break
            
            if question.lower() == 'help':
                print("\n🧠 Deep Research Examples:")
                print("• How do consent mechanisms differ across GDPR, CCPA, and LGPD frameworks?")
                print("• What are the comprehensive data breach notification requirements globally?")
                print("• Analyze the evolution of data subject rights across jurisdictions")
                print("• How do international data transfer mechanisms compare in effectiveness?")
                print("• What are the implications of AI regulation on data privacy compliance?")
                print("• Comprehensive analysis of privacy by design requirements across frameworks")
                print()
                print("🔍 Standard Query Examples:")
                print("• What is the definition of personal data under GDPR?")
                print("• Compare data subject rights in EU vs California")
                print("• What are the penalties for non-compliance in different jurisdictions?")
                print()
                print("🛠️ Special commands:")
                print("• 'deep-research [topic]' - Conduct iterative deep research on complex topic")
                print("• 'diagnostics' - Show system diagnostic information")
                print("• 'jurisdictions' - Show available jurisdictions")
                print("• 'research-demo' - Run deep research demonstration")
                print("• 'exit' - Quit the chatbot")
                continue
            
            if question.lower().startswith('deep-research '):
                topic = question[14:].strip()
                if topic:
                    print(f"\n🔬 Conducting deep iterative research on: {topic}")
                    print("This may take 1-2 minutes for comprehensive analysis...")
                    try:
                        research_result = await interface.conduct_deep_research(topic, max_iterations=3)
                        print(f"\n📊 **Deep Research Completed**")
                        print(f"Iterations: {research_result.get('iterations_completed', 0)}")
                        print(f"Confidence: {research_result.get('confidence', 'unknown')}")
                        print("="*70)
                        print(research_result.get('final_report', 'No report generated'))
                        print("="*70)
                        
                        if research_result.get('accumulated_knowledge'):
                            print("\n📚 **Knowledge Areas Covered:**")
                            for area, insights in research_result['accumulated_knowledge'].items():
                                print(f"• {area.upper()}: {len(insights)} insights")
                                
                    except Exception as e:
                        print(f"Deep research error: {e}")
                else:
                    print("Please provide a topic for deep research. Example: deep-research GDPR consent requirements")
                continue
            
            if question.lower() == 'research-demo':
                print("\n🧪 Running Deep Research Demonstration...")
                demo_topic = "How do data breach notification requirements vary across major privacy frameworks and what are the key compliance challenges?"
                print(f"Demo Topic: {demo_topic}")
                print("This will take 1-2 minutes...")
                
                try:
                    research_result = await interface.conduct_deep_research(demo_topic, max_iterations=2)
                    print(f"\n📊 **Demo Research Completed**")
                    print(f"Iterations: {research_result.get('iterations_completed', 0)}")
                    print("="*70)
                    print(research_result.get('final_report', 'No report generated')[:1000] + "...")
                    print("="*70)
                except Exception as e:
                    print(f"Demo research error: {e}")
                continue
            
            if question.lower() == 'diagnostics':
                print("\n🔧 System Diagnostics:")
                print("-" * 70)
                diagnostics = interface.chatbot.get_diagnostics()
                print(json.dumps(diagnostics, indent=2))
                print("-" * 70)
                continue
            
            if question.lower() == 'jurisdictions':
                print("\n🌍 Checking available jurisdictions...")
                try:
                    summary = await interface.chatbot.es_manager.get_jurisdiction_summary()
                    if summary:
                        print(f"\nAvailable Jurisdictions: {', '.join(summary.get('jurisdictions', []))}")
                        print(f"Document Types: {', '.join(summary.get('document_types', []))}")
                        print(f"Framework Types: {', '.join(summary.get('framework_types', []))}")
                    else:
                        print("Unable to retrieve jurisdiction information")
                except Exception as e:
                    print(f"Error getting jurisdiction summary: {e}")
                continue
            
            if not question:
                print("Please enter a question.")
                continue
            
            print("\n🔍 Analyzing query and adapting approach dynamically...")
            
            response = await interface.ask_question(question, thread_id)
            
            print(f"\n📋 **Dynamic Answer** (Confidence: {response.get('confidence', 'unknown')})")
            print(f"Intent: {response.get('intent', 'unknown')} | Approach: {response.get('approach', 'unknown')}")
            print("="*70)
            print(response['answer'])
            print("="*70)
            
        except KeyboardInterrupt:
            print("\n👋 Goodbye!")
            break
        except Exception as e:
            print(f"\n❌ Error: {e}")

async def main():
    """Main function to run the dynamic chatbot with deep research capabilities"""
    print("Dynamic Privacy Q&A Chatbot - Global Privacy Expert with Deep Research")
    print("=" * 80)
    
    # Validate configuration
    print("🔍 Validating configuration...")
    
    try:
        # Test OpenAI connection
        test_client = openai.OpenAI(api_key=config.OPENAI_API_KEY, base_url=config.OPENAI_BASE_URL)
        test_response = test_client.chat.completions.create(
            model=config.REASONING_MODEL,
            messages=[{"role": "user", "content": "test"}],
            reasoning_effort=config.REASONING_EFFORT
        )
        print("✓ OpenAI API connection validated")
    except Exception as e:
        print(f"❌ Error: Cannot connect to OpenAI API: {e}")
        return
    
    # Test Elasticsearch connection
    try:
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        if os.path.exists(config.ES_CACERT_PATH):
            ssl_context.load_verify_locations(config.ES_CACERT_PATH)
        
        test_es = Elasticsearch(
            [{"host": config.ES_HOST, "port": config.ES_PORT, "scheme": "https"}],
            basic_auth=(config.ES_USERNAME, config.ES_PASSWORD),
            ssl_context=ssl_context,
            verify_certs=True,
            request_timeout=30,
            max_retries=3,
            retry_on_timeout=True
        )
        
        info = test_es.info()
        print(f"✓ Elasticsearch connection validated - Version: {info['version']['number']}")
        test_es.close()
    except Exception as e:
        print(f"❌ Error: Cannot connect to Elasticsearch: {e}")
        return
    
    print("✅ All connections validated successfully!")
    print("\n🧠 Deep Research Features Available:")
    print("• Multi-iteration research with knowledge gap analysis")
    print("• Research planning and structured investigation")
    print("• Query refinement based on findings")
    print("• Comprehensive report synthesis")
    print("\n🚀 Starting interactive session...")
    print("💡 Type 'quit' or 'exit' to end the session")
    print("💡 Type 'help' for available commands and examples")
    print("💡 Type 'deep-research [topic]' for comprehensive analysis")
    print("-" * 80)
    
    await interactive_loop()

def run_main():
    """Run the main application with proper mode selection"""
    print("🧠 Enhanced Deep Research Features:")
    print("• Multi-iteration research following Open Deep Research patterns")
    print("• AI-powered research planning and knowledge gap analysis")
    print("• Query refinement and iterative search strategies")
    print("• Comprehensive report synthesis across multiple research cycles")
    print("• Dynamic QA chain selection based on query complexity")
    print("• Multi-jurisdiction support with adaptive search")
    print("• Cross-framework comparison capabilities")
    print("• Internal knowledge base focus (no web search)")
    print()
    
    mode = input("Choose mode:\n1. Interactive Session (with Deep Research)\n2. Single Question\n3. Deep Research Only\nEnter choice (1-3): ").strip()
    
    if mode == "1":
        try:
            loop = get_event_loop()
            if loop.is_running():
                print("Running in existing event loop...")
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, main())
                    future.result()
            else:
                asyncio.run(main())
        except Exception as e:
            logger.error(f"Error in interactive session: {e}")
            print(f"❌ Interactive session error: {e}")
    
    elif mode == "2":
        async def single_question():
            interface = DynamicPrivacyChatbotInterface()
            
            if not await interface.initialize():
                print("❌ Failed to initialize dynamic chatbot")
                return
            
            question = input("Enter your data privacy question: ").strip()
            if question:
                print("\n🧠 Processing with dynamic analysis and adaptation...")
                response = await interface.ask_question(question)
                print(f"\n📋 Dynamic Answer (Confidence: {response.get('confidence', 'unknown')}):")
                print(f"Intent: {response.get('intent')} | Approach: {response.get('approach')}")
                print("=" * 70)
                print(response['answer'])
                print("=" * 70)
            else:
                print("No question provided.")
        
        try:
            loop = get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, single_question())
                    future.result()
            else:
                asyncio.run(single_question())
        except Exception as e:
            logger.error(f"Error in single question mode: {e}")
            print(f"❌ Single question error: {e}")
    
    elif mode == "3":
        async def deep_research_only():
            interface = DynamicPrivacyChatbotInterface()
            
            if not await interface.initialize():
                print("❌ Failed to initialize dynamic chatbot")
                return
            
            topic = input("Enter your deep research topic: ").strip()
            if topic:
                max_iter = input("Maximum iterations (1-5, default 3): ").strip()
                try:
                    max_iter = int(max_iter) if max_iter else 3
                    max_iter = min(max(max_iter, 1), 5)  # Clamp between 1-5
                except:
                    max_iter = 3
                
                print(f"\n🔬 Conducting deep research on: {topic}")
                print(f"Maximum iterations: {max_iter}")
                print("This may take 2-5 minutes for comprehensive analysis...")
                
                research_result = await interface.conduct_deep_research(topic, max_iter)
                print(f"\n📊 **Deep Research Completed**")
                print(f"Iterations: {research_result.get('iterations_completed', 0)}")
                print(f"Confidence: {research_result.get('confidence', 'unknown')}")
                print("=" * 70)
                print(research_result.get('final_report', 'No report generated'))
                print("=" * 70)
                
                if research_result.get('accumulated_knowledge'):
                    print("\n📚 **Knowledge Areas Covered:**")
                    for area, insights in research_result['accumulated_knowledge'].items():
                        print(f"• {area.upper()}: {len(insights)} insights")
            else:
                print("No topic provided.")
        
        try:
            loop = get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, deep_research_only())
                    future.result()
            else:
                asyncio.run(deep_research_only())
        except Exception as e:
            logger.error(f"Error in deep research mode: {e}")
            print(f"❌ Deep research error: {e}")
    
    else:
        print("Invalid choice. Please run again and select 1, 2, or 3.")

# Demo function
async def demo_dynamic_chatbot():
    """Demonstrate the dynamic chatbot capabilities including deep research"""
    interface = DynamicPrivacyChatbotInterface()
    
    if not await interface.initialize():
        print("❌ Failed to initialize dynamic chatbot for demo")
        return
    
    print("\n" + "="*80)
    print("DYNAMIC PRIVACY CHATBOT WITH DEEP RESEARCH DEMONSTRATION")
    print("="*80)
    
    # Demo deep research
    print(f"\n📌 Deep Research Demonstration:")
    deep_research_topic = "How do data subject rights implementation requirements differ across GDPR, CCPA, and LGPD, and what are the key compliance challenges?"
    print(f"Topic: {deep_research_topic}")
    print("-" * 70)
    
    try:
        print("🔬 Conducting deep iterative research (this may take 1-2 minutes)...")
        research_result = await interface.conduct_deep_research(deep_research_topic, max_iterations=2)
        print(f"🎯 Research Completed - Iterations: {research_result.get('iterations_completed', 0)}")
        print(f"📝 Confidence: {research_result.get('confidence', 'unknown')}")
        print("\n📋 Deep Research Report:")
        print(research_result.get('final_report', 'No report generated')[:800] + "...")
        
        if research_result.get('accumulated_knowledge'):
            print(f"\n📚 Knowledge Areas: {', '.join(research_result['accumulated_knowledge'].keys())}")
            
    except Exception as e:
        print(f"❌ Deep Research Error: {e}")
    
    print("\n" + "="*80)
    
    demo_questions = [
        "What is the definition of personal data under GDPR vs CCPA?",
        "Compare consent requirements between GDPR, CCPA, and LGPD",
        "What are the penalties for non-compliance across jurisdictions?"
    ]
    
    # Test standard questions
    for i, question in enumerate(demo_questions, 1):
        print(f"\n📌 Standard Demo Question {i}: {question}")
        print("-" * 70)
        
        try:
            response = await interface.ask_question(question)
            print(f"🎯 Confidence: {response.get('confidence', 'unknown')}")
            print(f"📝 Intent: {response.get('intent', 'unknown')}")
            print(f"🧠 Approach: {response.get('approach', 'unknown')}")
            print("\n📋 Answer:")
            print(response['answer'][:600] + "..." if len(response['answer']) > 600 else response['answer'])
            
        except Exception as e:
            print(f"❌ Error: {e}")
        
        print("\n" + "="*80)

if __name__ == "__main__":
    try:
        run_main()
    except KeyboardInterrupt:
        print("\n👋 Goodbye!")
    except Exception as e:
        logger.error(f"Fatal error: {e}")
        print(f"❌ Fatal error: {e}")
        sys.exit(1)
