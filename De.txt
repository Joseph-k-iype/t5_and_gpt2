"""
Updated Azure OpenAI service with local tiktoken support.
"""

import os
import logging
import openai
from typing import List, Dict, Any, Optional, Union
from langchain_openai import AzureOpenAIEmbeddings
from langchain_openai import AzureChatOpenAI
from app.core.auth_helper import get_azure_token_cached, refresh_token_if_needed
from dotenv import dotenv_values

# Import local tiktoken configuration early to override download behavior
try:
    # Import local tiktoken override before other imports that might use tiktoken
    from app.utils.tiktoken_local import override_tiktoken_download
    override_tiktoken_download()
except Exception as e:
    logging.warning(f"Could not initialize local tiktoken: {e}")

logger = logging.getLogger(__name__)

# Load credentials directly from file
credentials_path = os.path.join("env", "credentials.env")
config_path = os.path.join("env", "config.env")
credentials_values = {}
config_values = {}

try:
    if os.path.isfile(credentials_path):
        logger.info(f"AzureOpenAIService loading credentials from {credentials_path}")
        credentials_values = dotenv_values(credentials_path)
        logger.info(f"Loaded {len(credentials_values)} values from {credentials_path}")
    else:
        logger.warning(f"Credentials file not found: {credentials_path}")
        
    if os.path.isfile(config_path):
        logger.info(f"AzureOpenAIService loading config from {config_path}")
        config_values = dotenv_values(config_path)
        logger.info(f"Loaded {len(config_values)} values from {config_path}")
    else:
        logger.warning(f"Config file not found: {config_path}")
except Exception as e:
    logger.error(f"Error loading env files: {e}")

# Combine values, with credentials taking precedence
all_values = {**config_values, **credentials_values}

# Extract values directly
AZURE_TENANT_ID = all_values.get("AZURE_TENANT_ID", "")
AZURE_CLIENT_ID = all_values.get("AZURE_CLIENT_ID", "")
AZURE_CLIENT_SECRET = all_values.get("AZURE_CLIENT_SECRET", "")
AZURE_OPENAI_ENDPOINT = all_values.get("AZURE_OPENAI_ENDPOINT", "")
AZURE_EMBEDDING_MODEL = all_values.get("AZURE_EMBEDDING_MODEL", "text-embedding-3-large")
AZURE_EMBEDDING_DEPLOYMENT = all_values.get("AZURE_EMBEDDING_DEPLOYMENT", "text-embedding-3-large")
AZURE_LLM_MODEL = all_values.get("AZURE_LLM_MODEL", "gpt-4o-mini")
AZURE_LLM_DEPLOYMENT = all_values.get("AZURE_LLM_DEPLOYMENT", "gpt-4o-mini")

# Set environment variable for tiktoken to use local file
os.environ["TIKTOKEN_LOCAL_BPE_PATH"] = os.path.join("data", "cl100k_base.tiktoken")

# Log values (masked for security)
if AZURE_TENANT_ID:
    masked_tenant = f"{AZURE_TENANT_ID[:4]}...{AZURE_TENANT_ID[-4:]}" if len(AZURE_TENANT_ID) > 8 else "***"
    logger.info(f"Using Azure tenant ID: {masked_tenant}")
else:
    logger.warning("AZURE_TENANT_ID is missing")

if AZURE_CLIENT_ID:
    masked_client = f"{AZURE_CLIENT_ID[:4]}...{AZURE_CLIENT_ID[-4:]}" if len(AZURE_CLIENT_ID) > 8 else "***"
    logger.info(f"Using Azure client ID: {masked_client}")
else:
    logger.warning("AZURE_CLIENT_ID is missing")

if AZURE_CLIENT_SECRET:
    logger.info(f"Azure client secret is set (length: {len(AZURE_CLIENT_SECRET)} characters)")
else:
    logger.warning("AZURE_CLIENT_SECRET is missing")

logger.info(f"Using Azure OpenAI endpoint: {AZURE_OPENAI_ENDPOINT}")
logger.info(f"Using embedding model: {AZURE_EMBEDDING_MODEL}, deployment: {AZURE_EMBEDDING_DEPLOYMENT}")
logger.info(f"Using LLM model: {AZURE_LLM_MODEL}, deployment: {AZURE_LLM_DEPLOYMENT}")

class AzureOpenAIService:
    """Service for interacting with Azure OpenAI models."""
    
    def __init__(self):
        """Initialize the Azure OpenAI service."""
        self.tenant_id = AZURE_TENANT_ID
        self.client_id = AZURE_CLIENT_ID
        self.client_secret = AZURE_CLIENT_SECRET
        self.endpoint = AZURE_OPENAI_ENDPOINT
        self.embedding_model = AZURE_EMBEDDING_MODEL
        self.embedding_deployment = AZURE_EMBEDDING_DEPLOYMENT
        self.llm_model = AZURE_LLM_MODEL
        self.llm_deployment = AZURE_LLM_DEPLOYMENT
        
        # Show the actual values being used (partially masked for security)
        masked_tenant = f"{self.tenant_id[:4]}...{self.tenant_id[-4:]}" if len(self.tenant_id) > 8 else "***"
        masked_client = f"{self.client_id[:4]}...{self.client_id[-4:]}" if len(self.client_id) > 8 else "***"
        logger.info(f"AzureOpenAIService initialized with:")
        logger.info(f"  - Tenant ID: {masked_tenant}")
        logger.info(f"  - Client ID: {masked_client}") 
        logger.info(f"  - Client secret length: {len(self.client_secret)} characters")
        logger.info(f"  - OpenAI endpoint: {self.endpoint}")
        
        # Get an initial token
        logger.info("Acquiring Azure AD token...")
        self.token = get_azure_token_cached(
            tenant_id=self.tenant_id,
            client_id=self.client_id,
            client_secret=self.client_secret,
            scope="https://cognitiveservices.azure.com/.default"
        )
        
        if not self.token:
            logger.error("Failed to get Azure AD token for OpenAI. Check your Azure AD credentials.")
            raise ValueError("Failed to get Azure AD token for OpenAI")
        
        logger.info("Successfully acquired Azure AD token")
        
        # Set up the client and components
        self._setup_client()
        self._setup_langchain()
        
        logger.info(f"AzureOpenAIService initialized successfully")
    
    def _setup_client(self):
        """Set up the OpenAI client for Azure."""
        # Initialize the Azure OpenAI client using the Azure AD token
        self.client = openai.AzureOpenAI(
            api_key=self.token,  # Use the token as the API key
            api_version="2023-05-15",
            azure_endpoint=self.endpoint
        )
        
        logger.info(f"Azure OpenAI client configured with endpoint: {self.endpoint}")
    
    def _setup_langchain(self):
        """Set up LangChain components for Azure OpenAI."""
        try:
            # Create LangChain embeddings with local tiktoken path
            self.embeddings = AzureOpenAIEmbeddings(
                azure_endpoint=self.endpoint,
                api_key=self.token,  # Use the token
                api_version="2023-05-15",
                deployment=self.embedding_deployment,
                model=self.embedding_model,
                dimensions=3072,  # Maximum dimensions for text-embedding-3-large
                chunk_size=1
            )
            
            # Create LangChain chat model with local tiktoken path
            self.chat_model = AzureChatOpenAI(
                azure_endpoint=self.endpoint,
                api_key=self.token,  # Use the token
                api_version="2023-05-15",
                deployment=self.llm_deployment,
                model=self.llm_model,
                temperature=0.0,
                max_tokens=2000,
                tiktoken_local_path=os.environ.get("TIKTOKEN_LOCAL_BPE_PATH")
            )
            
            logger.info(f"LangChain components initialized with embedding model: {self.embedding_model} and LLM model: {self.llm_model}")
            logger.info(f"Using local tiktoken path: {os.environ.get('TIKTOKEN_LOCAL_BPE_PATH')}")
        except Exception as e:
            logger.error(f"Error setting up LangChain components: {e}")
            raise
    
    def refresh_tokens(self):
        """Refresh the Azure tokens."""
        logger.info("Refreshing Azure AD token...")
        token = get_azure_token_cached(
            tenant_id=self.tenant_id,
            client_id=self.client_id,
            client_secret=self.client_secret,
            scope="https://cognitiveservices.azure.com/.default"
        )
        if token:
            self.token = token
            # Update the client
            self.client = openai.AzureOpenAI(
                api_key=token,
                api_version="2023-05-15",
                azure_endpoint=self.endpoint
            )
            
            # Update LangChain components
            self._setup_langchain()
            
            logger.info("Azure OpenAI token refreshed")
            return True
        else:
            logger.error("Failed to refresh Azure OpenAI token")
            return False
    
    async def generate_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        Generate embeddings for a list of texts.
        
        Args:
            texts: List of texts to embed
            
        Returns:
            List of embedding vectors
        """
        try:
            embeddings = await self.embeddings.aembed_documents(texts)
            logger.debug(f"Generated embeddings for {len(texts)} texts")
            return embeddings
        except Exception as e:
            logger.error(f"Error generating embeddings: {e}")
            # Try refreshing token and retry
            if "401" in str(e) or "unauthorized" in str(e).lower():
                logger.info("Token might be expired, attempting to refresh...")
                if self.refresh_tokens():
                    # Retry the operation
                    embeddings = await self.embeddings.aembed_documents(texts)
                    return embeddings
            raise
    
    async def generate_single_embedding(self, text: str) -> List[float]:
        """
        Generate embeddings for a single text.
        
        Args:
            text: Text to embed
            
        Returns:
            Embedding vector
        """
        try:
            embedding = await self.embeddings.aembed_query(text)
            return embedding
        except Exception as e:
            logger.error(f"Error generating single embedding: {e}")
            # Try refreshing token and retry
            if "401" in str(e) or "unauthorized" in str(e).lower():
                logger.info("Token might be expired, attempting to refresh...")
                if self.refresh_tokens():
                    # Retry the operation
                    embedding = await self.embeddings.aembed_query(text)
                    return embedding
            raise
    
    async def generate_completion(self, 
                                messages: List[Dict[str, str]], 
                                temperature: float = 0.0,
                                max_tokens: int = 2000) -> str:
        """
        Generate a completion using the chat model.
        
        Args:
            messages: List of messages (system, user, assistant)
            temperature: Temperature for generation
            max_tokens: Maximum tokens to generate
            
        Returns:
            Generated text
        """
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error generating completion: {e}")
            # Check if token refresh is needed
            if "401" in str(e) or "unauthorized" in str(e).lower():
                logger.info("Attempting to refresh token and retry request")
                if self.refresh_tokens():
                    # Retry the request
                    response = await self.client.chat.completions.create(
                        model=self.llm_model,
                        messages=messages,
                        temperature=temperature,
                        max_tokens=max_tokens
                    )
                    return response.choices[0].message.content
            raise
