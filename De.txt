#!/usr/bin/env python3
"""
Working JSON-LD Ontology Extractor with TTL Export

This script extracts ontology information from JSON-LD files and saves to TTL format.
Includes comprehensive debugging and error handling.
"""

import json
import sys
import os
from typing import Dict, List, Set, Any, Union
from collections import defaultdict
from datetime import datetime

# Try to import rdflib for better RDF handling
try:
    from rdflib import Graph
    RDFLIB_AVAILABLE = True
except ImportError:
    RDFLIB_AVAILABLE = False


class JsonLdOntologyExtractor:
    def __init__(self, debug=True):
        self.debug = debug
        
        # Core ontology elements
        self.classes = set()
        self.individuals = set()
        self.object_properties = set()
        self.data_properties = set()
        self.annotation_properties = set()
        
        # Relationships
        self.subclass_relationships = []
        self.equivalent_classes = []
        self.disjoint_classes = []
        
        # Property details
        self.property_domains = defaultdict(set)
        self.property_ranges = defaultdict(set)
        self.property_characteristics = defaultdict(set)
        
        # Annotations
        self.labels = {}
        self.comments = {}
        self.namespaces = {}
        
        # For rdflib method
        self.graph = None
        
    def log(self, message):
        """Debug logging"""
        if self.debug:
            print(f"[DEBUG] {message}")
    
    def extract_from_file(self, file_path: str, method: str = "auto"):
        """Main extraction method"""
        self.log(f"Starting extraction from: {file_path}")
        
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")
        
        # Determine method
        if method == "auto":
            method = "rdflib" if RDFLIB_AVAILABLE else "json"
        
        self.log(f"Using method: {method}")
        
        if method == "rdflib" and RDFLIB_AVAILABLE:
            return self._extract_with_rdflib(file_path)
        else:
            return self._extract_with_json(file_path)
    
    def _extract_with_rdflib(self, file_path: str):
        """Extract using rdflib"""
        try:
            self.log("Loading graph with rdflib...")
            self.graph = Graph()
            self.graph.parse(file_path, format='json-ld')
            
            self.log(f"Graph loaded with {len(self.graph)} triples")
            
            # Extract namespaces
            for prefix, namespace in self.graph.namespaces():
                self.namespaces[str(prefix)] = str(namespace)
                
            self.log(f"Found {len(self.namespaces)} namespaces")
            
            # Use SPARQL queries for reliable extraction
            self._extract_with_sparql()
            
            return True
            
        except Exception as e:
            self.log(f"rdflib extraction failed: {e}")
            self.log("Falling back to JSON method...")
            return self._extract_with_json(file_path)
    
    def _extract_with_sparql(self):
        """Extract using SPARQL queries"""
        
        # Extract classes
        classes_query = """
        SELECT DISTINCT ?class WHERE {
            { ?class a owl:Class } UNION { ?class a rdfs:Class }
        }
        """
        try:
            results = self.graph.query(classes_query)
            for row in results:
                self.classes.add(str(row.class))
            self.log(f"Found {len(self.classes)} classes via SPARQL")
        except:
            self.log("SPARQL classes query failed, using basic iteration")
            self._extract_classes_basic()
        
        # Extract object properties
        obj_props_query = """
        SELECT DISTINCT ?prop WHERE {
            ?prop a owl:ObjectProperty
        }
        """
        try:
            results = self.graph.query(obj_props_query)
            for row in results:
                self.object_properties.add(str(row.prop))
            self.log(f"Found {len(self.object_properties)} object properties via SPARQL")
        except:
            self.log("SPARQL object properties query failed")
            self._extract_properties_basic()
        
        # Extract data properties
        data_props_query = """
        SELECT DISTINCT ?prop WHERE {
            ?prop a owl:DatatypeProperty
        }
        """
        try:
            results = self.graph.query(data_props_query)
            for row in results:
                self.data_properties.add(str(row.prop))
            self.log(f"Found {len(self.data_properties)} data properties via SPARQL")
        except:
            pass
        
        # Extract subclass relationships
        subclass_query = """
        SELECT DISTINCT ?sub ?super WHERE {
            ?sub rdfs:subClassOf ?super
        }
        """
        try:
            results = self.graph.query(subclass_query)
            for row in results:
                self.subclass_relationships.append((str(row.sub), str(row.super)))
            self.log(f"Found {len(self.subclass_relationships)} subclass relationships")
        except:
            self.log("SPARQL subclass query failed")
        
        # Extract labels and comments
        self._extract_annotations_sparql()
    
    def _extract_classes_basic(self):
        """Basic class extraction without SPARQL"""
        from rdflib import RDF, RDFS, OWL
        
        for s in self.graph.subjects(RDF.type, RDFS.Class):
            self.classes.add(str(s))
        for s in self.graph.subjects(RDF.type, OWL.Class):
            self.classes.add(str(s))
        
        self.log(f"Found {len(self.classes)} classes via basic iteration")
    
    def _extract_properties_basic(self):
        """Basic property extraction without SPARQL"""
        from rdflib import RDF, OWL
        
        for s in self.graph.subjects(RDF.type, OWL.ObjectProperty):
            self.object_properties.add(str(s))
        for s in self.graph.subjects(RDF.type, OWL.DatatypeProperty):
            self.data_properties.add(str(s))
    
    def _extract_annotations_sparql(self):
        """Extract labels and comments"""
        try:
            # Labels
            labels_query = """
            SELECT DISTINCT ?entity ?label WHERE {
                ?entity rdfs:label ?label
            }
            """
            results = self.graph.query(labels_query)
            for row in results:
                self.labels[str(row.entity)] = str(row.label)
            
            # Comments  
            comments_query = """
            SELECT DISTINCT ?entity ?comment WHERE {
                ?entity rdfs:comment ?comment
            }
            """
            results = self.graph.query(comments_query)
            for row in results:
                self.comments[str(row.entity)] = str(row.comment)
                
            self.log(f"Found {len(self.labels)} labels and {len(self.comments)} comments")
            
        except Exception as e:
            self.log(f"Annotation extraction failed: {e}")
    
    def _extract_with_json(self, file_path: str):
        """Extract using JSON parsing"""
        try:
            self.log("Loading JSON-LD file...")
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.log(f"Loaded JSON data: {type(data)}")
            
            # Extract context/namespaces
            if isinstance(data, dict) and '@context' in data:
                context = data['@context']
                if isinstance(context, dict):
                    self.namespaces.update({k: v for k, v in context.items() if isinstance(v, str)})
            
            self.log(f"Found {len(self.namespaces)} namespaces in context")
            
            # Get items to process
            items = self._get_items_from_data(data)
            self.log(f"Processing {len(items)} items")
            
            # Process each item
            for i, item in enumerate(items):
                if i < 5:  # Debug first few items
                    self.log(f"Processing item {i}: {item.get('@id', 'no-id')} - {item.get('@type', 'no-type')}")
                self._process_json_item(item)
            
            self.log("JSON extraction completed")
            return True
            
        except Exception as e:
            self.log(f"JSON extraction failed: {e}")
            raise
    
    def _get_items_from_data(self, data):
        """Extract items from various JSON-LD structures"""
        if isinstance(data, list):
            return data
        elif isinstance(data, dict):
            if '@graph' in data:
                return data['@graph'] if isinstance(data['@graph'], list) else [data['@graph']]
            else:
                return [data]
        else:
            return []
    
    def _process_json_item(self, item):
        """Process a single JSON-LD item"""
        if not isinstance(item, dict):
            return
        
        item_id = item.get('@id', '')
        item_types = item.get('@type', [])
        
        if isinstance(item_types, str):
            item_types = [item_types]
        
        # Extract classes
        class_indicators = ['owl:Class', 'rdfs:Class', 'Class']
        if any(t in class_indicators for t in item_types):
            self.classes.add(item_id)
            self.log(f"Found class: {item_id}")
        
        # Extract object properties
        obj_prop_indicators = ['owl:ObjectProperty', 'ObjectProperty']
        if any(t in obj_prop_indicators for t in item_types):
            self.object_properties.add(item_id)
            self.log(f"Found object property: {item_id}")
        
        # Extract data properties
        data_prop_indicators = ['owl:DatatypeProperty', 'DatatypeProperty']
        if any(t in data_prop_indicators for t in item_types):
            self.data_properties.add(item_id)
            self.log(f"Found data property: {item_id}")
        
        # Extract subclass relationships
        if 'rdfs:subClassOf' in item:
            parent = self._extract_id_from_value(item['rdfs:subClassOf'])
            if parent:
                self.subclass_relationships.append((item_id, parent))
                self.log(f"Found subclass: {item_id} -> {parent}")
        
        # Extract labels and comments
        if 'rdfs:label' in item:
            label = self._extract_literal_value(item['rdfs:label'])
            if label:
                self.labels[item_id] = label
        
        if 'rdfs:comment' in item:
            comment = self._extract_literal_value(item['rdfs:comment'])
            if comment:
                self.comments[item_id] = comment
        
        # Extract domains and ranges
        if 'rdfs:domain' in item:
            domain = self._extract_id_from_value(item['rdfs:domain'])
            if domain:
                self.property_domains[item_id].add(domain)
        
        if 'rdfs:range' in item:
            range_val = self._extract_id_from_value(item['rdfs:range'])
            if range_val:
                self.property_ranges[item_id].add(range_val)
        
        # Extract property characteristics
        char_indicators = {
            'owl:FunctionalProperty': 'functional',
            'owl:TransitiveProperty': 'transitive', 
            'owl:SymmetricProperty': 'symmetric'
        }
        for indicator, characteristic in char_indicators.items():
            if indicator in item_types:
                self.property_characteristics[item_id].add(characteristic)
    
    def _extract_id_from_value(self, value):
        """Extract @id from a value that could be string, dict, or list"""
        if isinstance(value, str):
            return value
        elif isinstance(value, dict) and '@id' in value:
            return value['@id']
        elif isinstance(value, list) and len(value) > 0:
            return self._extract_id_from_value(value[0])
        return None
    
    def _extract_literal_value(self, value):
        """Extract literal value from various JSON-LD structures"""
        if isinstance(value, str):
            return value
        elif isinstance(value, dict):
            if '@value' in value:
                return value['@value']
            elif '@id' in value:
                return value['@id']
        elif isinstance(value, list) and len(value) > 0:
            return self._extract_literal_value(value[0])
        return None
    
    def print_summary(self):
        """Print extraction summary"""
        print("=" * 60)
        print("🎯 ONTOLOGY EXTRACTION RESULTS")
        print("=" * 60)
        
        if self.namespaces:
            print(f"\n🌐 NAMESPACES ({len(self.namespaces)}):")
            for prefix, uri in sorted(self.namespaces.items()):
                print(f"  {prefix}: {uri}")
        
        print(f"\n📁 CLASSES ({len(self.classes)}):")
        for cls in sorted(self.classes):
            print(f"  • {cls}")
            if cls in self.labels:
                print(f"    Label: {self.labels[cls]}")
            if cls in self.comments:
                print(f"    Comment: {self.comments[cls]}")
        
        if self.subclass_relationships:
            print(f"\n🔗 SUBCLASS RELATIONSHIPS ({len(self.subclass_relationships)}):")
            for child, parent in sorted(self.subclass_relationships):
                print(f"  • {child} ⊆ {parent}")
        
        print(f"\n🔧 OBJECT PROPERTIES ({len(self.object_properties)}):")
        for prop in sorted(self.object_properties):
            print(f"  • {prop}")
            if prop in self.labels:
                print(f"    Label: {self.labels[prop]}")
            if prop in self.property_domains:
                domains = ", ".join(sorted(self.property_domains[prop]))
                print(f"    Domain: {domains}")
            if prop in self.property_ranges:
                ranges = ", ".join(sorted(self.property_ranges[prop]))
                print(f"    Range: {ranges}")
            if prop in self.property_characteristics:
                chars = ", ".join(sorted(self.property_characteristics[prop]))
                print(f"    Characteristics: {chars}")
        
        print(f"\n📊 DATA PROPERTIES ({len(self.data_properties)}):")
        for prop in sorted(self.data_properties):
            print(f"  • {prop}")
            if prop in self.labels:
                print(f"    Label: {self.labels[prop]}")
            if prop in self.property_domains:
                domains = ", ".join(sorted(self.property_domains[prop]))
                print(f"    Domain: {domains}")
            if prop in self.property_ranges:
                ranges = ", ".join(sorted(self.property_ranges[prop]))
                print(f"    Range: {ranges}")
        
        print(f"\n📈 SUMMARY:")
        total = len(self.classes) + len(self.object_properties) + len(self.data_properties)
        print(f"  • Total entities: {total}")
        print(f"  • Total relationships: {len(self.subclass_relationships)}")
        print(f"  • Total annotations: {len(self.labels) + len(self.comments)}")
        print()
        
        return total > 0  # Return True if we found anything
    
    def save_as_ttl(self, output_file: str):
        """Save extracted ontology as TTL"""
        try:
            self.log(f"Saving TTL to: {output_file}")
            
            if self.graph and RDFLIB_AVAILABLE:
                # Use rdflib's serialization if available
                self.log("Using rdflib TTL serialization")
                ttl_content = self.graph.serialize(format='turtle')
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(ttl_content)
            else:
                # Manual TTL creation
                self.log("Creating TTL manually")
                self._create_manual_ttl(output_file)
            
            self.log(f"✅ TTL saved successfully to: {output_file}")
            return True
            
        except Exception as e:
            self.log(f"❌ Failed to save TTL: {e}")
            return False
    
    def _create_manual_ttl(self, output_file: str):
        """Create TTL manually from extracted data"""
        with open(output_file, 'w', encoding='utf-8') as f:
            # Write header
            f.write(f"# Ontology extracted on {datetime.now().isoformat()}\n")
            f.write("# Generated by JSON-LD Ontology Extractor\n\n")
            
            # Write prefixes
            f.write("@prefix owl: <http://www.w3.org/2002/07/owl#> .\n")
            f.write("@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n")
            f.write("@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n")
            f.write("@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n")
            
            # Add custom prefixes
            for prefix, uri in self.namespaces.items():
                if prefix not in ['owl', 'rdf', 'rdfs', 'xsd'] and uri.startswith('http'):
                    f.write(f"@prefix {prefix}: <{uri}> .\n")
            f.write("\n")
            
            # Write classes
            if self.classes:
                f.write("# === CLASSES ===\n")
                for cls in sorted(self.classes):
                    f.write(f"<{cls}> rdf:type owl:Class .\n")
                    if cls in self.labels:
                        f.write(f"<{cls}> rdfs:label \"{self._escape_literal(self.labels[cls])}\" .\n")
                    if cls in self.comments:
                        f.write(f"<{cls}> rdfs:comment \"{self._escape_literal(self.comments[cls])}\" .\n")
                    f.write("\n")
            
            # Write subclass relationships
            if self.subclass_relationships:
                f.write("# === SUBCLASS RELATIONSHIPS ===\n")
                for child, parent in sorted(self.subclass_relationships):
                    f.write(f"<{child}> rdfs:subClassOf <{parent}> .\n")
                f.write("\n")
            
            # Write object properties
            if self.object_properties:
                f.write("# === OBJECT PROPERTIES ===\n")
                for prop in sorted(self.object_properties):
                    f.write(f"<{prop}> rdf:type owl:ObjectProperty .\n")
                    self._write_property_details(f, prop)
                f.write("\n")
            
            # Write data properties
            if self.data_properties:
                f.write("# === DATA PROPERTIES ===\n")
                for prop in sorted(self.data_properties):
                    f.write(f"<{prop}> rdf:type owl:DatatypeProperty .\n")
                    self._write_property_details(f, prop)
                f.write("\n")
    
    def _write_property_details(self, f, prop):
        """Write property details to TTL file"""
        if prop in self.labels:
            f.write(f"<{prop}> rdfs:label \"{self._escape_literal(self.labels[prop])}\" .\n")
        if prop in self.comments:
            f.write(f"<{prop}> rdfs:comment \"{self._escape_literal(self.comments[prop])}\" .\n")
        if prop in self.property_domains:
            for domain in sorted(self.property_domains[prop]):
                f.write(f"<{prop}> rdfs:domain <{domain}> .\n")
        if prop in self.property_ranges:
            for range_val in sorted(self.property_ranges[prop]):
                f.write(f"<{prop}> rdfs:range <{range_val}> .\n")
        
        # Property characteristics
        if prop in self.property_characteristics:
            for char in sorted(self.property_characteristics[prop]):
                if char == 'functional':
                    f.write(f"<{prop}> rdf:type owl:FunctionalProperty .\n")
                elif char == 'transitive':
                    f.write(f"<{prop}> rdf:type owl:TransitiveProperty .\n")
                elif char == 'symmetric':
                    f.write(f"<{prop}> rdf:type owl:SymmetricProperty .\n")
        f.write("\n")
    
    def _escape_literal(self, literal):
        """Escape literal values for TTL"""
        return literal.replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n')
    
    def save_as_json(self, output_file: str):
        """Save extracted ontology as JSON"""
        try:
            data = {
                'extraction_info': {
                    'timestamp': datetime.now().isoformat(),
                    'method': 'rdflib' if self.graph else 'json',
                    'total_entities': len(self.classes) + len(self.object_properties) + len(self.data_properties)
                },
                'namespaces': dict(self.namespaces),
                'classes': list(self.classes),
                'object_properties': list(self.object_properties),
                'data_properties': list(self.data_properties),
                'subclass_relationships': self.subclass_relationships,
                'labels': dict(self.labels),
                'comments': dict(self.comments),
                'property_domains': {k: list(v) for k, v in self.property_domains.items()},
                'property_ranges': {k: list(v) for k, v in self.property_ranges.items()},
                'property_characteristics': {k: list(v) for k, v in self.property_characteristics.items()}
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            self.log(f"✅ JSON saved successfully to: {output_file}")
            return True
            
        except Exception as e:
            self.log(f"❌ Failed to save JSON: {e}")
            return False


def main():
    """Main CLI function"""
    if len(sys.argv) < 2:
        print("Usage: python extractor.py <jsonld_file> [options]")
        print("\nOptions:")
        print("  --ttl <file>       Save as TTL file")
        print("  --json <file>      Save as JSON file") 
        print("  --method <method>  Use 'rdflib' or 'json' (default: auto)")
        print("  --quiet            Suppress debug output")
        print("  --no-summary       Don't print summary")
        print("\nExample:")
        print("  python extractor.py ontology.jsonld --ttl output.ttl --json output.json")
        sys.exit(1)
    
    # Parse arguments
    file_path = sys.argv[1]
    ttl_output = None
    json_output = None
    method = "auto"
    quiet = False
    show_summary = True
    
    i = 2
    while i < len(sys.argv):
        arg = sys.argv[i]
        if arg == '--ttl' and i + 1 < len(sys.argv):
            ttl_output = sys.argv[i + 1]
            i += 2
        elif arg == '--json' and i + 1 < len(sys.argv):
            json_output = sys.argv[i + 1]
            i += 2
        elif arg == '--method' and i + 1 < len(sys.argv):
            method = sys.argv[i + 1]
            i += 2
        elif arg == '--quiet':
            quiet = True
            i += 1
        elif arg == '--no-summary':
            show_summary = False
            i += 1
        else:
            i += 1
    
    # Run extraction
    try:
        extractor = JsonLdOntologyExtractor(debug=not quiet)
        
        print(f"🔍 Extracting ontology from: {file_path}")
        success = extractor.extract_from_file(file_path, method)
        
        if not success:
            print("❌ Extraction failed")
            sys.exit(1)
        
        # Print summary
        if show_summary:
            found_data = extractor.print_summary()
            if not found_data:
                print("⚠️  Warning: No ontology data was extracted!")
        
        # Save outputs
        if ttl_output:
            if extractor.save_as_ttl(ttl_output):
                print(f"✅ TTL saved to: {ttl_output}")
            else:
                print("❌ Failed to save TTL")
        
        if json_output:
            if extractor.save_as_json(json_output):
                print(f"✅ JSON saved to: {json_output}")
            else:
                print("❌ Failed to save JSON")
        
        if not ttl_output and not json_output:
            print("💡 Add --ttl <file> or --json <file> to save extracted data")
            
    except Exception as e:
        print(f"❌ Error: {e}")
        if not quiet:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
