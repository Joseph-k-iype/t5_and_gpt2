"""
Usage examples for HSBC OpenAI wrapper
Shows integration with OpenAI SDK, LangChain, and LangGraph
"""
import os
import asyncio
from openai import OpenAI
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated, Sequence
import operator

# Import our HSBC wrapper
from hsbc_openai_client import create_hsbc_client
from config import Config, get_openai_client, get_hsbc_credentials


# ============================================================================
# SETUP: Configure HSBC credentials
# ============================================================================

def setup_hsbc_environment():
    """Set up environment variables for HSBC API."""
    os.environ["USE_HSBC_API"] = "true"
    os.environ["HSBC_USERNAME"] = "GB-RulesEng-Dev"
    os.environ["HSBC_PASSWORD"] = "your_password_here"
    os.environ["HSBC_USER_ID"] = "UC0002731"


# ============================================================================
# EXAMPLE 1: Direct OpenAI SDK Usage
# ============================================================================

def example_1_direct_openai():
    """Example using OpenAI SDK directly with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 1: Direct OpenAI SDK with HSBC")
    print("="*80)
    
    # Get configured client (automatically uses HSBC if USE_HSBC_API=true)
    client = get_openai_client()
    
    # Use exactly like standard OpenAI client
    response = client.chat.completions.create(
        model=Config.get_effective_model(),
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is a Large Language Model?"}
        ]
    )
    
    print(f"Response: {response.choices[0].message.content}")
    print(f"Model used: {Config.get_effective_model()}")


# ============================================================================
# EXAMPLE 2: Using with existing OpenAIService
# ============================================================================

async def example_2_openai_service():
    """Example using your existing OpenAIService class."""
    print("\n" + "="*80)
    print("EXAMPLE 2: Using OpenAIService (Your Existing Code)")
    print("="*80)
    
    from openai_service import OpenAIService
    
    # Initialize service (automatically detects HSBC mode)
    service = OpenAIService()
    
    # Use your existing methods
    messages = [
        SystemMessage(content="You are a legal compliance assistant."),
        HumanMessage(content="Explain data minimization principle in GDPR.")
    ]
    
    response = await service.chat_completion(messages)
    print(f"Response: {response}")


# ============================================================================
# EXAMPLE 3: LangChain Integration
# ============================================================================

def example_3_langchain():
    """Example using LangChain with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 3: LangChain Integration")
    print("="*80)
    
    # Get HSBC credentials
    creds = get_hsbc_credentials()
    
    # Create LangChain ChatOpenAI with HSBC settings
    llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"],
        temperature=0
    )
    
    # Use LangChain as normal
    messages = [
        SystemMessage(content="You are a privacy expert."),
        HumanMessage(content="What are the key principles of GDPR?")
    ]
    
    response = llm.invoke(messages)
    print(f"Response: {response.content}")


# ============================================================================
# EXAMPLE 4: LangGraph Multi-Agent System
# ============================================================================

class AgentState(TypedDict):
    """State for multi-agent system."""
    messages: Annotated[Sequence[str], operator.add]
    current_agent: str
    final_answer: str


def example_4_langgraph():
    """Example using LangGraph with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 4: LangGraph Multi-Agent System")
    print("="*80)
    
    # Get HSBC credentials
    creds = get_hsbc_credentials()
    
    # Create LLM instances for different agents
    legal_llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"]
    )
    
    compliance_llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"]
    )
    
    # Define agent nodes
    def legal_agent(state: AgentState) -> AgentState:
        """Legal analysis agent."""
        response = legal_llm.invoke([
            SystemMessage(content="You are a legal analyst. Analyze legal requirements."),
            HumanMessage(content=state["messages"][-1])
        ])
        return {
            "messages": [f"Legal Agent: {response.content}"],
            "current_agent": "compliance",
            "final_answer": ""
        }
    
    def compliance_agent(state: AgentState) -> AgentState:
        """Compliance review agent."""
        response = compliance_llm.invoke([
            SystemMessage(content="You are a compliance officer. Review for compliance."),
            HumanMessage(content=state["messages"][-1])
        ])
        return {
            "messages": [f"Compliance Agent: {response.content}"],
            "current_agent": "end",
            "final_answer": response.content
        }
    
    # Build graph
    workflow = StateGraph(AgentState)
    workflow.add_node("legal", legal_agent)
    workflow.add_node("compliance", compliance_agent)
    
    workflow.set_entry_point("legal")
    workflow.add_edge("legal", "compliance")
    workflow.add_edge("compliance", END)
    
    app = workflow.compile()
    
    # Run the graph
    initial_state = {
        "messages": ["Analyze data retention requirements under GDPR Article 5"],
        "current_agent": "legal",
        "final_answer": ""
    }
    
    result = app.invoke(initial_state)
    print(f"Final Answer: {result['final_answer']}")


# ============================================================================
# EXAMPLE 5: Streaming Responses
# ============================================================================

def example_5_streaming():
    """Example with streaming responses."""
    print("\n" + "="*80)
    print("EXAMPLE 5: Streaming Responses")
    print("="*80)
    
    client = get_openai_client()
    
    stream = client.chat.completions.create(
        model=Config.get_effective_model(),
        messages=[
            {"role": "user", "content": "Explain privacy by design in 3 points."}
        ],
        stream=True
    )
    
    print("Streaming response:")
    for chunk in stream:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print("\n")


# ============================================================================
# EXAMPLE 6: Token Management
# ============================================================================

def example_6_token_management():
    """Example showing token management."""
    print("\n" + "="*80)
    print("EXAMPLE 6: Token Management")
    print("="*80)
    
    # Create HSBC client directly for token management
    hsbc_client = create_hsbc_client(
        token_api_url=Config.HSBC_TOKEN_API_URL,
        base_url=Config.HSBC_BASE_URL,
        username=Config.HSBC_USERNAME,
        password=Config.HSBC_PASSWORD
    )
    
    # Get current token
    token = hsbc_client.get_api_key()
    print(f"Current Token: {token[:20]}...")
    
    # Force refresh
    print("Refreshing token...")
    hsbc_client.refresh_token()
    new_token = hsbc_client.get_api_key()
    print(f"New Token: {new_token[:20]}...")
    
    # Get OpenAI client
    client = hsbc_client.get_client()
    print(f"OpenAI client ready with base URL: {hsbc_client.get_base_url()}")


# ============================================================================
# EXAMPLE 7: Error Handling
# ============================================================================

async def example_7_error_handling():
    """Example with proper error handling."""
    print("\n" + "="*80)
    print("EXAMPLE 7: Error Handling")
    print("="*80)
    
    from openai_service import OpenAIService
    
    try:
        service = OpenAIService()
        
        messages = [
            HumanMessage(content="Test message")
        ]
        
        response = await service.chat_completion(messages)
        print(f"Success: {response[:100]}...")
        
    except ValueError as e:
        print(f"Configuration Error: {e}")
    except Exception as e:
        print(f"API Error: {e}")
        # Token might be expired - could trigger refresh here


# ============================================================================
# MAIN: Run all examples
# ============================================================================

def main():
    """Run all examples."""
    print("\n" + "="*80)
    print("HSBC OpenAI Wrapper - Usage Examples")
    print("="*80)
    
    # Setup environment
    setup_hsbc_environment()
    
    # Run examples
    try:
        example_1_direct_openai()
        asyncio.run(example_2_openai_service())
        example_3_langchain()
        example_4_langgraph()
        example_5_streaming()
        example_6_token_management()
        asyncio.run(example_7_error_handling())
        
        print("\n" + "="*80)
        print("All examples completed!")
        print("="*80)
        
    except Exception as e:
        print(f"\nError running examples: {e}")
        print("Make sure to set HSBC_PASSWORD environment variable!")


if __name__ == "__main__":
    main()


# ============================================================================
# SETUP: Configure HSBC credentials
# ============================================================================

def setup_hsbc_environment():
    """Set up environment variables for HSBC API."""
    os.environ["USE_HSBC_API"] = "true"
    os.environ["HSBC_USERNAME"] = "GB-RulesEng-Dev"
    os.environ["HSBC_PASSWORD"] = "your_password_here"
    os.environ["HSBC_USER_ID"] = "UC0002731"


# ============================================================================
# EXAMPLE 1: Direct OpenAI SDK Usage
# ============================================================================

def example_1_direct_openai():
    """Example using OpenAI SDK directly with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 1: Direct OpenAI SDK with HSBC")
    print("="*80)
    
    # Get configured client (automatically uses HSBC if USE_HSBC_API=true)
    client = get_openai_client()
    
    # Use exactly like standard OpenAI client
    response = client.chat.completions.create(
        model=Config.get_effective_model(),
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "What is a Large Language Model?"}
        ]
    )
    
    print(f"Response: {response.choices[0].message.content}")
    print(f"Model used: {Config.get_effective_model()}")


# ============================================================================
# EXAMPLE 2: Using with existing OpenAIService
# ============================================================================

async def example_2_openai_service():
    """Example using your existing OpenAIService class."""
    print("\n" + "="*80)
    print("EXAMPLE 2: Using OpenAIService (Your Existing Code)")
    print("="*80)
    
    from openai_service_hsbc import OpenAIService
    
    # Initialize service (automatically detects HSBC mode)
    service = OpenAIService()
    
    # Use your existing methods
    messages = [
        SystemMessage(content="You are a legal compliance assistant."),
        HumanMessage(content="Explain data minimization principle in GDPR.")
    ]
    
    response = await service.chat_completion(messages)
    print(f"Response: {response}")


# ============================================================================
# EXAMPLE 3: LangChain Integration
# ============================================================================

def example_3_langchain():
    """Example using LangChain with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 3: LangChain Integration")
    print("="*80)
    
    # Get HSBC credentials
    creds = get_hsbc_credentials()
    
    # Create LangChain ChatOpenAI with HSBC settings
    llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"],
        temperature=0
    )
    
    # Use LangChain as normal
    messages = [
        SystemMessage(content="You are a privacy expert."),
        HumanMessage(content="What are the key principles of GDPR?")
    ]
    
    response = llm.invoke(messages)
    print(f"Response: {response.content}")


# ============================================================================
# EXAMPLE 4: LangGraph Multi-Agent System
# ============================================================================

class AgentState(TypedDict):
    """State for multi-agent system."""
    messages: Annotated[Sequence[str], operator.add]
    current_agent: str
    final_answer: str


def example_4_langgraph():
    """Example using LangGraph with HSBC wrapper."""
    print("\n" + "="*80)
    print("EXAMPLE 4: LangGraph Multi-Agent System")
    print("="*80)
    
    # Get HSBC credentials
    creds = get_hsbc_credentials()
    
    # Create LLM instances for different agents
    legal_llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"]
    )
    
    compliance_llm = ChatOpenAI(
        model=creds["model"],
        openai_api_key=creds["api_key"],
        openai_api_base=creds["base_url"],
        default_headers=creds["headers"]
    )
    
    # Define agent nodes
    def legal_agent(state: AgentState) -> AgentState:
        """Legal analysis agent."""
        response = legal_llm.invoke([
            SystemMessage(content="You are a legal analyst. Analyze legal requirements."),
            HumanMessage(content=state["messages"][-1])
        ])
        return {
            "messages": [f"Legal Agent: {response.content}"],
            "current_agent": "compliance",
            "final_answer": ""
        }
    
    def compliance_agent(state: AgentState) -> AgentState:
        """Compliance review agent."""
        response = compliance_llm.invoke([
            SystemMessage(content="You are a compliance officer. Review for compliance."),
            HumanMessage(content=state["messages"][-1])
        ])
        return {
            "messages": [f"Compliance Agent: {response.content}"],
            "current_agent": "end",
            "final_answer": response.content
        }
    
    # Build graph
    workflow = StateGraph(AgentState)
    workflow.add_node("legal", legal_agent)
    workflow.add_node("compliance", compliance_agent)
    
    workflow.set_entry_point("legal")
    workflow.add_edge("legal", "compliance")
    workflow.add_edge("compliance", END)
    
    app = workflow.compile()
    
    # Run the graph
    initial_state = {
        "messages": ["Analyze data retention requirements under GDPR Article 5"],
        "current_agent": "legal",
        "final_answer": ""
    }
    
    result = app.invoke(initial_state)
    print(f"Final Answer: {result['final_answer']}")


# ============================================================================
# EXAMPLE 5: Streaming Responses
# ============================================================================

def example_5_streaming():
    """Example with streaming responses."""
    print("\n" + "="*80)
    print("EXAMPLE 5: Streaming Responses")
    print("="*80)
    
    client = get_openai_client()
    
    stream = client.chat.completions.create(
        model=Config.get_effective_model(),
        messages=[
            {"role": "user", "content": "Explain privacy by design in 3 points."}
        ],
        stream=True
    )
    
    print("Streaming response:")
    for chunk in stream:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
    print("\n")


# ============================================================================
# EXAMPLE 6: Token Management
# ============================================================================

def example_6_token_management():
    """Example showing token management."""
    print("\n" + "="*80)
    print("EXAMPLE 6: Token Management")
    print("="*80)
    
    # Create HSBC client directly for token management
    hsbc_client = create_hsbc_client(
        token_api_url=Config.HSBC_TOKEN_API_URL,
        chat_api_url=Config.HSBC_CHAT_API_URL,
        username=Config.HSBC_USERNAME,
        password=Config.HSBC_PASSWORD
    )
    
    # Get current token
    token = hsbc_client.get_api_key()
    print(f"Current Token: {token[:20]}...")
    
    # Force refresh
    print("Refreshing token...")
    hsbc_client.refresh_token()
    new_token = hsbc_client.get_api_key()
    print(f"New Token: {new_token[:20]}...")
    
    # Get OpenAI client
    client = hsbc_client.get_client()
    print(f"OpenAI client ready with base URL: {hsbc_client.get_base_url()}")


# ============================================================================
# EXAMPLE 7: Error Handling
# ============================================================================

async def example_7_error_handling():
    """Example with proper error handling."""
    print("\n" + "="*80)
    print("EXAMPLE 7: Error Handling")
    print("="*80)
    
    from openai_service_hsbc import OpenAIService
    
    try:
        service = OpenAIService()
        
        messages = [
            HumanMessage(content="Test message")
        ]
        
        response = await service.chat_completion(messages)
        print(f"Success: {response[:100]}...")
        
    except ValueError as e:
        print(f"Configuration Error: {e}")
    except Exception as e:
        print(f"API Error: {e}")
        # Token might be expired - could trigger refresh here


# ============================================================================
# MAIN: Run all examples
# ============================================================================

def main():
    """Run all examples."""
    print("\n" + "="*80)
    print("HSBC OpenAI Wrapper - Usage Examples")
    print("="*80)
    
    # Setup environment
    setup_hsbc_environment()
    
    # Run examples
    try:
        example_1_direct_openai()
        asyncio.run(example_2_openai_service())
        example_3_langchain()
        example_4_langgraph()
        example_5_streaming()
        example_6_token_management()
        asyncio.run(example_7_error_handling())
        
        print("\n" + "="*80)
        print("All examples completed!")
        print("="*80)
        
    except Exception as e:
        print(f"\nError running examples: {e}")
        print("Make sure to set HSBC_PASSWORD environment variable!")


if __name__ == "__main__":
    main()
