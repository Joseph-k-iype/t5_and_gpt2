"""
Legal Document Analyzer - COMPLETE VERSION WITH SUPERVISOR & KNOWLEDGE GRAPH
- NO TRUNCATION - processes full content
- Supervisor agent for validation
- Knowledge graph reasoning with networkx
- Complete extraction of constraints, conditions, and enterprise policies
- Multi-level analysis (Level 1: Legislation, Level 2: Guidance, Level 3: Enterprise)

Location: src/analyzers/legal_document_analyzer.py
"""

from typing import Dict, List, Optional, Any, Tuple, Set
import json
from dataclasses import dataclass, field
import logging
import re
from collections import defaultdict

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import networkx as nx

from src.prompting.advanced_strategies import AdvancedPromptingStrategies
from src.services.openai_service import OpenAIService
from src.utils.document_chunker import DocumentChunker
from src.config import Config

logger = logging.getLogger(__name__)


# SIMPLIFIED ACTION TAXONOMY
class DataActionType:
    """Simplified data action taxonomy"""
    DATA_SHARING_AND_ACCESS = "data_sharing_and_access"
    DATA_STORAGE_AND_HOSTING = "data_storage_and_hosting"
    DATA_USAGE = "data_usage"


class RuleClassification:
    """Rule classification"""
    CONDITION = "condition"
    RESTRICTION = "restriction"


@dataclass
class Citation:
    """Citation for extracted information"""
    text_excerpt: str
    chunk_id: int
    document_level: int
    reasoning: str = ""


@dataclass
class Evidence:
    """Evidence supporting a rule or requirement"""
    description: str
    citations: List[Citation] = field(default_factory=list)


@dataclass
class Constraint:
    """Constraint or condition"""
    type: str  # temporal, spatial, technical, procedural, purpose
    description: str
    left_operand: str
    operator: str
    right_operand: Any
    citations: List[Citation] = field(default_factory=list)
    scope: str = "general"  # permission, prohibition, duty, general


@dataclass
class EnterprisePolicy:
    """Enterprise-specific policy"""
    policy_name: str
    description: str
    organization: str
    applies_to: List[str]
    internal_tools: List[str]
    citations: List[Citation] = field(default_factory=list)
    level: int = 3


class KnowledgeGraphBuilder:
    """
    Builds and maintains knowledge graph of legal requirements
    Uses networkx for graph operations and reasoning
    """
    
    def __init__(self):
        self.graph = nx.DiGraph()
        self.node_counter = 0
        
    def add_rule(self, rule_id: str, rule_data: Dict[str, Any]):
        """Add a rule node to the graph"""
        self.graph.add_node(
            rule_id,
            type='rule',
            data=rule_data,
            level=rule_data.get('level', 1)
        )
        
    def add_constraint(self, constraint_id: str, constraint: Constraint, rule_id: str):
        """Add constraint and link to rule"""
        self.graph.add_node(
            constraint_id,
            type='constraint',
            constraint_type=constraint.type,
            description=constraint.description,
            operator=constraint.operator,
            scope=constraint.scope
        )
        self.graph.add_edge(rule_id, constraint_id, relationship='has_constraint')
        
    def add_action(self, action_id: str, action_data: Dict[str, Any], rule_id: str):
        """Add action and link to rule"""
        self.graph.add_node(
            action_id,
            type='action',
            action_type=action_data['type'],
            description=action_data['description']
        )
        self.graph.add_edge(rule_id, action_id, relationship='requires_action')
        
    def add_evidence(self, evidence_id: str, evidence_data: Dict[str, Any], rule_id: str, evidence_type: str):
        """Add evidence (user or system) and link to rule"""
        self.graph.add_node(
            evidence_id,
            type=f'{evidence_type}_evidence',
            description=evidence_data['description']
        )
        self.graph.add_edge(rule_id, evidence_id, relationship=f'has_{evidence_type}_evidence')
        
    def add_enterprise_policy(self, policy_id: str, policy: EnterprisePolicy, rule_id: str):
        """Add enterprise policy and link to rule"""
        self.graph.add_node(
            policy_id,
            type='enterprise_policy',
            policy_name=policy.policy_name,
            organization=policy.organization,
            description=policy.description,
            level=policy.level
        )
        self.graph.add_edge(rule_id, policy_id, relationship='implements_policy')
        
    def link_rules(self, source_rule_id: str, target_rule_id: str, relationship: str):
        """Link two rules with a relationship"""
        self.graph.add_edge(source_rule_id, target_rule_id, relationship=relationship)
        
    def find_conflicts(self) -> List[Tuple[str, str, str]]:
        """Find conflicting rules in the graph"""
        conflicts = []
        
        # Find rules with conflicting constraints
        constraint_nodes = [n for n, d in self.graph.nodes(data=True) if d.get('type') == 'constraint']
        
        for i, c1 in enumerate(constraint_nodes):
            for c2 in constraint_nodes[i+1:]:
                c1_data = self.graph.nodes[c1]
                c2_data = self.graph.nodes[c2]
                
                # Check for conflicting operators on same operand
                if (c1_data.get('constraint_type') == c2_data.get('constraint_type') and
                    self._operators_conflict(c1_data.get('operator'), c2_data.get('operator'))):
                    conflicts.append((c1, c2, "conflicting_operators"))
                    
        return conflicts
        
    def _operators_conflict(self, op1: str, op2: str) -> bool:
        """Check if two operators conflict"""
        conflicting_pairs = [
            ('eq', 'neq'),
            ('gt', 'lt'),
            ('gte', 'lte'),
            ('isAnyOf', 'isNoneOf')
        ]
        return (op1, op2) in conflicting_pairs or (op2, op1) in conflicting_pairs
        
    def find_dependencies(self, rule_id: str) -> List[str]:
        """Find all rules that this rule depends on"""
        return list(self.graph.predecessors(rule_id))
        
    def find_dependents(self, rule_id: str) -> List[str]:
        """Find all rules that depend on this rule"""
        return list(self.graph.successors(rule_id))
        
    def get_rule_subgraph(self, rule_id: str, depth: int = 2) -> nx.DiGraph:
        """Get subgraph centered on a specific rule"""
        nodes = nx.single_source_shortest_path_length(self.graph, rule_id, cutoff=depth).keys()
        return self.graph.subgraph(nodes).copy()
        
    def find_cross_level_relationships(self) -> List[Tuple[str, str, int, int]]:
        """Find relationships between rules at different levels"""
        relationships = []
        
        for source, target, data in self.graph.edges(data=True):
            source_level = self.graph.nodes[source].get('level', 0)
            target_level = self.graph.nodes[target].get('level', 0)
            
            if source_level != target_level:
                relationships.append((source, target, source_level, target_level))
                
        return relationships
        
    def reason_about_rule(self, rule_id: str) -> Dict[str, Any]:
        """
        Reason about a rule using graph structure
        Returns insights and validations
        """
        reasoning = {
            'rule_id': rule_id,
            'has_constraints': False,
            'has_actions': False,
            'has_evidence': False,
            'has_enterprise_policies': False,
            'dependencies': [],
            'dependents': [],
            'conflicts': [],
            'completeness_score': 0.0,
            'insights': []
        }
        
        if rule_id not in self.graph:
            reasoning['insights'].append("Rule not found in graph")
            return reasoning
            
        # Check what components exist
        for neighbor in self.graph.neighbors(rule_id):
            neighbor_type = self.graph.nodes[neighbor].get('type')
            
            if neighbor_type == 'constraint':
                reasoning['has_constraints'] = True
            elif neighbor_type == 'action':
                reasoning['has_actions'] = True
            elif neighbor_type in ['user_evidence', 'system_evidence']:
                reasoning['has_evidence'] = True
            elif neighbor_type == 'enterprise_policy':
                reasoning['has_enterprise_policies'] = True
                
        # Get dependencies
        reasoning['dependencies'] = self.find_dependencies(rule_id)
        reasoning['dependents'] = self.find_dependents(rule_id)
        
        # Calculate completeness score
        score = 0.0
        if reasoning['has_constraints']: score += 0.25
        if reasoning['has_actions']: score += 0.25
        if reasoning['has_evidence']: score += 0.25
        if reasoning['has_enterprise_policies']: score += 0.25
        reasoning['completeness_score'] = score
        
        # Generate insights
        if not reasoning['has_constraints']:
            reasoning['insights'].append("Missing constraints - rule may lack specific conditions")
        if not reasoning['has_actions']:
            reasoning['insights'].append("Missing actions - rule may lack actionable requirements")
        if not reasoning['has_evidence']:
            reasoning['insights'].append("Missing evidence requirements - validation may be unclear")
            
        rule_level = self.graph.nodes[rule_id].get('level', 0)
        if rule_level == 3 and not reasoning['has_enterprise_policies']:
            reasoning['insights'].append("Level 3 rule missing enterprise policies")
            
        return reasoning
        
    def get_statistics(self) -> Dict[str, Any]:
        """Get graph statistics"""
        stats = {
            'total_nodes': self.graph.number_of_nodes(),
            'total_edges': self.graph.number_of_edges(),
            'rules': 0,
            'constraints': 0,
            'actions': 0,
            'evidence': 0,
            'enterprise_policies': 0
        }
        
        for node, data in self.graph.nodes(data=True):
            node_type = data.get('type', '')
            if node_type == 'rule':
                stats['rules'] += 1
            elif node_type == 'constraint':
                stats['constraints'] += 1
            elif node_type == 'action':
                stats['actions'] += 1
            elif 'evidence' in node_type:
                stats['evidence'] += 1
            elif node_type == 'enterprise_policy':
                stats['enterprise_policies'] += 1
                
        return stats


class SupervisorAgent:
    """
    Supervisor agent that validates and reasons about analysis results
    Uses knowledge graph for deep reasoning
    """
    
    def __init__(self, llm: ChatOpenAI, knowledge_graph: KnowledgeGraphBuilder):
        self.llm = llm
        self.kg = knowledge_graph
        
    def validate_analysis(self, analysis: Dict[str, Any], rule_id: str) -> Dict[str, Any]:
        """
        Comprehensive validation of analysis results
        """
        validation_result = {
            'valid': True,
            'errors': [],
            'warnings': [],
            'suggestions': [],
            'graph_insights': {}
        }
        
        # 1. Structure validation
        required_fields = ['description', 'citations', 'data_actions', 'constraints']
        for field in required_fields:
            if field not in analysis:
                validation_result['errors'].append(f"Missing required field: {field}")
                validation_result['valid'] = False
                
        # 2. Content validation
        if 'description' in analysis and len(analysis['description']) < 50:
            validation_result['warnings'].append("Description seems too short")
            
        if 'citations' in analysis and len(analysis['citations']) == 0:
            validation_result['warnings'].append("No citations provided - claims may not be traceable")
            
        if 'constraints' in analysis and len(analysis['constraints']) == 0:
            validation_result['warnings'].append("No constraints extracted - rule may lack specificity")
            
        # 3. Knowledge graph reasoning
        if rule_id in self.kg.graph:
            graph_reasoning = self.kg.reason_about_rule(rule_id)
            validation_result['graph_insights'] = graph_reasoning
            
            if graph_reasoning['completeness_score'] < 0.5:
                validation_result['suggestions'].append(
                    f"Rule completeness is {graph_reasoning['completeness_score']:.0%} - consider extracting more components"
                )
                
            for insight in graph_reasoning['insights']:
                validation_result['suggestions'].append(insight)
                
        # 4. Check for conflicts
        conflicts = self.kg.find_conflicts()
        if conflicts:
            validation_result['warnings'].append(f"Found {len(conflicts)} potential conflicts in knowledge graph")
            
        return validation_result
        
    def reason_about_levels(self, level_1_analysis: Dict, level_2_analysis: Dict, level_3_analysis: Dict) -> Dict[str, Any]:
        """
        Reason about relationships between the three document levels
        """
        reasoning = {
            'level_alignment': {},
            'enhancement_opportunities': [],
            'consistency_issues': []
        }
        
        # Check if Level 2 enhances Level 1
        l1_constraints = len(level_1_analysis.get('constraints', []))
        l2_constraints = len(level_2_analysis.get('constraints', []))
        
        if l2_constraints > l1_constraints:
            reasoning['level_alignment']['guidance_adds_detail'] = True
            reasoning['enhancement_opportunities'].append(
                f"Level 2 guidance adds {l2_constraints - l1_constraints} additional constraints"
            )
        else:
            reasoning['level_alignment']['guidance_adds_detail'] = False
            
        # Check if Level 3 provides enterprise context
        l3_policies = level_3_analysis.get('enterprise_policies', [])
        if len(l3_policies) > 0:
            reasoning['level_alignment']['enterprise_specific'] = True
            reasoning['enhancement_opportunities'].append(
                f"Level 3 provides {len(l3_policies)} enterprise-specific policies"
            )
        else:
            reasoning['level_alignment']['enterprise_specific'] = False
            reasoning['enhancement_opportunities'].append(
                "Level 3 missing enterprise-specific policies"
            )
            
        # Check for consistency in classifications
        classifications = [
            level_1_analysis.get('classification'),
            level_2_analysis.get('classification'),
            level_3_analysis.get('classification')
        ]
        
        if len(set(classifications)) > 1:
            reasoning['consistency_issues'].append(
                f"Inconsistent classifications across levels: {classifications}"
            )
            
        return reasoning
        
    def suggest_improvements(self, analysis: Dict[str, Any]) -> List[str]:
        """
        Use LLM to suggest improvements
        """
        prompt = f"""Review this legal document analysis and suggest improvements:

ANALYSIS:
{json.dumps(analysis, indent=2)}

Provide specific, actionable suggestions for:
1. Missing constraints or conditions
2. Insufficient citations
3. Unclear evidence requirements
4. Incomplete enterprise policies (if Level 3)
5. Classification accuracy

Return a JSON list of suggestions."""

        messages = [
            SystemMessage(content="You are a legal analysis supervisor. Review analyses for completeness and accuracy."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = self.llm.invoke(messages)
            suggestions = json.loads(response.content)
            return suggestions if isinstance(suggestions, list) else []
        except:
            return ["Unable to generate suggestions"]


class LegalDocumentAnalyzer:
    """
    COMPLETE Legal Document Analyzer with Supervisor and Knowledge Graph
    - NO TRUNCATION
    - Complete extraction of constraints, conditions, enterprise policies
    - Knowledge graph reasoning
    - Supervisor validation
    """
    
    def __init__(self, config: Config = None):
        self.config = config or Config()
        
        if not self.config.API_KEY:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        self.openai_service = OpenAIService()
        self.llm = ChatOpenAI(
            model=self.config.CHAT_MODEL,
            openai_api_key=self.config.API_KEY,
            openai_api_base=self.config.BASE_URL
        )
        
        chunk_size = getattr(self.config, 'CHUNK_SIZE', 3000)
        overlap_size = getattr(self.config, 'OVERLAP_SIZE', 200)
        
        self.chunker = DocumentChunker(
            chunk_size=chunk_size,
            chunk_overlap=overlap_size,
            respect_boundaries=True
        )
        
        # Initialize knowledge graph and supervisor
        self.knowledge_graph = KnowledgeGraphBuilder()
        self.supervisor = SupervisorAgent(self.llm, self.knowledge_graph)
        
    def analyze_document(
        self,
        rule_name: str,
        jurisdiction: str,
        document_text: str,
        level: int,
        enterprise_context: Optional[Dict[str, Any]] = None,
        previous_level_analysis: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Main document analysis with NO TRUNCATION
        """
        print(f"\n{'='*60}")
        print(f"Analyzing: {rule_name} (Level {level})")
        print(f"Document length: {len(document_text)} chars")
        print(f"{'='*60}")
        
        # Initialize strategies
        strategies = AdvancedPromptingStrategies(rule_name, jurisdiction)
        
        # Chunk document
        chunks = self.chunker.chunk_document(
            text=document_text,
            metadata={
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level
            }
        )
        
        print(f"Created {len(chunks)} chunks")
        
        # Process each chunk with FULL CONTENT
        chunk_analyses = []
        for i, chunk in enumerate(chunks):
            print(f"\nProcessing chunk {i+1}/{len(chunks)} (size: {len(chunk['text'])} chars)...")
            
            try:
                analysis = self._analyze_single_chunk_complete(
                    chunk=chunk,
                    strategies=strategies,
                    level=level,
                    enterprise_context=enterprise_context,
                    full_document_text=document_text  # Pass full document for context
                )
                
                if analysis:
                    chunk_analyses.append(analysis)
                    print(f"  âœ“ Extracted: {len(analysis.get('data_actions', []))} actions, "
                          f"{len(analysis.get('citations', []))} citations, "
                          f"{len(analysis.get('constraints', []))} constraints, "
                          f"{len(analysis.get('enterprise_policies', []))} enterprise policies")
                else:
                    print(f"  âš  No data extracted from chunk {i+1}")
                    
            except Exception as e:
                print(f"  âœ— Error processing chunk {i+1}: {e}")
                logger.error(f"Chunk {i+1} error: {e}", exc_info=True)
                continue
        
        # Merge all chunk analyses
        print(f"\nMerging {len(chunk_analyses)} chunk analyses...")
        final_analysis = self._merge_chunk_analyses_complete(
            chunk_analyses=chunk_analyses,
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            level=level,
            enterprise_context=enterprise_context
        )
        
        # Add to knowledge graph
        rule_id = f"{rule_name}_level_{level}"
        final_analysis['rule_id'] = rule_id
        self._add_to_knowledge_graph(rule_id, final_analysis, level)
        
        # Supervisor validation
        validation = self.supervisor.validate_analysis(final_analysis, rule_id)
        final_analysis['validation'] = validation
        
        # Print validation results
        if not validation['valid']:
            print(f"\nâš  VALIDATION ERRORS:")
            for error in validation['errors']:
                print(f"  - {error}")
                
        if validation['warnings']:
            print(f"\nâš  VALIDATION WARNINGS:")
            for warning in validation['warnings']:
                print(f"  - {warning}")
                
        if validation['suggestions']:
            print(f"\nðŸ’¡ SUGGESTIONS:")
            for suggestion in validation['suggestions']:
                print(f"  - {suggestion}")
        
        return final_analysis
    
    def _analyze_single_chunk_complete(
        self,
        chunk: Dict[str, Any],
        strategies: AdvancedPromptingStrategies,
        level: int,
        enterprise_context: Optional[Dict[str, Any]],
        full_document_text: str
    ) -> Optional[Dict[str, Any]]:
        """
        Analyze single chunk with COMPLETE extraction - NO TRUNCATION
        """
        chunk_text = chunk['text']
        chunk_id = chunk.get('chunk_id', 0)
        chunk_context = self.chunker.get_chunk_context(chunk)
        
        # Create comprehensive prompt WITHOUT TRUNCATION
        prompt = f"""Analyze this legal text comprehensively. Extract ALL components with complete citations.

CHUNK CONTEXT: {chunk_context}

ENTERPRISE CONTEXT: {json.dumps(enterprise_context) if enterprise_context else 'None'}

DOCUMENT LEVEL: {level}
{self._get_level_description(level)}

FULL CHUNK TEXT (NO TRUNCATION):
{chunk_text}

EXTRACTION REQUIREMENTS:

1. DESCRIPTION: Comprehensive description of requirements

2. CITATIONS: For EVERY claim, provide exact text excerpts (up to 200 chars) with reasoning

3. DATA ACTIONS: Map to taxonomy:
   - data_sharing_and_access (sharing, transferring, disclosing, accessing)
   - data_storage_and_hosting (storing, hosting, retaining, archiving)
   - data_usage (using, processing, analyzing, collecting)

4. CONSTRAINTS: Extract ALL constraints and conditions:
   - type: temporal|spatial|technical|procedural|purpose|party
   - description: COMPLETE description
   - left_operand: What is being constrained
   - operator: eq|neq|gt|lt|gte|lte|isAnyOf|isNoneOf
   - right_operand: Constraint value
   - scope: permission|prohibition|duty|general
   - citations: Supporting text

5. USER EVIDENCE: What users must/can/cannot do

6. SYSTEM EVIDENCE: What systems must implement

7. ENTERPRISE POLICIES (especially Level 3):
   - policy_name: Name of policy
   - description: COMPLETE description
   - organization: Organization name
   - applies_to: Who/what it applies to
   - internal_tools: Mentioned tools (e.g., DataVisa, PrivacyHub)
   - citations: Supporting text

8. CLASSIFICATION: "condition" (allowed under conditions) or "restriction" (prohibited)

Return JSON with ALL fields fully populated. NO TRUNCATION or placeholders."""

        messages = [
            SystemMessage(content=strategies.get_react_agent_system_prompt()),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = self.llm.invoke(messages)
            response_text = response.content
            
            logger.info(f"Chunk {chunk_id} response length: {len(response_text)} chars")
            
            # Extract structured data
            extracted = self._extract_complete_from_response(
                response_text=response_text,
                chunk_id=chunk_id,
                level=level
            )
            
            return extracted
            
        except Exception as e:
            logger.error(f"Error in LLM call for chunk {chunk_id}: {e}")
            return None
    
    def _get_level_description(self, level: int) -> str:
        """Get description of document level"""
        descriptions = {
            1: "Level 1: PRIMARY LEGISLATION - Base legal requirements",
            2: "Level 2: REGULATORY GUIDANCE - Detailed interpretation and guidance",
            3: "Level 3: ENTERPRISE POLICIES - Organization-specific implementation"
        }
        return descriptions.get(level, "")
    
    def _extract_complete_from_response(
        self,
        response_text: str,
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """
        COMPLETE extraction - handles all components including constraints and enterprise policies
        """
        # Try JSON extraction strategies
        parsed = self._try_json_extraction(response_text)
        
        if parsed:
            logger.info(f"Chunk {chunk_id}: Successfully extracted JSON")
            return self._normalize_complete_data(parsed, chunk_id, level)
        else:
            logger.warning(f"Chunk {chunk_id}: JSON extraction failed, using text extraction")
            return self._extract_complete_from_text(response_text, chunk_id, level)
    
    def _try_json_extraction(self, text: str) -> Optional[Dict]:
        """Try multiple JSON extraction strategies"""
        # Strategy 1: Direct JSON
        try:
            return json.loads(text)
        except:
            pass
        
        # Strategy 2: Markdown JSON block
        try:
            match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if match:
                return json.loads(match.group(1))
        except:
            pass
        
        # Strategy 3: Find largest JSON object
        try:
            pattern = r'\{(?:[^{}]|(?:\{(?:[^{}]|(?:\{[^{}]*\}))*\}))*\}'
            matches = re.findall(pattern, text, re.DOTALL)
            for match in sorted(matches, key=len, reverse=True):
                try:
                    parsed = json.loads(match)
                    if isinstance(parsed, dict) and len(parsed) > 3:
                        return parsed
                except:
                    continue
        except:
            pass
        
        return None
    
    def _normalize_complete_data(
        self,
        data: Dict[str, Any],
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """
        Normalize with COMPLETE extraction of all components
        """
        normalized = {
            "description": str(data.get("description", "")),
            "citations": [],
            "data_actions": [],
            "user_evidence": [],
            "system_evidence": [],
            "constraints": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": ""
        }
        
        # Extract citations - NO TRUNCATION
        for cite in data.get("citations", []):
            if isinstance(cite, dict):
                normalized["citations"].append({
                    "text": str(cite.get("text", "")),
                    "chunk_id": chunk_id,
                    "level": level,
                    "reasoning": str(cite.get("reasoning", ""))
                })
            elif isinstance(cite, str):
                normalized["citations"].append({
                    "text": cite,
                    "chunk_id": chunk_id,
                    "level": level,
                    "reasoning": ""
                })
        
        # Extract data actions
        for action in data.get("data_actions", []):
            if isinstance(action, dict):
                action_type = self._map_to_taxonomy(action.get("type", ""))
                normalized["data_actions"].append({
                    "type": action_type,
                    "description": str(action.get("description", "")),
                    "citations": action.get("citations", [])
                })
            elif isinstance(action, str):
                normalized["data_actions"].append({
                    "type": DataActionType.DATA_USAGE,
                    "description": action,
                    "citations": []
                })
        
        # Extract constraints - COMPLETE
        for constraint in data.get("constraints", []):
            if isinstance(constraint, dict):
                normalized["constraints"].append({
                    "type": constraint.get("type", "general"),
                    "description": str(constraint.get("description", "")),
                    "left_operand": str(constraint.get("left_operand", "")),
                    "operator": str(constraint.get("operator", "eq")),
                    "right_operand": constraint.get("right_operand"),
                    "scope": constraint.get("scope", "general"),
                    "citations": constraint.get("citations", []),
                    "chunk_id": chunk_id,
                    "level": level
                })
            elif isinstance(constraint, str) and len(constraint) > 5:
                normalized["constraints"].append({
                    "type": "general",
                    "description": constraint,
                    "left_operand": "",
                    "operator": "eq",
                    "right_operand": True,
                    "scope": "general",
                    "citations": [],
                    "chunk_id": chunk_id,
                    "level": level
                })
        
        # Extract user evidence
        for evidence in data.get("user_evidence", []):
            if isinstance(evidence, dict):
                normalized["user_evidence"].append({
                    "description": str(evidence.get("description", "")),
                    "citations": evidence.get("citations", [])
                })
            elif isinstance(evidence, str):
                normalized["user_evidence"].append({
                    "description": evidence,
                    "citations": []
                })
        
        # Extract system evidence
        for evidence in data.get("system_evidence", []):
            if isinstance(evidence, dict):
                normalized["system_evidence"].append({
                    "description": str(evidence.get("description", "")),
                    "citations": evidence.get("citations", [])
                })
            elif isinstance(evidence, str):
                normalized["system_evidence"].append({
                    "description": evidence,
                    "citations": []
                })
        
        # Extract enterprise policies - COMPLETE
        for policy in data.get("enterprise_policies", []):
            if isinstance(policy, dict):
                normalized["enterprise_policies"].append({
                    "policy_name": str(policy.get("policy_name", "")),
                    "description": str(policy.get("description", "")),
                    "organization": str(policy.get("organization", "")),
                    "applies_to": policy.get("applies_to", []),
                    "internal_tools": policy.get("internal_tools", []),
                    "citations": policy.get("citations", []),
                    "level": level
                })
        
        # Classification
        classification = str(data.get("classification", "condition")).lower()
        if "restriction" in classification or "prohibit" in classification:
            normalized["classification"] = "restriction"
        else:
            normalized["classification"] = "condition"
        
        normalized["classification_reasoning"] = str(data.get("classification_reasoning", ""))
        
        return normalized
    
    def _extract_complete_from_text(
        self,
        text: str,
        chunk_id: int,
        level: int
    ) -> Dict[str, Any]:
        """
        COMPLETE text extraction - fallback with full component extraction
        """
        result = {
            "description": "",
            "citations": [],
            "data_actions": [],
            "user_evidence": [],
            "system_evidence": [],
            "constraints": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": ""
        }
        
        lines = text.split('\n')
        current_section = None
        current_constraint = {}
        current_policy = {}
        
        for line in lines:
            line = line.strip()
            if not line or len(line) < 3:
                continue
            
            line_lower = line.lower()
            
            # Section identification
            if "description:" in line_lower:
                current_section = "description"
                desc = line.split(":", 1)[1].strip() if ":" in line else ""
                if desc:
                    result["description"] = desc
            elif "citation" in line_lower:
                current_section = "citations"
            elif "data action" in line_lower or "action:" in line_lower:
                current_section = "data_actions"
            elif "user evidence" in line_lower or "user:" in line_lower:
                current_section = "user_evidence"
            elif "system evidence" in line_lower or "system:" in line_lower:
                current_section = "system_evidence"
            elif "constraint" in line_lower:
                current_section = "constraints"
                if current_constraint:
                    result["constraints"].append(current_constraint)
                current_constraint = {"chunk_id": chunk_id, "level": level}
            elif "enterprise polic" in line_lower or "organizational polic" in line_lower:
                current_section = "enterprise_policies"
                if current_policy:
                    result["enterprise_policies"].append(current_policy)
                current_policy = {"level": level}
            elif "classification:" in line_lower:
                if "restriction" in line_lower or "prohibit" in line_lower:
                    result["classification"] = "restriction"
                else:
                    result["classification"] = "condition"
            elif current_section:
                # Process line based on current section
                if line.startswith("-") or line.startswith("â€¢") or line.startswith("*"):
                    item = line.lstrip("-â€¢* ").strip()
                    
                    if current_section == "citations" and len(item) > 5:
                        result["citations"].append({
                            "text": item,
                            "chunk_id": chunk_id,
                            "level": level,
                            "reasoning": "Text extraction"
                        })
                    elif current_section == "data_actions" and len(item) > 5:
                        action_type = self._map_to_taxonomy(item)
                        result["data_actions"].append({
                            "type": action_type,
                            "description": item,
                            "citations": []
                        })
                    elif current_section == "user_evidence" and len(item) > 5:
                        result["user_evidence"].append({
                            "description": item,
                            "citations": []
                        })
                    elif current_section == "system_evidence" and len(item) > 5:
                        result["system_evidence"].append({
                            "description": item,
                            "citations": []
                        })
                elif current_section == "constraints":
                    # Parse constraint fields
                    if "type:" in line_lower:
                        current_constraint["type"] = line.split(":", 1)[1].strip()
                    elif "description:" in line_lower:
                        current_constraint["description"] = line.split(":", 1)[1].strip()
                    elif "operator:" in line_lower:
                        current_constraint["operator"] = line.split(":", 1)[1].strip()
                elif current_section == "enterprise_policies":
                    # Parse policy fields
                    if "policy name:" in line_lower or "name:" in line_lower:
                        current_policy["policy_name"] = line.split(":", 1)[1].strip()
                    elif "description:" in line_lower:
                        current_policy["description"] = line.split(":", 1)[1].strip()
                    elif "organization:" in line_lower:
                        current_policy["organization"] = line.split(":", 1)[1].strip()
                    elif "tool" in line_lower:
                        tools = line.split(":", 1)[1].strip() if ":" in line else ""
                        current_policy["internal_tools"] = [t.strip() for t in tools.split(",")]
        
        # Add last constraint/policy if any
        if current_constraint and "description" in current_constraint:
            result["constraints"].append(current_constraint)
        if current_policy and "policy_name" in current_policy:
            result["enterprise_policies"].append(current_policy)
        
        # Fallback description
        if not result["description"] and text:
            result["description"] = text[:500]
            result["citations"].append({
                "text": text[:200],
                "chunk_id": chunk_id,
                "level": level,
                "reasoning": "Fallback citation"
            })
        
        return result
    
    def _map_to_taxonomy(self, action_type: str) -> str:
        """Map action to simplified taxonomy"""
        action_lower = action_type.lower().strip()
        
        if any(word in action_lower for word in ['share', 'transfer', 'disclose', 'access', 'provide', 'send']):
            return DataActionType.DATA_SHARING_AND_ACCESS
        
        if any(word in action_lower for word in ['store', 'host', 'retain', 'keep', 'maintain', 'archive']):
            return DataActionType.DATA_STORAGE_AND_HOSTING
        
        return DataActionType.DATA_USAGE
    
    def _merge_chunk_analyses_complete(
        self,
        chunk_analyses: List[Dict[str, Any]],
        rule_name: str,
        jurisdiction: str,
        level: int,
        enterprise_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        COMPLETE merge with all components
        """
        if not chunk_analyses:
            return self._empty_analysis(rule_name, jurisdiction, level, enterprise_context)
        
        # Merge descriptions - NO TRUNCATION
        descriptions = [c.get("description", "") for c in chunk_analyses if c.get("description")]
        merged_description = " ".join(descriptions).strip()
        
        # Collect and deduplicate all components
        all_citations = []
        seen_citations = set()
        for chunk in chunk_analyses:
            for cite in chunk.get("citations", []):
                cite_text = cite.get("text", "")[:50]
                if cite_text and cite_text not in seen_citations:
                    all_citations.append(cite)
                    seen_citations.add(cite_text)
        
        all_actions = []
        seen_actions = set()
        for chunk in chunk_analyses:
            for action in chunk.get("data_actions", []):
                key = (action.get("type", ""), action.get("description", "")[:50])
                if key not in seen_actions:
                    all_actions.append(action)
                    seen_actions.add(key)
        
        all_constraints = []
        seen_constraints = set()
        for chunk in chunk_analyses:
            for constraint in chunk.get("constraints", []):
                key = (
                    constraint.get("type", ""),
                    constraint.get("description", "")[:50],
                    constraint.get("operator", "")
                )
                if key not in seen_constraints:
                    all_constraints.append(constraint)
                    seen_constraints.add(key)
        
        all_user_evidence = []
        seen_user = set()
        for chunk in chunk_analyses:
            for evidence in chunk.get("user_evidence", []):
                desc = evidence.get("description", "")[:50]
                if desc and desc not in seen_user:
                    all_user_evidence.append(evidence)
                    seen_user.add(desc)
        
        all_system_evidence = []
        seen_system = set()
        for chunk in chunk_analyses:
            for evidence in chunk.get("system_evidence", []):
                desc = evidence.get("description", "")[:50]
                if desc and desc not in seen_system:
                    all_system_evidence.append(evidence)
                    seen_system.add(desc)
        
        all_enterprise_policies = []
        seen_policies = set()
        for chunk in chunk_analyses:
            for policy in chunk.get("enterprise_policies", []):
                policy_name = policy.get("policy_name", "")
                if policy_name and policy_name not in seen_policies:
                    all_enterprise_policies.append(policy)
                    seen_policies.add(policy_name)
        
        # Determine classification
        classifications = [c.get("classification", "") for c in chunk_analyses if c.get("classification")]
        final_classification = "condition"
        if "restriction" in classifications:
            final_classification = "restriction"
        elif classifications:
            final_classification = classifications[0]
        
        reasonings = [c.get("classification_reasoning", "") for c in chunk_analyses if c.get("classification_reasoning")]
        combined_reasoning = "; ".join(reasonings).strip()
        
        # Build final analysis
        final = {
            "description": merged_description,
            "citations": all_citations,
            "data_actions": all_actions,
            "constraints": all_constraints,
            "user_evidence": all_user_evidence,
            "system_evidence": all_system_evidence,
            "enterprise_policies": all_enterprise_policies,
            "classification": final_classification,
            "classification_reasoning": combined_reasoning,
            "level": level,
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level,
                "document_length": sum(len(c.get("description", "")) for c in chunk_analyses),
                "chunks_processed": len(chunk_analyses),
                "enterprise_context": enterprise_context,
                "total_citations": len(all_citations),
                "total_actions": len(all_actions),
                "total_constraints": len(all_constraints),
                "total_user_evidence": len(all_user_evidence),
                "total_system_evidence": len(all_system_evidence),
                "total_enterprise_policies": len(all_enterprise_policies)
            }
        }
        
        # Print summary
        print(f"\nâœ“ Merge complete:")
        print(f"  Description: {len(merged_description)} chars")
        print(f"  Citations: {len(all_citations)}")
        print(f"  Actions: {len(all_actions)}")
        print(f"  Constraints: {len(all_constraints)}")
        print(f"  User evidence: {len(all_user_evidence)}")
        print(f"  System evidence: {len(all_system_evidence)}")
        print(f"  Enterprise policies: {len(all_enterprise_policies)}")
        print(f"  Classification: {final_classification}")
        
        return final
    
    def _empty_analysis(self, rule_name: str, jurisdiction: str, level: int, enterprise_context: Optional[Dict]) -> Dict:
        """Return empty analysis structure"""
        return {
            "description": "",
            "citations": [],
            "data_actions": [],
            "constraints": [],
            "user_evidence": [],
            "system_evidence": [],
            "enterprise_policies": [],
            "classification": "condition",
            "classification_reasoning": "",
            "level": level,
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "level": level,
                "chunks_processed": 0,
                "enterprise_context": enterprise_context
            }
        }
    
    def _add_to_knowledge_graph(self, rule_id: str, analysis: Dict[str, Any], level: int):
        """Add analysis to knowledge graph"""
        # Add rule node
        self.knowledge_graph.add_rule(rule_id, {
            'description': analysis.get('description'),
            'level': level,
            'classification': analysis.get('classification')
        })
        
        # Add constraints
        for i, constraint in enumerate(analysis.get('constraints', [])):
            constraint_id = f"{rule_id}_constraint_{i}"
            constraint_obj = Constraint(
                type=constraint.get('type', 'general'),
                description=constraint.get('description', ''),
                left_operand=constraint.get('left_operand', ''),
                operator=constraint.get('operator', 'eq'),
                right_operand=constraint.get('right_operand'),
                scope=constraint.get('scope', 'general')
            )
            self.knowledge_graph.add_constraint(constraint_id, constraint_obj, rule_id)
        
        # Add actions
        for i, action in enumerate(analysis.get('data_actions', [])):
            action_id = f"{rule_id}_action_{i}"
            self.knowledge_graph.add_action(action_id, action, rule_id)
        
        # Add evidence
        for i, evidence in enumerate(analysis.get('user_evidence', [])):
            evidence_id = f"{rule_id}_user_evidence_{i}"
            self.knowledge_graph.add_evidence(evidence_id, evidence, rule_id, 'user')
            
        for i, evidence in enumerate(analysis.get('system_evidence', [])):
            evidence_id = f"{rule_id}_system_evidence_{i}"
            self.knowledge_graph.add_evidence(evidence_id, evidence, rule_id, 'system')
        
        # Add enterprise policies
        for i, policy in enumerate(analysis.get('enterprise_policies', [])):
            policy_id = f"{rule_id}_policy_{i}"
            policy_obj = EnterprisePolicy(
                policy_name=policy.get('policy_name', ''),
                description=policy.get('description', ''),
                organization=policy.get('organization', ''),
                applies_to=policy.get('applies_to', []),
                internal_tools=policy.get('internal_tools', []),
                level=level
            )
            self.knowledge_graph.add_enterprise_policy(policy_id, policy_obj, rule_id)
    
    def analyze_multi_level(
        self,
        rule_name: str,
        jurisdiction: str,
        level_1_text: str,
        level_2_text: str,
        level_3_text: str,
        enterprise_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        COMPLETE multi-level analysis with supervisor reasoning
        """
        print(f"\n{'#'*60}")
        print(f"# MULTI-LEVEL ANALYSIS: {rule_name}")
        print(f"# WITH SUPERVISOR VALIDATION & KNOWLEDGE GRAPH REASONING")
        print(f"{'#'*60}")
        
        # Level 1 Analysis
        print(f"\n>>> LEVEL 1: LEGISLATION ({len(level_1_text)} chars)")
        level_1_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_1_text,
            level=1,
            enterprise_context=enterprise_context
        )
        
        # Level 2 Analysis
        print(f"\n>>> LEVEL 2: GUIDANCE ({len(level_2_text)} chars)")
        level_2_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_2_text,
            level=2,
            enterprise_context=enterprise_context
        )
        
        # Level 3 Analysis
        print(f"\n>>> LEVEL 3: ENTERPRISE POLICIES ({len(level_3_text)} chars)")
        level_3_analysis = self.analyze_document(
            rule_name=rule_name,
            jurisdiction=jurisdiction,
            document_text=level_3_text,
            level=3,
            enterprise_context=enterprise_context
        )
        
        # Supervisor reasoning about levels
        print(f"\n>>> SUPERVISOR: REASONING ABOUT LEVEL RELATIONSHIPS")
        level_reasoning = self.supervisor.reason_about_levels(
            level_1_analysis,
            level_2_analysis,
            level_3_analysis
        )
        
        # Combine all levels
        print(f"\n>>> COMBINING ALL LEVELS")
        combined = {
            "description": " ".join([
                level_1_analysis.get("description", ""),
                level_2_analysis.get("description", ""),
                level_3_analysis.get("description", "")
            ]).strip(),
            
            "citations": (
                level_1_analysis.get("citations", []) +
                level_2_analysis.get("citations", []) +
                level_3_analysis.get("citations", [])
            ),
            
            "data_actions": (
                level_1_analysis.get("data_actions", []) +
                level_2_analysis.get("data_actions", []) +
                level_3_analysis.get("data_actions", [])
            ),
            
            "constraints": (
                level_1_analysis.get("constraints", []) +
                level_2_analysis.get("constraints", []) +
                level_3_analysis.get("constraints", [])
            ),
            
            "user_evidence": (
                level_1_analysis.get("user_evidence", []) +
                level_2_analysis.get("user_evidence", []) +
                level_3_analysis.get("user_evidence", [])
            ),
            
            "system_evidence": (
                level_1_analysis.get("system_evidence", []) +
                level_2_analysis.get("system_evidence", []) +
                level_3_analysis.get("system_evidence", [])
            ),
            
            "enterprise_policies": (
                level_1_analysis.get("enterprise_policies", []) +
                level_2_analysis.get("enterprise_policies", []) +
                level_3_analysis.get("enterprise_policies", [])
            ),
            
            "classification": level_1_analysis.get("classification", "condition"),
            
            "classification_reasoning": "; ".join([
                level_1_analysis.get("classification_reasoning", ""),
                level_2_analysis.get("classification_reasoning", ""),
                level_3_analysis.get("classification_reasoning", "")
            ]).strip(),
            
            "level_reasoning": level_reasoning,
            
            "knowledge_graph_stats": self.knowledge_graph.get_statistics(),
            
            "metadata": {
                "rule_name": rule_name,
                "jurisdiction": jurisdiction,
                "enterprise_context": enterprise_context,
                "level_1_chunks": level_1_analysis.get("metadata", {}).get("chunks_processed", 0),
                "level_2_chunks": level_2_analysis.get("metadata", {}).get("chunks_processed", 0),
                "level_3_chunks": level_3_analysis.get("metadata", {}).get("chunks_processed", 0),
                "total_citations": 0,
                "total_actions": 0,
                "total_constraints": 0,
                "total_enterprise_policies": 0
            }
        }
        
        # Update counts
        combined["metadata"]["total_citations"] = len(combined["citations"])
        combined["metadata"]["total_actions"] = len(combined["data_actions"])
        combined["metadata"]["total_constraints"] = len(combined["constraints"])
        combined["metadata"]["total_enterprise_policies"] = len(combined["enterprise_policies"])
        
        # Print comprehensive summary
        print(f"\n{'#'*60}")
        print(f"# MULTI-LEVEL ANALYSIS COMPLETE")
        print(f"{'#'*60}")
        print(f"Total description: {len(combined['description'])} chars")
        print(f"Total citations: {len(combined['citations'])}")
        print(f"Total actions: {len(combined['data_actions'])}")
        print(f"Total constraints: {len(combined['constraints'])}")
        print(f"Total user evidence: {len(combined['user_evidence'])}")
        print(f"Total system evidence: {len(combined['system_evidence'])}")
        print(f"Total enterprise policies: {len(combined['enterprise_policies'])}")
        print(f"Classification: {combined['classification']}")
        
        print(f"\n{'='*60}")
        print(f"KNOWLEDGE GRAPH STATISTICS:")
        for key, value in combined["knowledge_graph_stats"].items():
            print(f"  {key}: {value}")
        
        print(f"\n{'='*60}")
        print(f"LEVEL REASONING:")
        for key, value in level_reasoning.items():
            print(f"  {key}: {value}")
        
        return combined
