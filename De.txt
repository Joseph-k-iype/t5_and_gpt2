"""
Query understanding node for the Agentic RAG system.

This module implements the query understanding node for the Agentic RAG system,
which analyzes the query to determine the most effective retrieval strategy.
"""

import json
import logging
import re
from typing import Dict, Any, List, Optional

from app.config.settings import get_llm

logger = logging.getLogger(__name__)

async def query_understanding(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Analyze the query to understand its intent and extract key concepts.
    This helps to determine the best retrieval strategy.
    
    Args:
        state: Current graph state
        
    Returns:
        Updated state with query analysis
    """
    logger.info(f"Analyzing query: {state['element_name']}")
    
    try:
        llm = get_llm()
        
        # Extract element details
        element_name = state.get('element_name', '')
        element_description = state.get('element_description', '')
        cdm_context = state.get('cdm_context', None)
        example_context = state.get('example_context', None)
        process_name = state.get('process_name_context', None)
        process_description = state.get('process_description_context', None)
        
        # Build context string
        context_parts = []
        if cdm_context:
            context_parts.append(f"CDM: {cdm_context}")
        if example_context:
            context_parts.append(f"Examples: {example_context}")
        if process_name:
            context_parts.append(f"Related Process: {process_name}")
        if process_description:
            context_parts.append(f"Process Description: {process_description}")
        
        context_str = " ".join(context_parts)
        
        # Prepare prompt for query analysis
        prompt = f"""
        You are an expert in data governance and business terminology. 
        Analyze the following data element to understand its meaning and identify key concepts:
        
        Element Name: {element_name}
        Element Description: {element_description}
        {context_str if context_str else ""}
        
        Task:
        1. Identify the main business concept(s) in this element
        2. Extract important keywords that define this concept
        3. Determine potential synonyms or related terms for better matching
        4. Determine if this is a:
           - Basic concept (e.g., "customer name", "product id")
           - Compound concept (e.g., "total transaction amount")
           - Domain-specific concept (e.g., industry-specific terminology)
        
        Provide your analysis in JSON format with these fields:
        {{
          "main_concept": "brief description of the main concept",
          "keywords": ["list", "of", "important", "keywords"],
          "synonyms": ["list", "of", "potential", "synonyms"],
          "concept_type": "basic|compound|domain-specific",
          "domain": "general|finance|healthcare|etc" (if applicable),
          "rephrased_query": "rephrased version of the element name and description for better retrieval"
        }}
        
        Ensure the response is valid JSON.
        """
        
        # Get analysis from LLM
        analysis_response = await llm.ainvoke(prompt)
        
        # Extract JSON from response
        analysis = _extract_json_from_llm_response(analysis_response)
        
        # Check if JSON extraction failed
        if not analysis:
            # Fallback to basic analysis
            logger.warning("LLM didn't return valid JSON for query analysis, using fallback")
            analysis = {
                "main_concept": element_name,
                "keywords": element_name.lower().split() + element_description.lower().split(),
                "synonyms": [],
                "concept_type": "unknown",
                "domain": "general",
                "rephrased_query": f"{element_name}. {element_description}"
            }
        
        # Update state with analysis
        state['query'] = {
            "original_text": f"{element_name}. {element_description}",
            "rephrased_text": analysis.get("rephrased_query", f"{element_name}. {element_description}"),
            "expanded_terms": analysis.get("synonyms", []),
            "relevant_context": json.dumps(analysis)
        }
        
        logger.info(f"Query analysis completed: {analysis['main_concept']}")
        return state
        
    except Exception as e:
        logger.error(f"Error in query understanding: {e}", exc_info=True)
        state["error"] = f"Query understanding failed: {str(e)}"
        
        # Add fallback query info to avoid downstream errors
        state['query'] = {
            "original_text": f"{state.get('element_name', '')}. {state.get('element_description', '')}",
            "rephrased_text": None,
            "expanded_terms": [],
            "relevant_context": None
        }
        
        return state

def _extract_json_from_llm_response(response: str) -> Optional[Dict[str, Any]]:
    """
    Extract JSON from LLM response text.
    
    Args:
        response: LLM response text
        
    Returns:
        Extracted JSON as dict or None if extraction failed
    """
    try:
        # Try direct JSON parsing first
        return json.loads(response)
    except json.JSONDecodeError:
        # Try to find JSON-like pattern in the response
        try:
            # Find text that looks like JSON (between curly braces)
            json_match = re.search(r'({.*})', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group(1))
        except (json.JSONDecodeError, AttributeError):
            pass
        
        # More aggressive pattern matching if the above fails
        try:
            # Look for content between triple backticks (common LLM format)
            code_block_match = re.search(r'```(?:json)?\s*(.*?)\s*```', response, re.DOTALL)
            if code_block_match:
                return json.loads(code_block_match.group(1))
        except (json.JSONDecodeError, AttributeError):
            pass
        
        # Final attempt - try to find anything that looks like a dictionary
        try:
            dict_pattern = re.search(r'({[\s\S]*})', response, re.DOTALL)
            if dict_pattern:
                # Clean up the text to help with parsing
                dict_text = dict_pattern.group(1)
                dict_text = re.sub(r'(\w+):', r'"\1":', dict_text)  # Add quotes to keys
                dict_text = re.sub(r'\'', r'"', dict_text)  # Standardize quotes
                return json.loads(dict_text)
        except (json.JSONDecodeError, AttributeError):
            pass
    
    return None
