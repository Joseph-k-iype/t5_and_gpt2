#!/usr/bin/env python3
"""
Advanced Multi-Agent Legal Document Rule Extraction System using LangGraph
Mixture of Experts with Chain of Thought for JSON Rules Engine Compatibility
Accurate rule extraction with proper definitions, conditions, and references
ERROR-FREE VERSION with comprehensive rule interpretation
"""

import os
import json
import logging
import asyncio
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Literal, TypedDict
from datetime import datetime
import re
import uuid
import math
from dataclasses import dataclass

# Core libraries
import pandas as pd
import PyPDF2
from pydantic import BaseModel, Field, ValidationError, model_validator
from pydantic_core import from_json

# LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI

# OpenAI for embeddings (if needed)
import openai

# Global Configuration
API_KEY = os.getenv("OPENAI_API_KEY", "your-openai-api-key-here")
BASE_URL = "https://api.openai.com/v1"
MODEL_NAME = "gpt-4o-mini"  
EMBEDDING_MODEL = "text-embedding-3-large"
CHUNK_SIZE = 8000  
OVERLAP_SIZE = 1000  
MAX_CHUNKS = 50  

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Enhanced Pydantic v2 Models for JSON Rules Engine Compatibility
class RuleCondition(BaseModel):
    """JSON Rules Engine compatible condition structure"""
    condition_id: str = Field(..., description="Unique condition identifier")
    condition_definition: str = Field(..., description="Human readable condition description")
    fact: str = Field(..., description="The data property to evaluate (e.g., 'user.role', 'data.category', 'request.type')")
    operator: str = Field(..., description="JSON rules engine operator (equal, notEqual, in, notIn, greaterThan, lessThan, contains)")
    value: Union[str, int, float, bool, List[Any]] = Field(..., description="Value to compare against")
    role: str = Field(..., description="Stakeholder role (data_controller, data_processor, joint_controller, data_subject, dpo, supervisory_authority, third_party)")
    if_condition: Optional[str] = Field(None, description="IF part of the condition logic")
    else_condition: Optional[str] = Field(None, description="ELSE part of the condition logic")

class ExtractedRule(BaseModel):
    """JSON Rules Engine compatible rule structure"""
    rule_id: str = Field(..., description="Unique rule identifier")
    rule_definition: str = Field(..., description="Specific, detailed rule definition extracted from document")
    rule_type: str = Field(..., description="Type of rule (access_right, processing_obligation, consent_requirement, data_transfer, etc.)")
    applicable_countries: List[str] = Field(..., description="ISO country codes where rule applies")
    adequacy_countries: List[str] = Field(default_factory=list, description="Countries with adequacy decisions")
    conditions: List[RuleCondition] = Field(..., description="List of rule conditions with if-else logic")
    aggregated_roles: List[str] = Field(default_factory=list, description="All stakeholder roles involved")
    data_category: str = Field(..., description="Specific data category (personal_data, special_category, pseudonymised, anonymised, etc.)")
    domain: str = Field(..., description="Legal domain (gdpr_compliance, data_subject_rights, cross_border_transfers, etc.)")
    action: str = Field(..., description="Specific required action extracted from document")
    consequence: str = Field(default="", description="Consequence if rule is violated")
    timeframe: str = Field(default="", description="Timeframe for compliance (if specified)")
    reference: str = Field(..., description="Exact article, section, and paragraph reference")
    priority: str = Field(default="medium", description="Rule priority (high, medium, low)")
    
    # JSON Rules Engine compatibility
    event_type: str = Field(default="rule_evaluation", description="Event that triggers rule evaluation")
    params: Dict[str, Any] = Field(default_factory=dict, description="Additional parameters for rule engine")

class MetadataConfig(BaseModel):
    """Configuration model"""
    pdf_path: str = Field(..., description="Path to PDF file")
    applicable_countries: List[str] = Field(..., description="ISO country codes where rules apply")
    document_type: str = Field(default="regulation", description="Type of document")

# Document Chunk Management
@dataclass
class DocumentChunk:
    """Document chunk with metadata"""
    content: str
    chunk_id: str
    start_page: int
    end_page: int
    section_type: str
    overlap_content: str = ""

# Multi-Agent State Management
class MultiAgentState(TypedDict):
    """Enhanced shared state between all agents"""
    # Input data
    document_text: str
    document_chunks: List[Dict[str, Any]]
    metadata_config: dict
    geography_data: dict
    
    # Expert analysis results
    legal_obligations: dict  # Expert 1 results
    regulatory_requirements: dict  # Expert 2 results  
    compliance_conditions: dict  # Expert 3 results
    stakeholder_roles: dict  # Expert 4 results
    
    # Processing stages
    parsed_sections: dict
    knowledge_graph: dict
    identified_countries: dict
    extracted_rules: list
    validated_rules: list
    
    # Agent reasoning traces
    agent1_reasoning: list
    agent1_knowledge_graph: dict
    agent2_reasoning: list  
    agent2_knowledge_graph: dict
    agent3_reasoning: list
    agent3_knowledge_graph: dict
    agent4_reasoning: list
    agent4_knowledge_graph: dict
    
    # Processing control
    current_agent: str
    processing_complete: bool
    chunks_processed: int
    total_chunks: int

# Safe utility functions (same as before)
def safe_get(obj: Any, key: str, default: Any = None) -> Any:
    """Safely get attribute from object"""
    try:
        if isinstance(obj, dict):
            return obj.get(key, default)
        elif hasattr(obj, key):
            return getattr(obj, key, default)
        else:
            return default
    except:
        return default

def safe_json_parse(json_str: str) -> Any:
    """Safely parse JSON string"""
    try:
        return json.loads(json_str)
    except Exception as e:
        logger.debug(f"JSON parsing failed: {e}")
        return None

def ensure_dict(obj: Any) -> Dict[str, Any]:
    """Ensure object is a dictionary"""
    if isinstance(obj, dict):
        return obj
    elif obj is None:
        return {}
    else:
        try:
            return {"value": str(obj)}
        except:
            return {}

def ensure_list(obj: Any) -> List[Any]:
    """Ensure object is a list"""
    if isinstance(obj, list):
        return obj
    elif obj is None:
        return []
    else:
        return [obj]

# Enhanced Geography Handler (same as before with fixes)
class GeographyHandler:
    """Enhanced geography handler with better country verification"""
    
    def __init__(self, geography_file: str):
        self.geography_data = self._load_geography_data(geography_file)
        self.all_countries = self._extract_all_countries()
        self.country_variations = self._build_country_variations()
        logger.info(f"ðŸŒ Geography data loaded: {len(self.all_countries)} countries")
    
    def _load_geography_data(self, file_path: str) -> Dict[str, Any]:
        """Load geography data from JSON file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load geography data: {e}")
            return {}
    
    def _extract_all_countries(self) -> Dict[str, str]:
        """Extract all countries from geography.json"""
        countries = {}
        
        try:
            for region_key, region_data in self.geography_data.items():
                if isinstance(region_data, dict):
                    if 'countries' in region_data:
                        for country in ensure_list(region_data['countries']):
                            if isinstance(country, dict):
                                iso2 = safe_get(country, 'iso2', '')
                                name = safe_get(country, 'name', '')
                                if iso2 and name:
                                    countries[iso2] = name
                    
                    if region_key == 'By_Continent':
                        for continent, continent_data in region_data.items():
                            continent_dict = ensure_dict(continent_data)
                            if 'countries' in continent_dict:
                                for country in ensure_list(continent_dict['countries']):
                                    if isinstance(country, dict):
                                        iso2 = safe_get(country, 'iso2', '')
                                        name = safe_get(country, 'name', '')
                                        if iso2 and name:
                                            countries[iso2] = name
        except Exception as e:
            logger.error(f"Error extracting countries: {e}")
        
        return countries
    
    def _build_country_variations(self) -> Dict[str, str]:
        """Build country name variations for better matching"""
        variations = {}
        try:
            for iso, name in self.all_countries.items():
                if isinstance(name, str) and isinstance(iso, str):
                    variations[name.lower()] = iso.upper()
                    variations[iso.lower()] = iso.upper()
                    if "," in name:
                        short_name = name.split(",")[0].strip()
                        variations[short_name.lower()] = iso.upper()
        except Exception as e:
            logger.error(f"Error building country variations: {e}")
        return variations
    
    def is_valid_country(self, iso_code: str) -> bool:
        """Check if ISO code is valid country"""
        try:
            return str(iso_code).upper() in self.all_countries if iso_code else False
        except:
            return False
    
    def find_countries_in_text(self, text: str) -> List[str]:
        """Enhanced country finding with better matching"""
        found_countries = set()
        try:
            if not text:
                return []
            
            text_lower = str(text).lower()
            
            for variation, iso in self.country_variations.items():
                if len(variation) > 2:
                    if re.search(r'\b' + re.escape(variation) + r'\b', text_lower):
                        found_countries.add(iso)
        except Exception as e:
            logger.error(f"Error finding countries in text: {e}")
        
        return list(found_countries)

# Enhanced PDF Processing (same as before)
class PDFProcessor:
    """Enhanced PDF processor with complete content extraction"""
    
    @staticmethod
    def extract_complete_text_from_pdf(pdf_path: str) -> Dict[str, Any]:
        """Extract complete text from PDF with page metadata"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                complete_text = ""
                page_contents = []
                
                for page_num, page in enumerate(pdf_reader.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            page_contents.append({
                                'page_number': page_num + 1,
                                'content': str(page_text),
                                'length': len(str(page_text))
                            })
                            complete_text += f"\n[PAGE {page_num + 1}]\n{page_text}\n"
                    except Exception as e:
                        logger.warning(f"Failed to extract page {page_num + 1}: {e}")
                        continue
                
                return {
                    'complete_text': complete_text,
                    'page_contents': page_contents,
                    'total_pages': len(pdf_reader.pages),
                    'total_length': len(complete_text)
                }
        except Exception as e:
            logger.error(f"Failed to extract text from PDF {pdf_path}: {e}")
            return {'complete_text': "", 'page_contents': [], 'total_pages': 0, 'total_length': 0}
    
    @staticmethod
    def create_overlapping_chunks(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = OVERLAP_SIZE) -> List[DocumentChunk]:
        """Create overlapping chunks from text for complete coverage"""
        chunks = []
        
        try:
            if not text:
                return chunks
            
            text = str(text)
            text_length = len(text)
            
            if text_length <= chunk_size:
                chunks.append(DocumentChunk(
                    content=text,
                    chunk_id="chunk_1",
                    start_page=1,
                    end_page=1,
                    section_type="complete_document"
                ))
                return chunks
            
            start = 0
            chunk_num = 1
            
            while start < text_length and chunk_num <= MAX_CHUNKS:
                end = min(start + chunk_size, text_length)
                chunk_content = text[start:end]
                
                overlap_content = ""
                if end < text_length:
                    overlap_end = min(end + overlap, text_length)
                    overlap_content = text[end:overlap_end]
                
                try:
                    page_matches = re.findall(r'\[PAGE (\d+)\]', text[:start])
                    start_page = int(page_matches[-1]) if page_matches else 1
                    
                    page_matches_end = re.findall(r'\[PAGE (\d+)\]', text[:end])
                    end_page = int(page_matches_end[-1]) if page_matches_end else start_page
                except:
                    start_page, end_page = 1, 1
                
                chunk = DocumentChunk(
                    content=chunk_content,
                    chunk_id=f"chunk_{chunk_num}",
                    start_page=start_page,
                    end_page=end_page,
                    section_type="document_section",
                    overlap_content=overlap_content
                )
                
                chunks.append(chunk)
                start += chunk_size - overlap
                chunk_num += 1
            
            logger.info(f"ðŸ“„ Created {len(chunks)} overlapping chunks from {text_length} characters")
        except Exception as e:
            logger.error(f"Error creating chunks: {e}")
        
        return chunks

# MIXTURE OF EXPERTS AGENT 1: Legal Document Structure Expert
class LegalDocumentExpert:
    """Expert 1: Legal document structure and section analysis"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.name = "LegalDocumentExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Extract precise document structure and legal obligations"""
        
        logger.info(f"ðŸŽ“ {self.name}: Analyzing legal document structure")
        
        try:
            pdf_processor = PDFProcessor()
            chunks = pdf_processor.create_overlapping_chunks(state['document_text'])
            
            system_prompt = """You are a Legal Document Structure Expert specializing in regulatory document analysis.

EXPERTISE: Document structure, legal obligations, regulatory requirements, compliance mandates

MISSION: Extract PRECISE legal obligations, requirements, and mandates with SPECIFIC details.

CHAIN OF THOUGHT ANALYSIS:
1. IDENTIFY: Legal obligation patterns (must, shall, required, obligated, prohibited)
2. EXTRACT: Specific requirements with exact wording from document
3. CLASSIFY: Type of obligation (access right, processing requirement, consent, transfer, etc.)
4. REFERENCE: Exact article, section, paragraph numbers
5. TIMEFRAME: Any specific timeframes or deadlines mentioned
6. CONSEQUENCE: Penalties or consequences for non-compliance

CRITICAL INSTRUCTIONS:
- Extract ACTUAL text from document, not generic summaries
- Identify SPECIFIC legal requirements, not general compliance
- Include EXACT article/section references
- Capture PRECISE obligations with their conditions
- Note any TIMEFRAMES or deadlines
- Identify different TYPES of rules (access, processing, consent, transfer)

OUTPUT FORMAT: Structured analysis with exact quotes and references."""

            all_obligations = {}
            reasoning_trace = []
            knowledge_graph = {"entities": [], "relationships": [], "obligations": {}}
            
            for i, chunk in enumerate(chunks):
                if chunk and hasattr(chunk, 'content'):
                    logger.info(f"ðŸ“š Expert analyzing chunk {i+1}/{len(chunks)}")
                    
                    user_prompt = f"""LEGAL DOCUMENT STRUCTURE ANALYSIS - Chunk {i+1}/{len(chunks)}:

DOCUMENT CONTENT:
{chunk.content}

EXPERT ANALYSIS REQUIRED:
1. LEGAL OBLIGATIONS: Extract specific "must", "shall", "required" statements with exact text
2. REGULATORY REQUIREMENTS: Identify compliance requirements with conditions
3. RULE TYPES: Classify each requirement (data_subject_rights, controller_obligations, processor_requirements, consent_management, data_transfers, etc.)
4. REFERENCES: Extract exact article/section numbers and titles
5. TIMEFRAMES: Note any deadlines, timeframes, or temporal requirements
6. STAKEHOLDERS: Identify who has obligations (controller, processor, data subject, etc.)

CHAIN OF THOUGHT:
Step 1: Scan for legal obligation keywords (must, shall, required, obligated, entitled, prohibited)
Step 2: Extract exact text of each obligation with surrounding context
Step 3: Identify the subject (who) and object (what) of each obligation
Step 4: Classify the type of requirement
Step 5: Extract precise reference (article, section, paragraph)
Step 6: Note any conditions or exceptions

Return structured analysis with exact quotes from document."""

                    messages = [
                        SystemMessage(content=system_prompt),
                        HumanMessage(content=user_prompt)
                    ]
                    
                    try:
                        response = self.llm.invoke(messages)
                        response_text = str(response.content) if response and response.content else ""
                        
                        chunk_reasoning = self._extract_reasoning_trace(response_text)
                        reasoning_trace.extend(chunk_reasoning)
                        
                        chunk_obligations = self._extract_legal_obligations(response_text, chunk.content)
                        
                        # Merge obligations
                        for obligation_type, obligations in chunk_obligations.items():
                            if obligation_type in all_obligations:
                                all_obligations[obligation_type].extend(obligations)
                            else:
                                all_obligations[obligation_type] = obligations
                        
                        chunk_kg = self._extract_knowledge_graph(response_text)
                        self._merge_knowledge_graphs(knowledge_graph, chunk_kg)
                        
                    except Exception as e:
                        logger.error(f"âŒ Expert chunk {i+1} failed: {e}")
                        reasoning_trace.append(f"ERROR Chunk {i+1}: {str(e)}")
            
            # Update state
            state['legal_obligations'] = all_obligations
            state['parsed_sections'] = self._create_structured_sections(all_obligations)
            state['agent1_reasoning'] = reasoning_trace
            state['agent1_knowledge_graph'] = knowledge_graph
            state['chunks_processed'] = len(chunks)
            state['total_chunks'] = len(chunks)
            state['current_agent'] = 'GeographyAgent'
            
            logger.info(f"âœ… {self.name}: Extracted {len(all_obligations)} obligation types")
            
        except Exception as e:
            logger.error(f"âŒ {self.name}: Processing failed: {e}")
            state['legal_obligations'] = {}
            state['agent1_reasoning'] = [f"ERROR: {str(e)}"]
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace"""
        trace = []
        try:
            if response_text:
                # Look for chain of thought patterns
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'ANALYSIS:\s*(.*?)(?=CONCLUSION:|$)',
                    r'FINDINGS:\s*(.*?)(?=RECOMMENDATIONS:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_legal_obligations(self, response_text: str, original_content: str) -> Dict[str, List]:
        """Extract specific legal obligations from expert analysis"""
        obligations = {
            "data_subject_rights": [],
            "controller_obligations": [],
            "processor_requirements": [],
            "consent_management": [],
            "data_transfers": [],
            "compliance_requirements": [],
            "penalties": []
        }
        
        try:
            # Enhanced patterns to extract specific legal obligations
            obligation_patterns = {
                "data_subject_rights": [
                    r'(data subject[^.]*?(?:right|entitled)[^.]*?\w)',
                    r'(individual[^.]*?(?:request|access|rectification|erasure)[^.]*?\w)',
                    r'(person[^.]*?(?:right to|may request)[^.]*?\w)'
                ],
                "controller_obligations": [
                    r'(controller[^.]*?(?:must|shall|required)[^.]*?\w)',
                    r'(data controller[^.]*?(?:obligation|duty)[^.]*?\w)'
                ],
                "processor_requirements": [
                    r'(processor[^.]*?(?:must|shall|required)[^.]*?\w)',
                    r'(data processor[^.]*?(?:obligation|duty)[^.]*?\w)'
                ],
                "consent_management": [
                    r'(consent[^.]*?(?:must|shall|required|obtained)[^.]*?\w)',
                    r'(consent[^.]*?(?:withdrawal|revocation)[^.]*?\w)'
                ],
                "data_transfers": [
                    r'(transfer[^.]*?(?:personal data|data)[^.]*?(?:third country|outside)[^.]*?\w)',
                    r'(adequacy[^.]*?(?:decision|assessment)[^.]*?\w)'
                ]
            }
            
            # Search both response and original content
            search_texts = [response_text, original_content]
            
            for text in search_texts:
                if not text:
                    continue
                
                text = str(text)
                for obligation_type, patterns in obligation_patterns.items():
                    for pattern in patterns:
                        matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
                        for match in matches:
                            if isinstance(match, str) and len(match) > 20:
                                obligations[obligation_type].append({
                                    "text": match.strip(),
                                    "source": "expert_analysis" if text == response_text else "original_document"
                                })
            
            # Extract specific requirements with must/shall patterns
            must_shall_pattern = r'([^.]*?(?:must|shall|required|obligated)[^.]*?\.)'
            must_shall_matches = re.findall(must_shall_pattern, original_content, re.IGNORECASE)
            
            for match in must_shall_matches:
                if len(match) > 30:  # Substantial requirement
                    # Classify the requirement
                    match_lower = match.lower()
                    if any(keyword in match_lower for keyword in ['data subject', 'individual', 'person', 'right']):
                        obligations["data_subject_rights"].append({"text": match.strip(), "source": "pattern_match"})
                    elif any(keyword in match_lower for keyword in ['controller', 'data controller']):
                        obligations["controller_obligations"].append({"text": match.strip(), "source": "pattern_match"})
                    elif any(keyword in match_lower for keyword in ['processor', 'data processor']):
                        obligations["processor_requirements"].append({"text": match.strip(), "source": "pattern_match"})
                    elif any(keyword in match_lower for keyword in ['consent']):
                        obligations["consent_management"].append({"text": match.strip(), "source": "pattern_match"})
                    elif any(keyword in match_lower for keyword in ['transfer', 'third country']):
                        obligations["data_transfers"].append({"text": match.strip(), "source": "pattern_match"})
                    else:
                        obligations["compliance_requirements"].append({"text": match.strip(), "source": "pattern_match"})
        
        except Exception as e:
            logger.error(f"Error extracting legal obligations: {e}")
        
        return obligations
    
    def _extract_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract knowledge graph from expert analysis"""
        kg = {"entities": [], "relationships": [], "obligations": []}
        
        try:
            if response_text:
                # Extract legal entities
                entity_patterns = [
                    r'(?:Article|Section|Paragraph)\s+(\d+(?:\.\d+)*)',
                    r'(data controller|controller)',
                    r'(data processor|processor)',
                    r'(data subject)',
                    r'(personal data)',
                    r'(consent)',
                    r'(adequacy decision)'
                ]
                
                for pattern in entity_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if isinstance(match, str) and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting knowledge graph: {e}")
        
        return kg
    
    def _merge_knowledge_graphs(self, main_kg: Dict, chunk_kg: Dict):
        """Merge knowledge graphs safely"""
        try:
            chunk_kg = ensure_dict(chunk_kg)
            
            # Merge entities
            chunk_entities = ensure_list(chunk_kg.get("entities", []))
            for entity in chunk_entities:
                entity_str = str(entity) if entity else ""
                if entity_str and entity_str not in main_kg["entities"]:
                    main_kg["entities"].append(entity_str)
        
        except Exception as e:
            logger.debug(f"Error merging knowledge graphs: {e}")
    
    def _create_structured_sections(self, obligations: Dict) -> Dict[str, str]:
        """Create structured sections from obligations"""
        sections = {}
        
        try:
            for obligation_type, obligation_list in obligations.items():
                if obligation_list:
                    section_content = f"## {obligation_type.replace('_', ' ').title()}\n\n"
                    for i, obligation in enumerate(obligation_list[:5], 1):  # Limit to top 5
                        if isinstance(obligation, dict):
                            text = obligation.get("text", "")
                            source = obligation.get("source", "")
                            section_content += f"{i}. {text} (Source: {source})\n\n"
                        else:
                            section_content += f"{i}. {str(obligation)}\n\n"
                    sections[f"Level-1-{obligation_type}"] = section_content
        
        except Exception as e:
            logger.error(f"Error creating structured sections: {e}")
        
        return sections

# MIXTURE OF EXPERTS AGENT 2: Geography and Jurisdiction Expert  
class GeographyJurisdictionExpert:
    """Expert 2: Geography, jurisdiction, and adequacy analysis"""
    
    def __init__(self, llm: ChatOpenAI, geography_handler: GeographyHandler):
        self.llm = llm
        self.geography_handler = geography_handler
        self.name = "GeographyJurisdictionExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Expert analysis of jurisdictions and country-specific requirements"""
        
        logger.info(f"ðŸŒ {self.name}: Analyzing jurisdictions and adequacy")
        
        try:
            system_prompt = f"""You are a Geography and Jurisdiction Expert specializing in international data protection law.

EXPERTISE: Cross-border data transfers, adequacy decisions, jurisdictional requirements

AVAILABLE GEOGRAPHY DATA:
{json.dumps(dict(list(self.geography_handler.all_countries.items())[:30]), indent=2)}
... (Total: {len(self.geography_handler.all_countries)} countries)

MISSION: Identify SPECIFIC countries mentioned in document with their legal context.

CHAIN OF THOUGHT ANALYSIS:
1. SCAN: Look for country names, ISO codes, regional references (EU, EEA, etc.)
2. ADEQUACY CONTEXT: Find "adequacy decision", "adequate protection", "safe harbor"
3. TRANSFER REQUIREMENTS: Identify cross-border transfer conditions
4. JURISDICTION MAPPING: Map legal requirements to specific countries
5. REGIONAL ANALYSIS: Convert regional references (EU, EEA) to specific countries
6. VERIFICATION: Verify all countries against geography database

CRITICAL INSTRUCTIONS:
- Find ALL country mentions with their legal context
- Identify adequacy countries with SPECIFIC context
- Map regional references to actual countries
- Extract transfer requirements and restrictions
- Verify ALL countries against provided geography data
- NO generic answers - find ACTUAL countries from document"""

            # Combine all legal obligations for analysis
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            all_content = ""
            for obligation_type, obligations in legal_obligations.items():
                for obligation in ensure_list(obligations):
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        all_content += f"\n{text}\n"
                    else:
                        all_content += f"\n{str(obligation)}\n"
            
            if not all_content.strip():
                all_content = str(state.get('document_text', ''))[:8000]
            
            user_prompt = f"""GEOGRAPHY AND JURISDICTION ANALYSIS:

DOCUMENT CONTENT FOR ANALYSIS:
{all_content[:8000]}

CONFIGURATION DATA:
- Applicable Countries (from config): {state['metadata_config'].get('applicable_countries', [])}

EXPERT ANALYSIS REQUIRED:
1. COUNTRY IDENTIFICATION: Find ALL specific country mentions with context
2. ADEQUACY ANALYSIS: Identify countries with "adequacy decision" or "adequate protection" 
3. TRANSFER RULES: Extract cross-border transfer requirements
4. REGIONAL MAPPING: Convert EU/EEA references to specific country lists
5. JURISDICTION VERIFICATION: Verify all countries against geography database

CHAIN OF THOUGHT:
Step 1: Scan entire document for country names, ISO codes, regional terms
Step 2: Find adequacy contexts: "Country X has adequacy decision", "adequate protection in Y"
Step 3: Extract transfer restrictions and requirements
Step 4: Map regions (EU = 27 countries, EEA = EU + Iceland, Liechtenstein, Norway)
Step 5: Verify all identified countries exist in geography database
Step 6: Categorize by legal context (adequacy, restriction, requirement)

Return detailed country analysis with specific legal contexts and exact quotes from document."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse expert analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_geography_knowledge_graph(response_text)
            country_results = self._extract_and_verify_countries(response_text, all_content)
            
            # Update state
            state['identified_countries'] = country_results
            state['agent2_reasoning'] = reasoning_trace
            state['agent2_knowledge_graph'] = knowledge_graph
            state['current_agent'] = 'RuleExtractionAgent'
            
            mentioned_count = len(country_results.get('mentioned_countries', []))
            adequacy_count = len(country_results.get('adequacy_countries', []))
            
            logger.info(f"âœ… {self.name}: Identified {mentioned_count} countries, {adequacy_count} with adequacy")
            
        except Exception as e:
            logger.error(f"âŒ {self.name}: Processing failed: {e}")
            state['agent2_reasoning'] = [f"ERROR: {str(e)}"]
            state['identified_countries'] = {
                "mentioned_countries": [],
                "adequacy_countries": [],
                "transfer_restrictions": [],
                "verification_status": "failed"
            }
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace from geography expert"""
        trace = []
        try:
            if response_text:
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'COUNTRY ANALYSIS:\s*(.*?)(?=ADEQUACY ANALYSIS:|$)',
                    r'ADEQUACY ANALYSIS:\s*(.*?)(?=VERIFICATION:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_geography_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract geography knowledge graph"""
        kg = {"entities": [], "relationships": [], "adequacy_mapping": {}}
        
        try:
            if response_text:
                # Extract geography entities
                geo_patterns = [
                    r'([A-Z]{2})\s*-\s*([^,\n]+)',  # ISO-Country pairs
                    r'adequacy[^.]*?([A-Z]{2}|[A-Z][a-z]+)',  # Adequacy contexts
                    r'transfer[^.]*?([A-Z]{2}|[A-Z][a-z]+)'   # Transfer contexts
                ]
                
                for pattern in geo_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if isinstance(match, tuple):
                            kg["entities"].extend([str(m) for m in match if m])
                        elif match:
                            kg["entities"].append(str(match))
        
        except Exception as e:
            logger.debug(f"Error extracting geography knowledge graph: {e}")
        
        return kg
    
    def _extract_and_verify_countries(self, response_text: str, document_text: str) -> Dict[str, Any]:
        """Extract and verify countries with expert analysis"""
        try:
            # Enhanced country extraction with context
            mentioned_countries = self.geography_handler.find_countries_in_text(document_text)
            adequacy_countries = []
            transfer_restrictions = []
            
            # Enhanced adequacy detection patterns
            adequacy_patterns = [
                r'adequacy decision[^.]*?([A-Z]{2})',
                r'adequate protection[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?adequacy decision',
                r'([A-Z]{2})[^.]*?adequate protection',
                r'adequate level of protection[^.]*?([A-Z]{2})',
                r'Commission decision[^.]*?adequacy[^.]*?([A-Z]{2})'
            ]
            
            all_text = f"{response_text} {document_text}"
            
            for pattern in adequacy_patterns:
                try:
                    matches = re.findall(pattern, all_text, re.IGNORECASE)
                    for match in matches:
                        if match and self.geography_handler.is_valid_country(str(match)):
                            adequacy_countries.append(str(match).upper())
                except Exception as e:
                    logger.debug(f"Error in adequacy pattern: {e}")
                    continue
            
            # Extract transfer restrictions
            restriction_patterns = [
                r'transfer[^.]*?prohibited[^.]*?([A-Z]{2})',
                r'([A-Z]{2})[^.]*?restricted[^.]*?transfer',
                r'no transfer[^.]*?([A-Z]{2})'
            ]
            
            for pattern in restriction_patterns:
                try:
                    matches = re.findall(pattern, all_text, re.IGNORECASE)
                    for match in matches:
                        if match and self.geography_handler.is_valid_country(str(match)):
                            transfer_restrictions.append(str(match).upper())
                except Exception as e:
                    logger.debug(f"Error in restriction pattern: {e}")
                    continue
            
            # Also check country names in adequacy contexts
            for iso in mentioned_countries:
                try:
                    country_name = self.geography_handler.get_country_name(iso)
                    if country_name:
                        name_lower = str(country_name).lower()
                        adequacy_context_patterns = [
                            rf'{re.escape(name_lower)}[^.]*?adequacy',
                            rf'adequacy[^.]*?{re.escape(name_lower)}',
                            rf'{re.escape(name_lower)}[^.]*?adequate protection'
                        ]
                        
                        text_lower = all_text.lower()
                        for pattern in adequacy_context_patterns:
                            if re.search(pattern, text_lower):
                                adequacy_countries.append(iso)
                                break
                except Exception as e:
                    logger.debug(f"Error checking adequacy context: {e}")
                    continue
            
            return {
                "mentioned_countries": list(set(mentioned_countries)),
                "adequacy_countries": list(set(adequacy_countries)),
                "transfer_restrictions": list(set(transfer_restrictions)),
                "verification_status": "verified against geography data"
            }
        
        except Exception as e:
            logger.error(f"Error extracting countries: {e}")
            return {
                "mentioned_countries": [],
                "adequacy_countries": [],
                "transfer_restrictions": [],
                "verification_status": "error"
            }

# MIXTURE OF EXPERTS AGENT 3: Rule Engine Expert
class RuleEngineExpert:
    """Expert 3: JSON Rules Engine compatible rule extraction"""
    
    def __init__(self, llm: ChatOpenAI):
        self.llm = llm
        self.name = "RuleEngineExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Extract rules in JSON Rules Engine compatible format"""
        
        logger.info(f"âš–ï¸ {self.name}: Extracting JSON Rules Engine compatible rules")
        
        try:
            system_prompt = """You are a Rule Engine Expert specializing in converting legal requirements to machine-readable rules.

EXPERTISE: JSON Rules Engine format, if-else logic, machine-readable conditions

MISSION: Convert legal obligations to JSON Rules Engine compatible rules with precise conditions.

JSON RULES ENGINE FORMAT REQUIRED:
{
  "rule_id": "specific_rule_identifier",
  "rule_definition": "EXACT legal requirement from document (not generic)",
  "rule_type": "access_right|processing_obligation|consent_requirement|data_transfer|breach_notification|etc",
  "conditions": [
    {
      "condition_id": "specific_condition_id",
      "condition_definition": "Human readable condition",
      "fact": "user.role|data.category|request.type|processing.purpose|etc",
      "operator": "equal|notEqual|in|notIn|greaterThan|lessThan|contains",
      "value": "specific_value_or_list",
      "role": "data_controller|data_processor|joint_controller|data_subject|dpo|supervisory_authority|third_party",
      "if_condition": "IF this condition is true",
      "else_condition": "ELSE alternative condition"
    }
  ],
  "action": "SPECIFIC action from document (not generic)",
  "consequence": "Penalty or outcome if rule violated",
  "timeframe": "Specific timeframe (24 hours, 1 month, etc.)",
  "reference": "EXACT Article X.Y or Section Z reference",
  "priority": "high|medium|low"
}

CHAIN OF THOUGHT PROCESS:
1. ANALYZE: Each legal obligation for specific requirements
2. EXTRACT: Precise rule definition (not generic)
3. IDENTIFY: Specific conditions with if-else logic
4. CLASSIFY: Rule type and stakeholder roles
5. MAP: Conditions to JSON Rules Engine operators
6. DEFINE: Specific actions and consequences
7. REFERENCE: Exact legal citations

CRITICAL INSTRUCTIONS:
- Extract ACTUAL rule text, not "Legal compliance requirement"
- Use SPECIFIC actions, not "Must ensure compliance"
- Include EXACT references, not "Document reference"
- Create IF-ELSE condition logic
- Use proper JSON Rules Engine operators
- Include ALL stakeholder roles (controller, processor, DPO, supervisory authority, etc.)
- Set appropriate rule priorities based on penalties/importance"""

            # Get legal obligations for rule extraction
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            country_info = ensure_dict(state.get('identified_countries', {}))
            
            obligations_text = ""
            for obligation_type, obligations in legal_obligations.items():
                obligations_text += f"\n## {obligation_type.upper()}\n"
                for obligation in ensure_list(obligations)[:3]:  # Top 3 per type
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        obligations_text += f"- {text}\n"
                    else:
                        obligations_text += f"- {str(obligation)}\n"
            
            user_prompt = f"""RULE ENGINE CONVERSION TASK:

LEGAL OBLIGATIONS TO CONVERT:
{obligations_text[:10000]}

JURISDICTION CONTEXT:
- Applicable Countries: {state['metadata_config'].get('applicable_countries', [])}
- Adequacy Countries: {country_info.get('adequacy_countries', [])}

EXPERT ANALYSIS REQUIRED:
Convert each legal obligation to JSON Rules Engine format with:

1. SPECIFIC RULE DEFINITIONS (exact text from document)
2. PRECISE CONDITIONS with if-else logic
3. PROPER JSON Rules Engine operators
4. STAKEHOLDER ROLES (data_controller, data_processor, joint_controller, data_subject, dpo, supervisory_authority, third_party)
5. EXACT ACTIONS (from document text)
6. SPECIFIC REFERENCES (Article numbers, sections)
7. TIMEFRAMES and CONSEQUENCES

CHAIN OF THOUGHT:
Step 1: For each obligation, extract the exact requirement text
Step 2: Identify WHO has the obligation (role)
Step 3: Determine WHEN it applies (conditions with if-else)
Step 4: Define WHAT must be done (specific action)
Step 5: Extract LEGAL REFERENCE (article/section)
Step 6: Note TIMEFRAME and CONSEQUENCES
Step 7: Convert to JSON Rules Engine format

EXAMPLE OUTPUT FORMAT:
[
  {
    "rule_id": "gdpr_art_15_access_request",
    "rule_definition": "The data subject shall have the right to obtain from the controller confirmation as to whether or not personal data concerning him or her are being processed",
    "rule_type": "access_right",
    "conditions": [
      {
        "condition_id": "access_request_received",
        "condition_definition": "When data subject submits access request",
        "fact": "request.type",
        "operator": "equal",
        "value": "subject_access_request",
        "role": "data_subject",
        "if_condition": "IF request is valid access request",
        "else_condition": "ELSE reject invalid request"
      }
    ],
    "action": "Provide confirmation and copy of personal data being processed",
    "timeframe": "within one month",
    "reference": "GDPR Article 15(1)",
    "priority": "high"
  }
]

Return JSON array of properly formatted rules."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse expert analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_rule_knowledge_graph(response_text)
            extracted_rules = self._extract_json_rules(response_text, state)
            
            # Update state
            state['extracted_rules'] = extracted_rules
            state['agent3_reasoning'] = reasoning_trace
            state['agent3_knowledge_graph'] = knowledge_graph
            state['current_agent'] = 'ValidationAgent'
            
            logger.info(f"âœ… {self.name}: Extracted {len(extracted_rules)} JSON Rules Engine compatible rules")
            
        except Exception as e:
            logger.error(f"âŒ {self.name}: Processing failed: {e}")
            state['agent3_reasoning'] = [f"ERROR: {str(e)}"]
            state['extracted_rules'] = []
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract reasoning trace from rule engine expert"""
        trace = []
        try:
            if response_text:
                cot_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'ANALYSIS:\s*(.*?)(?=CONVERSION:|$)',
                    r'RULE EXTRACTION:\s*(.*?)(?=VALIDATION:|$)'
                ]
                
                for pattern in cot_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting reasoning: {e}")
        return trace
    
    def _extract_rule_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract rule knowledge graph"""
        kg = {"entities": [], "relationships": [], "rule_mappings": {}}
        
        try:
            if response_text:
                # Extract rule entities
                rule_patterns = [
                    r'rule_id[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'rule_type[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'fact[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'operator[\'"]:\s*[\'"]([^\'\"]+)[\'"]',
                    r'role[\'"]:\s*[\'"]([^\'\"]+)[\'"]'
                ]
                
                for pattern in rule_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting rule knowledge graph: {e}")
        
        return kg
    
    def _extract_json_rules(self, response_text: str, state: MultiAgentState) -> List[Dict]:
        """Extract JSON Rules Engine compatible rules"""
        rules = []
        
        try:
            # Try to extract JSON array from response
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                try:
                    rules_data = json.loads(json_match.group(0))
                    if isinstance(rules_data, list):
                        rules = rules_data
                    elif isinstance(rules_data, dict):
                        rules = [rules_data]
                except json.JSONDecodeError as e:
                    logger.warning(f"JSON parsing failed: {e}")
            
            # If no valid JSON found, create rules from legal obligations
            if not rules:
                rules = self._create_rules_from_obligations(state)
            
            # Enhance rules with proper JSON Rules Engine format
            enhanced_rules = []
            for rule in rules:
                if rule:
                    enhanced_rule = self._enhance_rule_for_json_engine(rule, state)
                    if enhanced_rule:
                        enhanced_rules.append(enhanced_rule)
            
            return enhanced_rules
        
        except Exception as e:
            logger.error(f"Error extracting JSON rules: {e}")
            return []
    
    def _create_rules_from_obligations(self, state: MultiAgentState) -> List[Dict]:
        """Create rules from legal obligations when JSON extraction fails"""
        rules = []
        
        try:
            legal_obligations = ensure_dict(state.get('legal_obligations', {}))
            country_info = ensure_dict(state.get('identified_countries', {}))
            
            rule_types = {
                "data_subject_rights": "access_right",
                "controller_obligations": "processing_obligation", 
                "processor_requirements": "processor_obligation",
                "consent_management": "consent_requirement",
                "data_transfers": "data_transfer",
                "compliance_requirements": "compliance_obligation",
                "penalties": "penalty_provision"
            }
            
            for obligation_type, obligations in legal_obligations.items():
                rule_type = rule_types.get(obligation_type, "compliance_obligation")
                
                for i, obligation in enumerate(ensure_list(obligations)[:5]):  # Max 5 per type
                    if isinstance(obligation, dict):
                        text = obligation.get("text", "")
                        source = obligation.get("source", "")
                        
                        if len(text) > 30:  # Substantial rule
                            rule = {
                                "rule_id": f"{rule_type}_{i+1}_{uuid.uuid4().hex[:8]}",
                                "rule_definition": text,
                                "rule_type": rule_type,
                                "conditions": self._create_conditions_from_text(text, obligation_type),
                                "action": self._extract_action_from_text(text),
                                "timeframe": self._extract_timeframe_from_text(text),
                                "reference": self._extract_reference_from_text(text),
                                "priority": self._determine_priority(text)
                            }
                            rules.append(rule)
                    
                    if len(rules) >= 20:  # Limit total rules
                        break
                
                if len(rules) >= 20:
                    break
        
        except Exception as e:
            logger.error(f"Error creating rules from obligations: {e}")
        
        return rules
    
    def _create_conditions_from_text(self, text: str, obligation_type: str) -> List[Dict]:
        """Create JSON Rules Engine compatible conditions"""
        conditions = []
        
        try:
            text_lower = str(text).lower()
            
            # Role mapping based on obligation type and text content
            role = "data_controller"  # Default
            if "processor" in text_lower:
                role = "data_processor"
            elif "data subject" in text_lower or "individual" in text_lower:
                role = "data_subject"
            elif "joint" in text_lower:
                role = "joint_controller"
            elif "dpo" in text_lower or "data protection officer" in text_lower:
                role = "dpo"
            elif "supervisory authority" in text_lower or "authority" in text_lower:
                role = "supervisory_authority"
            
            # Create condition based on obligation type
            if obligation_type == "data_subject_rights":
                conditions.append({
                    "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When data subject exercises their rights",
                    "fact": "request.type",
                    "operator": "in",
                    "value": ["access_request", "rectification_request", "erasure_request", "portability_request"],
                    "role": "data_subject",
                    "if_condition": "IF valid data subject request received",
                    "else_condition": "ELSE reject invalid request"
                })
            elif obligation_type == "controller_obligations":
                conditions.append({
                    "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When controller processes personal data",
                    "fact": "data.category",
                    "operator": "equal",
                    "value": "personal_data",
                    "role": "data_controller",
                    "if_condition": "IF processing personal data",
                    "else_condition": "ELSE no obligation applies"
                })
            elif obligation_type == "consent_management":
                conditions.append({
                    "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When consent is required for processing",
                    "fact": "processing.lawful_basis",
                    "operator": "equal",
                    "value": "consent",
                    "role": role,
                    "if_condition": "IF consent is lawful basis",
                    "else_condition": "ELSE use alternative lawful basis"
                })
            elif obligation_type == "data_transfers":
                conditions.append({
                    "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When transferring data to third country",
                    "fact": "transfer.destination_country",
                    "operator": "notIn",
                    "value": ["adequacy_countries"],
                    "role": role,
                    "if_condition": "IF destination lacks adequacy decision",
                    "else_condition": "ELSE transfer allowed with adequacy"
                })
            else:
                # Generic condition
                conditions.append({
                    "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When obligation applies",
                    "fact": "obligation.context",
                    "operator": "equal",
                    "value": "applicable",
                    "role": role,
                    "if_condition": "IF conditions are met",
                    "else_condition": "ELSE no action required"
                })
        
        except Exception as e:
            logger.debug(f"Error creating conditions: {e}")
            # Fallback condition
            conditions = [{
                "condition_id": f"condition_{uuid.uuid4().hex[:8]}",
                "condition_definition": "Default condition",
                "fact": "obligation.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF obligation applies",
                "else_condition": "ELSE no action required"
            }]
        
        return conditions
    
    def _extract_action_from_text(self, text: str) -> str:
        """Extract specific action from rule text"""
        try:
            text = str(text)
            
            # Look for action patterns
            action_patterns = [
                r'(?:must|shall|required to)\s+([^.]+)',
                r'(?:obligation to|duty to)\s+([^.]+)',
                r'(?:right to)\s+([^.]+)'
            ]
            
            for pattern in action_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    action = match.group(1).strip()
                    if len(action) > 10:
                        return action
            
            # Fallback: extract first significant sentence
            sentences = re.split(r'[.!?]', text)
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 20 and any(word in sentence.lower() for word in ['provide', 'ensure', 'implement', 'obtain', 'notify']):
                    return sentence
            
            return "Comply with stated requirement"
        
        except Exception as e:
            logger.debug(f"Error extracting action: {e}")
            return "Comply with stated requirement"
    
    def _extract_timeframe_from_text(self, text: str) -> str:
        """Extract timeframe from rule text"""
        try:
            text = str(text)
            
            # Common timeframe patterns
            timeframe_patterns = [
                r'within\s+(\d+\s+(?:days?|weeks?|months?|years?))',
                r'(\d+\s+(?:days?|weeks?|months?|years?))',
                r'(immediately|without delay|promptly)',
                r'(24\s+hours|72\s+hours)'
            ]
            
            for pattern in timeframe_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
            
            return ""
        
        except Exception as e:
            logger.debug(f"Error extracting timeframe: {e}")
            return ""
    
    def _extract_reference_from_text(self, text: str) -> str:
        """Extract legal reference from rule text"""
        try:
            text = str(text)
            
            # Reference patterns
            reference_patterns = [
                r'(Article\s+\d+(?:\.\d+)?(?:\(\d+\))?)',
                r'(Section\s+\d+(?:\.\d+)?)',
                r'(Paragraph\s+\d+(?:\.\d+)?)',
                r'(Chapter\s+\d+)',
                r'(Regulation\s+\d+)',
                r'(GDPR\s+Article\s+\d+)'
            ]
            
            for pattern in reference_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    return match.group(1).strip()
            
            return "Legal requirement"
        
        except Exception as e:
            logger.debug(f"Error extracting reference: {e}")
            return "Legal requirement"
    
    def _determine_priority(self, text: str) -> str:
        """Determine rule priority based on content"""
        try:
            text_lower = str(text).lower()
            
            # High priority indicators
            if any(indicator in text_lower for indicator in ['penalty', 'fine', 'sanction', 'breach', 'violation', 'criminal']):
                return "high"
            
            # Medium priority indicators  
            if any(indicator in text_lower for indicator in ['must', 'shall', 'required', 'obligation']):
                return "medium"
            
            # Low priority (recommendations, etc.)
            return "low"
        
        except Exception as e:
            logger.debug(f"Error determining priority: {e}")
            return "medium"
    
    def _enhance_rule_for_json_engine(self, rule: Dict, state: MultiAgentState) -> Dict:
        """Enhance rule for JSON Rules Engine compatibility"""
        try:
            rule_dict = ensure_dict(rule)
            country_info = ensure_dict(state.get('identified_countries', {}))
            
            # Ensure all required fields for JSON Rules Engine
            enhanced_rule = {
                "rule_id": safe_get(rule_dict, "rule_id", f"rule_{uuid.uuid4().hex[:8]}"),
                "rule_definition": safe_get(rule_dict, "rule_definition", "Legal compliance requirement"),
                "rule_type": safe_get(rule_dict, "rule_type", "compliance_obligation"),
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": ensure_list(country_info.get('adequacy_countries', [])),
                "conditions": self._validate_conditions_for_json_engine(
                    ensure_list(rule_dict.get("conditions", []))
                ),
                "aggregated_roles": [],  # Will be populated from conditions
                "data_category": safe_get(rule_dict, "data_category", "personal_data"),
                "domain": safe_get(rule_dict, "domain", "data_protection_compliance"),
                "action": safe_get(rule_dict, "action", "Comply with legal requirement"),
                "consequence": safe_get(rule_dict, "consequence", ""),
                "timeframe": safe_get(rule_dict, "timeframe", ""),
                "reference": safe_get(rule_dict, "reference", "Legal requirement"),
                "priority": safe_get(rule_dict, "priority", "medium"),
                "event_type": "rule_evaluation",
                "params": {}
            }
            
            # Aggregate roles from conditions
            roles = set()
            for condition in enhanced_rule['conditions']:
                if isinstance(condition, dict) and condition.get('role'):
                    roles.add(str(condition['role']))
            enhanced_rule["aggregated_roles"] = list(roles)
            
            return enhanced_rule
        
        except Exception as e:
            logger.error(f"Error enhancing rule: {e}")
            return {}
    
    def _validate_conditions_for_json_engine(self, conditions: List) -> List[Dict]:
        """Validate conditions for JSON Rules Engine compatibility"""
        validated_conditions = []
        
        try:
            valid_operators = ['equal', 'notEqual', 'in', 'notIn', 'greaterThan', 'lessThan', 'contains']
            valid_roles = ['data_controller', 'data_processor', 'joint_controller', 'data_subject', 'dpo', 'supervisory_authority', 'third_party']
            
            for condition in ensure_list(conditions):
                condition_dict = ensure_dict(condition)
                
                # Validate operator
                operator = safe_get(condition_dict, 'operator', 'equal')
                if operator not in valid_operators:
                    operator = 'equal'
                
                # Validate role
                role = safe_get(condition_dict, 'role', 'data_controller')
                if role not in valid_roles:
                    role = 'data_controller'
                
                validated_condition = {
                    "condition_id": safe_get(condition_dict, "condition_id", f"cond_{uuid.uuid4().hex[:8]}"),
                    "condition_definition": safe_get(condition_dict, "condition_definition", "Condition applies"),
                    "fact": safe_get(condition_dict, "fact", "obligation.applicable"),
                    "operator": operator,
                    "value": safe_get(condition_dict, "value", True),
                    "role": role,
                    "if_condition": safe_get(condition_dict, "if_condition", "IF condition is met"),
                    "else_condition": safe_get(condition_dict, "else_condition", "ELSE no action required")
                }
                validated_conditions.append(validated_condition)
            
            # Ensure at least one condition
            if not validated_conditions:
                validated_conditions.append({
                    "condition_id": f"cond_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "Default condition for rule application",
                    "fact": "rule.applicable",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF rule conditions are met",
                    "else_condition": "ELSE rule does not apply"
                })
        
        except Exception as e:
            logger.error(f"Error validating conditions: {e}")
            validated_conditions = [{
                "condition_id": f"cond_{uuid.uuid4().hex[:8]}",
                "condition_definition": "Default condition",
                "fact": "rule.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF rule applies",
                "else_condition": "ELSE no action required"
            }]
        
        return validated_conditions

# MIXTURE OF EXPERTS AGENT 4: Validation and Quality Expert
class ValidationQualityExpert:
    """Expert 4: Rule validation and quality assurance"""
    
    def __init__(self, llm: ChatOpenAI, geography_handler: GeographyHandler):
        self.llm = llm
        self.geography_handler = geography_handler
        self.name = "ValidationQualityExpert"
    
    def process(self, state: MultiAgentState) -> MultiAgentState:
        """Expert validation of extracted rules"""
        
        logger.info(f"âœ… {self.name}: Validating and ensuring rule quality")
        
        try:
            system_prompt = """You are a Validation and Quality Expert specializing in rule accuracy and completeness.

EXPERTISE: Rule validation, quality assurance, completeness checking, JSON Rules Engine compatibility

MISSION: Ensure ACCURATE, SPECIFIC, and COMPLETE rules with proper references and conditions.

VALIDATION CHECKLIST:
1. RULE DEFINITION: Must be specific legal requirement, not generic text
2. APPLICABLE COUNTRIES: Must match configuration countries
3. ADEQUACY COUNTRIES: Must be actual countries (not regions) with adequacy context
4. CONDITIONS: Must have proper if-else logic and valid JSON Rules Engine operators
5. ACTIONS: Must be specific requirements, not generic compliance statements
6. REFERENCES: Must be exact article/section numbers, not generic references
7. ROLES: Must include all relevant stakeholders
8. TIMEFRAMES: Must include specific deadlines when mentioned
9. CONSEQUENCES: Must include penalties/outcomes when specified

QUALITY STANDARDS:
- No duplicate rules (same requirement with different IDs)
- No generic fallback text ("Legal compliance requirement", "Must ensure compliance")
- No generic references ("Document reference", "Level reference")
- All countries verified against geography database
- All conditions have valid operators (equal, in, greaterThan, etc.)
- All roles are valid (data_controller, data_processor, etc.)

CHAIN OF THOUGHT VALIDATION:
1. CHECK: Each rule definition for specificity and accuracy
2. VERIFY: Country codes against geography database
3. VALIDATE: Condition logic and JSON Rules Engine compatibility  
4. CONFIRM: Action specificity and legal accuracy
5. ENSURE: Reference precision and completeness
6. DEDUPLICATE: Remove identical or substantially similar rules
7. ENHANCE: Add missing timeframes, consequences, priorities"""

            extracted_rules = ensure_list(state.get('extracted_rules', []))
            
            user_prompt = f"""RULE VALIDATION AND QUALITY ASSURANCE:

EXTRACTED RULES TO VALIDATE:
{json.dumps(extracted_rules[:3], indent=2) if extracted_rules else '[]'}
... (Total: {len(extracted_rules)} rules for validation)

CONTEXT FOR VALIDATION:
- Available Countries: {len(self.geography_handler.all_countries)} in geography database
- Applicable Countries: {state['metadata_config'].get('applicable_countries', [])}
- Adequacy Countries Found: {state.get('identified_countries', {}).get('adequacy_countries', [])}

EXPERT VALIDATION REQUIRED:
1. ACCURACY CHECK: Ensure rule definitions are specific legal requirements
2. COUNTRY VERIFICATION: Validate all countries against geography database
3. CONDITION VALIDATION: Check JSON Rules Engine operator compatibility
4. REFERENCE VERIFICATION: Ensure exact article/section citations
5. DEDUPLICATION: Remove identical or substantially similar rules
6. COMPLETENESS: Add missing timeframes, consequences, priorities
7. QUALITY ENHANCEMENT: Improve generic statements to specific requirements

VALIDATION CHAIN OF THOUGHT:
Step 1: Check each rule_definition for specificity (reject generic statements)
Step 2: Verify applicable_countries match configuration
Step 3: Validate adequacy_countries are real countries with context
Step 4: Check conditions have proper if-else logic and valid operators
Step 5: Ensure actions are specific (not "Must ensure compliance")
Step 6: Verify references are exact (not "Document reference")
Step 7: Remove duplicate rules with same essential requirement
Step 8: Enhance with missing details (timeframes, consequences)

Return validated and enhanced rules array with quality improvements."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm.invoke(messages)
            response_text = str(response.content) if response and response.content else ""
            
            # Parse validation analysis
            reasoning_trace = self._extract_reasoning_trace(response_text)
            knowledge_graph = self._extract_validation_knowledge_graph(response_text)
            validated_rules = self._comprehensive_validation(response_text, state)
            
            # Update state
            state['validated_rules'] = validated_rules
            state['agent4_reasoning'] = reasoning_trace
            state['agent4_knowledge_graph'] = knowledge_graph
            state['processing_complete'] = True
            
            logger.info(f"âœ… {self.name}: Validated {len(validated_rules)} high-quality rules")
            
        except Exception as e:
            logger.error(f"âŒ {self.name}: Validation failed: {e}")
            state['agent4_reasoning'] = [f"ERROR: {str(e)}"]
            state['validated_rules'] = []
        
        return state
    
    def _extract_reasoning_trace(self, response_text: str) -> List[str]:
        """Extract validation reasoning trace"""
        trace = []
        try:
            if response_text:
                validation_patterns = [
                    r'Step \d+:\s*(.*?)(?=Step \d+:|$)',
                    r'VALIDATION:\s*(.*?)(?=ENHANCEMENT:|$)',
                    r'QUALITY CHECK:\s*(.*?)(?=RESULT:|$)'
                ]
                
                for pattern in validation_patterns:
                    matches = re.findall(pattern, response_text, re.DOTALL | re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            trace.append(str(match).strip())
        except Exception as e:
            logger.debug(f"Error extracting validation reasoning: {e}")
        return trace
    
    def _extract_validation_knowledge_graph(self, response_text: str) -> Dict[str, List]:
        """Extract validation knowledge graph"""
        kg = {"entities": [], "relationships": [], "validation_results": {}}
        
        try:
            if response_text:
                validation_patterns = [
                    r'VALIDATED:\s*([^,\n]+)',
                    r'ENHANCED:\s*([^,\n]+)',
                    r'REJECTED:\s*([^,\n]+)',
                    r'DUPLICATE:\s*([^,\n]+)'
                ]
                
                for pattern in validation_patterns:
                    matches = re.findall(pattern, response_text, re.IGNORECASE)
                    for match in matches:
                        if match and match.strip():
                            kg["entities"].append(match.strip())
        
        except Exception as e:
            logger.debug(f"Error extracting validation knowledge graph: {e}")
        
        return kg
    
    def _comprehensive_validation(self, response_text: str, state: MultiAgentState) -> List[Dict]:
        """Comprehensive validation with quality enhancement"""
        validated_rules = []
        
        try:
            # Try to extract validated rules from expert response
            json_match = re.search(r'\[.*\]', response_text, re.DOTALL)
            if json_match:
                try:
                    expert_rules = json.loads(json_match.group(0))
                    if isinstance(expert_rules, list):
                        validated_rules = expert_rules
                except json.JSONDecodeError:
                    logger.warning("Expert validation JSON parsing failed")
            
            # If expert validation failed, apply our own validation
            if not validated_rules:
                extracted_rules = ensure_list(state.get('extracted_rules', []))
                validated_rules = self._apply_validation_rules(extracted_rules, state)
            
            # Apply final quality checks and Pydantic validation
            final_validated_rules = []
            seen_definitions = set()  # For deduplication
            
            for rule_data in validated_rules:
                if not rule_data:
                    continue
                
                try:
                    rule_dict = ensure_dict(rule_data)
                    
                    # Skip duplicates
                    rule_def = str(rule_dict.get('rule_definition', '')).strip()
                    if rule_def in seen_definitions or len(rule_def) < 20:
                        continue
                    seen_definitions.add(rule_def)
                    
                    # Apply comprehensive validation
                    validated_rule = self._apply_comprehensive_validation(rule_dict, state)
                    
                    # Validate with Pydantic
                    pydantic_rule = ExtractedRule.model_validate(validated_rule)
                    final_validated_rules.append(pydantic_rule.model_dump())
                    
                except ValidationError as e:
                    logger.warning(f"Pydantic validation failed: {e}")
                    # Try to fix and re-validate
                    fixed_rule = self._fix_validation_errors(rule_dict, state)
                    if fixed_rule:
                        try:
                            pydantic_rule = ExtractedRule.model_validate(fixed_rule)
                            final_validated_rules.append(pydantic_rule.model_dump())
                        except ValidationError:
                            logger.debug("Could not fix validation errors")
                            continue
                except Exception as e:
                    logger.error(f"Unexpected validation error: {e}")
                    continue
            
            return final_validated_rules
        
        except Exception as e:
            logger.error(f"Error in comprehensive validation: {e}")
            return []
    
    def _apply_validation_rules(self, rules: List[Dict], state: MultiAgentState) -> List[Dict]:
        """Apply validation rules when expert validation fails"""
        validated_rules = []
        
        try:
            for rule in ensure_list(rules):
                rule_dict = ensure_dict(rule)
                
                # Skip rules with generic content
                rule_def = str(rule_dict.get('rule_definition', '')).strip()
                if any(generic in rule_def.lower() for generic in [
                    'legal compliance requirement',
                    'must ensure compliance',
                    'comply with requirements'
                ]):
                    logger.debug(f"Skipping generic rule: {rule_def[:50]}...")
                    continue
                
                # Skip rules with generic references
                reference = str(rule_dict.get('reference', '')).strip()
                if any(generic in reference.lower() for generic in [
                    'document reference',
                    'level reference',
                    'document - level'
                ]):
                    logger.debug(f"Skipping rule with generic reference: {reference}")
                    continue
                
                validated_rules.append(rule_dict)
        
        except Exception as e:
            logger.error(f"Error applying validation rules: {e}")
        
        return validated_rules
    
    def _apply_comprehensive_validation(self, rule_dict: Dict, state: MultiAgentState) -> Dict:
        """Apply comprehensive validation to a single rule"""
        try:
            country_info = ensure_dict(state.get('identified_countries', {}))
            
            # Comprehensive validation and enhancement
            validated_rule = {
                "rule_id": safe_get(rule_dict, "rule_id", f"rule_{uuid.uuid4().hex[:8]}"),
                "rule_definition": safe_get(rule_dict, "rule_definition", "Specific legal requirement"),
                "rule_type": safe_get(rule_dict, "rule_type", "compliance_obligation"),
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": self._verify_adequacy_countries(
                    ensure_list(country_info.get('adequacy_countries', []))
                ),
                "conditions": self._validate_and_enhance_conditions(
                    ensure_list(rule_dict.get("conditions", []))
                ),
                "aggregated_roles": [],  # Will be populated
                "data_category": safe_get(rule_dict, "data_category", "personal_data"),
                "domain": safe_get(rule_dict, "domain", "data_protection_compliance"),
                "action": safe_get(rule_dict, "action", "Implement required measures"),
                "consequence": safe_get(rule_dict, "consequence", ""),
                "timeframe": safe_get(rule_dict, "timeframe", ""),
                "reference": safe_get(rule_dict, "reference", "Legal provision"),
                "priority": safe_get(rule_dict, "priority", "medium"),
                "event_type": "rule_evaluation",
                "params": ensure_dict(rule_dict.get("params", {}))
            }
            
            # Aggregate roles from conditions
            roles = set()
            for condition in validated_rule['conditions']:
                if isinstance(condition, dict) and condition.get('role'):
                    roles.add(str(condition['role']))
            validated_rule["aggregated_roles"] = list(roles) if roles else ["data_controller"]
            
            return validated_rule
        
        except Exception as e:
            logger.error(f"Error in comprehensive validation: {e}")
            return {}
    
    def _verify_adequacy_countries(self, adequacy_countries: List[str]) -> List[str]:
        """Verify adequacy countries are actual countries"""
        verified = []
        
        try:
            for country in ensure_list(adequacy_countries):
                if not country:
                    continue
                
                country_str = str(country).strip()
                
                # Skip regions and invalid entries
                if len(country_str) == 2 and self.geography_handler.is_valid_country(country_str):
                    verified.append(country_str.upper())
                elif len(country_str) > 2:
                    # Try to convert country name to ISO
                    iso = self.geography_handler.get_country_iso(country_str)
                    if iso:
                        verified.append(iso.upper())
        
        except Exception as e:
            logger.debug(f"Error verifying adequacy countries: {e}")
        
        return list(set(verified))
    
    def _validate_and_enhance_conditions(self, conditions: List) -> List[Dict]:
        """Validate and enhance conditions for JSON Rules Engine"""
        validated_conditions = []
        
        try:
            valid_operators = ['equal', 'notEqual', 'in', 'notIn', 'greaterThan', 'lessThan', 'contains']
            valid_roles = ['data_controller', 'data_processor', 'joint_controller', 'data_subject', 'dpo', 'supervisory_authority', 'third_party']
            
            for condition in ensure_list(conditions):
                condition_dict = ensure_dict(condition)
                
                # Validate and fix operator
                operator = safe_get(condition_dict, 'operator', 'equal')
                if operator not in valid_operators:
                    operator = 'equal'
                
                # Validate and fix role
                role = safe_get(condition_dict, 'role', 'data_controller')
                if role not in valid_roles:
                    # Try to map invalid roles
                    role_lower = str(role).lower()
                    if 'controller' in role_lower:
                        role = 'data_controller'
                    elif 'processor' in role_lower:
                        role = 'data_processor'
                    elif 'subject' in role_lower:
                        role = 'data_subject'
                    elif 'dpo' in role_lower:
                        role = 'dpo'
                    elif 'authority' in role_lower:
                        role = 'supervisory_authority'
                    else:
                        role = 'data_controller'
                
                validated_condition = {
                    "condition_id": safe_get(condition_dict, "condition_id", f"cond_{uuid.uuid4().hex[:8]}"),
                    "condition_definition": safe_get(condition_dict, "condition_definition", "Condition for rule application"),
                    "fact": safe_get(condition_dict, "fact", "rule.context"),
                    "operator": operator,
                    "value": safe_get(condition_dict, "value", "applicable"),
                    "role": role,
                    "if_condition": safe_get(condition_dict, "if_condition", "IF condition is true"),
                    "else_condition": safe_get(condition_dict, "else_condition", "ELSE condition is false")
                }
                validated_conditions.append(validated_condition)
            
            # Ensure at least one condition
            if not validated_conditions:
                validated_conditions.append({
                    "condition_id": f"cond_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "Rule applies when relevant context exists",
                    "fact": "context.relevant",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF relevant context exists",
                    "else_condition": "ELSE rule does not apply"
                })
        
        except Exception as e:
            logger.error(f"Error validating conditions: {e}")
            validated_conditions = [{
                "condition_id": f"cond_{uuid.uuid4().hex[:8]}",
                "condition_definition": "Default condition",
                "fact": "rule.applicable",
                "operator": "equal",
                "value": True,
                "role": "data_controller",
                "if_condition": "IF rule is applicable",
                "else_condition": "ELSE rule does not apply"
            }]
        
        return validated_conditions
    
    def _fix_validation_errors(self, rule_dict: Dict, state: MultiAgentState) -> Dict:
        """Attempt to fix common validation errors"""
        try:
            # Create a basic valid rule structure
            fixed_rule = {
                "rule_id": f"rule_{uuid.uuid4().hex[:8]}",
                "rule_definition": "Data protection compliance requirement",
                "rule_type": "compliance_obligation",
                "applicable_countries": ensure_list(state['metadata_config'].get('applicable_countries', [])),
                "adequacy_countries": [],
                "conditions": [{
                    "condition_id": f"cond_{uuid.uuid4().hex[:8]}",
                    "condition_definition": "When data protection rules apply",
                    "fact": "data.processing",
                    "operator": "equal",
                    "value": True,
                    "role": "data_controller",
                    "if_condition": "IF processing personal data",
                    "else_condition": "ELSE rule does not apply"
                }],
                "aggregated_roles": ["data_controller"],
                "data_category": "personal_data",
                "domain": "data_protection_compliance",
                "action": "Ensure compliance with data protection requirements",
                "consequence": "",
                "timeframe": "",
                "reference": "Data protection law",
                "priority": "medium",
                "event_type": "rule_evaluation",
                "params": {}
            }
            
            # Try to preserve original data where possible
            for key in ['rule_definition', 'action', 'reference', 'rule_type', 'timeframe', 'consequence']:
                original_value = safe_get(rule_dict, key, "")
                if original_value and len(str(original_value)) > 5:
                    fixed_rule[key] = str(original_value)
            
            return fixed_rule
        
        except Exception as e:
            logger.error(f"Error fixing validation errors: {e}")
            return {}

# Enhanced Multi-Agent Orchestrator with Mixture of Experts
class MultiAgentLegalProcessor:
    """Multi-agent orchestrator with Mixture of Experts approach"""
    
    def __init__(self, geography_file: str):
        try:
            # Initialize LLM
            self.llm = ChatOpenAI(
                model=MODEL_NAME,
                openai_api_key=API_KEY,
                openai_api_base=BASE_URL
            )
            
            # Initialize geography handler
            self.geography_handler = GeographyHandler(geography_file)
            
            # Initialize Mixture of Experts
            self.legal_document_expert = LegalDocumentExpert(self.llm)
            self.geography_expert = GeographyJurisdictionExpert(self.llm, self.geography_handler)
            self.rule_engine_expert = RuleEngineExpert(self.llm)
            self.validation_expert = ValidationQualityExpert(self.llm, self.geography_handler)
            
            # Create enhanced workflow
            self.workflow = self._create_expert_workflow()
            
            logger.info("ðŸŽ“ Mixture of Experts Legal Processor initialized")
            logger.info(f"ðŸ“ Geography data: {len(self.geography_handler.all_countries)} countries")
        
        except Exception as e:
            logger.error(f"Error initializing processor: {e}")
            raise
    
    def _create_expert_workflow(self) -> StateGraph:
        """Create Mixture of Experts workflow"""
        
        try:
            workflow = StateGraph(MultiAgentState)
            
            # Add expert nodes
            workflow.add_node("legal_document_expert", self.legal_document_expert.process)
            workflow.add_node("geography_expert", self.geography_expert.process)
            workflow.add_node("rule_engine_expert", self.rule_engine_expert.process)
            workflow.add_node("validation_expert", self.validation_expert.process)
            
            # Set entry point
            workflow.set_entry_point("legal_document_expert")
            
            # Sequential expert processing
            workflow.add_edge("legal_document_expert", "geography_expert")
            workflow.add_edge("geography_expert", "rule_engine_expert")
            workflow.add_edge("rule_engine_expert", "validation_expert")
            workflow.add_edge("validation_expert", END)
            
            return workflow.compile(checkpointer=MemorySaver())
        
        except Exception as e:
            logger.error(f"Error creating expert workflow: {e}")
            raise
    
    async def process_document(self, metadata_config: MetadataConfig) -> List[ExtractedRule]:
        """Process document with Mixture of Experts"""
        
        try:
            logger.info(f"ðŸŽ“ Starting Mixture of Experts processing: {metadata_config.pdf_path}")
            
            # Extract complete PDF content
            pdf_processor = PDFProcessor()
            pdf_data = pdf_processor.extract_complete_text_from_pdf(metadata_config.pdf_path)
            
            if not pdf_data['complete_text']:
                raise ValueError("No text extracted from PDF")
            
            logger.info(f"ðŸ“Š PDF: {pdf_data['total_pages']} pages, {pdf_data['total_length']} characters")
            
            # Initialize expert state
            initial_state = MultiAgentState(
                document_text=pdf_data['complete_text'],
                document_chunks=[],
                metadata_config=metadata_config.model_dump(),
                geography_data=self.geography_handler.geography_data,
                legal_obligations={},
                regulatory_requirements={},
                compliance_conditions={},
                stakeholder_roles={},
                parsed_sections={},
                knowledge_graph={"entities": [], "relationships": []},
                identified_countries={},
                extracted_rules=[],
                validated_rules=[],
                agent1_reasoning=[],
                agent1_knowledge_graph={},
                agent2_reasoning=[],
                agent2_knowledge_graph={},
                agent3_reasoning=[],
                agent3_knowledge_graph={},
                agent4_reasoning=[],
                agent4_knowledge_graph={},
                current_agent="LegalDocumentExpert",
                processing_complete=False,
                chunks_processed=0,
                total_chunks=0
            )
            
            # Run expert workflow
            config = {"configurable": {"thread_id": f"expert_{uuid.uuid4().hex[:8]}"}}
            
            final_state = self.workflow.invoke(initial_state, config)
            
            # Convert to Pydantic models
            validated_rules = []
            for rule_data in ensure_list(final_state.get('validated_rules', [])):
                if rule_data:
                    try:
                        rule = ExtractedRule.model_validate(ensure_dict(rule_data))
                        validated_rules.append(rule)
                    except ValidationError as e:
                        logger.warning(f"Final rule validation failed: {e}")
                        continue
            
            # Log expert summary
            self._log_expert_summary(final_state, validated_rules, pdf_data)
            
            return validated_rules
            
        except Exception as e:
            logger.error(f"Expert processing failed: {e}")
            raise
    
    def _log_expert_summary(self, final_state: MultiAgentState, rules: List[ExtractedRule], pdf_data: Dict):
        """Log expert processing summary"""
        
        try:
            logger.info("ðŸŽ“ Mixture of Experts Processing Complete!")
            logger.info(f"ðŸ“„ PDF: {pdf_data.get('total_pages', 0)} pages")
            logger.info(f"ðŸŽ¯ Legal obligations: {len(final_state.get('legal_obligations', {}))}")
            logger.info(f"ðŸŒ Countries identified: {len(final_state.get('identified_countries', {}).get('mentioned_countries', []))}")
            logger.info(f"âš–ï¸ Rules extracted: {len(final_state.get('extracted_rules', []))}")
            logger.info(f"âœ… Rules validated: {len(rules)}")
            
            # Expert knowledge graphs
            for i, expert_name in enumerate(['LegalDocumentExpert', 'GeographyExpert', 'RuleEngineExpert', 'ValidationExpert'], 1):
                kg = final_state.get(f'agent{i}_knowledge_graph', {})
                entities = len(ensure_list(kg.get('entities', [])))
                logger.info(f"ðŸ§  {expert_name}: {entities} knowledge entities")
            
            # Sample high-quality rule
            if rules:
                sample_rule = rules[0]
                logger.info("ðŸ“‹ Sample high-quality rule:")
                logger.info(f"   ðŸ†” ID: {sample_rule.rule_id}")
                logger.info(f"   ðŸ“ Definition: {sample_rule.rule_definition[:100]}...")
                logger.info(f"   ðŸ·ï¸ Type: {sample_rule.rule_type}")
                logger.info(f"   ðŸŒ Applicable: {sample_rule.applicable_countries}")
                logger.info(f"   âœ… Adequacy: {sample_rule.adequacy_countries}")
                logger.info(f"   ðŸ‘¥ Roles: {sample_rule.aggregated_roles}")
                logger.info(f"   âš¡ Action: {sample_rule.action[:100]}...")
                logger.info(f"   ðŸ“ Reference: {sample_rule.reference}")
                logger.info(f"   â° Timeframe: {sample_rule.timeframe}")
                logger.info(f"   ðŸ§© Conditions: {len(sample_rule.conditions)}")
        
        except Exception as e:
            logger.debug(f"Error logging expert summary: {e}")

# Enhanced Pipeline with Mixture of Experts
class LegalRuleExtractionPipeline:
    """Enhanced pipeline with Mixture of Experts"""
    
    def __init__(self, geography_file: str):
        try:
            self.processor = MultiAgentLegalProcessor(geography_file)
            logger.info("ðŸŽ“ Mixture of Experts Legal Rule Extraction Pipeline initialized")
        except Exception as e:
            logger.error(f"Error initializing pipeline: {e}")
            raise
    
    async def process_document(self, metadata_config: MetadataConfig) -> List[ExtractedRule]:
        """Process single document with experts"""
        return await self.processor.process_document(metadata_config)
    
    async def process_multiple_documents(self, config_file: str) -> List[ExtractedRule]:
        """Process multiple documents with expert analysis"""
        logger.info(f"ðŸ“ Processing multiple documents with experts: {config_file}")
        
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                configs_data = json.load(f)
        except Exception as e:
            logger.error(f"Config loading failed: {e}")
            raise
        
        all_rules = []
        
        for config_data in ensure_list(configs_data):
            if not config_data:
                continue
            
            try:
                config_dict = ensure_dict(config_data)
                metadata_config = MetadataConfig.model_validate(config_dict)
                rules = await self.process_document(metadata_config)
                all_rules.extend(rules)
                
                logger.info(f"âœ… Processed {config_dict.get('pdf_path', 'unknown')}: {len(rules)} rules")
                
            except ValidationError as e:
                logger.error(f"Invalid config: {e}")
                continue
            except Exception as e:
                logger.error(f"Processing failed for {config_dict.get('pdf_path', 'unknown')}: {e}")
                continue
        
        return all_rules
    
    def save_results(self, rules: List[ExtractedRule], output_dir: str):
        """Save JSON Rules Engine compatible results"""
        try:
            logger.info(f"ðŸ’¾ Saving JSON Rules Engine compatible results to {output_dir}")
            
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            # Convert to dictionaries
            rules_dicts = []
            for rule in rules:
                if rule:
                    try:
                        rule_dict = rule.model_dump()
                        rules_dicts.append(rule_dict)
                    except Exception as e:
                        logger.debug(f"Error converting rule to dict: {e}")
                        continue
            
            # Save JSON Rules Engine compatible JSON
            json_file = Path(output_dir) / "json_rules_engine_rules.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "engine_version": "1.0",
                    "rules": rules_dicts,
                    "metadata": {
                        "generated_by": "Multi-Agent Legal Rule Extraction System",
                        "generation_date": datetime.now().isoformat(),
                        "total_rules": len(rules_dicts),
                        "methodology": "Mixture of Experts with Chain of Thought"
                    }
                }, f, indent=2, ensure_ascii=False)
            
            # Save detailed CSV analysis
            csv_file = Path(output_dir) / "detailed_rule_analysis.csv"
            if rules_dicts:
                detailed_rules = []
                for rule in rules_dicts:
                    try:
                        rule_dict = ensure_dict(rule)
                        
                        # Create detailed analysis row
                        detailed_rule = {
                            "rule_id": safe_get(rule_dict, "rule_id", ""),
                            "rule_definition": safe_get(rule_dict, "rule_definition", ""),
                            "rule_type": safe_get(rule_dict, "rule_type", ""),
                            "applicable_countries": json.dumps(ensure_list(rule_dict.get("applicable_countries", [])), ensure_ascii=False),
                            "adequacy_countries": json.dumps(ensure_list(rule_dict.get("adequacy_countries", [])), ensure_ascii=False),
                            "aggregated_roles": json.dumps(ensure_list(rule_dict.get("aggregated_roles", [])), ensure_ascii=False),
                            "data_category": safe_get(rule_dict, "data_category", ""),
                            "domain": safe_get(rule_dict, "domain", ""),
                            "action": safe_get(rule_dict, "action", ""),
                            "consequence": safe_get(rule_dict, "consequence", ""),
                            "timeframe": safe_get(rule_dict, "timeframe", ""),
                            "reference": safe_get(rule_dict, "reference", ""),
                            "priority": safe_get(rule_dict, "priority", ""),
                            "conditions_count": len(ensure_list(rule_dict.get("conditions", []))),
                            "has_if_else_logic": "Yes" if any(
                                safe_get(ensure_dict(cond), "if_condition", "") and safe_get(ensure_dict(cond), "else_condition", "")
                                for cond in ensure_list(rule_dict.get("conditions", []))
                            ) else "No",
                            "json_rules_engine_compatible": "Yes",
                            "conditions_details": json.dumps(ensure_list(rule_dict.get("conditions", [])), ensure_ascii=False)
                        }
                        detailed_rules.append(detailed_rule)
                    except Exception as e:
                        logger.debug(f"Error creating detailed rule: {e}")
                        continue
                
                if detailed_rules:
                    df = pd.DataFrame(detailed_rules)
                    df.to_csv(csv_file, index=False, encoding='utf-8')
            
            # Save rule types summary
            rule_types_file = Path(output_dir) / "rule_types_summary.json"
            rule_types_summary = {}
            role_distribution = {}
            
            for rule in rules_dicts:
                rule_dict = ensure_dict(rule)
                
                # Count rule types
                rule_type = safe_get(rule_dict, "rule_type", "unknown")
                rule_types_summary[rule_type] = rule_types_summary.get(rule_type, 0) + 1
                
                # Count role distribution
                for role in ensure_list(rule_dict.get("aggregated_roles", [])):
                    role_distribution[str(role)] = role_distribution.get(str(role), 0) + 1
            
            summary_data = {
                "total_rules": len(rules_dicts),
                "rule_types": rule_types_summary,
                "role_distribution": role_distribution,
                "unique_countries": list(set([
                    country 
                    for rule in rules_dicts 
                    for country in ensure_list(ensure_dict(rule).get("applicable_countries", []))
                ])),
                "adequacy_countries": list(set([
                    country 
                    for rule in rules_dicts 
                    for country in ensure_list(ensure_dict(rule).get("adequacy_countries", []))
                ])),
                "json_rules_engine_features": {
                    "operators_used": list(set([
                        safe_get(ensure_dict(cond), "operator", "")
                        for rule in rules_dicts
                        for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                    ])),
                    "facts_used": list(set([
                        safe_get(ensure_dict(cond), "fact", "")
                        for rule in rules_dicts
                        for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                    ])),
                    "if_else_conditions": sum(1 for rule in rules_dicts
                        if any(
                            safe_get(ensure_dict(cond), "if_condition", "") and safe_get(ensure_dict(cond), "else_condition", "")
                            for cond in ensure_list(ensure_dict(rule).get("conditions", []))
                        )
                    )
                }
            }
            
            with open(rule_types_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)
            
            # Save processing methodology report
            methodology_file = Path(output_dir) / "expert_processing_methodology.json"
            with open(methodology_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "methodology": "Mixture of Experts with Chain of Thought Reasoning",
                    "experts_used": [
                        {
                            "name": "Legal Document Structure Expert",
                            "role": "Extract precise legal obligations and requirements",
                            "techniques": ["Pattern matching", "Obligation analysis", "Structure parsing"]
                        },
                        {
                            "name": "Geography and Jurisdiction Expert", 
                            "role": "Identify countries and adequacy contexts",
                            "techniques": ["Country extraction", "Adequacy analysis", "Jurisdiction mapping"]
                        },
                        {
                            "name": "Rule Engine Expert",
                            "role": "Convert to JSON Rules Engine format",
                            "techniques": ["Condition mapping", "IF-ELSE logic", "Operator validation"]
                        },
                        {
                            "name": "Validation and Quality Expert",
                            "role": "Ensure accuracy and completeness", 
                            "techniques": ["Quality checks", "Deduplication", "Reference validation"]
                        }
                    ],
                    "features_implemented": [
                        "NO truncation - complete document processing",
                        "Mixture of Experts approach for specialized analysis",
                        "Chain of Thought reasoning in all experts",
                        "JSON Rules Engine compatibility",
                        "IF-ELSE condition logic",
                        "Multiple stakeholder roles (7 types)",
                        "Precise rule definitions (not generic)",
                        "Exact legal references",
                        "Timeframe and consequence extraction",
                        "Country verification against geography database",
                        "Rule type classification",
                        "Priority assignment",
                        "Comprehensive deduplication"
                    ],
                    "json_rules_engine_compatibility": {
                        "supported_operators": ["equal", "notEqual", "in", "notIn", "greaterThan", "lessThan", "contains"],
                        "fact_structure": "Hierarchical facts (user.role, data.category, request.type, etc.)",
                        "condition_logic": "IF-ELSE conditions for each rule condition",
                        "event_handling": "rule_evaluation events with parameters"
                    },
                    "stakeholder_roles": [
                        "data_controller", "data_processor", "joint_controller", 
                        "data_subject", "dpo", "supervisory_authority", "third_party"
                    ],
                    "rule_types": [
                        "access_right", "processing_obligation", "consent_requirement",
                        "data_transfer", "breach_notification", "compliance_obligation",
                        "penalty_provision", "processor_obligation"
                    ]
                }, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… JSON Rules Engine compatible results saved:")
            logger.info(f"   ðŸ“„ Rules JSON: {json_file}")
            logger.info(f"   ðŸ“Š Detailed CSV: {csv_file}")
            logger.info(f"   ðŸ“ˆ Summary: {rule_types_file}")
            logger.info(f"   ðŸ“‹ Methodology: {methodology_file}")
            
        except Exception as e:
            logger.error(f"Error saving results: {e}")
            raise

# CLI Interface with Expert Processing
async def main():
    """Enhanced CLI interface with Mixture of Experts"""
    import argparse
    
    try:
        parser = argparse.ArgumentParser(
            description="Mixture of Experts Legal Rule Extraction for JSON Rules Engine",
            formatter_class=argparse.RawDescriptionHelpFormatter,
            epilog="""
Examples:
  python enhanced_legal_extraction.py --config metadata_config.json --geography geography.json --output ./output

Features:
  - Mixture of Experts approach with specialized agents
  - Chain of Thought reasoning for accurate extraction  
  - JSON Rules Engine compatible output format
  - IF-ELSE condition logic for complex rules
  - Complete document processing (no truncation)
  - Multiple stakeholder roles and rule types
  - Exact legal references and timeframes
            """
        )
        parser.add_argument("--config", required=True, help="Metadata configuration JSON file")
        parser.add_argument("--geography", required=True, help="Geography JSON file")
        parser.add_argument("--output", default="./output", help="Output directory")
        
        args = parser.parse_args()
        
        logger.info("ðŸŽ“ Starting Mixture of Experts Legal Rule Extraction")
        logger.info(f"ðŸ“ Config: {args.config}")
        logger.info(f"ðŸŒ Geography: {args.geography}")
        logger.info(f"ðŸ“¤ Output: {args.output}")
        
        # Initialize expert pipeline
        pipeline = LegalRuleExtractionPipeline(args.geography)
        
        # Process documents with expert analysis
        rules = await pipeline.process_multiple_documents(args.config)
        
        # Save JSON Rules Engine compatible results
        pipeline.save_results(rules, args.output)
        
        # Final expert summary
        logger.info("ðŸŽ‰ Mixture of Experts processing complete!")
        logger.info(f"ðŸ“Š Total rules generated: {len(rules)}")
        
        if rules:
            # Analyze results
            rule_types = {}
            roles = set()
            countries = set()
            has_timeframes = 0
            has_consequences = 0
            has_if_else = 0
            
            for rule in rules:
                # Count rule types
                rule_type = getattr(rule, 'rule_type', 'unknown')
                rule_types[rule_type] = rule_types.get(rule_type, 0) + 1
                
                # Collect roles
                roles.update(getattr(rule, 'aggregated_roles', []))
                
                # Collect countries
                countries.update(getattr(rule, 'applicable_countries', []))
                
                # Count features
                if getattr(rule, 'timeframe', ''):
                    has_timeframes += 1
                if getattr(rule, 'consequence', ''):
                    has_consequences += 1
                
                # Check IF-ELSE logic
                conditions = getattr(rule, 'conditions', [])
                if any(getattr(cond, 'if_condition', '') and getattr(cond, 'else_condition', '') 
                       for cond in conditions):
                    has_if_else += 1
            
            logger.info("ðŸ“ˆ Expert Analysis Results:")
            logger.info(f"   ðŸ·ï¸ Rule types: {len(rule_types)} ({', '.join(rule_types.keys())})")
            logger.info(f"   ðŸ‘¥ Stakeholder roles: {len(roles)} ({', '.join(sorted(roles))})")
            logger.info(f"   ðŸŒ Countries: {len(countries)} ({', '.join(sorted(countries))})")
            logger.info(f"   â° Rules with timeframes: {has_timeframes}/{len(rules)}")
            logger.info(f"   âš–ï¸ Rules with consequences: {has_consequences}/{len(rules)}")
            logger.info(f"   ðŸ”€ Rules with IF-ELSE logic: {has_if_else}/{len(rules)}")
            
            # Display sample expert-extracted rule
            sample_rule = rules[0]
            logger.info("ðŸ“‹ Sample Expert-Extracted Rule:")
            logger.info(f"   ðŸ†” ID: {sample_rule.rule_id}")
            logger.info(f"   ðŸ“ Definition: {sample_rule.rule_definition[:120]}...")
            logger.info(f"   ðŸ·ï¸ Type: {sample_rule.rule_type}")
            logger.info(f"   ðŸŒ Countries: {sample_rule.applicable_countries}")
            logger.info(f"   âœ… Adequacy: {sample_rule.adequacy_countries}")
            logger.info(f"   ðŸ‘¥ Roles: {sample_rule.aggregated_roles}")
            logger.info(f"   ðŸŽ¯ Domain: {sample_rule.domain}")
            logger.info(f"   âš¡ Action: {sample_rule.action[:100]}...")
            logger.info(f"   ðŸ“ Reference: {sample_rule.reference}")
            
            if sample_rule.timeframe:
                logger.info(f"   â° Timeframe: {sample_rule.timeframe}")
            if sample_rule.consequence:
                logger.info(f"   âš–ï¸ Consequence: {sample_rule.consequence}")
            
            logger.info(f"   ðŸ§© Conditions: {len(sample_rule.conditions)}")
            if sample_rule.conditions:
                sample_condition = sample_rule.conditions[0]
                logger.info(f"   ðŸ“‹ Sample Condition:")
                logger.info(f"      ðŸ” Fact: {sample_condition.fact}")
                logger.info(f"      ðŸ”§ Operator: {sample_condition.operator}")
                logger.info(f"      ðŸ’Ž Value: {sample_condition.value}")
                logger.info(f"      ðŸ‘¤ Role: {sample_condition.role}")
                if hasattr(sample_condition, 'if_condition') and sample_condition.if_condition:
                    logger.info(f"      âž¡ï¸ IF: {sample_condition.if_condition}")
                if hasattr(sample_condition, 'else_condition') and sample_condition.else_condition:
                    logger.info(f"      â¬…ï¸ ELSE: {sample_condition.else_condition}")
        
        logger.info("ðŸŽ“ Expert processing completed successfully!")
        logger.info("ðŸ“„ JSON Rules Engine compatible output generated.")
        
        return 0
        
    except Exception as e:
        logger.error(f"Expert processing pipeline failed: {e}")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
