"""
LangChain example with HSBC authentication
Based on working httpx + truststore implementation
"""
import logging
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, SystemMessage

load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

from src.config import Config


def example_1_simple_langchain():
    """Example 1: Simple LangChain usage with HSBC auth"""
    print("\n" + "="*70)
    print("Example 1: Simple LangChain with HSBC Authentication")
    print("="*70)
    
    from src.services.hsbc_openai_client import create_langchain_client
    
    llm = create_langchain_client()
    
    print("\nSending message to LLM...")
    message = HumanMessage(content="What is LLM? Answer in one sentence.")
    
    response = llm.invoke([message])
    
    print(f"\nResponse:")
    print(f"  {response.content}")
    print("\n✓ Success!")


def example_2_conversation():
    """Example 2: Multi-turn conversation"""
    print("\n" + "="*70)
    print("Example 2: Multi-turn Conversation")
    print("="*70)
    
    from src.services.hsbc_openai_client import create_langchain_client
    
    llm = create_langchain_client()
    
    messages = [
        SystemMessage(content="You are a helpful assistant. Keep responses brief."),
        HumanMessage(content="What is data privacy?")
    ]
    
    print("\nUser: What is data privacy?")
    response1 = llm.invoke(messages)
    print(f"Assistant: {response1.content}\n")
    
    messages.append(response1)
    messages.append(HumanMessage(content="Give me an example of a privacy regulation."))
    
    print("User: Give me an example of a privacy regulation.")
    response2 = llm.invoke(messages)
    print(f"Assistant: {response2.content}")
    
    print("\n✓ Conversation completed!")


def example_3_streaming():
    """Example 3: Streaming responses"""
    print("\n" + "="*70)
    print("Example 3: Streaming Responses")
    print("="*70)
    
    from src.services.hsbc_openai_client import create_langchain_client
    
    llm = create_langchain_client()
    
    print("\nStreaming response...")
    print("Assistant: ", end="", flush=True)
    
    for chunk in llm.stream([HumanMessage(content="Count from 1 to 5, one number per line.")]):
        print(chunk.content, end="", flush=True)
    
    print("\n\n✓ Streaming completed!")


def example_4_batch_processing():
    """Example 4: Batch processing multiple requests"""
    print("\n" + "="*70)
    print("Example 4: Batch Processing")
    print("="*70)
    
    from src.services.hsbc_openai_client import create_langchain_client
    
    llm = create_langchain_client()
    
    questions = [
        "What is GDPR?",
        "What is CCPA?",
        "What is data sovereignty?"
    ]
    
    print("\nProcessing batch of questions...")
    
    message_batches = [[HumanMessage(content=q)] for q in questions]
    
    responses = llm.batch(message_batches)
    
    print("\nResults:")
    for question, response in zip(questions, responses):
        print(f"\nQ: {question}")
        print(f"A: {response.content[:150]}...")
    
    print("\n✓ Batch processing completed!")


def example_5_with_openai_service():
    """Example 5: Using OpenAIService wrapper"""
    print("\n" + "="*70)
    print("Example 5: Using OpenAIService Wrapper")
    print("="*70)
    
    import asyncio
    from src.services.openai_service import OpenAIService
    
    async def test():
        service = OpenAIService()
        
        print("\nUsing OpenAIService for chat completion...")
        
        response = await service.chat_completion([
            SystemMessage(content="You are a helpful assistant."),
            HumanMessage(content="Explain machine learning in one sentence.")
        ])
        
        print(f"\nResponse: {response}")
        
        print("\nCreating LangChain client from service...")
        langchain_llm = service.create_langchain_client()
        
        langchain_response = langchain_llm.invoke([
            HumanMessage(content="What is artificial intelligence?")
        ])
        
        print(f"\nLangChain Response: {langchain_response.content}")
        
        print("\n✓ Both methods working!")
    
    asyncio.run(test())


def example_6_langgraph_integration():
    """Example 6: LangGraph integration"""
    print("\n" + "="*70)
    print("Example 6: LangGraph Integration")
    print("="*70)
    
    try:
        from langgraph.graph import StateGraph, END
        from typing import TypedDict, Annotated
        from operator import add
        
        from src.services.hsbc_openai_client import create_langchain_client
        
        class State(TypedDict):
            messages: Annotated[list, add]
        
        llm = create_langchain_client()
        
        def llm_node(state: State):
            response = llm.invoke(state["messages"])
            return {"messages": [response]}
        
        workflow = StateGraph(State)
        workflow.add_node("llm", llm_node)
        workflow.set_entry_point("llm")
        workflow.add_edge("llm", END)
        
        app = workflow.compile()
        
        print("\nRunning LangGraph workflow...")
        result = app.invoke({
            "messages": [HumanMessage(content="What is the capital of France?")]
        })
        
        print(f"\nResponse: {result['messages'][-1].content}")
        print("\n✓ LangGraph integration working!")
        
    except ImportError:
        print("\n⊘ LangGraph not installed. Install with: pip install langgraph")


def main():
    """Run all examples"""
    print("\n" + "="*70)
    print(" HSBC LangChain Examples")
    print("="*70)
    
    print(f"\nConfiguration:")
    print(f"  HSBC Auth: {Config.USE_HSBC_AUTH}")
    print(f"  Base URL: {Config.BASE_URL[:50]}...")
    print(f"  Model: {Config.CHAT_MODEL}")
    print(f"  User: {Config.HSBC_USER_ID}")
    
    if not Config.HSBC_PASSWORD:
        print("\n❌ Error: HSBC_PASSWORD not set!")
        print("   Set it with: export HSBC_PASSWORD='your-password'")
        return
    
    try:
        example_1_simple_langchain()
        example_2_conversation()
        example_3_streaming()
        example_4_batch_processing()
        example_5_with_openai_service()
        example_6_langgraph_integration()
        
        print("\n" + "="*70)
        print(" All Examples Completed Successfully! ✓")
        print("="*70)
        
    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
