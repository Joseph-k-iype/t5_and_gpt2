"""
ChromaDB vector store implementation for the AI Tagging Service.
"""

import os
import uuid
import logging
from typing import List, Dict, Any, Optional, Tuple, Union
from langchain_core.documents import Document
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_chroma import Chroma
from chromadb.config import Settings as ChromaSettings
from pydantic import BaseModel
from app.config.settings import get_settings
from app.core.services.embeddings import get_embedding_service

logger = logging.getLogger(__name__)

class ChromaVectorStore:
    """ChromaDB vector store for storing and retrieving embeddings."""
    
    _instance = None
    
    def __new__(cls):
        """Implement singleton pattern."""
        if cls._instance is None:
            cls._instance = super(ChromaVectorStore, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """Initialize the ChromaDB vector store."""
        if self._initialized:
            return
            
        self._initialized = True
        self.settings = get_settings()
        self.embedding_service = get_embedding_service()
        
        # Get embedding function for ChromaDB
        self.embedding_function = self.embedding_service.get_langchain_compatible_embeddings()
        
        # Create directory for persistence if it doesn't exist
        os.makedirs(self.settings.vector_db.persist_dir, exist_ok=True)
        
        # Create ChromaDB settings with telemetry disabled
        self.chroma_settings = ChromaSettings(
            anonymized_telemetry=False,
            allow_reset=True,
            is_persistent=True
        )
        
        # Initialize the vector store
        self.initialize()
        
        logger.info(f"ChromaDB vector store initialized with collection '{self.settings.vector_db.collection_name}' "
                    f"in '{self.settings.vector_db.persist_dir}'")
    
    def initialize(self):
        """Initialize the vector store."""
        try:
            self.vectorstore = Chroma(
                collection_name=self.settings.vector_db.collection_name,
                embedding_function=self.embedding_function,
                persist_directory=self.settings.vector_db.persist_dir,
                client_settings=self.chroma_settings
            )
        except Exception as e:
            logger.error(f"Error initializing ChromaDB vector store: {e}")
            # Try fallback initialization with default settings
            try:
                logger.warning("Attempting fallback initialization with default settings")
                self.vectorstore = Chroma(
                    collection_name=self.settings.vector_db.collection_name,
                    embedding_function=self.embedding_function,
                    persist_directory=self.settings.vector_db.persist_dir
                )
            except Exception as fallback_error:
                logger.error(f"Fallback initialization also failed: {fallback_error}")
                raise
    
    def add_documents(self, documents: List[Document], ids: Optional[List[str]] = None) -> List[str]:
        """
        Add documents to the vector store.
        
        Args:
            documents: List of documents to add
            ids: Optional list of document IDs
            
        Returns:
            List of document IDs
        """
        try:
            if not ids:
                ids = [str(uuid.uuid4()) for _ in range(len(documents))]
            
            # Ensure all documents have unique IDs
            id_set = set()
            unique_docs = []
            unique_ids = []
            
            for i, (doc, doc_id) in enumerate(zip(documents, ids)):
                if doc_id in id_set:
                    # Generate new ID for duplicate
                    new_id = f"{doc_id}-{uuid.uuid4()}"
                    logger.warning(f"Duplicate document ID {doc_id} found, using {new_id} instead")
                    doc_id = new_id
                
                id_set.add(doc_id)
                unique_docs.append(doc)
                unique_ids.append(doc_id)
            
            # Process in batches to avoid overwhelming the database
            batch_size = 50
            all_added_ids = []
            
            for i in range(0, len(unique_docs), batch_size):
                try:
                    batch_docs = unique_docs[i:i + batch_size]
                    batch_ids = unique_ids[i:i + batch_size]
                    
                    # Filter out complex metadata that ChromaDB can't handle
                    filtered_batch = filter_complex_metadata(batch_docs)
                    
                    # Add metadata to document content for better search if needed
                    for j, doc in enumerate(filtered_batch):
                        id_str = str(batch_ids[j])
                        # Ensure the ID is in metadata
                        if 'id' not in doc.metadata:
                            doc.metadata['id'] = id_str
                    
                    self.vectorstore.add_documents(documents=filtered_batch, ids=batch_ids)
                    all_added_ids.extend(batch_ids)
                    logger.info(f"Added batch {i//batch_size + 1} of {(len(unique_docs) - 1)//batch_size + 1} to ChromaDB vector store")
                except Exception as batch_error:
                    logger.error(f"Error adding batch {i//batch_size + 1} to ChromaDB: {batch_error}")
                    # Continue with next batch instead of failing
            
            if not all_added_ids:
                logger.error("Failed to add any documents to ChromaDB")
            else:
                logger.info(f"Added total of {len(all_added_ids)} out of {len(documents)} documents to ChromaDB vector store")
            
            return all_added_ids
            
        except Exception as e:
            logger.error(f"Error adding documents to vector store: {e}")
            return []
    
    def add_texts(self, texts: List[str], metadatas: Optional[List[Dict]] = None, ids: Optional[List[str]] = None) -> List[str]:
        """
        Add texts to the vector store.
        
        Args:
            texts: List of texts to add
            metadatas: Optional list of metadata dictionaries
            ids: Optional list of document IDs
            
        Returns:
            List of document IDs
        """
        try:
            if not ids:
                ids = [str(uuid.uuid4()) for _ in range(len(texts))]
            
            # Process in batches
            batch_size = 50
            all_added_ids = []
            
            for i in range(0, len(texts), batch_size):
                try:
                    batch_texts = texts[i:i + batch_size]
                    batch_ids = ids[i:i + batch_size]
                    
                    # Handle metadata batching
                    batch_metadatas = None
                    if metadatas:
                        batch_metadatas = metadatas[i:i + batch_size]
                        
                        # Ensure all metadata has id field
                        if batch_metadatas:
                            for j, metadata in enumerate(batch_metadatas):
                                if 'id' not in metadata:
                                    metadata['id'] = batch_ids[j]
                    
                    self.vectorstore.add_texts(
                        texts=batch_texts, 
                        metadatas=batch_metadatas, 
                        ids=batch_ids
                    )
                    all_added_ids.extend(batch_ids)
                    logger.info(f"Added text batch {i//batch_size + 1} of {(len(texts) - 1)//batch_size + 1} to ChromaDB vector store")
                except Exception as batch_error:
                    logger.error(f"Error adding text batch {i//batch_size + 1} to ChromaDB: {batch_error}")
                    # Continue with next batch
            
            if not all_added_ids:
                logger.error("Failed to add any texts to ChromaDB")
            else:
                logger.info(f"Added total of {len(all_added_ids)} out of {len(texts)} texts to ChromaDB vector store")
            
            return all_added_ids
            
        except Exception as e:
            logger.error(f"Error adding texts to vector store: {e}")
            return []
    
    def similarity_search(self, query: str, k: int = 5, filter: Optional[Dict] = None) -> List[Document]:
        """
        Search for documents similar to the query.
        
        Args:
            query: Query text
            k: Number of results to return
            filter: Optional filter to apply to the search
            
        Returns:
            List of similar documents
        """
        try:
            # Defensive query handling
            if not query or not query.strip():
                logger.warning(f"Empty query in similarity_search, using default query")
                query = "term"  # Default query to return some results
            
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    return self.vectorstore.similarity_search(query, k=k, filter=filter)
                except Exception as search_error:
                    if attempt < max_retries - 1:
                        logger.warning(f"Search attempt {attempt+1} failed, retrying: {search_error}")
                        # Try to reinitialize before retry
                        self.initialize()
                    else:
                        logger.error(f"All search attempts failed: {search_error}")
                        return []  # Return empty list on failure
                        
        except Exception as e:
            logger.error(f"Error searching vector store: {e}")
            return []
    
    def similarity_search_with_score(self, query: str, k: int = 5, filter: Optional[Dict] = None) -> List[Tuple[Document, float]]:
        """
        Search for documents similar to the query with scores.
        
        Args:
            query: Query text
            k: Number of results to return
            filter: Optional filter to apply to the search
            
        Returns:
            List of (document, score) tuples
        """
        try:
            # Defensive query handling
            if not query or not query.strip():
                logger.warning(f"Empty query in similarity_search_with_score, using default query")
                query = "term"  # Default query to return some results
            
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    return self.vectorstore.similarity_search_with_score(query, k=k, filter=filter)
                except Exception as search_error:
                    if attempt < max_retries - 1:
                        logger.warning(f"Search with score attempt {attempt+1} failed, retrying: {search_error}")
                        # Try to reinitialize before retry
                        self.initialize()
                    else:
                        logger.error(f"All search with score attempts failed: {search_error}")
                        return []  # Return empty list on failure
                        
        except Exception as e:
            logger.error(f"Error searching vector store with scores: {e}")
            return []
    
    def max_marginal_relevance_search(self, query: str, k: int = 5, fetch_k: int = 20, 
                                     lambda_mult: float = 0.5, filter: Optional[Dict] = None) -> List[Document]:
        """
        Search for documents with maximal marginal relevance.
        
        Args:
            query: Query text
            k: Number of results to return
            fetch_k: Number of documents to consider
            lambda_mult: Diversity vs. relevance tradeoff
            filter: Optional filter to apply to the search
            
        Returns:
            List of documents
        """
        try:
            # Fall back to regular similarity search if MMR fails
            try:
                return self.vectorstore.max_marginal_relevance_search(
                    query=query, k=k, fetch_k=fetch_k, lambda_mult=lambda_mult, filter=filter
                )
            except Exception as mmr_error:
                logger.warning(f"MMR search failed, falling back to regular search: {mmr_error}")
                return self.similarity_search(query, k=k, filter=filter)
                
        except Exception as e:
            logger.error(f"Error with MMR search: {e}")
            return []
    
    def as_retriever(self, search_type: str = "similarity", search_kwargs: Optional[Dict] = None):
        """
        Get the vector store as a retriever.
        
        Args:
            search_type: Type of search to perform
            search_kwargs: Optional search kwargs
            
        Returns:
            Retriever
        """
        return self.vectorstore.as_retriever(search_type=search_type, search_kwargs=search_kwargs)
    
    def delete(self, ids: Optional[List[str]] = None) -> bool:
        """
        Delete documents from the vector store.
        
        Args:
            ids: Optional list of document IDs to delete
            
        Returns:
            True if successful, False otherwise
        """
        try:
            if ids:
                # Delete specific documents
                self.vectorstore.delete(ids=ids)
                logger.info(f"Deleted {len(ids)} documents from vector store")
                return True
            else:
                # Try different approaches to delete entire collection
                try:
                    # Approach 1: Use built-in method if available
                    if hasattr(self.vectorstore, 'delete_collection'):
                        self.vectorstore.delete_collection()
                        # Reinitialize after deletion
                        self.initialize()
                        logger.info(f"Deleted entire collection from vector store using delete_collection()")
                        return True
                    
                    # Approach 2: Use client interface if available
                    elif hasattr(self.vectorstore, '_client'):
                        try:
                            self.vectorstore._client.delete_collection(self.settings.vector_db.collection_name)
                            # Reinitialize after deletion
                            self.initialize()
                            logger.info(f"Deleted entire collection from vector store using _client")
                            return True
                        except Exception as client_error:
                            logger.error(f"Error deleting collection via client: {client_error}")
                    
                    # Approach 3: Create a new empty collection
                    # Get all document IDs and delete them
                    logger.info(f"Attempting to delete all documents in collection")
                    # This is a fallback approach - it may not work well for large collections
                    all_docs = self.similarity_search("", k=1000)  # Get a large batch
                    if all_docs:
                        all_ids = [doc.metadata.get('id') for doc in all_docs if 'id' in doc.metadata]
                        if all_ids:
                            self.vectorstore.delete(ids=all_ids)
                            logger.info(f"Deleted {len(all_ids)} documents from vector store")
                            return True
                    
                    # If all else fails, try to create a new vectorstore instance
                    logger.info(f"Recreating vector store instance")
                    self._initialized = False
                    self.__init__()
                    return True
                    
                except Exception as delete_error:
                    logger.error(f"Error deleting collection: {delete_error}")
                    return False
                
        except Exception as e:
            logger.error(f"Error deleting from vector store: {e}")
            return False
    
    def get_collection_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the collection.
        
        Returns:
            Dictionary with collection statistics
        """
        try:
            document_count = 0
            
            if hasattr(self.vectorstore, '_client'):
                try:
                    collection = self.vectorstore._client.get_collection(self.settings.vector_db.collection_name)
                    count = collection.count()
                    return {
                        "collection_name": self.settings.vector_db.collection_name,
                        "document_count": count,
                        "persist_directory": self.settings.vector_db.persist_dir
                    }
                except Exception as client_error:
                    logger.warning(f"Error getting collection stats from client: {client_error}")
            
            # Alternative approach - try to get document count by querying
            try:
                # Get a sample to estimate collection size
                docs = self.similarity_search("", k=1)
                if docs:
                    document_count = 1
            except Exception as query_error:
                logger.warning(f"Error querying vector store for stats: {query_error}")
            
            return {
                "collection_name": self.settings.vector_db.collection_name,
                "document_count": document_count,
                "persist_directory": self.settings.vector_db.persist_dir
            }
        except Exception as e:
            logger.error(f"Error getting collection stats: {e}")
            return {
                "collection_name": self.settings.vector_db.collection_name,
                "error": str(e),
                "persist_directory": self.settings.vector_db.persist_dir
            }


# Get the ChromaDB vector store instance
def get_chroma_store() -> ChromaVectorStore:
    """
    Get the ChromaDB vector store instance.
    
    Returns:
        ChromaVectorStore: Vector store instance
    """
    return ChromaVectorStore()
