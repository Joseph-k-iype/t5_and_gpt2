"""
Query-related data models and schemas for the Enhanced RDF Knowledge Graph Chatbot.
"""

from typing import List, Dict, Any, Optional, Union, Set, Tuple
from datetime import datetime
from enum import Enum
from pydantic import BaseModel, Field, ConfigDict, field_validator, computed_field
import re

class QueryType(str, Enum):
    """Types of queries supported by the system."""
    NATURAL_LANGUAGE = "natural_language"
    SPARQL = "sparql"
    VECTOR_SEARCH = "vector_search"
    KEYWORD_SEARCH = "keyword_search"
    HYBRID = "hybrid"

class QueryIntent(str, Enum):
    """Intent classification for natural language queries."""
    DEFINITION = "definition"
    RELATIONSHIP = "relationship"
    PROPERTY = "property"
    LISTING = "listing"
    COMPARISON = "comparison"
    HIERARCHICAL = "hierarchical"
    EXISTENCE = "existence"
    COUNT = "count"
    GENERAL = "general"
    COMPLEX = "complex"

class ProcessingMethod(str, Enum):
    """Methods used for query processing."""
    VECTOR_SEARCH = "vector_search"
    SPARQL_CHAIN = "sparql_chain"
    DIRECT_SPARQL = "direct_sparql"
    KEYWORD_SEARCH = "keyword_search"
    HYBRID_SEARCH = "hybrid_search"
    LLM_GENERATION = "llm_generation"

class SearchMethod(str, Enum):
    """Vector search methods."""
    COSINE_SIMILARITY = "cosine_similarity"
    EUCLIDEAN_DISTANCE = "euclidean_distance"
    DOT_PRODUCT = "dot_product"
    HYBRID = "hybrid"

class QueryStatus(str, Enum):
    """Query execution status."""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"

class KeyConcept(BaseModel):
    """Extracted key concept from query."""
    model_config = ConfigDict(extra="forbid")
    
    text: str = Field(..., description="Concept text")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Extraction confidence")
    entity_type: Optional[str] = Field(None, description="Predicted entity type")
    matched_entities: List[str] = Field(default_factory=list, description="Matched entity URIs")
    is_primary: bool = Field(False, description="Whether this is a primary concept")

class QueryClassification(BaseModel):
    """Query classification results."""
    model_config = ConfigDict(extra="forbid")
    
    primary_intent: QueryIntent = Field(..., description="Primary query intent")
    secondary_intent: Optional[QueryIntent] = Field(None, description="Secondary intent")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Classification confidence")
    all_scores: Dict[QueryIntent, float] = Field(default_factory=dict, description="All intent scores")
    features: Dict[str, Any] = Field(default_factory=dict, description="Classification features")
    
    @computed_field
    @property
    def is_confident(self) -> bool:
        """Check if classification is confident enough."""
        return self.confidence >= 0.7

class QueryAnalysis(BaseModel):
    """Comprehensive query analysis."""
    model_config = ConfigDict(extra="forbid")
    
    original_query: str = Field(..., description="Original query text")
    normalized_query: str = Field(..., description="Normalized query text")
    language: str = Field("en", description="Detected language")
    length: int = Field(..., ge=0, description="Query length in characters")
    word_count: int = Field(..., ge=0, description="Number of words")
    
    # Extracted information
    key_concepts: List[KeyConcept] = Field(default_factory=list, description="Extracted key concepts")
    classification: QueryClassification = Field(..., description="Query classification")
    entities_mentioned: List[str] = Field(default_factory=list, description="Explicitly mentioned entities")
    
    # Processing hints
    suggested_methods: List[ProcessingMethod] = Field(default_factory=list, description="Suggested processing methods")
    complexity_score: float = Field(..., ge=0.0, le=1.0, description="Query complexity score")
    requires_reasoning: bool = Field(False, description="Whether query requires complex reasoning")
    
    @field_validator('original_query', 'normalized_query')
    @classmethod
    def validate_query_text(cls, v: str) -> str:
        """Validate query text."""
        if not v or not v.strip():
            raise ValueError("Query text cannot be empty")
        return v.strip()

class SparqlQuery(BaseModel):
    """SPARQL query representation."""
    model_config = ConfigDict(extra="forbid")
    
    query: str = Field(..., description="SPARQL query string")
    query_type: str = Field(..., description="SPARQL query type (SELECT, CONSTRUCT, etc.)")
    variables: List[str] = Field(default_factory=list, description="Query variables")
    prefixes: Dict[str, str] = Field(default_factory=dict, description="Namespace prefixes used")
    is_valid: bool = Field(True, description="Whether query is syntactically valid")
    validation_errors: List[str] = Field(default_factory=list, description="Validation errors")
    estimated_complexity: str = Field("medium", description="Estimated query complexity")
    
    @field_validator('query')
    @classmethod
    def validate_sparql_query(cls, v: str) -> str:
        """Basic SPARQL query validation."""
        if not v or not v.strip():
            raise ValueError("SPARQL query cannot be empty")
        
        # Check for dangerous operations
        dangerous_ops = ["DELETE", "INSERT", "DROP", "CREATE", "CLEAR", "COPY", "MOVE", "ADD"]
        query_upper = v.upper()
        
        for op in dangerous_ops:
            if op in query_upper:
                raise ValueError(f"SPARQL {op} operations are not allowed")
        
        return v.strip()
    
    @computed_field
    @property
    def is_read_only(self) -> bool:
        """Check if query is read-only."""
        read_only_keywords = ["SELECT", "CONSTRUCT", "ASK", "DESCRIBE"]
        query_upper = self.query.upper()
        return any(keyword in query_upper for keyword in read_only_keywords)

class VectorSearchParams(BaseModel):
    """Parameters for vector search."""
    model_config = ConfigDict(extra="forbid")
    
    query_vector: Optional[List[float]] = Field(None, description="Pre-computed query vector")
    query_text: Optional[str] = Field(None, description="Text to embed for search")
    top_k: int = Field(10, ge=1, le=1000, description="Number of top results")
    min_score: float = Field(0.0, ge=0.0, le=1.0, description="Minimum similarity score")
    search_method: SearchMethod = Field(SearchMethod.COSINE_SIMILARITY, description="Search method")
    include_metadata: bool = Field(True, description="Include entity metadata")
    filter_entity_types: Optional[List[str]] = Field(None, description="Filter by entity types")
    filter_namespaces: Optional[List[str]] = Field(None, description="Filter by namespaces")
    
    @field_validator('query_vector')
    @classmethod
    def validate_query_vector(cls, v: Optional[List[float]]) -> Optional[List[float]]:
        """Validate query vector dimensions."""
        if v is not None and len(v) != 3072:  # text-embedding-3-large dimensions
            raise ValueError("Query vector must have 3072 dimensions for text-embedding-3-large")
        return v

class KeywordSearchParams(BaseModel):
    """Parameters for keyword search."""
    model_config = ConfigDict(extra="forbid")
    
    keywords: List[str] = Field(..., description="Search keywords")
    search_fields: List[str] = Field(
        default_factory=lambda: ["local_name", "labels", "comments", "text_content"],
        description="Fields to search"
    )
    operator: str = Field("OR", description="Keyword operator (AND/OR)")
    fuzzy: bool = Field(False, description="Enable fuzzy matching")
    boost_exact_matches: bool = Field(True, description="Boost exact matches")

class SearchResult(BaseModel):
    """Individual search result."""
    model_config = ConfigDict(extra="forbid")
    
    entity_uri: str = Field(..., description="Entity URI")
    score: float = Field(..., description="Relevance score")
    rank: int = Field(..., ge=1, description="Result rank")
    matched_fields: List[str] = Field(default_factory=list, description="Fields that matched")
    highlights: Dict[str, List[str]] = Field(default_factory=dict, description="Search highlights")
    explanation: Optional[str] = Field(None, description="Score explanation")

class QueryExecution(BaseModel):
    """Query execution tracking."""
    model_config = ConfigDict(extra="forbid")
    
    query_id: str = Field(..., description="Unique query identifier")
    status: QueryStatus = Field(QueryStatus.PENDING, description="Execution status")
    start_time: datetime = Field(default_factory=datetime.now, description="Execution start time")
    end_time: Optional[datetime] = Field(None, description="Execution end time")
    processing_methods: List[ProcessingMethod] = Field(default_factory=list, description="Methods used")
    
    # Resource usage
    execution_time_ms: Optional[float] = Field(None, description="Execution time in milliseconds")
    memory_usage_mb: Optional[float] = Field(None, description="Memory usage in MB")
    token_usage: Optional[int] = Field(None, description="LLM tokens used")
    
    # Results
    result_count: int = Field(0, ge=0, description="Number of results returned")
    error_message: Optional[str] = Field(None, description="Error message if failed")
    warnings: List[str] = Field(default_factory=list, description="Execution warnings")
    
    @computed_field
    @property
    def duration_seconds(self) -> Optional[float]:
        """Calculate execution duration in seconds."""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return None

class QueryContext(BaseModel):
    """Context information for query processing."""
    model_config = ConfigDict(extra="forbid")
    
    user_id: Optional[str] = Field(None, description="User identifier")
    session_id: Optional[str] = Field(None, description="Session identifier")
    conversation_history: List[str] = Field(default_factory=list, description="Previous queries in session")
    domain_context: Optional[str] = Field(None, description="Domain or topic context")
    preferences: Dict[str, Any] = Field(default_factory=dict, description="User preferences")
    
    # Knowledge base context
    active_ontologies: List[str] = Field(default_factory=list, description="Active ontology files")
    namespace_preferences: List[str] = Field(default_factory=list, description="Preferred namespaces")
    entity_focus: List[str] = Field(default_factory=list, description="Entities of interest")

class QueryPlan(BaseModel):
    """Execution plan for complex queries."""
    model_config = ConfigDict(extra="forbid")
    
    steps: List[Dict[str, Any]] = Field(default_factory=list, description="Execution steps")
    estimated_cost: float = Field(0.0, description="Estimated execution cost")
    parallel_execution: bool = Field(False, description="Whether steps can run in parallel")
    fallback_plan: Optional['QueryPlan'] = Field(None, description="Fallback execution plan")
    
    def add_step(self, method: ProcessingMethod, params: Dict[str, Any], estimated_time: float = 0.0) -> None:
        """Add an execution step to the plan."""
        step = {
            "method": method,
            "params": params,
            "estimated_time": estimated_time,
            "order": len(self.steps)
        }
        self.steps.append(step)
        self.estimated_cost += estimated_time

class QueryResult(BaseModel):
    """Complete query result."""
    model_config = ConfigDict(extra="forbid")
    
    query_id: str = Field(..., description="Query identifier")
    original_query: str = Field(..., description="Original query")
    query_analysis: QueryAnalysis = Field(..., description="Query analysis")
    execution: QueryExecution = Field(..., description="Execution tracking")
    
    # Results from different methods
    vector_results: List[SearchResult] = Field(default_factory=list, description="Vector search results")
    sparql_results: List[Dict[str, Any]] = Field(default_factory=list, description="SPARQL query results")
    llm_response: Optional[str] = Field(None, description="LLM-generated response")
    
    # Combined and processed results
    final_answer: str = Field(..., description="Final answer to the query")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Answer confidence")
    sources: List[str] = Field(default_factory=list, description="Information sources")
    related_queries: List[str] = Field(default_factory=list, description="Related query suggestions")
    
    @computed_field
    @property
    def was_successful(self) -> bool:
        """Check if query was processed successfully."""
        return self.execution.status == QueryStatus.COMPLETED and bool(self.final_answer)

class QueryBatch(BaseModel):
    """Batch of queries for processing."""
    model_config = ConfigDict(extra="forbid")
    
    batch_id: str = Field(..., description="Batch identifier")
    queries: List[QueryResult] = Field(default_factory=list, description="Queries in batch")
    created_at: datetime = Field(default_factory=datetime.now, description="Batch creation time")
    priority: int = Field(0, description="Batch priority")
    
    @computed_field
    @property
    def total_queries(self) -> int:
        """Total number of queries in batch."""
        return len(self.queries)
    
    @computed_field
    @property
    def completed_queries(self) -> int:
        """Number of completed queries."""
        return sum(1 for q in self.queries if q.execution.status == QueryStatus.COMPLETED)

class QueryTemplate(BaseModel):
    """Template for common query patterns."""
    model_config = ConfigDict(extra="forbid")
    
    name: str = Field(..., description="Template name")
    description: str = Field(..., description="Template description")
    pattern: str = Field(..., description="Query pattern with placeholders")
    parameters: List[str] = Field(default_factory=list, description="Template parameters")
    intent: QueryIntent = Field(..., description="Query intent this template handles")
    examples: List[str] = Field(default_factory=list, description="Example queries")
    
    def instantiate(self, **kwargs) -> str:
        """Instantiate template with provided parameters."""
        query = self.pattern
        for param, value in kwargs.items():
            if param in self.parameters:
                query = query.replace(f"{{{param}}}", str(value))
        return query

class QueryCache(BaseModel):
    """Cache entry for query results."""
    model_config = ConfigDict(extra="forbid")
    
    query_hash: str = Field(..., description="Hash of the query")
    cached_result: QueryResult = Field(..., description="Cached query result")
    created_at: datetime = Field(default_factory=datetime.now, description="Cache creation time")
    access_count: int = Field(0, description="Number of times accessed")
    last_accessed: Optional[datetime] = Field(None, description="Last access time")
    ttl_seconds: int = Field(3600, description="Time to live in seconds")
    
    @computed_field
    @property
    def is_expired(self) -> bool:
        """Check if cache entry is expired."""
        if self.ttl_seconds <= 0:
            return False
        
        expiry_time = self.created_at.timestamp() + self.ttl_seconds
        return datetime.now().timestamp() > expiry_time

class QueryMetrics(BaseModel):
    """Metrics for query processing."""
    model_config = ConfigDict(extra="forbid")
    
    total_queries: int = Field(0, description="Total queries processed")
    successful_queries: int = Field(0, description="Successfully processed queries")
    failed_queries: int = Field(0, description="Failed queries")
    average_response_time: float = Field(0.0, description="Average response time in seconds")
    average_token_usage: float = Field(0.0, description="Average LLM token usage")
    
    # Intent distribution
    intent_distribution: Dict[QueryIntent, int] = Field(default_factory=dict, description="Distribution by intent")
    method_usage: Dict[ProcessingMethod, int] = Field(default_factory=dict, description="Usage by method")
    
    # Performance metrics
    fastest_query_time: float = Field(float('inf'), description="Fastest query time")
    slowest_query_time: float = Field(0.0, description="Slowest query time")
    cache_hit_rate: float = Field(0.0, description="Cache hit rate")
    
    @computed_field
    @property
    def success_rate(self) -> float:
        """Calculate success rate."""
        if self.total_queries == 0:
            return 0.0
        return self.successful_queries / self.total_queries

# Factory functions for common query types
def create_definition_query(entity_name: str) -> QueryAnalysis:
    """Create a definition query analysis."""
    return QueryAnalysis(
        original_query=f"What is {entity_name}?",
        normalized_query=f"what is {entity_name.lower()}",
        length=len(f"What is {entity_name}?"),
        word_count=3,
        key_concepts=[KeyConcept(text=entity_name, confidence=0.9, is_primary=True)],
        classification=QueryClassification(
            primary_intent=QueryIntent.DEFINITION,
            confidence=0.95,
            all_scores={QueryIntent.DEFINITION: 0.95}
        ),
        suggested_methods=[ProcessingMethod.VECTOR_SEARCH, ProcessingMethod.SPARQL_CHAIN],
        complexity_score=0.3
    )

def create_relationship_query(entity1: str, entity2: str) -> QueryAnalysis:
    """Create a relationship query analysis."""
    query_text = f"How are {entity1} and {entity2} related?"
    return QueryAnalysis(
        original_query=query_text,
        normalized_query=query_text.lower(),
        length=len(query_text),
        word_count=len(query_text.split()),
        key_concepts=[
            KeyConcept(text=entity1, confidence=0.9, is_primary=True),
            KeyConcept(text=entity2, confidence=0.9, is_primary=True)
        ],
        classification=QueryClassification(
            primary_intent=QueryIntent.RELATIONSHIP,
            confidence=0.9,
            all_scores={QueryIntent.RELATIONSHIP: 0.9}
        ),
        suggested_methods=[ProcessingMethod.DIRECT_SPARQL, ProcessingMethod.VECTOR_SEARCH],
        complexity_score=0.6,
        requires_reasoning=True
    )

def create_listing_query(entity_type: str) -> QueryAnalysis:
    """Create a listing query analysis."""
    query_text = f"List all {entity_type}"
    return QueryAnalysis(
        original_query=query_text,
        normalized_query=query_text.lower(),
        length=len(query_text),
        word_count=len(query_text.split()),
        key_concepts=[KeyConcept(text=entity_type, confidence=0.85, is_primary=True)],
        classification=QueryClassification(
            primary_intent=QueryIntent.LISTING,
            confidence=0.9,
            all_scores={QueryIntent.LISTING: 0.9}
        ),
        suggested_methods=[ProcessingMethod.DIRECT_SPARQL, ProcessingMethod.KEYWORD_SEARCH],
        complexity_score=0.4
    )
