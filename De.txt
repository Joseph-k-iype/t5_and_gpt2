"""
LLM-based guidance analyzer for extracting ODRL components from guidance text.

CRITICAL FIX:
- Action validation and normalization at EVERY stage
- Ensures ONLY 5 standard actions: share, store, process, update, create
- Post-processes ALL LLM outputs to fix actions
- Supervisor agent validates and corrects
- Removes legal citations
- Generates detailed comments

Location: src/analyzers/guidance_analyzer.py
"""
import logging
from typing import Dict, List, Any, Optional
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, ValidationError

from ..services.openai_service import OpenAIService
from ..utils.json_parser import SafeJsonParser
from ..prompting.strategies import PromptingStrategies
from ..validators import ODRLLogicalValidator

logger = logging.getLogger(__name__)


class ODRLComponents(BaseModel):
    """Extracted ODRL components from guidance text."""
    
    # Core ODRL elements
    actions: List[str] = Field(default_factory=list, description="Standard actions: share, store, process, update, create")
    permissions: List[Dict[str, Any]] = Field(default_factory=list, description="Permitted actions with details")
    prohibitions: List[Dict[str, Any]] = Field(default_factory=list, description="Prohibited actions with details")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="Constraints and conditions")
    
    # Data context
    data_categories: List[str] = Field(default_factory=list, description="Types of data involved")
    data_subjects: List[str] = Field(default_factory=list, description="Who the data is about")
    
    # Parties and roles (NO assigner/assignee)
    parties: Dict[str, List[str]] = Field(default_factory=dict, description="Parties by role (controller, processor, data_subject)")
    
    # Additional context
    purpose: Optional[str] = Field(None, description="Purpose of processing")
    legal_basis: Optional[str] = Field(None, description="Legal basis without article citations")
    geographic_scope: List[str] = Field(default_factory=list, description="Geographic applicability")
    
    # Evidence and verification
    evidence_requirements: List[str] = Field(default_factory=list, description="Evidence needed")
    verification_methods: List[str] = Field(default_factory=list, description="How to verify compliance")
    
    # Metadata
    confidence_score: float = Field(0.8, description="Confidence in extraction")
    extraction_reasoning: str = Field("", description="Reasoning for extraction")
    
    # Supervisor review metadata
    supervisor_reviewed: bool = Field(False, description="Whether supervisor agent reviewed")
    supervisor_corrections: int = Field(0, description="Number of corrections made by supervisor")


class GuidanceAnalyzer:
    """
    Analyzes guidance text using LLM to extract ODRL components.
    CRITICAL: Validates and fixes ALL actions to ensure ONLY standard taxonomy is used.
    """
    
    # ============================================================================
    # STANDARD ACTION TAXONOMY - THESE ARE THE ONLY 5 ACTIONS PERMITTED
    # ============================================================================
    STANDARD_ACTIONS = {"share", "store", "process", "update", "create"}
    
    # ============================================================================
    # COMPREHENSIVE SYNONYM MAPPING
    # ============================================================================
    ACTION_SYNONYMS = {
        # Share synonyms
        "share": "share", "distribute": "share", "transfer": "share",
        "disclose": "share", "transmit": "share", "send": "share",
        "communicate": "share", "provide": "share", "give": "share",
        "forward": "share", "reveal": "share", "expose": "share",
        
        # Store synonyms
        "store": "store", "archive": "store", "retain": "store",
        "keep": "store", "maintain": "store", "hold": "store",
        "save": "store", "preserve": "store", "backup": "store",
        
        # Process synonyms
        "process": "process", "use": "process", "analyze": "process",
        "transform": "process", "modify": "process", "manipulate": "process",
        "handle": "process", "execute": "process", "apply": "process",
        "implement": "process", "perform": "process", "read": "process",
        "access": "process", "view": "process",
        
        # Update synonyms
        "update": "update", "change": "update", "amend": "update",
        "revise": "update", "alter": "update", "edit": "update",
        "correct": "update", "rectify": "update", "fix": "update",
        
        # Create synonyms
        "create": "create", "collect": "create", "generate": "create",
        "produce": "create", "derive": "create", "obtain": "create",
        "gather": "create", "acquire": "create", "compile": "create"
    }
    
    def __init__(self):
        """Initialize guidance analyzer with LLM service."""
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
        logger.info("Initialized GuidanceAnalyzer with STRICT 5-action taxonomy")
    
    # ============================================================================
    # ACTION VALIDATION AND NORMALIZATION
    # ============================================================================
    
    def _validate_and_fix_action(self, action: str) -> str:
        """
        Validate and map action to standard taxonomy.
        
        This is CRITICAL - all actions from LLM must pass through this method.
        
        Args:
            action: Action from LLM (may be synonym or non-standard)
            
        Returns:
            Normalized standard action (share/store/process/update/create)
        """
        if not action:
            logger.warning("Empty action provided, defaulting to 'process'")
            return "process"
        
        # Clean and normalize
        action_clean = action.lower().strip()
        
        # Remove URI parts if present
        if "/" in action_clean:
            action_clean = action_clean.split("/")[-1]
        if "#" in action_clean:
            action_clean = action_clean.split("#")[-1]
        if ":" in action_clean:
            action_clean = action_clean.split(":")[-1]
        
        # Remove common prefixes
        action_clean = action_clean.replace("data ", "").replace(" data", "")
        
        # Direct match with standard actions
        if action_clean in self.STANDARD_ACTIONS:
            return action_clean
        
        # Synonym mapping
        if action_clean in self.ACTION_SYNONYMS:
            mapped = self.ACTION_SYNONYMS[action_clean]
            if action_clean != mapped:
                logger.info(f"Mapped action '{action}' → '{mapped}'")
            return mapped
        
        # Partial matching for complex action names
        for synonym, standard_action in self.ACTION_SYNONYMS.items():
            if synonym in action_clean or action_clean in synonym:
                logger.info(f"Partially matched action '{action}' → '{standard_action}'")
                return standard_action
        
        # If we can't map it, log error and default to process
        logger.warning(f"Unknown action '{action}', defaulting to 'process'")
        return "process"
    
    def _fix_actions_in_components(self, components: Dict[str, Any]) -> Dict[str, Any]:
        """
        Post-process to fix ALL actions in extracted components.
        
        This method ensures that even if the LLM returns non-standard actions,
        they are automatically corrected before being used.
        
        Args:
            components: Raw components from LLM
            
        Returns:
            Fixed components with validated actions
        """
        actions_fixed = 0
        
        # Fix actions list
        if "actions" in components:
            fixed_actions = []
            for action in components["actions"]:
                original = action
                fixed_action = self._validate_and_fix_action(action)
                if original != fixed_action:
                    actions_fixed += 1
                if fixed_action not in fixed_actions:
                    fixed_actions.append(fixed_action)
            components["actions"] = fixed_actions
            logger.info(f"Fixed {actions_fixed} actions in action list")
        
        # Fix permissions
        if "permissions" in components:
            for perm in components["permissions"]:
                if "action" in perm:
                    original = perm["action"]
                    fixed = self._validate_and_fix_action(perm["action"])
                    if original != fixed:
                        logger.info(f"Fixed permission action: '{original}' → '{fixed}'")
                    perm["action"] = fixed
        
        # Fix prohibitions
        if "prohibitions" in components:
            for prohib in components["prohibitions"]:
                if "action" in prohib:
                    original = prohib["action"]
                    fixed = self._validate_and_fix_action(prohib["action"])
                    if original != fixed:
                        logger.info(f"Fixed prohibition action: '{original}' → '{fixed}'")
                    prohib["action"] = fixed
        
        # Fix duties
        if "duties" in components:
            for duty in components["duties"]:
                if isinstance(duty, dict) and "action" in duty:
                    original = duty["action"]
                    fixed = self._validate_and_fix_action(duty["action"])
                    if original != fixed:
                        logger.info(f"Fixed duty action: '{original}' → '{fixed}'")
                    duty["action"] = fixed
        
        return components
    
    # ============================================================================
    # MAIN ANALYSIS WORKFLOW
    # ============================================================================
    
    async def analyze_guidance(
        self, 
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        rule_id: str
    ) -> ODRLComponents:
        """
        Comprehensive analysis of guidance text to extract ODRL components.
        Includes action validation at EVERY stage.
        
        Args:
            guidance_text: Complete guidance text
            rule_name: Name/title of the rule
            framework_type: Framework identifier (DSS, DataVISA, etc.)
            restriction_condition: Type (restriction or condition)
            rule_id: Unique identifier
            
        Returns:
            ODRLComponents with validated actions (only standard taxonomy)
        """
        logger.info(f"Analyzing guidance for rule: {rule_name} ({rule_id})")
        
        try:
            # Stage 1: Comprehensive analysis
            initial_analysis = await self._stage1_comprehensive_analysis(
                guidance_text, rule_name, framework_type, restriction_condition
            )
            
            # Stage 2: ODRL-specific extraction
            odrl_extraction = await self._stage2_odrl_extraction(
                guidance_text, rule_name, initial_analysis
            )
            
            # Stage 3: Constraint analysis
            constraint_analysis = await self._stage3_constraint_analysis(
                guidance_text, rule_name, odrl_extraction
            )
            
            # Stage 4: Data category identification
            data_categories = await self._stage4_data_category_identification(
                guidance_text, rule_name, constraint_analysis
            )
            
            # Stage 5: Synthesis
            synthesized_components = await self._stage5_synthesis(
                guidance_text, rule_name, framework_type, restriction_condition,
                initial_analysis, odrl_extraction, constraint_analysis, data_categories
            )
            
            # Stage 6: Supervisor review
            final_components = await self._stage6_supervisor_review(
                synthesized_components, guidance_text, rule_name
            )
            
            # CRITICAL: Final action validation
            logger.info(f"Final action validation for {rule_name}...")
            final_components = self._validate_final_components(final_components)
            
            return final_components
        
        except Exception as e:
            logger.error(f"Error analyzing guidance for {rule_name}: {e}")
            # Return minimal valid components on error
            return ODRLComponents(
                actions=["process"],
                permissions=[],
                prohibitions=[],
                constraints=[],
                confidence_score=0.0,
                extraction_reasoning=f"Error during analysis: {str(e)}"
            )
    
    def _validate_final_components(self, components: ODRLComponents) -> ODRLComponents:
        """
        Final validation of components to ensure ONLY standard actions.
        
        This is the last line of defense to ensure no non-standard actions slip through.
        """
        # Validate and fix all actions
        validated_actions = []
        for action in components.actions:
            validated = self._validate_and_fix_action(action)
            if validated not in validated_actions:
                validated_actions.append(validated)
        components.actions = validated_actions
        
        # Validate permissions
        for perm in components.permissions:
            if "action" in perm:
                perm["action"] = self._validate_and_fix_action(perm["action"])
        
        # Validate prohibitions
        for prohib in components.prohibitions:
            if "action" in prohib:
                prohib["action"] = self._validate_and_fix_action(prohib["action"])
        
        logger.info(f"Final validation complete. Actions: {components.actions}")
        return components
    
    # ============================================================================
    # ANALYSIS STAGES
    # ============================================================================
    
    async def _stage1_comprehensive_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        framework_type: str,
        restriction_condition: str
    ) -> str:
        """Stage 1: Comprehensive understanding of guidance text."""
        
        prompt = PromptingStrategies.comprehensive_document_analysis_prompt(
            legislation_text=guidance_text,
            existing_context="",
            level="rule"
        )
        
        messages = [
            SystemMessage(content=(
                "You are a legal and data protection expert analyzing regulatory guidance. "
                "Use ONLY standard action taxonomy: share, store, process, update, create. "
                "DO NOT include assigner or assignee fields. "
                "Convert all legal citations to plain language requirements."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 1 complete: Comprehensive analysis for {rule_name}")
            return response
        except Exception as e:
            logger.error(f"Error in stage 1 analysis: {e}")
            return f"Error in comprehensive analysis: {str(e)}"
    
    async def _stage2_odrl_extraction(
        self,
        guidance_text: str,
        rule_name: str,
        initial_analysis: str
    ) -> str:
        """Stage 2: Extract ODRL-specific components."""
        
        prompt = PromptingStrategies.odrl_component_extraction(
            guidance_text=guidance_text,
            rule_name=rule_name,
            initial_analysis=initial_analysis
        )
        
        messages = [
            SystemMessage(content=(
                "You are extracting ODRL components from guidance. "
                "CRITICAL: Use ONLY these 5 actions: share, store, process, update, create. "
                "Do NOT use: distribute, archive, use, modify, derive, transfer, or any other synonyms. "
                "NO assigner or assignee fields."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 2 complete: ODRL extraction for {rule_name}")
            return response
        except Exception as e:
            logger.error(f"Error in stage 2 extraction: {e}")
            return f"Error in ODRL extraction: {str(e)}"
    
    async def _stage3_constraint_analysis(
        self,
        guidance_text: str,
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 3: Detailed constraint analysis."""
        
        prompt = f"""
        Analyze constraints in detail for precise machine-readable rules.
        
        RULE: {rule_name}
        
        ODRL EXTRACTION:
        {odrl_extraction}
        
        ORIGINAL GUIDANCE:
        {guidance_text}
        
        Analyze constraints with focus on:
        1. Left operand (what is constrained)
        2. Operator (comparison type)
        3. Right operand (constraint value)
        4. Logical relationships (AND, OR, NOT)
        5. Testability - can this be automatically verified?
        
        Provide detailed constraint analysis in plain English.
        """
        
        messages = [
            SystemMessage(content="You are analyzing constraints for ODRL policies. Focus on making constraints concrete, testable, and machine-readable."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 3 complete: Constraint analysis for {rule_name}")
            return response
        except Exception as e:
            logger.error(f"Error in stage 3 analysis: {e}")
            return f"Error in constraint analysis: {str(e)}"
    
    async def _stage4_data_category_identification(
        self,
        guidance_text: str,
        rule_name: str,
        constraint_analysis: str
    ) -> str:
        """Stage 4: Identify data categories."""
        
        prompt = f"""
        Identify all data categories mentioned in the guidance.
        
        RULE: {rule_name}
        
        CONSTRAINT ANALYSIS:
        {constraint_analysis}
        
        ORIGINAL GUIDANCE:
        {guidance_text}
        
        Extract:
        1. Specific data categories (e.g., "personal data", "financial data", "health data")
        2. Data subjects (who the data is about)
        3. Special category data (sensitive data types)
        
        Be specific and comprehensive. List all data categories found.
        """
        
        messages = [
            SystemMessage(content="You are identifying data categories from regulatory guidance. Be precise and specific."),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 4 complete: Data category identification for {rule_name}")
            return response
        except Exception as e:
            logger.error(f"Error in stage 4 identification: {e}")
            return f"Error in data category identification: {str(e)}"
    
    async def _stage5_synthesis(
        self,
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        initial_analysis: str,
        odrl_extraction: str,
        constraint_analysis: str,
        data_categories: str
    ) -> ODRLComponents:
        """Stage 5: Synthesize all analyses into final components."""
        
        prompt = PromptingStrategies.final_synthesis_prompt(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition,
            initial_analysis=initial_analysis,
            odrl_extraction=odrl_extraction,
            constraint_analysis=constraint_analysis,
            data_categories=data_categories
        )
        
        messages = [
            SystemMessage(content=(
                "You are synthesizing final ODRL components. "
                "CRITICAL: All actions MUST be one of: share, store, process, update, create. "
                "NO other action names permitted. NO assigner/assignee fields."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 5 complete: Synthesis for {rule_name}")
            
            # Parse JSON response
            components_dict = self.json_parser.parse_json(response)
            
            if not components_dict:
                logger.error(f"Failed to parse JSON in stage 5 for {rule_name}")
                return self._create_default_components()
            
            # CRITICAL: Fix actions before creating Pydantic model
            components_dict = self._fix_actions_in_components(components_dict)
            
            # Create Pydantic model
            components = ODRLComponents(**components_dict)
            
            logger.info(f"Synthesized components for {rule_name}:")
            logger.info(f"  - Actions: {components.actions}")
            logger.info(f"  - Permissions: {len(components.permissions)}")
            logger.info(f"  - Prohibitions: {len(components.prohibitions)}")
            
            return components
        
        except Exception as e:
            logger.error(f"Error in stage 5 synthesis: {e}")
            return self._create_default_components()
    
    async def _stage6_supervisor_review(
        self,
        synthesized_components: ODRLComponents,
        guidance_text: str,
        rule_name: str
    ) -> ODRLComponents:
        """Stage 6: Supervisor agent review and correction."""
        
        # Convert components to dict for review
        components_dict = synthesized_components.dict()
        
        prompt = PromptingStrategies.supervisor_review_prompt(
            extracted_components=str(components_dict),
            original_guidance=guidance_text,
            rule_name=rule_name
        )
        
        messages = [
            SystemMessage(content=(
                "You are a supervisor agent reviewing ODRL components for quality and correctness. "
                "ENFORCE STRICTLY: Only these 5 actions are permitted: share, store, process, update, create. "
                "If you find ANY other actions (distribute, archive, use, modify, derive, etc.), FIX them. "
                "Remove all assigner/assignee fields. Ensure detailed comments."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            response = await self.openai_service.chat_completion(messages)
            logger.info(f"Stage 6 complete: Supervisor review for {rule_name}")
            
            # Parse supervisor response
            supervisor_result = self.json_parser.parse_json(response)
            
            if not supervisor_result:
                logger.warning(f"Failed to parse supervisor response for {rule_name}, using synthesized components")
                return synthesized_components
            
            # Extract corrected components
            if "corrected_components" in supervisor_result:
                corrected_dict = supervisor_result["corrected_components"]
                
                # CRITICAL: Fix actions again after supervisor review
                corrected_dict = self._fix_actions_in_components(corrected_dict)
                
                # Create updated components
                corrected_components = ODRLComponents(**corrected_dict)
                
                # Add supervisor metadata
                corrected_components.supervisor_reviewed = True
                corrections = supervisor_result.get("corrections_made", [])
                corrected_components.supervisor_corrections = len(corrections)
                
                if corrections:
                    logger.info(f"Supervisor made {len(corrections)} corrections for {rule_name}")
                    for correction in corrections[:3]:  # Log first 3
                        logger.info(f"  - {correction}")
                
                return corrected_components
            else:
                logger.warning(f"No corrected components in supervisor response for {rule_name}")
                return synthesized_components
        
        except Exception as e:
            logger.error(f"Error in stage 6 supervisor review: {e}")
            return synthesized_components
    
    def _create_default_components(self) -> ODRLComponents:
        """Create default/fallback components."""
        return ODRLComponents(
            actions=["process"],
            permissions=[],
            prohibitions=[],
            constraints=[],
            confidence_score=0.5,
            extraction_reasoning="Created default components due to extraction error"
        )
