import json
import pandas as pd
import glob
import os
from datetime import datetime

def find_latest_json_file(pattern: str) -> str:
    """
    Finds the most recently created file matching a glob pattern.

    Args:
        pattern (str): The glob pattern to search for (e.g., 'complete_unified_output_*.json').

    Returns:
        str: The path to the latest file, or None if no file is found.
    """
    files = glob.glob(pattern)
    if not files:
        return None
    latest_file = max(files, key=os.path.getctime)
    return latest_file

def process_simplified_rules(data: dict) -> pd.DataFrame:
    """
    Processes the 'unified_simplified_rules' section of the JSON data into a DataFrame.
    It unnests list-based columns into delimited strings.

    Args:
        data (dict): The loaded JSON data.

    Returns:
        pd.DataFrame: A DataFrame containing the simplified rules.
    """
    print("Processing 'unified_simplified_rules'...")
    rules_data = data.get('unified_simplified_rules', [])
    if not rules_data:
        print("Warning: 'unified_simplified_rules' section is empty or not found.")
        return pd.DataFrame()

    processed_rules = []
    for rule in rules_data:
        # Create a copy to avoid modifying the original data
        processed_rule = rule.copy()
        
        # Unnest lists into pipe-separated strings for CSV compatibility
        if 'conditions' in processed_rule and isinstance(processed_rule['conditions'], list):
            processed_rule['conditions'] = ' | '.join(map(str, processed_rule['conditions']))
            
        if 'key_phrases' in processed_rule and isinstance(processed_rule['key_phrases'], list):
            processed_rule['key_phrases'] = ' | '.join(map(str, processed_rule['key_phrases']))
            
        processed_rules.append(processed_rule)
        
    df = pd.DataFrame(processed_rules)
    print(f"-> Found and processed {len(df)} simplified rules.")
    return df

def process_decision_tables(data: dict) -> pd.DataFrame:
    """
    Processes the 'unified_decision_tables' section of the JSON data.
    It flattens the hierarchical structure of tables, rules, conditions, and actions.

    Args:
        data (dict): The loaded JSON data.

    Returns:
        pd.DataFrame: A flattened DataFrame of all rules from all decision tables.
    """
    print("Processing 'unified_decision_tables'...")
    decision_tables_data = data.get('unified_decision_tables', {}).get('decision_tables', [])
    if not decision_tables_data:
        print("Warning: 'unified_decision_tables' section is empty or not found.")
        return pd.DataFrame()

    flattened_rules = []
    for table in decision_tables_data:
        table_info = {
            'table_id': table.get('table_id'),
            'table_name': table.get('name'),
            'table_description': table.get('description')
        }
        
        for rule in table.get('rules', []):
            # Start with the parent table's info
            flat_rule = table_info.copy()
            
            # Add the rule-specific info
            flat_rule['dt_rule_id'] = rule.get('rule_id')
            flat_rule['priority'] = rule.get('priority')
            flat_rule['source_rule_id'] = rule.get('source_rule')
            
            # Unnest actions list into a comma-separated string
            if 'actions' in rule and isinstance(rule['actions'], list):
                flat_rule['actions'] = ', '.join(map(str, rule['actions']))
            
            # Unnest references list into a JSON string
            if 'references' in rule and isinstance(rule['references'], list):
                flat_rule['references_json'] = json.dumps(rule.get('references', []))
            
            # Add the rule's conditions, which will become columns
            rule_conditions = rule.get('conditions', {})
            if isinstance(rule_conditions, dict):
                flat_rule.update(rule_conditions)
                
            flattened_rules.append(flat_rule)
            
    df = pd.DataFrame(flattened_rules)
    print(f"-> Found and processed {len(df)} decision table rules from {len(decision_tables_data)} tables.")
    return df

def main():
    """
    Main function to orchestrate the JSON to CSV conversion.
    """
    print("Starting JSON to CSV conversion process...")
    
    # --- Configuration ---
    # The script will automatically find the latest 'complete_unified_output_*.json' file.
    # If you want to specify a file manually, replace the line below with:
    # INPUT_JSON_FILE = 'your_file_name.json'
    INPUT_JSON_FILE = find_latest_json_file('complete_unified_output_*.json')
    
    if not INPUT_JSON_FILE:
        print("\nERROR: No 'complete_unified_output_*.json' file found in the current directory.")
        print("Please make sure the JSON file is present and the script is run from the same folder.")
        return

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    OUTPUT_CSV_FILE = f'unified_rules_detailed_output_{timestamp}.csv'
    
    print(f"Input file: {INPUT_JSON_FILE}")
    print(f"Output file: {OUTPUT_CSV_FILE}")

    # --- Load Data ---
    try:
        with open(INPUT_JSON_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print("JSON file loaded successfully.")
    except FileNotFoundError:
        print(f"ERROR: The file '{INPUT_JSON_FILE}' was not found.")
        return
    except json.JSONDecodeError:
        print(f"ERROR: The file '{INPUT_JSON_FILE}' is not a valid JSON file.")
        return

    # --- Process Data ---
    simplified_rules_df = process_simplified_rules(data)
    decision_tables_df = process_decision_tables(data)

    if simplified_rules_df.empty or decision_tables_df.empty:
        print("\nOne of the data sections was empty. Cannot perform merge. Halting process.")
        if not simplified_rules_df.empty:
             simplified_rules_df.to_csv(f'simplified_rules_only_{timestamp}.csv', index=False)
             print(f"Saved simplified rules to 'simplified_rules_only_{timestamp}.csv'")
        if not decision_tables_df.empty:
             decision_tables_df.to_csv(f'decision_tables_only_{timestamp}.csv', index=False)
             print(f"Saved decision tables to 'decision_tables_only_{timestamp}.csv'")
        return

    # --- Merge DataFrames ---
    print("Merging decision tables with simplified rules...")
    # We merge the flattened decision table rules with the simplified rules
    # using the source_rule_id as the link.
    merged_df = pd.merge(
        decision_tables_df,
        simplified_rules_df,
        left_on='source_rule_id',
        right_on='rule_id',
        how='left',
        suffixes=('_dt', '_simplified') # Add suffixes to distinguish overlapping column names
    )
    print(f"-> Merge complete. Final dataset has {len(merged_df)} rows and {len(merged_df.columns)} columns.")

    # --- Save to CSV ---
    try:
        merged_df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig')
        print(f"\nSuccessfully created the detailed CSV file: {OUTPUT_CSV_FILE}")
    except Exception as e:
        print(f"\nERROR: Could not save the CSV file. Reason: {e}")

if __name__ == '__main__':
    # Before running, ensure you have pandas installed:
    # pip install pandas
    main()
