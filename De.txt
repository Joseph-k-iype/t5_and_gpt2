from fastapi import FastAPI, HTTPException, Body, Request
from fastapi.middleware.cors import CORSMiddleware
import json
from pathlib import Path
import pandas as pd
import numpy as np
import httpx
import os
import time
import logging
from typing import Optional
from collections import defaultdict
from datetime import datetime
import uuid

# ============= Structured Logging Setup =============
import logging.config

# Create log directory relative to this file (works on Windows)
log_dir = Path(__file__).parent / "logs"
log_dir.mkdir(parents=True, exist_ok=True)

LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "json": {
            "()": "pythonjsonlogger.jsonlogger.JsonFormatter",
            "format": "%(timestamp)s %(level)s %(name)s %(message)s %(request_id)s %(endpoint)s %(method)s %(status)s %(duration)s %(user_ip)s"
        },
        "standard": {
            "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "level": "INFO",
            "formatter": "standard",
            "stream": "ext://sys.stdout"
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "INFO",
            "formatter": "json",
            "filename": str(log_dir / "app.log"),
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5
        },
        "error_file": {
            "class": "logging.handlers.RotatingFileHandler",
            "level": "ERROR",
            "formatter": "json",
            "filename": str(log_dir / "error.log"),
            "maxBytes": 10485760,
            "backupCount": 5
        }
    },
    "loggers": {
        "": {
            "handlers": ["console", "file", "error_file"],
            "level": "INFO",
            "propagate": True
        },
        "uvicorn": {
            "handlers": ["console", "file"],
            "level": "INFO",
            "propagate": False
        }
    }
}

# Apply logging configuration
try:
    logging.config.dictConfig(LOGGING_CONFIG)
    print(f"‚úÖ Logging configured - files at: {log_dir}")
except Exception as e:
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(log_dir / 'app.log')
        ]
    )
    print(f"‚ö†Ô∏è  Warning: Could not configure JSON logging: {e}")

logger = logging.getLogger(__name__)

# ============= Metrics Collection =============
from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
from starlette.responses import Response

# Define metrics
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint']
)

active_requests = Gauge(
    'http_requests_active',
    'Number of active HTTP requests'
)

cache_hits = Counter(
    'app_cache_hits_total',
    'Total cache hits',
    ['cache_type']
)

cache_misses = Counter(
    'app_cache_misses_total',
    'Total cache misses',
    ['cache_type']
)

evaluation_count = Counter(
    'app_evaluations_total',
    'Total evaluations performed',
    ['status', 'has_case_id']
)

# ============= Configuration =============
DATA_PATH = Path(__file__).parent / "countries.json"
OPA_QUERY_URL = "https://nginx.dvc-opa.hsbc-11974748-dvcloud.dev.dev.gcp.cloud.uk.hsbc/v1/query"
DEBUG_MODE = os.getenv("DEBUG_MODE", "true").lower() == "true"

# ============= Global Cache =============
class DataCache:
    """Singleton cache for CSV data with O(1) lookups"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance.initialized = False
        return cls._instance
    
    def initialize(self):
        if self.initialized:
            return
        
        logger.info("Loading CSV data into memory...")
        start_time = pd.Timestamp.now()
        
        try:
            df = pd.read_csv("Full TIA details.csv")
            load_time = (pd.Timestamp.now() - start_time).total_seconds()
            logger.info(f"Loaded {len(df)} rows in {load_time:.2f}s")
            
            self._build_indexes(df)
            
            with DATA_PATH.open(encoding="utf-8") as f:
                self.POLICIES = json.load(f)
            
            self.initialized = True
            total_time = (pd.Timestamp.now() - start_time).total_seconds()
            logger.info(f"Total initialization time: {total_time:.2f}s")
        except Exception as e:
            logger.error(f"Failed to initialize cache: {str(e)}", exc_info=True)
            raise
    
    def _build_indexes(self, df: pd.DataFrame):
        """Convert DataFrame to optimized dict structures"""
        df = df.replace({np.nan: None})
        records = df.to_dict('records')
        
        self.by_app_id = defaultdict(list)
        self.by_dv_case_id = defaultdict(list)
        self.by_business_id = defaultdict(list)
        
        required_cols = {
            'ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_CODE',
            'ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_CODE',
            'ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_NAME',
            'ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_NAME',
            'CASE_MODULE_NAME',
            'CASE_MODULE_STATUS_NAME'
        }
        
        for record in records:
            compact_record = {
                k: v for k, v in record.items() 
                if k in required_cols and v is not None
            }
            
            if 'APPLICATION_INSTANCE_ID' in record and record['APPLICATION_INSTANCE_ID']:
                app_id = str(record['APPLICATION_INSTANCE_ID'])
                self.by_app_id[app_id].append(compact_record)
            
            if 'ASSURANCE_DV_CASE_ID' in record and record['ASSURANCE_DV_CASE_ID']:
                dv_id = str(record['ASSURANCE_DV_CASE_ID'])
                self.by_dv_case_id[dv_id].append(compact_record)
            
            if 'BUSINESS_APPLICATION_ID' in record and record['BUSINESS_APPLICATION_ID']:
                bus_id = str(record['BUSINESS_APPLICATION_ID'])
                self.by_business_id[bus_id].append(compact_record)
        
        self.by_app_id = dict(self.by_app_id)
        self.by_dv_case_id = dict(self.by_dv_case_id)
        self.by_business_id = dict(self.by_business_id)
        
        self._build_module_cache()
        
        logger.info(f"Indexed: {len(self.by_app_id)} APP_IDs, "
                   f"{len(self.by_dv_case_id)} DV_CASE_IDs, "
                   f"{len(self.by_business_id)} BUSINESS_IDs")
    
    def _build_module_cache(self):
        """Pre-compute module completion status for O(1) lookups"""
        self.pia_completed = set()
        self.tia_completed = set()
        
        for id_dict, id_type in [
            (self.by_app_id, 'app'),
            (self.by_dv_case_id, 'dv'),
            (self.by_business_id, 'ba')
        ]:
            for case_id, records in id_dict.items():
                for record in records:
                    module = record.get('CASE_MODULE_NAME')
                    status = record.get('CASE_MODULE_STATUS_NAME')
                    
                    if status == 'Completed':
                        full_id = f"{id_type}:{case_id}"
                        if module == 'PIA':
                            self.pia_completed.add(full_id)
                        elif module == 'TIA':
                            self.tia_completed.add(full_id)

cache = DataCache()

http_client = httpx.AsyncClient(
    verify=False,
    timeout=30.0,
    limits=httpx.Limits(
        max_keepalive_connections=20,
        max_connections=100,
        keepalive_expiry=30.0
    )
)

# ============= Helper Functions =============
def get_id_info(case_id):
    """Get ID column type and lookup dict"""
    case_str = str(case_id)
    
    if case_str.isdigit():
        cache_hits.labels(cache_type='app_id').inc()
        return "APPLICATION_INSTANCE_ID", cache.by_app_id, "app"
    elif case_str.startswith("DVC"):
        cache_hits.labels(cache_type='dv_case_id').inc()
        return "ASSURANCE_DV_CASE_ID", cache.by_dv_case_id, "dv"
    elif case_str.startswith("BA"):
        cache_hits.labels(cache_type='business_id').inc()
        return "BUSINESS_APPLICATION_ID", cache.by_business_id, "ba"
    else:
        cache_misses.labels(cache_type='unknown').inc()
        return None, None, None

def check_countries(case_id, sending_country, receiving_country):
    """Ultra-fast country matching using in-memory dicts"""
    id_col, lookup_dict, _ = get_id_info(case_id)
    
    if not id_col or not lookup_dict:
        return "no_case"
    
    case_data = lookup_dict.get(str(case_id))
    
    if not case_data:
        cache_misses.labels(cache_type='case_data').inc()
        return "no_case"
    
    cache_hits.labels(cache_type='case_data').inc()
    
    sending_match = any(
        record.get("ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_CODE") == sending_country or
        record.get("ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_NAME") == sending_country
        for record in case_data
    )
    
    receiving_match = any(
        record.get("ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_CODE") == receiving_country or
        record.get("ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_NAME") == receiving_country
        for record in case_data
    )
    
    if sending_match and receiving_match:
        return "all_match"
    elif not sending_match and not receiving_match:
        return "both_mismatch"
    elif not sending_match:
        return "sending_country_mismatch"
    elif not receiving_match:
        return "receiving_country_mismatch"

def check_module_complete(case_id, module_name):
    """O(1) module status check using pre-computed sets"""
    _, _, cache_prefix = get_id_info(case_id)
    
    if not cache_prefix:
        return False
    
    full_id = f"{cache_prefix}:{case_id}"
    
    if module_name == "PIA":
        return full_id in cache.pia_completed
    elif module_name == "TIA":
        return full_id in cache.tia_completed
    else:
        return False

async def query_opa(query: str, input_data: Optional[dict] = None) -> dict:
    """Reusable OPA query function with connection pooling"""
    payload = {"query": query}
    if input_data:
        payload["input"] = input_data
    
    try:
        if DEBUG_MODE:
            logger.debug(f"OPA Query: {query}", extra={"opa_query": query, "opa_input": input_data})
        
        response = await http_client.post(OPA_QUERY_URL, json=payload)
        response.raise_for_status()
        result = response.json()
        
        if DEBUG_MODE:
            logger.debug(f"OPA Response received", extra={"opa_response": result})
        
        return result
    except httpx.HTTPStatusError as e:
        error_detail = f"OPA HTTP Error: {e.response.status_code}"
        if DEBUG_MODE:
            error_detail += f" - {e.response.text}"
        logger.error(f"OPA HTTP Error: {e.response.status_code}", 
                    extra={"status_code": e.response.status_code, "response": e.response.text})
        raise HTTPException(
            status_code=502,
            detail=f"OPA query failed: {e.response.status_code}"
        )
    except httpx.RequestError as e:
        logger.error(f"OPA Request Error: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=503,
            detail=f"OPA service unavailable: {str(e)}"
        )

def extract_opa_message(opa_result: dict) -> Optional[str]:
    """Extract message from OPA response (handles multiple formats)"""
    if not isinstance(opa_result, dict):
        if DEBUG_MODE:
            logger.warning(f"OPA result is not a dict: {type(opa_result)}")
        return None
    
    if "result" in opa_result:
        result = opa_result["result"]
        
        if isinstance(result, str):
            return result
        
        if isinstance(result, list):
            if len(result) == 0:
                if DEBUG_MODE:
                    logger.debug("OPA result is an empty list")
                return None
                
            for item in result:
                if isinstance(item, dict) and "result" in item:
                    return item["result"]
                if isinstance(item, dict) and "message" in item:
                    return item["message"]
                if isinstance(item, str):
                    return item
        
        if isinstance(result, dict):
            if "result" in result:
                return result["result"]
            if "message" in result:
                return result["message"]
    
    if "message" in opa_result:
        return opa_result["message"]
    
    if DEBUG_MODE:
        logger.warning(f"Could not extract message from OPA result", extra={"opa_result": opa_result})
    
    return None

# ============= FastAPI App =============
app = FastAPI(
    title="TIA Evaluation Service",
    description="Ultra-fast TIA/PIA compliance evaluation with observability",
    version="2.0.0"
)

# ============= Request ID Middleware =============
@app.middleware("http")
async def add_request_id(request: Request, call_next):
    request_id = str(uuid.uuid4())
    request.state.request_id = request_id
    request.state.start_time = time.time()
    
    logger.info(
        f"Request started: {request.method} {request.url.path}",
        extra={
            "request_id": request_id,
            "method": request.method,
            "endpoint": request.url.path,
            "user_ip": request.client.host if request.client else "unknown"
        }
    )
    
    active_requests.inc()
    
    try:
        response = await call_next(request)
        duration = time.time() - request.state.start_time
        
        logger.info(
            f"Request completed: {request.method} {request.url.path}",
            extra={
                "request_id": request_id,
                "method": request.method,
                "endpoint": request.url.path,
                "status": response.status_code,
                "duration": f"{duration:.3f}",
                "user_ip": request.client.host if request.client else "unknown"
            }
        )
        
        request_count.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).inc()
        
        request_duration.labels(
            method=request.method,
            endpoint=request.url.path
        ).observe(duration)
        
        response.headers["X-Request-ID"] = request_id
        return response
        
    except Exception as e:
        duration = time.time() - request.state.start_time
        logger.error(
            f"Request failed: {request.method} {request.url.path}",
            extra={
                "request_id": request_id,
                "method": request.method,
                "endpoint": request.url.path,
                "duration": f"{duration:.3f}",
                "error": str(e),
                "user_ip": request.client.host if request.client else "unknown"
            },
            exc_info=True
        )
        raise
    finally:
        active_requests.dec()

# ============= CORS Configuration =============
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "http://localhost:3005",      # Added for React on port 3005
        "http://localhost:5173",
        "http://localhost:5174",
        "http://127.0.0.1:3000",
        "http://127.0.0.1:3005",      # Added for React on port 3005
        "http://127.0.0.1:5173",
        "http://127.0.0.1:5174",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

logger.info("‚úÖ CORS middleware configured successfully")

# ============= Startup/Shutdown Events =============
@app.on_event("startup")
async def startup_event():
    logger.info("üöÄ Starting TIA Evaluation Service...")
    try:
        cache.initialize()
        logger.info("‚úÖ Service ready!")
    except Exception as e:
        logger.critical(f"‚ùå Failed to start service: {str(e)}", exc_info=True)
        raise

@app.on_event("shutdown")
async def shutdown_event():
    logger.info("üõë Shutting down service...")
    await http_client.aclose()
    logger.info("‚úÖ Cleanup complete")

# ============= Metrics Endpoint =============
@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

# ============= API Routes =============
@app.post("/data/evaluate")
async def data_evaluate(
    request: Request,
    body: dict = Body(..., example={
        "caseId": "DVC123456",
        "sendingCountry": "GB",
        "receivingCountry": "US",
        "personalData": "Yes"
    })
):
    """Evaluate TIA/PIA requirements for a data transfer case"""
    request_id = request.state.request_id
    
    cid = body.get("caseId")
    sending_country = body.get("sendingCountry")
    receiving_country = body.get("receivingCountry")
    personal_data = body.get("personalData")
    
    logger.info(
        f"Evaluation request received",
        extra={
            "request_id": request_id,
            "case_id": cid,
            "sending_country": sending_country,
            "receiving_country": receiving_country,
            "personal_data": personal_data
        }
    )
    
    if not sending_country or not receiving_country or not personal_data:
        logger.warning(f"Missing required fields", extra={"request_id": request_id})
        raise HTTPException(
            status_code=400,
            detail="Missing required fields. Provide sendingCountry, receivingCountry, and personalData."
        )
    
    is_personal = str(personal_data).lower() not in ["no", "0", "false"]
    evaluation_count.labels(
        status="started",
        has_case_id="yes" if cid else "no"
    ).inc()
    
    # Case 1: No case ID and no personal data
    if not cid and not is_personal:
        opa_query = "result = data.Uk.no_id_given"
        opa_input = {
            "sendingCountry": sending_country,
            "receivingCountry": receiving_country,
        }
        opa_result = await query_opa(opa_query, opa_input)
        opa_message = extract_opa_message(opa_result)
        
        logger.info(f"No ID given evaluation", extra={"request_id": request_id, "message": opa_message})
        evaluation_count.labels(status="no_id_no_personal_data", has_case_id="no").inc()
        
        return {
            "opa_result": opa_result,
            "message": opa_message,
            "status": "no_id_no_personal_data"
        }
    
    # Case 2: Case ID provided
    if cid:
        result = check_countries(cid, sending_country, receiving_country)
        logger.debug(f"Country check result: {result}", extra={"request_id": request_id})
        
        if result == "no_case":
            opa_query = "result = data.Uk.no_case_found"
            opa_result = await query_opa(opa_query)
            opa_message = extract_opa_message(opa_result)
            
            logger.info(f"No case found", extra={"request_id": request_id, "case_id": cid})
            evaluation_count.labels(status="no_case", has_case_id="yes").inc()
            
            return {
                "opa_result": opa_result,
                "message": opa_message,
                "status": "no_case"
            }
        
        if result in ["sending_country_mismatch", "receiving_country_mismatch", "both_mismatch"]:
            if result == "both_mismatch":
                opa_query = "result = data.Uk.both_mismatch"
            elif result == "sending_country_mismatch":
                opa_query = "result = data.Uk.sending_mismatch"
            elif result == "receiving_country_mismatch":
                opa_query = "result = data.Uk.receiving_mismatch"
            
            opa_result = await query_opa(opa_query)
            opa_message = extract_opa_message(opa_result)
            
            logger.info(f"Country mismatch: {result}", extra={"request_id": request_id})
            evaluation_count.labels(status=result, has_case_id="yes").inc()
            
            return {
                "opa_result": opa_result,
                "message": opa_message,
                "status": result
            }
        
        if result == "all_match" and not is_personal:
            opa_query = "result = data.Uk.country_match_personal_no"
            opa_result = await query_opa(opa_query)
            opa_message = extract_opa_message(opa_result)
            
            logger.info(f"Countries match, no personal data", extra={"request_id": request_id})
            evaluation_count.labels(status="country_match_no_personal", has_case_id="yes").inc()
            
            return {
                "opa_result": opa_result,
                "message": opa_message,
                "status": "country_match_no_personal_data"
            }
        
        opa_query = "result = data.Uk.check_status"
        opa_input = {
            "sendingCountry": sending_country,
            "receivingCountry": receiving_country
        }
        opa_result = await query_opa(opa_query, opa_input)
        opa_message = extract_opa_message(opa_result)
        
        logger.debug(f"TIA/PIA status check", extra={"request_id": request_id, "opa_message": opa_message})
        
        if opa_message == "NO TIA":
            pia_complete = check_module_complete(cid, "PIA")
            
            if pia_complete:
                opa_query = "result = data.Uk.PIA_satisfied"
                opa_result = await query_opa(opa_query)
            else:
                opa_query = "result = data.Uk.PIA_not_satisfied"
                opa_result = await query_opa(opa_query)
            
            final_message = extract_opa_message(opa_result)
            status = "pia_satisfied" if pia_complete else "pia_not_satisfied"
            
            logger.info(f"PIA check result: {status}", extra={"request_id": request_id})
            evaluation_count.labels(status=status, has_case_id="yes").inc()
            
            return {
                "opa_result": opa_result,
                "message": final_message,
                "status": status
            }
        
        elif opa_message == "Check TIA":
            tia_complete = check_module_complete(cid, "TIA")
            pia_complete = check_module_complete(cid, "PIA")
            
            if tia_complete and pia_complete:
                opa_query = "result = data.Uk.TIA_PIA_satisfied"
                opa_result = await query_opa(opa_query)
            else:
                opa_query = "result = data.Uk.TIA_PIA_not_satisfied"
                opa_result = await query_opa(opa_query)
            
            final_message = extract_opa_message(opa_result)
            status = "tia_pia_satisfied" if (tia_complete and pia_complete) else "tia_pia_not_satisfied"
            
            logger.info(f"TIA/PIA check result: {status}", extra={"request_id": request_id})
            evaluation_count.labels(status=status, has_case_id="yes").inc()
            
            return {
                "opa_result": opa_result,
                "message": final_message,
                "status": status
            }
        
        return {
            "opa_result": opa_result,
            "message": opa_message
        }
    
    logger.error(f"Invalid request parameters", extra={"request_id": request_id})
    raise HTTPException(status_code=400, detail="Invalid request parameters")

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    if not cache.initialized:
        return {"status": "initializing", "cache_initialized": False}
    
    return {
        "status": "healthy",
        "cache_initialized": True,
        "indexes": {
            "application_ids": len(cache.by_app_id),
            "dv_case_ids": len(cache.by_dv_case_id),
            "business_ids": len(cache.by_business_id),
            "pia_completed_cases": len(cache.pia_completed),
            "tia_completed_cases": len(cache.tia_completed)
        }
    }

@app.get("/stats")
async def get_stats():
    """Detailed statistics"""
    if not cache.initialized:
        raise HTTPException(status_code=503, detail="Cache not initialized")
    
    return {
        "total_unique_cases": {
            "application_ids": len(cache.by_app_id),
            "dv_case_ids": len(cache.by_dv_case_id),
            "business_ids": len(cache.by_business_id)
        },
        "compliance_status": {
            "pia_completed": len(cache.pia_completed),
            "tia_completed": len(cache.tia_completed)
        },
        "performance": {
            "lookup_complexity": "O(1)",
            "module_check_complexity": "O(1)"
        }
    }

@app.post("/debug/opa")
async def debug_opa_query(
    body: dict = Body(..., example={
        "query": "result = data.Uk.check_status",
        "input": {"sendingCountry": "GB", "receivingCountry": "US"}
    })
):
    """Debug endpoint to test OPA queries directly"""
    query = body.get("query")
    input_data = body.get("input")
    
    if not query:
        raise HTTPException(status_code=400, detail="query field is required")
    
    try:
        opa_result = await query_opa(query, input_data)
        extracted_message = extract_opa_message(opa_result)
        
        return {
            "query": query,
            "input": input_data,
            "raw_opa_response": opa_result,
            "extracted_message": extracted_message,
            "extraction_successful": extracted_message is not None
        }
    except Exception as e:
        return {
            "query": query,
            "input": input_data,
            "error": str(e),
            "error_type": type(e).__name__
        }

@app.get("/debug/case/{case_id}")
async def debug_case_lookup(case_id: str):
    """Debug endpoint to check case data"""
    if not cache.initialized:
        raise HTTPException(status_code=503, detail="Cache not initialized")
    
    id_col, lookup_dict, cache_prefix = get_id_info(case_id)
    
    if not id_col:
        return {
            "case_id": case_id,
            "found": False,
            "error": "Invalid case ID format"
        }
    
    case_data = lookup_dict.get(str(case_id))
    
    if not case_data:
        return {
            "case_id": case_id,
            "id_type": id_col,
            "found": False
        }
    
    pia_complete = check_module_complete(case_id, "PIA")
    tia_complete = check_module_complete(case_id, "TIA")
    
    sending_countries = set()
    receiving_countries = set()
    
    for record in case_data:
        if record.get("ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_CODE"):
            sending_countries.add(record["ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_CODE"])
        if record.get("ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_NAME"):
            sending_countries.add(record["ASSURANCE_SENDING_COUNTRY_TERRITORY_ISO_NAME"])
        if record.get("ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_CODE"):
            receiving_countries.add(record["ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_CODE"])
        if record.get("ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_NAME"):
            receiving_countries.add(record["ASSURANCE_RECEIVING_COUNTRY_TERRITORY_ISO_NAME"])
    
    return {
        "case_id": case_id,
        "id_type": id_col,
        "found": True,
        "record_count": len(case_data),
        "compliance_status": {
            "pia_completed": pia_complete,
            "tia_completed": tia_complete
        },
        "countries": {
            "sending": list(sending_countries),
            "receiving": list(receiving_countries)
        },
        "raw_records": case_data
    }

@app.get("/debug/rego-policies")
async def debug_rego_policies():
    """Test all Rego policy queries to see what they return"""
    test_queries = [
        ("no_case_found", "result = data.Uk.no_case_found", None),
        ("both_mismatch", "result = data.Uk.both_mismatch", None),
        ("sending_mismatch", "result = data.Uk.sending_mismatch", None),
        ("receiving_mismatch", "result = data.Uk.receiving_mismatch", None),
        ("country_match_personal_no", "result = data.Uk.country_match_personal_no", None),
        ("PIA_satisfied", "result = data.Uk.PIA_satisfied", None),
        ("PIA_not_satisfied", "result = data.Uk.PIA_not_satisfied", None),
        ("TIA_PIA_satisfied", "result = data.Uk.TIA_PIA_satisfied", None),
        ("TIA_PIA_not_satisfied", "result = data.Uk.TIA_PIA_not_satisfied", None),
        ("check_status_GB_US", "result = data.Uk.check_status", 
         {"sendingCountry": "GB", "receivingCountry": "US"}),
        ("no_id_given_GB_US", "result = data.Uk.no_id_given",
         {"sendingCountry": "GB", "receivingCountry": "US"}),
    ]
    
    results = {}
    
    for name, query, input_data in test_queries:
        try:
            opa_result = await query_opa(query, input_data)
            extracted_message = extract_opa_message(opa_result)
            
            results[name] = {
                "query": query,
                "input": input_data,
                "raw_response": opa_result,
                "extracted_message": extracted_message,
                "has_message": extracted_message is not None,
                "is_empty": opa_result == {} or opa_result.get("result") == []
            }
        except Exception as e:
            results[name] = {
                "query": query,
                "input": input_data,
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    return {
        "test_results": results,
        "summary": {
            "total_queries": len(test_queries),
            "successful": sum(1 for r in results.values() if "error" not in r),
            "with_messages": sum(1 for r in results.values() if r.get("has_message")),
            "empty_responses": sum(1 for r in results.values() if r.get("is_empty"))
        }
    }

@app.get("/")
async def root():
    """Root endpoint with API information"""
    return {
        "service": "TIA/PIA Evaluation Service",
        "version": "2.0.0",
        "status": "running",
        "observability": {
            "metrics": "/metrics",
            "health": "/health",
            "logs": f"Check {log_dir}"
        },
        "endpoints": {
            "health": "/health",
            "stats": "/stats",
            "evaluate": "/data/evaluate",
            "debug_case": "/debug/case/{case_id}",
            "debug_opa": "/debug/opa",
            "debug_rego": "/debug/rego-policies",
            "docs": "/docs",
            "redoc": "/redoc"
        }
    }

if __name__ == "__main__":
    import uvicorn
    print("\n" + "="*60)
    print("üöÄ TIA/PIA Evaluation Service with Observability")
    print("="*60)
    print(f"üìç Server: http://localhost:8000")
    print(f"üìä Metrics: http://localhost:8000/metrics")
    print(f"üìù Logs: {log_dir}")
    print(f"üìö API Docs: http://localhost:8000/docs")
    print(f"üîç ReDoc: http://localhost:8000/redoc")
    print("="*60 + "\n")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True
    )
