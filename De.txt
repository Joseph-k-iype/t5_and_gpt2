"""
LLM-based guidance analyzer for extracting ODRL components from guidance text.
Uses advanced prompting strategies for comprehensive analysis.
Integrates with existing PromptingStrategies framework.
UPDATED: Includes Supervisor Agent for permission/prohibition review.

Location: src/analyzers/guidance_analyzer.py

FIXES APPLIED:
- Changed parse_json_safely() to parse_json_response()
- Removed temperature and max_tokens parameters from OpenAI calls
"""
import logging
from typing import Dict, List, Any, Optional
from langchain_core.messages import SystemMessage, HumanMessage
from pydantic import BaseModel, Field, ValidationError

from ..services.openai_service import OpenAIService
from ..utils.json_parser import SafeJsonParser
from ..prompting.strategies import PromptingStrategies
from ..validators import ODRLLogicalValidator

logger = logging.getLogger(__name__)


class ODRLComponents(BaseModel):
    """Extracted ODRL components from guidance text."""
    
    # Core ODRL elements
    actions: List[str] = Field(default_factory=list, description="Actions that can be performed")
    permissions: List[Dict[str, Any]] = Field(default_factory=list, description="Permitted actions with details")
    prohibitions: List[Dict[str, Any]] = Field(default_factory=list, description="Prohibited actions with details")
    constraints: List[Dict[str, Any]] = Field(default_factory=list, description="Constraints and conditions")
    
    # Data context
    data_categories: List[str] = Field(default_factory=list, description="Types of data involved")
    data_subjects: List[str] = Field(default_factory=list, description="Who the data is about")
    
    # Parties and roles
    parties: Dict[str, List[str]] = Field(default_factory=dict, description="Parties involved by role")
    
    # Additional context
    purpose: Optional[str] = Field(None, description="Purpose of processing")
    legal_basis: Optional[str] = Field(None, description="Legal basis for processing")
    geographic_scope: List[str] = Field(default_factory=list, description="Geographic applicability")
    
    # Evidence and verification
    evidence_requirements: List[str] = Field(default_factory=list, description="Evidence needed")
    verification_methods: List[str] = Field(default_factory=list, description="How to verify compliance")
    
    # Metadata
    confidence_score: float = Field(0.8, description="Confidence in extraction")
    extraction_reasoning: str = Field("", description="Reasoning for extraction")
    
    # Supervisor review metadata
    supervisor_reviewed: bool = Field(False, description="Whether supervisor reviewed classifications")
    supervisor_corrections: int = Field(0, description="Number of corrections made by supervisor")


class GuidanceAnalyzer:
    """
    Analyzes guidance text using LLM to extract ODRL components.
    Uses complex prompting strategies for accurate extraction.
    NOW INCLUDES: Supervisor agent for permission/prohibition review.
    """
    
    def __init__(self):
        """Initialize guidance analyzer with LLM service."""
        self.openai_service = OpenAIService()
        self.json_parser = SafeJsonParser()
    
    async def analyze_guidance(
        self, 
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        rule_id: str
    ) -> ODRLComponents:
        """
        Comprehensive analysis of guidance text to extract ODRL components.
        
        NEW: Includes supervisor review step between stages 4 and 5.
        
        Args:
            guidance_text: Complete guidance text
            rule_name: Name/title of the rule
            framework_type: DSS or DataVISA
            restriction_condition: restriction or condition
            rule_id: Unique identifier
            
        Returns:
            ODRLComponents with extracted and validated information
        """
        logger.info(f"Analyzing guidance for rule: {rule_name} ({rule_id})")
        
        # Multi-stage analysis for comprehensive extraction
        
        # Stage 1: Initial comprehensive analysis
        initial_analysis = await self._stage1_comprehensive_analysis(
            guidance_text, rule_name, framework_type, restriction_condition
        )
        
        # Stage 2: ODRL-specific extraction
        odrl_extraction = await self._stage2_odrl_extraction(
            guidance_text, rule_name, initial_analysis
        )
        
        # Stage 3: Constraint analysis
        constraint_analysis = await self._stage3_constraint_analysis(
            guidance_text, rule_name, odrl_extraction
        )
        
        # Stage 4: Data category identification
        data_categories = await self._stage4_data_category_identification(
            guidance_text, rule_name, constraint_analysis
        )
        
        # ═══════════════════════════════════════════════════════════════
        # NEW STAGE 4.5: SUPERVISOR REVIEW
        # ═══════════════════════════════════════════════════════════════
        # Before finalizing, have supervisor review permission/prohibition classifications
        reviewed_extraction = await self._stage4_5_supervisor_review(
            guidance_text, rule_name, odrl_extraction
        )
        
        # Stage 5: Synthesis and verification (using reviewed/corrected extraction)
        final_components = await self._stage5_synthesis(
            guidance_text, rule_name, framework_type, restriction_condition,
            initial_analysis, reviewed_extraction, constraint_analysis, data_categories
        )
        
        return final_components
    
    async def _stage1_comprehensive_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        framework_type: str,
        restriction_condition: str
    ) -> str:
        """Stage 1: Comprehensive understanding of guidance text."""
        
        prompt = PromptingStrategies.odrl_comprehensive_guidance_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition
        )
        
        messages = [
            SystemMessage(content="You are a legal and data protection expert analyzing regulatory guidance. Analyze text comprehensively to extract all relevant compliance requirements."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 1 analysis complete for {rule_name}")
        
        return response
    
    async def _stage2_odrl_extraction(
        self, 
        guidance_text: str, 
        rule_name: str,
        initial_analysis: str
    ) -> str:
        """Stage 2: Extract ODRL-specific components."""
        
        prompt = PromptingStrategies.odrl_component_extraction(
            guidance_text=guidance_text,
            rule_name=rule_name,
            initial_analysis=initial_analysis
        )
        
        messages = [
            SystemMessage(content="You are an ODRL specialist. Extract policy components according to ODRL ontology standards."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 2 ODRL extraction complete for {rule_name}")
        
        return response
    
    async def _stage3_constraint_analysis(
        self, 
        guidance_text: str, 
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """Stage 3: Detailed constraint analysis."""
        
        prompt = PromptingStrategies.odrl_constraint_analysis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            odrl_extraction=odrl_extraction
        )
        
        messages = [
            SystemMessage(content="You are an expert in ODRL constraints. Analyze and structure constraints according to ODRL specification."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 3 constraint analysis complete for {rule_name}")
        
        return response
    
    async def _stage4_data_category_identification(
        self, 
        guidance_text: str, 
        rule_name: str,
        constraint_analysis: str
    ) -> str:
        """Stage 4: Identify specific data categories."""
        
        prompt = PromptingStrategies.odrl_data_category_identification(
            guidance_text=guidance_text,
            rule_name=rule_name,
            constraint_analysis=constraint_analysis
        )
        
        messages = [
            SystemMessage(content="You are a data classification expert. Identify and categorize all types of data mentioned in regulatory guidance."),
            HumanMessage(content=prompt)
        ]
        
        response = await self.openai_service.chat_completion(messages)
        logger.info(f"Stage 4 data category identification complete for {rule_name}")
        
        return response
    
    async def _stage4_5_supervisor_review(
        self,
        guidance_text: str,
        rule_name: str,
        odrl_extraction: str
    ) -> str:
        """
        NEW STAGE 4.5: Supervisor review of permission/prohibition classification.
        
        This critical step prevents misclassification by having a supervisor agent
        review whether items were correctly classified as permissions or prohibitions
        based on the original guidance text context.
        
        Args:
            guidance_text: Original guidance text (source of truth)
            rule_name: Name of the rule being analyzed
            odrl_extraction: The ODRL extraction from stage 2
            
        Returns:
            Updated ODRL extraction with corrected classifications
        """
        logger.info(f"Stage 4.5: Supervisor review of classifications for {rule_name}")
        
        # Parse the ODRL extraction to get permissions and prohibitions
        try:
            # ✅ FIXED: Changed parse_json_safely to parse_json_response
            extraction_data = self.json_parser.parse_json_response(odrl_extraction)
            if not extraction_data or "error" in extraction_data:
                logger.warning(f"Could not parse ODRL extraction for supervisor review, using original")
                return odrl_extraction
            
            extracted_permissions = extraction_data.get("permissions", [])
            extracted_prohibitions = extraction_data.get("prohibitions", [])
            
            # If there are no permissions or prohibitions, skip supervisor review
            if not extracted_permissions and not extracted_prohibitions:
                logger.info("No permissions or prohibitions to review, skipping supervisor")
                return odrl_extraction
            
            # Build supervisor review prompt
            import json
            prompt = PromptingStrategies.supervisor_permission_prohibition_review(
                guidance_text=guidance_text,
                rule_name=rule_name,
                extracted_permissions=extracted_permissions,
                extracted_prohibitions=extracted_prohibitions,
                odrl_extraction=odrl_extraction
            )
            
            # Call supervisor agent
            messages = [
                SystemMessage(content=(
                    "You are a Supervisor Agent specializing in validating ODRL policy classifications. "
                    "Your role is CRITICAL: prevent misclassification of permissions and prohibitions by "
                    "carefully reviewing the original source text context. You are the final check before "
                    "policies are enforced. Be thorough and evidence-based in your review."
                )),
                HumanMessage(content=prompt)
            ]
            
            # ✅ FIXED: Removed temperature parameter
            supervisor_response = await self.openai_service.get_completion(messages)
            
            # ✅ FIXED: Changed parse_json_safely to parse_json_response
            review_data = self.json_parser.parse_json_response(supervisor_response.content)
            
            if not review_data or "error" in review_data:
                logger.warning(f"Could not parse supervisor review, using original extraction")
                return odrl_extraction
            
            # Check if corrections are needed
            overall_assessment = review_data.get("overall_assessment", {})
            requires_correction = overall_assessment.get("requires_correction", False)
            misclassifications_found = review_data.get("misclassifications_found", [])
            
            if requires_correction and misclassifications_found:
                logger.warning(
                    f"Supervisor found {len(misclassifications_found)} misclassifications in {rule_name}"
                )
                for misc in misclassifications_found:
                    logger.warning(f"  - {misc.get('issue', 'Unknown issue')}")
                
                # Use corrected permissions and prohibitions from supervisor
                corrected_permissions = review_data.get("corrected_permissions", extracted_permissions)
                corrected_prohibitions = review_data.get("corrected_prohibitions", extracted_prohibitions)
                
                # Update extraction data with corrections
                extraction_data["permissions"] = corrected_permissions
                extraction_data["prohibitions"] = corrected_prohibitions
                
                # Add supervisor metadata
                extraction_data["supervisor_reviewed"] = True
                extraction_data["supervisor_corrections"] = len(misclassifications_found)
                extraction_data["supervisor_review_summary"] = review_data.get("review_summary", "")
                
                # Convert back to string for next stage
                corrected_extraction = json.dumps(extraction_data, indent=2)
                
                logger.info(f"Supervisor corrections applied to {rule_name}")
                return corrected_extraction
            else:
                logger.info(f"Supervisor approved classifications for {rule_name} (no corrections needed)")
                # Add approval metadata
                extraction_data["supervisor_reviewed"] = True
                extraction_data["supervisor_corrections"] = 0
                extraction_data["supervisor_approval"] = "Classifications approved by supervisor"
                
                approved_extraction = json.dumps(extraction_data, indent=2)
                return approved_extraction
                
        except Exception as e:
            logger.error(f"Error in supervisor review for {rule_name}: {e}")
            logger.warning("Using original ODRL extraction due to supervisor review error")
            return odrl_extraction
    
    async def _stage5_synthesis(
        self,
        guidance_text: str,
        rule_name: str,
        framework_type: str,
        restriction_condition: str,
        initial_analysis: str,
        odrl_extraction: str,
        constraint_analysis: str,
        data_categories: str
    ) -> ODRLComponents:
        """Stage 5: Final synthesis and validation."""
        
        prompt = PromptingStrategies.odrl_final_synthesis(
            guidance_text=guidance_text,
            rule_name=rule_name,
            framework_type=framework_type,
            restriction_condition=restriction_condition,
            initial_analysis=initial_analysis,
            odrl_extraction=odrl_extraction,
            constraint_analysis=constraint_analysis,
            data_categories=data_categories
        )
        
        messages = [
            SystemMessage(content=(
                "You are a synthesis expert combining multiple analyses into final ODRL components. "
                "Synthesize complex analyses into precise, machine-readable ODRL structures. "
                "IMPORTANT: The permissions and prohibitions you receive have been reviewed by a supervisor agent. "
                "Trust the supervisor's classifications. "
                "CRITICAL: Avoid creating duplicate constraints in both permissions and prohibitions. "
                "Each constraint should appear in only ONE place. Use logical reasoning to determine "
                "whether a constraint belongs in permissions or prohibitions. "
                "Prefer positive framing (permissions with positive operators) over negative framing. "
                "Return only valid JSON with actual extracted data, not template instructions."
            )),
            HumanMessage(content=prompt)
        ]
        
        try:
            # ✅ FIXED: Removed temperature and max_tokens parameters
            logger.debug(f"Requesting LLM synthesis for {rule_name}")
            response = await self.openai_service.get_completion(messages)
            
            logger.debug(f"Received LLM response for {rule_name}")
            
            # ✅ FIXED: Changed parse_json_safely to parse_json_response
            parsed_data = self.json_parser.parse_json_response(response.content)
            
            if not parsed_data or "error" in parsed_data:
                logger.error(f"Failed to parse synthesis response for {rule_name}")
                logger.debug(f"Raw response: {response.content[:500]}...")
                return ODRLComponents(
                    extraction_reasoning="Failed to parse LLM response"
                )
            
            # Log LLM reasoning if provided
            if 'reasoning' in parsed_data:
                logger.info(f"LLM Reasoning for {rule_name}:")
                reasoning_lines = parsed_data['reasoning'].split('\n')
                for line in reasoning_lines[:10]:  # Log first 10 lines
                    if line.strip():
                        logger.info(f"  {line.strip()}")
                if len(reasoning_lines) > 10:
                    logger.info(f"  ... ({len(reasoning_lines) - 10} more lines)")
            
            # Sanitize data types to ensure proper structure
            logger.debug(f"Sanitizing parsed data for {rule_name}")
            
            # Ensure list fields are lists
            for key in ['actions', 'data_categories', 'data_subjects']:
                if key in parsed_data:
                    parsed_data[key] = self._sanitize_string_list(
                        parsed_data.get(key), 
                        f'{key}'
                    )
                else:
                    parsed_data[key] = []
            
            # Sanitize rule lists (permissions, prohibitions, constraints)
            for key in ['permissions', 'prohibitions', 'constraints']:
                if key in parsed_data:
                    parsed_data[key] = self._sanitize_dict_list(
                        parsed_data.get(key), 
                        f'{key}'
                    )
                else:
                    parsed_data[key] = []
            
            # Sanitize parties structure
            if 'parties' in parsed_data:
                if isinstance(parsed_data['parties'], dict):
                    for key in ['controllers', 'processors', 'assigners', 
                               'assignees', 'third_parties']:
                        if key in parsed_data['parties']:
                            if not isinstance(parsed_data['parties'][key], list):
                                logger.warning(
                                    f'parties.{key} is not a list, converting to empty list'
                                )
                                parsed_data['parties'][key] = []
                        else:
                            parsed_data['parties'][key] = []
                else:
                    logger.warning("parties is not a dict, creating empty structure")
                    parsed_data['parties'] = {
                        'controllers': [],
                        'processors': [],
                        'assigners': [],
                        'assignees': [],
                        'third_parties': []
                    }
            else:
                parsed_data['parties'] = {
                    'controllers': [],
                    'processors': [],
                    'assigners': [],
                    'assignees': [],
                    'third_parties': []
                }
            
            # Extract supervisor metadata from reviewed extraction
            try:
                # ✅ FIXED: Changed parse_json_safely to parse_json_response
                reviewed_data = self.json_parser.parse_json_response(odrl_extraction)
                if reviewed_data and not "error" in reviewed_data:
                    parsed_data['supervisor_reviewed'] = reviewed_data.get('supervisor_reviewed', False)
                    parsed_data['supervisor_corrections'] = reviewed_data.get('supervisor_corrections', 0)
            except:
                pass  # If we can't extract supervisor metadata, that's okay
            
            # Create ODRLComponents instance with sanitized data
            try:
                components = ODRLComponents(**parsed_data)
                logger.info(f"Successfully created ODRLComponents for {rule_name}")
                return components
            except ValidationError as e:
                logger.error(f"Validation error creating ODRLComponents: {e}")
                logger.debug(f"Parsed data: {parsed_data}")
                return ODRLComponents(
                    extraction_reasoning=f"Validation error: {str(e)}"
                )
        
        except Exception as e:
            logger.error(f"Error in synthesis stage: {e}", exc_info=True)
            return ODRLComponents(
                extraction_reasoning=f"Synthesis failed: {str(e)}"
            )
    
    def _sanitize_string_list(self, data: Any, field_name: str) -> List[str]:
        """
        Sanitize a field that should be a list of strings.
        Handles cases where LLM returns dicts, instructions, or malformed data.
        """
        if not data:
            return []
        
        if not isinstance(data, list):
            logger.warning(f"{field_name} is not a list, converting: {type(data)}")
            return []
        
        sanitized = []
        for item in data:
            if isinstance(item, str):
                # Skip instruction-like strings
                if len(item) > 200 or item.lower().startswith(('list all', 'include', 'complete list', 'use precise')):
                    logger.warning(f"Skipping instruction-like string in {field_name}: {item[:100]}")
                    continue
                sanitized.append(item)
            elif isinstance(item, dict):
                # Try to extract meaningful string from dict
                if 'name' in item:
                    sanitized.append(str(item['name']))
                elif 'category_name' in item:
                    sanitized.append(str(item['category_name']))
                elif 'action' in item:
                    sanitized.append(str(item['action']))
                else:
                    logger.warning(f"Dict in {field_name} has no extractable string: {item}")
            else:
                logger.warning(f"Non-string item in {field_name}: {type(item)}")
        
        return sanitized
    
    def _sanitize_dict_list(self, data: Any, field_name: str) -> List[Dict[str, Any]]:
        """
        Sanitize a field that should be a list of dictionaries.
        """
        if not data:
            return []
        
        if not isinstance(data, list):
            logger.warning(f"{field_name} is not a list, converting: {type(data)}")
            return []
        
        sanitized = []
        for item in data:
            if isinstance(item, dict):
                sanitized.append(item)
            else:
                logger.warning(f"Non-dict item in {field_name}: {type(item)}")
        
        return sanitized
