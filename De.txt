# üöÄ How to Run the Enhanced RDF Knowledge Graph Chatbot

This guide will walk you through setting up and running the Enhanced RDF Knowledge Graph Chatbot system.

## üìã Prerequisites

### Required Software
- **Python 3.11+** (3.11 or 3.12 recommended)
- **Docker & Docker Compose** (for easy deployment)
- **Git** (for cloning repositories)

### Azure Requirements
- **Azure OpenAI account** with deployed models:
  - `gpt-4o-mini` (for chat responses)
  - `text-embedding-3-large` (for vector embeddings)
- **Azure Active Directory** app registration with:
  - Tenant ID, Client ID, Client Secret
  - API permissions for Azure OpenAI

### Hardware Requirements
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 10GB free space
- **Network**: Internet connection for Azure OpenAI and Elasticsearch

## üõ†Ô∏è Step-by-Step Setup

### Step 1: Create Project Directory and Files

```bash
# Create main project directory
mkdir rdf-knowledge-chatbot
cd rdf-knowledge-chatbot

# Create directory structure
mkdir -p app/{config,core,utils,api,schemas} data logs temp

# Create all the Python files from the artifacts
# (Copy all the code from the artifacts into their respective files)
```

### Step 2: Install Dependencies

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your credentials
nano .env  # or use your preferred editor
```

**Required environment variables in `.env`:**
```bash
# Azure OpenAI Configuration
AZURE_TENANT_ID=your-tenant-id-here
AZURE_CLIENT_ID=your-client-id-here
AZURE_CLIENT_SECRET=your-client-secret-here
AZURE_ENDPOINT=https://your-openai-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key-here
AZURE_OPENAI_API_VERSION=2024-10-21

# Model Configuration
MODEL_NAME=gpt-4o-mini
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSIONS=3072
MAX_TOKENS=4000
TEMPERATURE=0.1

# Elasticsearch Configuration
ELASTICSEARCH_HOSTS=localhost:9200
ELASTICSEARCH_INDEX=rdf_knowledge_graph

# Application Settings
ONTOLOGY_PATH=data/ontology.ttl
LOG_LEVEL=INFO
```

### Step 4: Prepare Your Ontology

Place your RDF ontology file in the `data/` directory:

```bash
# Copy your ontology file
cp /path/to/your/ontology.ttl data/ontology.ttl

# OR create a sample ontology for testing
cat > data/ontology.ttl << 'EOF'
@prefix : <http://example.org/ontology#> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

# Ontology declaration
: rdf:type owl:Ontology ;
  rdfs:label "Sample Ontology"@en ;
  rdfs:comment "A sample ontology for testing"@en .

# Classes
:Person rdf:type owl:Class ;
        rdfs:label "Person"@en ;
        rdfs:comment "A human being"@en .

:Organization rdf:type owl:Class ;
              rdfs:label "Organization"@en ;
              rdfs:comment "A group of people with a common purpose"@en .

# Properties
:hasName rdf:type owl:DatatypeProperty ;
         rdfs:label "has name"@en ;
         rdfs:domain :Person ;
         rdfs:range xsd:string .

:worksFor rdf:type owl:ObjectProperty ;
          rdfs:label "works for"@en ;
          rdfs:domain :Person ;
          rdfs:range :Organization .

# Individuals
:john rdf:type :Person ;
      :hasName "John Doe" .

:acme rdf:type :Organization ;
      :hasName "ACME Corp" .

:john :worksFor :acme .
EOF
```

## üê≥ Option 1: Run with Docker (Recommended)

### Start Elasticsearch

```bash
# Start Elasticsearch first
docker run -d \
  --name elasticsearch \
  -p 9200:9200 \
  -p 9300:9300 \
  -e "discovery.type=single-node" \
  -e "xpack.security.enabled=false" \
  -e "ES_JAVA_OPTS=-Xms2g -Xmx2g" \
  docker.elastic.co/elasticsearch/elasticsearch:8.15.1

# Wait for Elasticsearch to be ready (about 30-60 seconds)
curl -X GET "localhost:9200/_cluster/health?wait_for_status=yellow&timeout=60s"
```

### Build and Run the Application

```bash
# Build the Docker image
docker build -t rdf-chatbot .

# Run the application
docker run -d \
  --name rdf-chatbot \
  -p 8000:8000 \
  --env-file .env \
  -v $(pwd)/data:/app/data:ro \
  -v $(pwd)/logs:/app/logs \
  --link elasticsearch:elasticsearch \
  -e ELASTICSEARCH_HOSTS=elasticsearch:9200 \
  rdf-chatbot

# Or use Docker Compose (easier)
docker-compose up -d
```

### Check Status

```bash
# Check if services are running
docker ps

# Check application logs
docker logs rdf-chatbot

# Test API health
curl http://localhost:8000/health
```

## üêç Option 2: Run Locally (Development)

### Start Elasticsearch

```bash
# Using Docker
docker run -d \
  --name elasticsearch \
  -p 9200:9200 \
  -e "discovery.type=single-node" \
  -e "xpack.security.enabled=false" \
  docker.elastic.co/elasticsearch/elasticsearch:8.15.1

# Verify Elasticsearch is running
curl http://localhost:9200
```

### Run the Application

#### Interactive Mode (Command Line)

```bash
# Activate virtual environment
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Run in interactive mode
python main.py

# OR explicitly specify interactive mode
python main.py interactive
```

#### API Mode (Web Service)

```bash
# Run API server
python main.py api

# Run on specific host/port
python main.py api --host 0.0.0.0 --port 8080

# Run with auto-reload for development
python main.py api --reload
```

#### Initialize Knowledge Base Only

```bash
# Initialize knowledge base without starting the chatbot
python main.py init

# Force rebuild of existing knowledge base
python scripts/initialize_kb.py --force
```

#### Health Check

```bash
# Check system health
python main.py health
```

## üîß Automated Setup (Easiest)

Use the setup script for automated configuration:

```bash
# Run the setup script
python setup.py

# This will:
# 1. Check dependencies
# 2. Configure environment (interactive)
# 3. Set up ontology
# 4. Install Python dependencies
# 5. Start Docker services
# 6. Test the installation
```

## üß™ Testing the Installation

### 1. Health Check

```bash
# Check API health
curl http://localhost:8000/health

# Expected response:
{
  "overall_healthy": true,
  "components": {
    "rdf_manager": {"healthy": true},
    "vector_store": {"healthy": true},
    "llm": {"healthy": true}
  }
}
```

### 2. Test Chat

```bash
# Test chat endpoint
curl -X POST "http://localhost:8000/chat" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is a Person?",
    "use_sparql_chain": true
  }'
```

### 3. Interactive Testing

```bash
# Run interactive mode
python main.py

# Try some queries:
You: What is a Person?
You: List all classes in the ontology
You: How are Person and Organization related?
```

## üìä Accessing the System

### Web Interfaces

- **API Documentation**: http://localhost:8000/docs
- **ReDoc Documentation**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health
- **Statistics**: http://localhost:8000/stats

### API Examples

```python
import requests

# Chat with the bot
response = requests.post("http://localhost:8000/chat", json={
    "message": "What classes are in this ontology?",
    "use_sparql_chain": True,
    "max_entities": 10
})
print(response.json()["response"])

# Search entities
response = requests.post("http://localhost:8000/search", json={
    "query": "person organization",
    "top_k": 5
})
print(response.json()["results"])

# Execute SPARQL
response = requests.post("http://localhost:8000/sparql", 
    params={"query": "SELECT ?class WHERE { ?class rdf:type owl:Class } LIMIT 5"})
print(response.json()["results"])

# Natural language to SPARQL
response = requests.post("http://localhost:8000/nl2sparql",
    params={"question": "Find all people in the ontology"})
print(response.json())
```

## üîç Monitoring and Logs

### View Logs

```bash
# Application logs
tail -f logs/chatbot.log

# Docker logs
docker logs -f rdf-chatbot

# Error logs
tail -f logs/errors.log
```

### Monitor Performance

```bash
# Get system statistics
curl http://localhost:8000/stats

# Check knowledge base status
curl http://localhost:8000/schema
```

## üêõ Troubleshooting

### Common Issues

#### 1. Elasticsearch Connection Failed

```bash
# Check if Elasticsearch is running
curl http://localhost:9200

# If not running, start it:
docker start elasticsearch

# Check logs:
docker logs elasticsearch
```

#### 2. Azure OpenAI Authentication Failed

```bash
# Test Azure credentials
python -c "
import os
from app.utils.auth_helper import get_azure_token
token = get_azure_token(
    os.getenv('AZURE_TENANT_ID'),
    os.getenv('AZURE_CLIENT_ID'), 
    os.getenv('AZURE_CLIENT_SECRET')
)
print('Token OK' if token else 'Token Failed')
"
```

#### 3. Ontology Loading Failed

```bash
# Validate ontology file
python scripts/validate_ontology.py data/ontology.ttl

# Check file permissions
ls -la data/ontology.ttl
```

#### 4. Knowledge Base Empty

```bash
# Force rebuild knowledge base
curl -X POST "http://localhost:8000/initialize" \
  -H "Content-Type: application/json" \
  -d '{"force_rebuild": true}'

# Check extraction logs
grep "entities" logs/chatbot.log
```

#### 5. Import Errors

```bash
# Check if all files are created
find app/ -name "*.py" -type f

# Make sure __init__.py files exist
find app/ -name "__init__.py"

# If missing, create them:
touch app/__init__.py
touch app/config/__init__.py
touch app/core/__init__.py
touch app/utils/__init__.py
touch app/api/__init__.py
touch app/schemas/__init__.py
```

### Debug Mode

```bash
# Run with debug logging
LOG_LEVEL=DEBUG python main.py

# Run with debug flag
python main.py api --debug
```

### Reset Everything

```bash
# Stop all containers
docker stop rdf-chatbot elasticsearch

# Remove containers
docker rm rdf-chatbot elasticsearch

# Clear logs
rm -rf logs/*

# Clear temporary files
rm -rf temp/*

# Restart fresh
docker-compose up -d
```

## üöÄ Production Deployment

### Docker Compose Production

```bash
# Use production compose file
docker-compose -f docker-compose.yml --profile monitoring up -d

# This includes:
# - Application container
# - Elasticsearch
# - Nginx reverse proxy
# - Monitoring (Prometheus/Grafana)
```

### Environment Variables for Production

```bash
# Production settings
DEBUG=false
LOG_LEVEL=INFO
LOG_TO_FILE=true

# Security
REQUIRE_AUTH=true
ADMIN_API_KEY=your-secure-api-key

# Performance
ELASTICSEARCH_HOSTS=elasticsearch-cluster:9200
MAX_QUERY_LENGTH=50000
```

### Health Monitoring

```bash
# Set up health check monitoring
curl http://localhost:8000/health

# Monitor metrics
curl http://localhost:8000/metrics

# Check performance
curl http://localhost:8000/stats
```

## üì± Quick Commands Reference

```bash
# Start everything with Docker
docker-compose up -d

# Interactive chat
python main.py

# API server
python main.py api

# Initialize knowledge base
python main.py init

# Health check
python main.py health

# View logs
docker logs rdf-chatbot

# Stop everything
docker-compose down

# Reset and restart
docker-compose down && docker-compose up -d
```

## üéØ Next Steps

1. **Customize your ontology**: Replace `data/ontology.ttl` with your domain-specific ontology
2. **Configure authentication**: Set up proper API keys for production
3. **Scale up**: Use multiple API instances behind a load balancer
4. **Monitor**: Set up proper monitoring and alerting
5. **Extend**: Add custom query processors or vector stores

Your Enhanced RDF Knowledge Graph Chatbot is now ready to use! üéâ
