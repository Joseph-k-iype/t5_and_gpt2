from rdflib import Graph
import pandas as pd

# Load RDF dataset
g = Graph()
g.parse("your_dataset.ttl", format="ttl")  # Replace with your RDF file

# Load the CSV data
csv_data = pd.read_csv("your_csv_file.csv")  # Columns: process, bde

# Convert the DataFrame to dictionaries for efficient processing
process_bde_dict = csv_data.to_dict(orient="records")  # List of dicts, e.g., [{'process': ..., 'bde': ...}, ...]

# Function to query SPARQL for all process-BDE combinations at once
def find_dimensions_and_apps_bulk(graph, process_bde_list):
    results = []
    for item in process_bde_list:
        process = item['process']
        bde = item['bde']
        query = f"""
        PREFIX ex: <http://example.org/>

        SELECT DISTINCT ?dimension ?app
        WHERE {{
            ?process a ex:Process ;
                     ex:hasName "{process}" ;
                     ex:hasBDE ?bde .
            ?bde ex:hasName "{bde}" ;
                 ex:hasDimension ?dimension .
            ?app ex:supportsProcess ?process ;
                 ex:supportsBDE ?bde .
        }}
        """
        for row in graph.query(query):
            results.append((process, bde, str(row['dimension']), str(row['app'])))
    return results

# Query RDF using the dictionary-based process-BDE list
bulk_results = find_dimensions_and_apps_bulk(g, process_bde_dict)

# Convert results to a DataFrame
results_df = pd.DataFrame(bulk_results, columns=['process', 'bde', 'dimension', 'app'])

# Group and count unique apps for each process-dimension combination
dimension_app_count = (
    results_df.groupby(['process', 'dimension'])
    .agg({'app': 'nunique'})  # Count unique apps per process-dimension
    .reset_index()
)

# Pivot to create a matrix with processes as rows and dimension combinations as columns
matrix = dimension_app_count.pivot_table(
    index='process',
    columns='dimension',
    values='app',
    fill_value=0
)

# Rename columns for better understanding
matrix.columns = [f"Apps for {col}" for col in matrix.columns]

# Display the optimized matrix
import ace_tools as tools; tools.display_dataframe_to_user(name="Optimized Process-Dimension-App Matrix", dataframe=matrix)
