"""
ODRL to Rego Conversion Agents
Individual agent implementations for the LangGraph workflow
"""
import json
import sys
from pathlib import Path
from typing import Dict, Any, List

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config import OPENAI_MODEL, Config
from .agent_state import AgentState, ConversionStage, ODRLComponentAnalysis, RegoValidationResult
from .rego_prompts import (
    ODRL_PARSER_PROMPT,
    TYPE_INFERENCE_PROMPT,
    LOGIC_ANALYZER_PROMPT,
    REGO_GENERATOR_PROMPT,
    REFLECTION_PROMPT,
    CORRECTION_PROMPT
)


class ODRLParserAgent:
    """
    Agent responsible for parsing and understanding ODRL JSON-LD documents.
    Uses Chain of Thought reasoning to extract policy components.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
        self.parser = JsonOutputParser()
    
    def parse_odrl(self, state: AgentState) -> AgentState:
        """
        Parse ODRL document and extract all components with semantic understanding.
        """
        # Create prompt with ODRL policy
        odrl_str = json.dumps(state.odrl_policy, indent=2)
        
        messages = [
            SystemMessage(content=ODRL_PARSER_PROMPT),
            HumanMessage(content=f"Parse this ODRL policy:\n{odrl_str}")
        ]
        
        # Get LLM response
        response = self.llm.invoke(messages)
        
        # Parse response
        try:
            analysis = self.parser.parse(response.content)
            
            # Update state
            state.odrl_analysis = ODRLComponentAnalysis(**analysis)
            state.reasoning_chain.append({
                "stage": "parsing",
                "reasoning": response.content
            })
            state.current_stage = ConversionStage.TYPE_INFERENCE
            state.messages.append("✓ ODRL parsing complete")
            
        except Exception as e:
            state.messages.append(f"✗ Error parsing ODRL: {str(e)}")
            state.error_message = str(e)
        
        return state


class TypeInferenceAgent:
    """
    Agent responsible for inferring types from ODRL constraints.
    Uses reasoning to determine appropriate Rego types.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    def infer_types(self, state: AgentState) -> AgentState:
        """
        Infer types for ODRL constraints and operators.
        """
        odrl_str = json.dumps(state.odrl_policy, indent=2)
        analysis_str = json.dumps(state.odrl_analysis.model_dump() if state.odrl_analysis else {}, indent=2)
        
        messages = [
            SystemMessage(content=TYPE_INFERENCE_PROMPT),
            HumanMessage(content=f"ODRL Policy:\n{odrl_str}\n\nAnalysis:\n{analysis_str}")
        ]
        
        response = self.llm.invoke(messages)
        
        state.reasoning_chain.append({
            "stage": "type_inference",
            "reasoning": response.content
        })
        state.current_stage = ConversionStage.LOGIC_ANALYSIS
        state.messages.append("✓ Type inference complete")
        
        return state


class LogicAnalyzerAgent:
    """
    Agent responsible for analyzing logical structure of ODRL policies.
    Ensures correct logical relationships and constraint composition.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    def analyze_logic(self, state: AgentState) -> AgentState:
        """
        Analyze logical structure and relationships.
        """
        odrl_str = json.dumps(state.odrl_policy, indent=2)
        
        messages = [
            SystemMessage(content=LOGIC_ANALYZER_PROMPT),
            HumanMessage(content=f"Analyze logic:\n{odrl_str}")
        ]
        
        response = self.llm.invoke(messages)
        
        state.reasoning_chain.append({
            "stage": "logic_analysis",
            "reasoning": response.content
        })
        state.current_stage = ConversionStage.REGO_GENERATION
        state.messages.append("✓ Logic analysis complete")
        
        return state


class RegoGeneratorAgent:
    """
    Agent responsible for generating Rego code from ODRL policies.
    Uses all previous analyses to create optimal Rego rules.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    def generate_rego(self, state: AgentState) -> AgentState:
        """
        Generate Rego code from all accumulated analyses.
        """
        # Compile all context
        context = {
            "odrl_policy": state.odrl_policy,
            "analysis": state.odrl_analysis.model_dump() if state.odrl_analysis else {},
            "reasoning_chain": state.reasoning_chain
        }
        
        context_str = json.dumps(context, indent=2)
        
        messages = [
            SystemMessage(content=REGO_GENERATOR_PROMPT),
            HumanMessage(content=f"Generate Rego:\n{context_str}")
        ]
        
        response = self.llm.invoke(messages)
        
        # Extract Rego code
        content = response.content
        if "```rego" in content:
            rego_code = content.split("```rego")[1].split("```")[0].strip()
        elif "```" in content:
            rego_code = content.split("```")[1].strip()
        else:
            rego_code = content
        
        state.generated_rego = rego_code
        state.reasoning_chain.append({
            "stage": "rego_generation",
            "reasoning": response.content
        })
        state.current_stage = ConversionStage.REFLECTION
        state.messages.append("✓ Rego generation complete")
        
        return state


class ReflectionAgent:
    """
    Agent responsible for self-reflection and validation.
    Reviews generated Rego code for correctness and completeness.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    def reflect(self, state: AgentState) -> AgentState:
        """
        Reflect on generated Rego code and identify issues.
        """
        messages = [
            SystemMessage(content=REFLECTION_PROMPT),
            HumanMessage(content=f"Validate:\n```rego\n{state.generated_rego}\n```")
        ]
        
        response = self.llm.invoke(messages)
        
        # Check if corrections needed
        needs_correction = any(keyword in response.content.lower() 
                             for keyword in ["error", "issue", "problem", "incorrect", "invalid"])
        
        if needs_correction:
            state.logical_issues.append(response.content)
            state.current_stage = ConversionStage.CORRECTION
            state.messages.append("⚠ Issues found, corrections needed")
        else:
            state.current_stage = ConversionStage.COMPLETED
            state.messages.append("✓ Validation passed")
        
        state.reasoning_chain.append({
            "stage": "reflection",
            "reasoning": response.content
        })
        
        return state


class CorrectionAgent:
    """
    Agent responsible for correcting issues in generated Rego code.
    Learns from validation feedback and applies corrections.
    """
    
    def __init__(self):
        if not Config.API_KEY:
            raise ValueError(
                "OPENAI_API_KEY environment variable is required. "
                "Please set it using: export OPENAI_API_KEY='your-api-key'"
            )
        
        self.llm = ChatOpenAI(
            model=OPENAI_MODEL,
            api_key=Config.API_KEY,
            base_url=Config.BASE_URL
        )
    
    def correct_rego(self, state: AgentState) -> AgentState:
        """
        Correct issues in Rego code based on validation feedback.
        """
        issues = "\n".join(state.logical_issues)
        
        correction_prompt = f"""
Fix the following Rego code:

```rego
{state.generated_rego}
```

Issues identified:
{issues}

Provide corrected code with explanations.
"""
        
        messages = [
            SystemMessage(content=CORRECTION_PROMPT),
            HumanMessage(content=correction_prompt)
        ]
        
        response = self.llm.invoke(messages)
        
        # Extract corrected code
        content = response.content
        if "```rego" in content:
            corrected_code = content.split("```rego")[1].split("```")[0].strip()
        elif "```" in content:
            corrected_code = content.split("```")[1].strip()
        else:
            corrected_code = content
        
        state.generated_rego = corrected_code
        state.correction_attempts += 1
        state.reasoning_chain.append({
            "stage": f"correction_{state.correction_attempts}",
            "reasoning": response.content
        })
        
        # Go back to reflection
        state.current_stage = ConversionStage.REFLECTION
        state.messages.append(f"✓ Correction attempt {state.correction_attempts} complete")
        
        return state
