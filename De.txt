"""
Advanced Prompting Strategies for Legal Document Analysis
Optimized for token efficiency while maintaining quality
"""

from typing import Optional, List, Dict, Any


class AdvancedPromptingStrategies:
    """
    Advanced prompting strategies with token optimization
    """
    
    def __init__(self, rule_name: str, jurisdiction: str):
        self.rule_name = rule_name
        self.jurisdiction = jurisdiction
    
    def get_react_agent_system_prompt(self) -> str:
        """
        OPTIMIZED: Concise ReAct agent system prompt
        """
        return f"""You are a legal document analyzer using ReAct methodology.

Rule: {self.rule_name}
Jurisdiction: {self.jurisdiction}

For each chunk:
1. THINK: What legal requirements are present?
2. ACT: Extract specific obligations, permissions, actions
3. OBSERVE: Structure findings as JSON

Extract:
- Description (what the rule requires)
- User actions (what users can/must/cannot do)
- System actions (what systems must implement)
- Duties (obligations for users/systems)
- Constraints (conditions, limitations)
- Rule type (permission/prohibition/obligation/combination)

Be concise and precise. Use plain English."""
    
    def get_multi_level_synthesis_prompt(
        self,
        level_1_analysis: str,
        level_2_analysis: str,
        level_3_analysis: str
    ) -> str:
        """
        OPTIMIZED: Concise multi-level synthesis prompt
        NOTE: Input analyses should be summaries, not full JSON
        """
        # Truncate if analyses are too long
        l1_truncated = level_1_analysis[:500] + "..." if len(level_1_analysis) > 500 else level_1_analysis
        l2_truncated = level_2_analysis[:500] + "..." if len(level_2_analysis) > 500 else level_2_analysis
        l3_truncated = level_3_analysis[:500] + "..." if len(level_3_analysis) > 500 else level_3_analysis
        
        return f"""Synthesize analyses from 3 document levels for "{self.rule_name}" in {self.jurisdiction}.

LEVEL 1 (Overview):
{l1_truncated}

LEVEL 2 (Details):
{l2_truncated}

LEVEL 3 (Technical):
{l3_truncated}

Integrate all insights into comprehensive JSON:
{{
    "description": "Complete description from all levels",
    "user_actions": ["all user actions"],
    "system_actions": ["all system actions"],
    "user_duties": ["all user obligations"],
    "system_duties": ["all system obligations"],
    "constraints": [{{"type": "...", "description": "..."}}],
    "rule_type": "permission/prohibition/obligation/combination",
    "confidence": "high/medium/low"
}}

Ensure:
- No contradictions between levels
- Progressively detailed (L1→L2→L3)
- Practical and implementable
- Complete coverage"""
    
    def get_reflection_prompt(self, current_analysis: str) -> str:
        """
        OPTIMIZED: Concise reflection prompt
        """
        # Truncate analysis for prompt
        analysis_truncated = current_analysis[:800] + "..." if len(current_analysis) > 800 else current_analysis
        
        return f"""Review this analysis for "{self.rule_name}":

{analysis_truncated}

Check:
1. Completeness - all requirements captured?
2. Accuracy - legally sound?
3. Clarity - understandable?
4. Actionability - implementable?

Provide:
- What's correct
- What needs improvement
- Enhanced final analysis (JSON format)

Be concise."""
    
    def get_chunk_analysis_prompt(
        self,
        chunk_text: str,
        chunk_context: str
    ) -> str:
        """
        OPTIMIZED: Concise chunk analysis prompt
        """
        return f"""Analyze this legal text chunk:

CONTEXT: {chunk_context}

TEXT:
{chunk_text}

Extract JSON:
{{
    "description": "What this chunk requires",
    "user_actions": ["specific actions"],
    "system_actions": ["system requirements"],
    "user_duties": ["user obligations"],
    "system_duties": ["system obligations"],
    "constraints": [{{"type": "...", "description": "..."}}],
    "rule_type": "type if determinable"
}}

Focus on this chunk only. Be precise."""
    
    def get_comprehensive_synthesis_prompt(
        self,
        chunk_analyses: List[Dict[str, Any]],
        total_chunks: int
    ) -> str:
        """
        OPTIMIZED: Concise comprehensive synthesis
        """
        # Summarize chunk analyses
        summaries = []
        for i, analysis in enumerate(chunk_analyses[:5]):  # Limit to first 5 for brevity
            desc = analysis.get("description", "")[:100]
            if desc:
                summaries.append(f"Chunk {i+1}: {desc}...")
        
        if len(chunk_analyses) > 5:
            summaries.append(f"... and {len(chunk_analyses) - 5} more chunks")
        
        chunks_summary = "\n".join(summaries) if summaries else "Multiple chunks analyzed"
        
        return f"""Synthesize {total_chunks} chunk analyses into final analysis:

{chunks_summary}

Provide comprehensive JSON with:
- Complete description
- All user/system actions
- All duties and constraints
- Rule type and confidence

Merge and deduplicate. Ensure completeness."""
    
    def get_decision_inference_prompt(self, rule_context: str) -> str:
        """
        OPTIMIZED: Concise decision inference prompt
        """
        # Truncate context
        context_truncated = rule_context[:600] + "..." if len(rule_context) > 600 else rule_context
        
        return f"""Identify decision scenarios in this rule:

{context_truncated}

For each scenario provide:
{{
    "scenario": "When does this apply?",
    "decision_type": "yes/no/maybe",
    "conditions": ["what conditions must be met"],
    "required_actions": ["actions if YES"],
    "prohibited_actions": ["actions if NO"]
}}

Focus on practical compliance decisions."""
    
    def get_action_extraction_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise action extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract actions from text:

{text_truncated}

Standard actions only: share, store, process, update, create

Provide JSON:
{{
    "user_actions": ["actions users take"],
    "system_actions": ["actions systems must do"]
}}

Map synonyms to standard actions."""
    
    def get_constraint_analysis_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise constraint extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract constraints from:

{text_truncated}

Provide JSON:
{{
    "constraints": [
        {{"type": "temporal/technical/procedural", "description": "..."}}
    ]
}}

Focus on conditions and limitations."""
    
    def get_duty_extraction_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Concise duty extraction
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Extract duties and obligations from:

{text_truncated}

Provide JSON:
{{
    "user_duties": ["what users must do"],
    "system_duties": ["what systems must do"]
}}

Focus on mandatory requirements."""
    
    def get_rule_classification_prompt(self, analysis: str) -> str:
        """
        OPTIMIZED: Concise rule classification
        """
        # Truncate analysis
        analysis_truncated = analysis[:600] + "..." if len(analysis) > 600 else analysis
        
        return f"""Classify this rule:

{analysis_truncated}

Determine:
- Rule type: permission/prohibition/obligation/combination
- Confidence: high/medium/low
- Reasoning: Brief justification

Provide JSON:
{{
    "rule_type": "...",
    "confidence": "...",
    "reasoning": "..."
}}"""
    
    def get_enterprise_context_prompt(self, text: str) -> str:
        """
        Extract enterprise-specific context
        """
        # Truncate text
        text_truncated = text[:800] + "..." if len(text) > 800 else text
        
        return f"""Identify enterprise-specific context from:

{text_truncated}

Extract:
- Organization name
- Internal tools/systems
- Specific processes
- Business units

Provide JSON:
{{
    "organization": "...",
    "tools": ["..."],
    "processes": ["..."],
    "business_units": ["..."]
}}"""
    
    def get_data_category_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Data category identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify data categories mentioned:

{text_truncated}

Common categories: personal data, sensitive data, financial data, health data, etc.

Provide JSON:
{{
    "data_categories": ["category1", "category2", ...]
}}"""
    
    def get_role_identification_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Role identification
        """
        # Truncate text
        text_truncated = text[:500] + "..." if len(text) > 500 else text
        
        return f"""Identify roles mentioned:

{text_truncated}

Common roles: data controller, data processor, data subject, third party, etc.

Provide JSON:
{{
    "roles": ["role1", "role2", ...]
}}"""
    
    def get_validation_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Validation prompt
        """
        # Create compact summary of analysis
        summary = f"""Rule: {analysis.get('description', 'N/A')[:200]}
User Actions: {len(analysis.get('user_actions', []))}
System Actions: {len(analysis.get('system_actions', []))}
Constraints: {len(analysis.get('constraints', []))}
Type: {analysis.get('rule_type', 'N/A')}"""
        
        return f"""Validate this analysis:

{summary}

Check for:
1. Logical consistency
2. Completeness
3. Accuracy
4. Missing information

Provide JSON:
{{
    "is_valid": true/false,
    "issues": ["issue1", "issue2", ...],
    "suggestions": ["suggestion1", "suggestion2", ...]
}}"""
    
    def get_merge_prompt(self, analyses: List[Dict[str, Any]]) -> str:
        """
        OPTIMIZED: Merge multiple analyses
        """
        # Create compact summaries
        summaries = []
        for i, analysis in enumerate(analyses[:3]):
            desc = analysis.get('description', '')[:100]
            summaries.append(f"Analysis {i+1}: {desc}...")
        
        if len(analyses) > 3:
            summaries.append(f"... and {len(analyses) - 3} more analyses")
        
        summary_text = "\n".join(summaries)
        
        return f"""Merge these analyses into one comprehensive analysis:

{summary_text}

Provide merged JSON with:
- Combined description
- All unique actions
- All unique constraints
- Unified rule type

Deduplicate and synthesize."""
    
    def get_refinement_prompt(self, analysis: Dict[str, Any], feedback: str) -> str:
        """
        OPTIMIZED: Refinement prompt based on feedback
        """
        # Create compact analysis summary
        summary = f"""Current analysis:
Description: {analysis.get('description', '')[:200]}...
Actions: {len(analysis.get('user_actions', []))} user, {len(analysis.get('system_actions', []))} system
Type: {analysis.get('rule_type', 'N/A')}"""
        
        return f"""Refine this analysis based on feedback:

{summary}

FEEDBACK:
{feedback[:300]}

Provide improved JSON with all required fields."""
    
    def get_summarization_prompt(self, full_analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Create concise summary of analysis
        """
        return f"""Create a concise summary (max 300 chars) of this analysis:

Rule: {full_analysis.get('rule_name', 'N/A')}
Description: {full_analysis.get('description', '')[:200]}
Actions: {len(full_analysis.get('user_actions', []))} user, {len(full_analysis.get('system_actions', []))} system
Type: {full_analysis.get('rule_type', 'N/A')}

Provide brief summary capturing key points."""
    
    def get_context_extraction_prompt(self, text: str) -> str:
        """
        OPTIMIZED: Extract key context from text
        """
        # Truncate text
        text_truncated = text[:600] + "..." if len(text) > 600 else text
        
        return f"""Extract key context from:

{text_truncated}

Identify:
- Main topic
- Key stakeholders
- Critical requirements
- Important conditions

Provide JSON:
{{
    "topic": "...",
    "stakeholders": ["..."],
    "requirements": ["..."],
    "conditions": ["..."]
}}"""
    
    def get_completeness_check_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Check analysis completeness
        """
        fields_present = []
        fields_missing = []
        
        required_fields = ['description', 'user_actions', 'system_actions', 'rule_type']
        for field in required_fields:
            if analysis.get(field):
                fields_present.append(field)
            else:
                fields_missing.append(field)
        
        return f"""Check completeness of analysis:

Present: {', '.join(fields_present)}
Missing: {', '.join(fields_missing)}

Rule: {self.rule_name}
Jurisdiction: {self.jurisdiction}

Is this analysis complete? What's missing?

Provide JSON:
{{
    "is_complete": true/false,
    "missing_elements": ["..."],
    "completeness_score": 0-100
}}"""
    
    def get_quality_assessment_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Assess analysis quality
        """
        # Create quality indicators
        has_description = bool(analysis.get('description'))
        has_actions = bool(analysis.get('user_actions') or analysis.get('system_actions'))
        has_type = bool(analysis.get('rule_type'))
        
        return f"""Assess quality of this analysis:

Rule: {self.rule_name}
Has description: {has_description}
Has actions: {has_actions}
Has type: {has_type}

Rate quality on:
1. Clarity (1-10)
2. Completeness (1-10)
3. Actionability (1-10)

Provide JSON:
{{
    "clarity_score": 0-10,
    "completeness_score": 0-10,
    "actionability_score": 0-10,
    "overall_quality": "high/medium/low",
    "recommendations": ["..."]
}}"""
    
    def get_consistency_check_prompt(self, analysis: Dict[str, Any]) -> str:
        """
        OPTIMIZED: Check internal consistency
        """
        rule_type = analysis.get('rule_type', 'unknown')
        has_permissions = 'permission' in rule_type.lower()
        has_prohibitions = 'prohibition' in rule_type.lower()
        has_obligations = 'obligation' in rule_type.lower()
        
        return f"""Check consistency of analysis:

Rule type: {rule_type}
Classified as permission: {has_permissions}
Classified as prohibition: {has_prohibitions}
Classified as obligation: {has_obligations}

User actions: {len(analysis.get('user_actions', []))}
System actions: {len(analysis.get('system_actions', []))}

Are rule type and actions consistent?

Provide JSON:
{{
    "is_consistent": true/false,
    "inconsistencies": ["..."],
    "suggestions": ["..."]
}}"""
