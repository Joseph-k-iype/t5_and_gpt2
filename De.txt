"""
Advanced GDPR Q&A Chatbot with Dynamic Multi-Agent ReAct Architecture + LangChain Elasticsearch

This system provides comprehensive, business-friendly answers using completely dynamic
approaches without any hardcoded terms or patterns.

Features:
- Fully dynamic term extraction and concept discovery
- AI-powered query analysis and intent detection
- Adaptive search strategies based on content analysis
- Self-learning document relationship discovery
- Dynamic QA chain selection based on query patterns
- LangChain Elasticsearch integration with hybrid search
- O3-mini reasoning model for intelligent analysis
- Direct OpenAI API integration for embeddings
- Business-friendly response formatting
- Data privacy focused responses only

Requirements:
- OpenAI API access with o3-mini model
- Elasticsearch with pre-indexed GDPR data
- Python 3.9+
- pip install langchain-elasticsearch langchain langchain-openai langchain-core elasticsearch

Environment Variables:
- OPENAI_API_KEY: Your OpenAI API key
- ES_USERNAME: Elasticsearch username
- ES_PASSWORD: Elasticsearch password
- ES_HOST: Elasticsearch host (default: localhost)
- ES_PORT: Elasticsearch port (default: 9200)
"""

import asyncio
import json
import logging
import os
import ssl
import uuid
import time
import sys
from datetime import datetime
from typing import Any, Dict, List, Optional, TypedDict, Annotated, Sequence, Tuple, Union, Callable
from dataclasses import dataclass, field
import re
from collections import defaultdict, Counter

# Core imports
import openai
from elasticsearch import Elasticsearch

# LangChain Elasticsearch integration
try:
    from langchain_elasticsearch import ElasticsearchStore, ElasticsearchRetriever
    from langchain_elasticsearch.vectorstores import DenseVectorStrategy, BM25Strategy
except ImportError:
    print("Error: langchain-elasticsearch not found. Install with: pip install langchain-elasticsearch")
    sys.exit(1)

# LangChain core
from langchain_core.documents import Document
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.runnables import RunnableConfig
from langchain_core.retrievers import BaseRetriever
from langchain_core.embeddings import Embeddings
from langchain_core.prompts import ChatPromptTemplate

# LangChain OpenAI
try:
    from langchain_openai import ChatOpenAI
except ImportError:
    print("Error: langchain-openai not found. Install with: pip install langchain-openai")
    sys.exit(1)

# LangChain QA chains
from langchain.chains import RetrievalQA, ConversationalRetrievalChain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain

# LangGraph
try:
    from langgraph.graph import StateGraph, MessagesState, START, END
    from langgraph.checkpoint.memory import MemorySaver
    from langgraph.store.memory import InMemoryStore
    from langgraph.prebuilt import ToolNode, create_react_agent
except ImportError:
    print("Error: langgraph not found. Install with: pip install langgraph")
    sys.exit(1)

# Pydantic
from pydantic import BaseModel, Field

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Configuration
class Config:
    """Configuration class with validation"""
    
    def __init__(self):
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        self.OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.ES_USERNAME = os.getenv("ES_USERNAME", "elastic")
        self.ES_PASSWORD = os.getenv("ES_PASSWORD")
        self.ES_HOST = os.getenv("ES_HOST", "localhost")
        
        # Validate required environment variables
        if not self.OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        if not self.ES_PASSWORD:
            raise ValueError("ES_PASSWORD environment variable is required")
        
        try:
            self.ES_PORT = int(os.getenv("ES_PORT", "9200"))
        except ValueError:
            self.ES_PORT = 9200
            
        self.ES_CACERT_PATH = os.getenv("ES_CACERT_PATH", "cacert.crt")
        
        # Model configurations
        self.REASONING_MODEL = "o3-mini-2025-01-31"
        self.EMBEDDING_MODEL = "text-embedding-3-large"
        self.EMBEDDING_DIMENSIONS = 3072
        self.REASONING_EFFORT = "high"
        
        # Search configurations
        self.MAX_SEARCH_RESULTS = 10
        self.SIMILARITY_THRESHOLD = 0.6
        self.MAX_CONTEXT_LENGTH = 8000

# Global config instance
try:
    config = Config()
except Exception as e:
    print(f"Configuration error: {e}")
    sys.exit(1)

# Enhanced Data Models
@dataclass
class SearchResult:
    """Enhanced search result with metadata"""
    content: str
    title: str
    document_type: str
    article_number: Optional[str]
    chapter_number: str
    score: float
    chunk_id: Optional[str] = None
    article_id: Optional[str] = None
    page_number: Optional[int] = None
    key_concepts: Optional[List[str]] = field(default_factory=list)
    supporting_references: Optional[List[Dict]] = field(default_factory=list)

@dataclass
class ConversationContext:
    """Conversation context and memory"""
    thread_id: str
    query: str
    intent: str = ""
    entities: List[str] = field(default_factory=list)
    previous_searches: List[Dict] = field(default_factory=list)
    conversation_history: List[BaseMessage] = field(default_factory=list)
    current_analysis: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DynamicConcepts:
    """Dynamically discovered concepts from documents"""
    terms: List[str] = field(default_factory=list)
    definitions: Dict[str, str] = field(default_factory=dict)
    relationships: Dict[str, List[str]] = field(default_factory=dict)
    importance_scores: Dict[str, float] = field(default_factory=dict)
    contexts: Dict[str, List[str]] = field(default_factory=dict)

class ChatbotState(TypedDict):
    """State for the chatbot workflow"""
    messages: Annotated[Sequence[BaseMessage], "The conversation messages"]
    current_query: str
    conversation_context: ConversationContext
    search_results: List[SearchResult]
    analysis_results: Dict[str, Any]
    final_answer: str
    citations: List[Dict]
    processing_stage: str

# Utility Functions
def safe_json_parse(json_string: str, fallback_value: Any = None) -> Any:
    """Safely parse JSON with fallback handling"""
    if not json_string or not isinstance(json_string, str):
        logger.warning(f"Invalid JSON input: {type(json_string)}")
        return fallback_value
    
    json_string = json_string.strip()
    
    # Try to extract JSON from markdown code blocks
    if "```json" in json_string:
        try:
            start_idx = json_string.find("```json") + 7
            end_idx = json_string.find("```", start_idx)
            if end_idx > start_idx:
                json_string = json_string[start_idx:end_idx].strip()
        except Exception:
            pass
    elif "```" in json_string:
        try:
            start_idx = json_string.find("```") + 3
            end_idx = json_string.find("```", start_idx)
            if end_idx > start_idx:
                json_string = json_string[start_idx:end_idx].strip()
        except Exception:
            pass
    
    # Multiple parsing attempts
    parse_attempts = [
        lambda: json.loads(json_string),
        lambda: json.loads(json_string.replace("'", '"')),
        lambda: json.loads(re.sub(r'(\w+):', r'"\1":', json_string)),
    ]
    
    for attempt in parse_attempts:
        try:
            result = attempt()
            if result is not None:
                return result
        except Exception:
            continue
    
    logger.error(f"Failed to parse JSON: {json_string[:200]}...")
    return fallback_value

def get_event_loop() -> asyncio.AbstractEventLoop:
    """Get or create event loop safely"""
    try:
        loop = asyncio.get_event_loop()
        if loop.is_closed():
            raise RuntimeError("Event loop is closed")
        return loop
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop

async def run_async_safe(coro):
    """Run async function safely in any context"""
    try:
        return await coro
    except Exception as e:
        logger.error(f"Error in async execution: {e}")
        raise

# Data Privacy Filter
class DataPrivacyFilter:
    """Filter to ensure responses are related to data privacy topics"""
    
    PRIVACY_KEYWORDS = [
        "gdpr", "data protection", "privacy", "personal data", "data controller",
        "data processor", "consent", "data subject", "data breach", "compliance",
        "regulation", "legal basis", "legitimate interest", "data rights",
        "erasure", "portability", "rectification", "processing", "security",
        "confidentiality", "integrity", "availability", "pseudonymization",
        "encryption", "data minimization", "purpose limitation", "accuracy",
        "storage limitation", "accountability", "privacy by design", "dpia",
        "data protection officer", "dpo", "supervisory authority", "cross-border",
        "transfer", "adequacy decision", "binding corporate rules", "bcr",
        "standard contractual clauses", "scc", "privacy policy", "cookie",
        "legitimate interests assessment", "lia", "records of processing",
        "data inventory", "privacy notice", "retention", "deletion", "anonymization",
        "special categories", "sensitive data", "children", "minors", "opt-in",
        "opt-out", "withdrawal", "transparency", "fairness", "lawfulness",
        "data sharing", "third party", "vendor", "sub-processor", "audit",
        "assessment", "impact", "risk", "mitigation", "breach notification",
        "72 hours", "penalty", "fine", "enforcement", "compliance framework",
        "iso 27001", "iso 27701", "soc 2", "privacy shield", "ccpa", "cpra",
        "lgpd", "pipeda", "data localization", "residency", "sovereignty"
    ]
    
    NON_PRIVACY_REJECTION_PHRASES = [
        "I'm designed to help with data privacy and GDPR-related questions.",
        "My expertise is focused on data protection regulations and privacy matters.",
        "I specialize in data privacy topics. Please ask questions related to GDPR, data protection, or privacy compliance.",
        "I can assist with questions about data privacy, GDPR compliance, and related regulations.",
        "My knowledge is specialized in data protection laws and privacy regulations."
    ]
    
    @classmethod
    def is_privacy_related(cls, query: str) -> bool:
        """Check if query is related to data privacy"""
        if not query:
            return False
        
        query_lower = query.lower()
        
        # Check for privacy keywords
        for keyword in cls.PRIVACY_KEYWORDS:
            if keyword in query_lower:
                return True
        
        # Check for privacy-related patterns
        privacy_patterns = [
            r'\bdata\s+(?:protection|privacy|security|breach)\b',
            r'\b(?:personal|sensitive|confidential)\s+(?:data|information)\b',
            r'\b(?:privacy|protection|compliance)\s+(?:law|regulation|requirement)\b',
            r'\b(?:user|customer|employee)\s+(?:data|information|privacy)\b',
            r'\b(?:collect|process|store|transfer|share)\s+(?:data|information)\b',
            r'\b(?:consent|permission|authorization|agreement)\b',
            r'\b(?:right|rights)\s+(?:to|of)\s+(?:access|erasure|portability|rectification)\b'
        ]
        
        for pattern in privacy_patterns:
            if re.search(pattern, query_lower):
                return True
        
        return False
    
    @classmethod
    def get_rejection_message(cls) -> str:
        """Get a polite rejection message for non-privacy queries"""
        import random
        return random.choice(cls.NON_PRIVACY_REJECTION_PHRASES)

# Dynamic Concept Discovery Engine
class DynamicConceptEngine:
    """Engine for dynamically discovering concepts, terms, and patterns from documents"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
        self.concept_cache: Dict[str, Any] = {}
        self.pattern_cache: Dict[str, List[str]] = {}
        self.relationship_cache: Dict[str, Dict] = {}
    
    async def extract_key_terms_from_query(self, query: str) -> List[str]:
        """Dynamically extract key terms from a query using AI"""
        if not query or not isinstance(query, str):
            return []
        
        # Check cache first
        cache_key = f"terms_{hash(query)}"
        if cache_key in self.concept_cache:
            return self.concept_cache[cache_key]
        
        system_prompt = """
        Analyze the given query and extract key terms, concepts, and entities that would be important 
        for searching legal/regulatory documents about data privacy and GDPR. Focus on:
        1. Data privacy terms and acronyms
        2. GDPR concepts
        3. Regulatory terms
        4. Compliance processes
        5. Roles and responsibilities
        
        Return only a JSON array of terms:
        ["term1", "term2", "term3"]
        """
        
        try:
            messages = [{"role": "user", "content": f"Extract key terms from: {query}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Parse JSON response
            terms = safe_json_parse(response, [])
            if not isinstance(terms, list):
                terms = []
            
            # Fallback if no terms found
            if not terms:
                terms = await self._fallback_term_extraction(query)
            
            # Cache result
            self.concept_cache[cache_key] = terms
            return terms
                
        except Exception as e:
            logger.error(f"Error in dynamic term extraction: {e}")
            return await self._fallback_term_extraction(query)
    
    async def _fallback_term_extraction(self, query: str) -> List[str]:
        """Fallback term extraction using basic NLP"""
        try:
            # Remove common words and extract potential terms
            words = re.findall(r'\b[A-Za-z]{3,}\b', query)
            
            # Common stop words to exclude
            stop_words = {
                'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'had', 
                'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 
                'how', 'man', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 
                'did', 'its', 'let', 'put', 'say', 'she', 'too', 'use', 'what', 'when',
                'where', 'why', 'with', 'this', 'that', 'they', 'them', 'than', 'then'
            }
            
            # Filter for meaningful terms
            meaningful_terms = []
            for word in words:
                if (len(word) >= 3 and 
                    word.lower() not in stop_words):
                    meaningful_terms.append(word.lower())
            
            return list(set(meaningful_terms))[:10]  # Limit to 10 terms
            
        except Exception as e:
            logger.error(f"Error in fallback term extraction: {e}")
            return []
    
    async def discover_document_concepts(self, documents: List[Document]) -> DynamicConcepts:
        """Dynamically discover concepts from a set of documents"""
        if not documents:
            return DynamicConcepts()
        
        try:
            # Combine document content for analysis
            combined_content = "\n".join([doc.page_content[:1000] for doc in documents[:5]])
            
            if not combined_content.strip():
                return DynamicConcepts()
            
            system_prompt = """
            Analyze the provided GDPR/data privacy document content and extract:
            1. Key terms and concepts (with importance scores 0-1)
            2. Definitions or explanations of terms
            3. Relationships between concepts
            4. Context where terms are used
            
            Return JSON in this format:
            {
                "terms": ["term1", "term2"],
                "definitions": {"term1": "definition", "term2": "definition"},
                "relationships": {"term1": ["related_term1", "related_term2"]},
                "importance_scores": {"term1": 0.9, "term2": 0.7},
                "contexts": {"term1": ["context1", "context2"]}
            }
            """
            
            messages = [{"role": "user", "content": f"Analyze this content:\n{combined_content}"}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            concept_data = safe_json_parse(response, {})
            if not isinstance(concept_data, dict):
                concept_data = {}
            
            return DynamicConcepts(
                terms=concept_data.get("terms", []),
                definitions=concept_data.get("definitions", {}),
                relationships=concept_data.get("relationships", {}),
                importance_scores=concept_data.get("importance_scores", {}),
                contexts=concept_data.get("contexts", {})
            )
                
        except Exception as e:
            logger.error(f"Error in concept discovery: {e}")
            return await self._fallback_concept_discovery(documents)
    
    async def _fallback_concept_discovery(self, documents: List[Document]) -> DynamicConcepts:
        """Fallback concept discovery using pattern matching"""
        try:
            all_text = " ".join([doc.page_content for doc in documents])
            
            if not all_text.strip():
                return DynamicConcepts()
            
            # Extract potential terms using patterns
            terms = []
            
            # Pattern 1: Capitalized terms
            capitalized_terms = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', all_text)
            terms.extend([term.lower() for term in capitalized_terms if len(term) > 3])
            
            # Pattern 2: Acronyms
            acronyms = re.findall(r'\b[A-Z]{2,}\b', all_text)
            terms.extend([term.lower() for term in acronyms])
            
            # Pattern 3: Quoted terms
            quoted_terms = re.findall(r'"([^"]*)"', all_text)
            terms.extend([term.lower() for term in quoted_terms if len(term) > 3])
            
            # Count frequency and calculate importance
            term_counts = Counter(terms)
            total_terms = sum(term_counts.values()) if term_counts else 1
            
            unique_terms = list(set(terms))[:20]  # Limit to top 20
            importance_scores = {term: term_counts[term] / total_terms for term in unique_terms}
            
            return DynamicConcepts(
                terms=unique_terms,
                definitions={},
                relationships={},
                importance_scores=importance_scores,
                contexts={}
            )
            
        except Exception as e:
            logger.error(f"Error in fallback concept discovery: {e}")
            return DynamicConcepts()
    
    async def generate_dynamic_search_patterns(self, query: str, discovered_terms: List[str]) -> List[str]:
        """Generate dynamic search patterns based on query and discovered terms"""
        if not query or not discovered_terms:
            return [query] if query else []
        
        system_prompt = """
        Given a query and discovered terms, generate effective search patterns for finding 
        definitions, explanations, and related content in GDPR/data privacy documents.
        
        Return JSON array of search patterns:
        ["pattern1", "pattern2", "pattern3"]
        """
        
        try:
            context = f"Query: {query}\nDiscovered terms: {', '.join(discovered_terms[:5])}"
            messages = [{"role": "user", "content": context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            patterns = safe_json_parse(response, [])
            if not isinstance(patterns, list):
                patterns = []
            
            # Fallback if no patterns generated
            if not patterns:
                patterns = await self._generate_fallback_patterns(query, discovered_terms)
            
            return patterns[:10]  # Limit to 10 patterns
                
        except Exception as e:
            logger.error(f"Error generating search patterns: {e}")
            return await self._generate_fallback_patterns(query, discovered_terms)
    
    async def _generate_fallback_patterns(self, query: str, discovered_terms: List[str]) -> List[str]:
        """Generate fallback search patterns"""
        patterns = [query] if query else []
        
        for term in discovered_terms[:5]:  # Use top 5 terms
            patterns.extend([
                f'"{term}" means',
                f'definition of {term}',
                f'{term} is defined as',
                f'{term} refers to',
                f'what is {term}',
                f'{term} requirements',
                f'{term} obligations'
            ])
        
        return patterns[:10]  # Limit to 10 patterns

# Custom Embeddings Wrapper for Direct OpenAI API
class DirectOpenAIEmbeddings(Embeddings):
    """Custom embeddings class that uses direct OpenAI API calls"""
    
    def __init__(self, openai_manager):
        self.openai_manager = openai_manager
        super().__init__()
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs synchronously"""
        try:
            loop = get_event_loop()
            if loop.is_running():
                # If we're in an async context, create a task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self._aembed_documents(texts))
                    return future.result()
            else:
                return asyncio.run(self._aembed_documents(texts))
        except Exception as e:
            logger.error(f"Error in embed_documents: {e}")
            return [[0.0] * config.EMBEDDING_DIMENSIONS for _ in texts]
    
    def embed_query(self, text: str) -> List[float]:
        """Embed query text synchronously"""
        try:
            loop = get_event_loop()
            if loop.is_running():
                # If we're in an async context, create a task
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self.openai_manager.create_embedding(text))
                    return future.result()
            else:
                return asyncio.run(self.openai_manager.create_embedding(text))
        except Exception as e:
            logger.error(f"Error in embed_query: {e}")
            return [0.0] * config.EMBEDDING_DIMENSIONS
    
    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Embed search docs asynchronously"""
        return await self._aembed_documents(texts)
    
    async def aembed_query(self, text: str) -> List[float]:
        """Embed query text asynchronously"""
        return await self.openai_manager.create_embedding(text)
    
    async def _aembed_documents(self, texts: List[str]) -> List[List[float]]:
        """Internal method to embed multiple documents"""
        embeddings = []
        for text in texts:
            try:
                embedding = await self.openai_manager.create_embedding(text)
                embeddings.append(embedding)
            except Exception as e:
                logger.error(f"Error embedding document: {e}")
                # Return zero vector as fallback
                embeddings.append([0.0] * config.EMBEDDING_DIMENSIONS)
        return embeddings

# Enhanced OpenAI Manager
class AdvancedOpenAIManager:
    """Advanced OpenAI manager with direct API integration"""
    
    def __init__(self):
        try:
            self.client = openai.OpenAI(
                api_key=config.OPENAI_API_KEY,
                base_url=config.OPENAI_BASE_URL
            )
            # Test connection
            self._test_connection()
        except Exception as e:
            logger.error(f"Failed to initialize OpenAI client: {e}")
            raise
    
    def _test_connection(self):
        """Test OpenAI connection"""
        try:
            # Test with a simple completion instead of listing models
            test_response = self.client.chat.completions.create(
                model=config.REASONING_MODEL,
                messages=[{"role": "user", "content": "test"}],
                reasoning_effort=config.REASONING_EFFORT
            )
            logger.info("OpenAI connection successful")
        except Exception as e:
            logger.error(f"OpenAI connection test failed: {e}")
            raise
    
    async def create_embedding(self, text: str) -> List[float]:
        """Create embedding using direct OpenAI API"""
        if not text or not isinstance(text, str):
            logger.warning("Empty or invalid text for embedding")
            return [0.0] * config.EMBEDDING_DIMENSIONS
        
        try:
            # Clean and truncate text for embedding
            clean_text = text.strip()[:8000]  # Limit text length
            
            response = self.client.embeddings.create(
                model=config.EMBEDDING_MODEL,
                input=clean_text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"Error creating embedding: {e}")
            raise
    
    async def reasoning_completion(self, messages: List[Dict], system_prompt: str = None) -> str:
        """Create completion using o3-mini with high reasoning effort"""
        if not messages:
            raise ValueError("Messages cannot be empty")
        
        try:
            formatted_messages = []
            
            if system_prompt:
                formatted_messages.append({"role": "developer", "content": system_prompt})
            
            formatted_messages.extend(messages)
            
            response = self.client.chat.completions.create(
                model=config.REASONING_MODEL,
                messages=formatted_messages,
                reasoning_effort=config.REASONING_EFFORT
            )
            
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"Error in reasoning completion: {e}")
            raise

# Dynamic Elasticsearch Manager
class DynamicElasticsearchManager:
    """Dynamic Elasticsearch manager that adapts to content and queries"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.concept_engine = DynamicConceptEngine(openai_manager)
        self.client = self._create_client()
        self.embeddings = DirectOpenAIEmbeddings(openai_manager)
        
        # Check and create indices if needed
        self._check_and_create_indices()
        
        # Initialize LangChain Elasticsearch stores
        self._setup_langchain_stores()
    
    def _create_client(self) -> Elasticsearch:
        """Create Elasticsearch client with SSL configuration"""
        try:
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE
            
            if os.path.exists(config.ES_CACERT_PATH):
                ssl_context.load_verify_locations(config.ES_CACERT_PATH)
            
            client = Elasticsearch(
                [{"host": config.ES_HOST, "port": config.ES_PORT, "scheme": "https"}],
                basic_auth=(config.ES_USERNAME, config.ES_PASSWORD),
                ssl_context=ssl_context,
                verify_certs=True,
                request_timeout=30,
                max_retries=3,
                retry_on_timeout=True
            )
            
            # Test connection
            info = client.info()
            logger.info(f"Connected to Elasticsearch: {info.get('version', {}).get('number', 'unknown')}")
            return client
            
        except Exception as e:
            logger.error(f"Failed to create Elasticsearch client: {e}")
            raise
    
    def _check_and_create_indices(self):
        """Check if indices exist and create them if needed"""
        try:
            # Check for gdpr_articles index
            if not self.client.indices.exists(index="gdpr_articles"):
                logger.warning("Index 'gdpr_articles' does not exist. Creating...")
                self.client.indices.create(
                    index="gdpr_articles",
                    body={
                        "mappings": {
                            "properties": {
                                "full_content": {"type": "text"},
                                "vector": {
                                    "type": "dense_vector",
                                    "dims": config.EMBEDDING_DIMENSIONS,
                                    "index": True,
                                    "similarity": "cosine"
                                },
                                "article_number": {"type": "keyword"},
                                "title": {"type": "text"},
                                "chapter_number": {"type": "keyword"}
                            }
                        }
                    }
                )
            
            # Check for gdpr_chunks index
            if not self.client.indices.exists(index="gdpr_chunks"):
                logger.warning("Index 'gdpr_chunks' does not exist. Creating...")
                self.client.indices.create(
                    index="gdpr_chunks",
                    body={
                        "mappings": {
                            "properties": {
                                "content": {"type": "text"},
                                "vector": {
                                    "type": "dense_vector",
                                    "dims": config.EMBEDDING_DIMENSIONS,
                                    "index": True,
                                    "similarity": "cosine"
                                },
                                "chunk_id": {"type": "keyword"},
                                "article_id": {"type": "keyword"},
                                "page_number": {"type": "integer"}
                            }
                        }
                    }
                )
        except Exception as e:
            logger.error(f"Error checking/creating indices: {e}")
    
    def _setup_langchain_stores(self):
        """Setup LangChain Elasticsearch stores for different indexes"""
        try:
            # Articles store - using simplified field names
            self.articles_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="gdpr_articles",
                embedding=self.embeddings,
                vector_query_field="vector",  # Fixed field name
                query_field="full_content",
                strategy=DenseVectorStrategy(
                    hybrid=False  # Disable hybrid search to avoid the error
                ),
                distance_strategy="COSINE"
            )
            logger.info("✓ Articles store initialized")
            
            # Chunks store - using simplified field names
            self.chunks_store = ElasticsearchStore(
                es_connection=self.client,
                index_name="gdpr_chunks",
                embedding=self.embeddings,
                vector_query_field="vector",  # Fixed field name
                query_field="content",
                strategy=DenseVectorStrategy(
                    hybrid=False  # Disable hybrid search to avoid the error
                ),
                distance_strategy="COSINE"
            )
            logger.info("✓ Chunks store initialized")
            
            # Create retrievers
            self.articles_retriever = self.articles_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 5}
            )
            
            self.chunks_retriever = self.chunks_store.as_retriever(
                search_type="similarity", 
                search_kwargs={"k": 10}
            )
            
            logger.info("✓ Dynamic LangChain Elasticsearch stores initialized successfully")
            
        except Exception as e:
            logger.error(f"Error setting up LangChain stores: {e}")
            raise
    
    async def dynamic_search_articles(self, query: str, k: int = 5) -> List[Document]:
        """Dynamic search that adapts based on query analysis"""
        if not query:
            return []
        
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            # Use similarity search without hybrid mode
            docs = self.articles_store.similarity_search(query=enhanced_query, k=k)
            return docs
        except Exception as e:
            logger.error(f"Error in dynamic article search: {e}")
            # Fallback to simple search
            try:
                return self.articles_store.similarity_search(query=query, k=k)
            except Exception as e2:
                logger.error(f"Fallback search also failed: {e2}")
                return []
    
    async def dynamic_search_chunks(self, query: str, k: int = 10) -> List[Document]:
        """Dynamic chunk search with adaptive strategies"""
        if not query:
            return []
        
        try:
            # Extract key terms dynamically
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Enhance query with discovered terms
            enhanced_query = await self._enhance_query_with_terms(query, key_terms)
            
            # Use similarity search without hybrid mode
            docs = self.chunks_store.similarity_search(query=enhanced_query, k=k)
            return docs
        except Exception as e:
            logger.error(f"Error in dynamic chunk search: {e}")
            # Fallback to simple search
            try:
                return self.chunks_store.similarity_search(query=query, k=k)
            except Exception as e2:
                logger.error(f"Fallback search also failed: {e2}")
                return []
    
    async def find_definitions_dynamically(self, query: str) -> List[Document]:
        """Dynamically find definitions using AI-generated search patterns"""
        if not query:
            return []
        
        try:
            # Extract terms that might need definition
            key_terms = await self.concept_engine.extract_key_terms_from_query(query)
            
            # Generate dynamic search patterns for definitions
            search_patterns = await self.concept_engine.generate_dynamic_search_patterns(query, key_terms)
            
            all_results = []
            for pattern in search_patterns[:5]:  # Use top 5 patterns
                try:
                    results = self.chunks_store.similarity_search(query=pattern, k=2)
                    all_results.extend(results)
                except Exception as e:
                    logger.warning(f"Error with search pattern '{pattern}': {e}")
                    continue
            
            # Remove duplicates based on content
            seen_content = set()
            unique_results = []
            for doc in all_results:
                content_hash = hash(doc.page_content[:200])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_results.append(doc)
            
            return unique_results[:8]  # Return top 8 unique results
            
        except Exception as e:
            logger.error(f"Error finding definitions dynamically: {e}")
            return []
    
    async def discover_cross_references_dynamically(self, query: str) -> List[Document]:
        """Dynamically discover cross-references using content analysis"""
        if not query:
            return []
        
        try:
            # First, get initial relevant documents
            initial_docs = await self.dynamic_search_chunks(query, k=5)
            
            if not initial_docs:
                return []
            
            # Discover concepts from initial documents
            concepts = await self.concept_engine.discover_document_concepts(initial_docs)
            
            # Use discovered concepts to find related content
            related_docs = []
            for term in concepts.terms[:5]:  # Use top 5 discovered terms
                try:
                    # Search for documents containing the discovered term
                    term_docs = self.chunks_store.similarity_search(query=term, k=3)
                    related_docs.extend(term_docs)
                except Exception as e:
                    logger.warning(f"Error searching for term '{term}': {e}")
                    continue
            
            # Remove duplicates and original documents
            initial_content_hashes = {hash(doc.page_content[:200]) for doc in initial_docs}
            
            unique_related = []
            seen_content = set()
            for doc in related_docs:
                content_hash = hash(doc.page_content[:200])
                if (content_hash not in seen_content and 
                    content_hash not in initial_content_hashes):
                    seen_content.add(content_hash)
                    unique_related.append(doc)
            
            return unique_related[:8]  # Return top 8 cross-references
            
        except Exception as e:
            logger.error(f"Error discovering cross-references dynamically: {e}")
            return []
    
    async def _enhance_query_with_terms(self, original_query: str, key_terms: List[str]) -> str:
        """Enhance query with dynamically discovered terms"""
        if not key_terms or not original_query:
            return original_query
        
        # Use AI to intelligently combine query with terms
        system_prompt = """
        Enhance the original query by incorporating the key terms in a natural way 
        that would improve search results in GDPR/data privacy documents.
        
        Return only the enhanced query string.
        """
        
        try:
            context = f"Original query: {original_query}\nKey terms: {', '.join(key_terms[:5])}"
            messages = [{"role": "user", "content": context}]
            enhanced_query = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            # Clean the response
            enhanced_query = enhanced_query.strip().strip('"\'')
            
            return enhanced_query if enhanced_query else original_query
            
        except Exception as e:
            logger.error(f"Error enhancing query: {e}")
            # Fallback: simple concatenation
            return f"{original_query} {' '.join(key_terms[:3])}"

# Dynamic Retriever for QA Chains
class DynamicElasticsearchRetriever(BaseRetriever):
    """Dynamic retriever that adapts its search strategy based on query analysis"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        super().__init__()
        self._es_manager = es_manager
    
    @property
    def es_manager(self) -> DynamicElasticsearchManager:
        """Get the Elasticsearch manager"""
        return self._es_manager
    
    def _get_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:
        """Synchronous wrapper for async search"""
        try:
            loop = get_event_loop()
            if loop.is_running():
                # If we're already in an event loop, we need to handle this differently
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, self._aget_relevant_documents(query))
                    return future.result()
            else:
                return asyncio.run(self._aget_relevant_documents(query))
        except Exception as e:
            logger.error(f"Error in _get_relevant_documents: {e}")
            return []
    
    async def _aget_relevant_documents(self, query: str, *, run_manager=None) -> List[Document]:
        """Get relevant documents using dynamic search strategies"""
        try:
            # Dynamic multi-strategy search
            article_docs = await self._es_manager.dynamic_search_articles(query, k=3)
            chunk_docs = await self._es_manager.dynamic_search_chunks(query, k=5)
            
            # Dynamic definition finding
            definition_docs = await self._es_manager.find_definitions_dynamically(query)
            
            # Dynamic cross-reference discovery
            cross_ref_docs = await self._es_manager.discover_cross_references_dynamically(query)
            
            # Combine all results
            all_docs = article_docs + chunk_docs + definition_docs + cross_ref_docs
            
            # Remove duplicates and limit results
            seen_content = set()
            unique_docs = []
            for doc in all_docs:
                content_hash = hash(doc.page_content[:200])
                if content_hash not in seen_content:
                    seen_content.add(content_hash)
                    unique_docs.append(doc)
                
                if len(unique_docs) >= config.MAX_SEARCH_RESULTS:
                    break
            
            return unique_docs
            
        except Exception as e:
            logger.error(f"Error in dynamic retriever: {e}")
            return []

# Dynamic QA Chain Manager
class DynamicQAChainManager:
    """Dynamic QA Chain Manager that adapts chain selection based on query analysis"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        self.es_manager = es_manager
        
        # Create retriever with proper error handling
        try:
            self.retriever = DynamicElasticsearchRetriever(es_manager)
        except Exception as e:
            logger.error(f"Error creating dynamic retriever: {e}")
            raise
        
        # Create LLM without temperature/token limits
        self.llm = ChatOpenAI(
            model=config.REASONING_MODEL,
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_BASE_URL
        )
        
        self._setup_dynamic_chains()
    
    def _setup_dynamic_chains(self):
        """Setup QA chains with dynamic prompts"""
        try:
            # 1. Basic RetrievalQA Chain
            self.retrieval_qa = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.retriever,
                return_source_documents=True
            )
            
            # 2. Conversational Retrieval Chain
            self.conversational_qa = ConversationalRetrievalChain.from_llm(
                llm=self.llm,
                retriever=self.retriever,
                return_source_documents=True
            )
            
            # 3. Dynamic Business Chain
            self.business_chain = create_stuff_documents_chain(
                self.llm,
                self._create_dynamic_business_prompt()
            )
            self.business_retrieval_chain = create_retrieval_chain(self.retriever, self.business_chain)
            
            # 4. Dynamic Definition Chain
            self.definition_chain = create_stuff_documents_chain(
                self.llm,
                self._create_dynamic_definition_prompt()
            )
            self.definition_retrieval_chain = create_retrieval_chain(self.retriever, self.definition_chain)
            
            # 5. Dynamic Compliance Chain
            self.compliance_chain = create_stuff_documents_chain(
                self.llm,
                self._create_dynamic_compliance_prompt()
            )
            self.compliance_retrieval_chain = create_retrieval_chain(self.retriever, self.compliance_chain)
            
        except Exception as e:
            logger.error(f"Error setting up dynamic chains: {e}")
            raise
    
    def _create_dynamic_business_prompt(self) -> ChatPromptTemplate:
        """Create dynamic business-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are a business consultant specializing in GDPR and data privacy compliance. 
            Analyze the provided context to answer questions in a business-friendly way.
            
            Adapt your response structure based on the query type:
            - For complex queries: Use structured sections with clear headings
            - For simple queries: Provide direct, concise answers
            - For technical queries: Include practical implementation guidance
            - For strategic queries: Focus on business implications and decisions
            
            Always cite specific sources and focus on actionable insights for GDPR compliance."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    def _create_dynamic_definition_prompt(self) -> ChatPromptTemplate:
        """Create dynamic definition-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are an expert in GDPR terminology and data privacy definitions.
            Analyze the context to provide comprehensive explanations that are:
            
            1. Precise and legally accurate
            2. Contextually relevant to GDPR and data protection
            3. Supplemented with practical examples when helpful
            4. Connected to related data privacy concepts when relevant
            5. Tailored to the user's apparent knowledge level
            
            Adapt your explanation depth based on the complexity of the term being defined."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    def _create_dynamic_compliance_prompt(self) -> ChatPromptTemplate:
        """Create dynamic compliance-focused prompt"""
        return ChatPromptTemplate.from_messages([
            ("system", """You are a GDPR compliance specialist with deep regulatory expertise.
            Analyze the context to provide compliance guidance that includes:
            
            1. Specific GDPR requirements and obligations
            2. Responsible parties and their roles
            3. Implementation timelines and deadlines
            4. Risk assessment and mitigation strategies
            5. Monitoring and reporting requirements
            
            Tailor your guidance to the specific context and scale of the inquiry."""),
            ("human", "Context: {context}\n\nQuestion: {input}")
        ])
    
    async def choose_optimal_chain_dynamically(self, query: str, context: ConversationContext) -> str:
        """Dynamically choose the best QA chain based on AI analysis"""
        if not query:
            return "business"
        
        system_prompt = """
        Analyze the query about GDPR/data privacy and context to determine the optimal response approach.
        Consider:
        1. Query intent and complexity
        2. Required expertise level
        3. Expected response format
        4. User context and background
        
        Return one of: "definition", "compliance", "business", "conversational", "retrieval"
        """
        
        try:
            analysis_context = f"Query: {query}\nContext: {context.current_analysis}"
            messages = [{"role": "user", "content": analysis_context}]
            response = await self.es_manager.openai_manager.reasoning_completion(messages, system_prompt)
            
            chain_type = response.strip().lower()
            if chain_type in ["definition", "compliance", "business", "conversational", "retrieval"]:
                return chain_type
            else:
                return "business"  # Default fallback
                
        except Exception as e:
            logger.error(f"Error in dynamic chain selection: {e}")
            return "business"  # Default fallback
    
    async def answer_with_dynamic_chain(self, query: str, context: ConversationContext, 
                                      chain_type: str = None) -> Dict[str, Any]:
        """Answer using dynamically selected QA chain"""
        if not query:
            return {
                "answer": "Please provide a question.",
                "source_documents": [],
                "chain_type": "error"
            }
        
        try:
            if not chain_type:
                chain_type = await self.choose_optimal_chain_dynamically(query, context)
            
            logger.info(f"Using dynamic QA chain: {chain_type}")
            
            if chain_type == "definition":
                result = await self.definition_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "definition"
                }
            
            elif chain_type == "compliance":
                result = await self.compliance_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "compliance"
                }
            
            elif chain_type == "conversational":
                # Format chat history dynamically
                chat_history = []
                messages = context.conversation_history
                for i in range(0, len(messages)-1, 2):
                    if i+1 < len(messages):
                        human_msg = messages[i]
                        ai_msg = messages[i+1]
                        if hasattr(human_msg, 'content') and hasattr(ai_msg, 'content'):
                            chat_history.append((human_msg.content, ai_msg.content))
                
                result = await self.conversational_qa.ainvoke({
                    "question": query,
                    "chat_history": chat_history
                })
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "conversational"
                }
            
            elif chain_type == "retrieval":
                result = self.retrieval_qa.invoke({"query": query})
                return {
                    "answer": result["result"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "retrieval"
                }
            
            else:  # business or default
                result = await self.business_retrieval_chain.ainvoke({"input": query})
                return {
                    "answer": result["answer"],
                    "source_documents": result.get("context", []),
                    "chain_type": "business"
                }
                
        except Exception as e:
            logger.error(f"Error in dynamic QA chain {chain_type}: {e}")
            # Fallback to basic retrieval
            try:
                result = self.retrieval_qa.invoke({"query": query})
                return {
                    "answer": result["result"],
                    "source_documents": result.get("source_documents", []),
                    "chain_type": "fallback"
                }
            except Exception as e2:
                logger.error(f"Fallback chain also failed: {e2}")
                return {
                    "answer": f"I apologize, but I encountered an error processing your question: {str(e)}",
                    "source_documents": [],
                    "chain_type": "error"
                }

# Dynamic Search Agent
class DynamicSearchAgent:
    """Agent that performs intelligent, adaptive search operations"""
    
    def __init__(self, es_manager: DynamicElasticsearchManager):
        self.es_manager = es_manager
        self.name = "DynamicSearchAgent"
    
    async def comprehensive_dynamic_search(self, query: str, context: ConversationContext) -> List[SearchResult]:
        """Perform comprehensive search with dynamic adaptation"""
        if not query:
            return []
        
        try:
            # Use dynamic search methods
            article_docs = await self.es_manager.dynamic_search_articles(query, k=3)
            chunk_docs = await self.es_manager.dynamic_search_chunks(query, k=5)
            
            # Dynamic definition finding
            definition_docs = await self.es_manager.find_definitions_dynamically(query)
            
            # Dynamic cross-reference discovery
            cross_ref_docs = await self.es_manager.discover_cross_references_dynamically(query)
            
            # Convert Documents to SearchResults
            all_results = []
            
            for doc_list, doc_type in [
                (article_docs, "article"),
                (chunk_docs, "chunk"), 
                (definition_docs, "definition"),
                (cross_ref_docs, "cross_reference")
            ]:
                for doc in doc_list:
                    result = self._document_to_search_result(doc, doc_type)
                    if result:
                        all_results.append(result)
            
            # Remove duplicates and rank by relevance
            seen_content = set()
            unique_results = []
            for result in all_results:
                content_hash = hash(result.content[:200])
                if content_hash not in seen_content and result.score > config.SIMILARITY_THRESHOLD:
                    seen_content.add(content_hash)
                    unique_results.append(result)
            
            # Sort by score and limit results
            unique_results.sort(key=lambda x: x.score, reverse=True)
            return unique_results[:config.MAX_SEARCH_RESULTS]
            
        except Exception as e:
            logger.error(f"Error in comprehensive dynamic search: {e}")
            return []
    
    def _document_to_search_result(self, doc: Document, doc_type: str) -> Optional[SearchResult]:
        """Convert LangChain Document to SearchResult"""
        try:
            metadata = doc.metadata if hasattr(doc, 'metadata') else {}
            
            # Extract score from metadata or use default
            score = float(metadata.get('_score', 0.8))
            
            result = SearchResult(
                content=doc.page_content,
                title=metadata.get('title', f'{doc_type.title()} Document'),
                document_type=metadata.get('document_type', 'Unknown'),
                article_number=metadata.get('article_number'),
                chapter_number=metadata.get('chapter_number', 'Unknown'),
                score=score,
                chunk_id=metadata.get('chunk_id'),
                article_id=metadata.get('article_id'),
                page_number=metadata.get('page_number'),
                key_concepts=metadata.get('key_concepts', []),
                supporting_references=metadata.get('supporting_references', [])
            )
            
            return result
            
        except Exception as e:
            logger.error(f"Error converting document to search result: {e}")
            return None

# Dynamic Analysis Agent
class DynamicAnalysisAgent:
    """Agent that performs adaptive query and content analysis"""
    
    def __init__(self, openai_manager: AdvancedOpenAIManager):
        self.openai_manager = openai_manager
        self.name = "DynamicAnalysisAgent"
    
    async def analyze_query_dynamically(self, query: str, context: ConversationContext) -> Dict[str, Any]:
        """Perform dynamic, adaptive query analysis"""
        if not query:
            return {
                "intent": "unknown",
                "complexity": "simple",
                "entities": [],
                "domain_focus": "general",
                "requires_cross_analysis": False,
                "optimal_approach": "business",
                "response_format": "simple",
                "reasoning": "Empty query provided"
            }
        
        system_prompt = """
        Perform a comprehensive analysis of the user's GDPR/data privacy query. Consider:
        
        1. Primary intent and secondary objectives
        2. Complexity level and required expertise
        3. Key entities, concepts, and relationships
        4. Context clues and domain indicators
        5. Optimal response format and approach
        6. Cross-document analysis requirements
        7. Business vs technical vs legal focus
        
        Adapt your analysis to the specific query characteristics.
        
        Return JSON:
        {
            "intent": "primary intent",
            "complexity": "simple|moderate|complex",
            "entities": ["entity1", "entity2"],
            "domain_focus": "business|technical|legal|mixed",
            "requires_cross_analysis": boolean,
            "optimal_approach": "approach_type",
            "response_format": "format_type",
            "reasoning": "analysis reasoning"
        }
        """
        
        try:
            analysis_context = f"Query: {query}\nPrevious context: {context.current_analysis}"
            messages = [{"role": "user", "content": analysis_context}]
            response = await self.openai_manager.reasoning_completion(messages, system_prompt)
            
            analysis = safe_json_parse(response, {})
            if not isinstance(analysis, dict):
                analysis = {}
            
            # Ensure all required fields are present
            return {
                "intent": analysis.get("intent", "explanation"),
                "complexity": analysis.get("complexity", "moderate"),
                "entities": analysis.get("entities", []),
                "domain_focus": analysis.get("domain_focus", "mixed"),
                "requires_cross_analysis": analysis.get("requires_cross_analysis", False),
                "optimal_approach": analysis.get("optimal_approach", "business"),
                "response_format": analysis.get("response_format", "structured"),
                "reasoning": analysis.get("reasoning", "Analysis completed")
            }
                
        except Exception as e:
            logger.error(f"Error in dynamic query analysis: {e}")
            return await self._adaptive_fallback_analysis(query, context)
    
    async def _adaptive_fallback_analysis(self, query: str, context: ConversationContext) -> Dict[str, Any]:
        """Adaptive fallback analysis based on query patterns"""
        if not query:
            return {
                "intent": "unknown",
                "complexity": "simple",
                "entities": [],
                "domain_focus": "general",
                "requires_cross_analysis": False,
                "optimal_approach": "business",
                "response_format": "simple",
                "reasoning": "Fallback analysis for empty query"
            }
        
        try:
            query_lower = query.lower()
            
            # Dynamic intent detection
            intent = "explanation"  # default
            if any(word in query_lower for word in ['what is', 'define', 'definition', 'meaning']):
                intent = "definition"
            elif any(word in query_lower for word in ['how to', 'implement', 'comply', 'requirement']):
                intent = "compliance"
            elif any(word in query_lower for word in ['difference', 'compare', 'versus', 'vs']):
                intent = "comparison"
            
            # Dynamic complexity assessment
            complexity = "moderate"
            if len(query.split()) < 5:
                complexity = "simple"
            elif len(query.split()) > 15 or any(word in query_lower for word in ['comprehensive', 'detailed', 'analysis']):
                complexity = "complex"
            
            return {
                "intent": intent,
                "complexity": complexity,
                "entities": [],
                "domain_focus": "mixed",
                "requires_cross_analysis": complexity == "complex",
                "optimal_approach": "business",
                "response_format": "structured",
                "reasoning": "Adaptive fallback analysis based on query patterns"
            }
        except Exception as e:
            logger.error(f"Error in fallback analysis: {e}")
            return {
                "intent": "unknown",
                "complexity": "simple",
                "entities": [],
                "domain_focus": "general",
                "requires_cross_analysis": False,
                "optimal_approach": "business",
                "response_format": "simple",
                "reasoning": f"Error in analysis: {str(e)}"
            }

# Dynamic Tools for ReAct Agent

@tool
async def dynamic_search_tool(query: str, search_strategy: str = "adaptive", 
                            k: int = 5, config: RunnableConfig = None) -> str:
    """
    Perform dynamic search that adapts its strategy based on query analysis.
    
    Args:
        query: The search query
        search_strategy: Strategy type ("adaptive", "articles", "chunks", "definitions", "cross_references")
        k: Maximum number of results
    
    Returns:
        Formatted search results
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        es_manager = config["configurable"]["es_manager"]
        
        if search_strategy == "articles":
            docs = await es_manager.dynamic_search_articles(query, k=k)
        elif search_strategy == "chunks":
            docs = await es_manager.dynamic_search_chunks(query, k=k)
        elif search_strategy == "definitions":
            docs = await es_manager.find_definitions_dynamically(query)
        elif search_strategy == "cross_references":
            docs = await es_manager.discover_cross_references_dynamically(query)
        else:  # adaptive
            # Use comprehensive approach
            article_docs = await es_manager.dynamic_search_articles(query, k=k//2)
            chunk_docs = await es_manager.dynamic_search_chunks(query, k=k//2)
            docs = article_docs + chunk_docs
        
        if not docs:
            return f"No relevant results found for query: {query}"
        
        formatted_results = []
        for i, doc in enumerate(docs):
            metadata = getattr(doc, 'metadata', {})
            score = metadata.get('_score', 0.0)
            
            formatted_results.append(
                f"Result {i+1} (Score: {score:.3f}):\n"
                f"Title: {metadata.get('title', 'N/A')}\n"
                f"Document: {metadata.get('document_type', 'N/A')}\n"
                f"Article: {metadata.get('article_number', 'N/A')}\n"
                f"Content: {doc.page_content[:400]}...\n"
            )
        
        return "\n---\n".join(formatted_results)
        
    except Exception as e:
        logger.error(f"Error in dynamic search tool: {e}")
        return f"Error in dynamic search: {str(e)}"

@tool
async def adaptive_qa_chain_tool(query: str, chain_type: str = "auto", config: RunnableConfig = None) -> str:
    """
    Use adaptive QA chains that dynamically select optimal approach.
    
    Args:
        query: The question to answer
        chain_type: Chain type ("auto", "definition", "compliance", "business", "conversational")
    
    Returns:
        Comprehensive answer from adaptive QA chain
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        qa_manager = config["configurable"]["qa_manager"]
        context = config["configurable"]["context"]
        
        if chain_type == "auto":
            chain_type = None  # Let the manager dynamically choose
        
        result = await qa_manager.answer_with_dynamic_chain(query, context, chain_type)
        
        answer = result["answer"]
        chain_used = result["chain_type"]
        num_sources = len(result.get("source_documents", []))
        
        formatted_response = f"**Answer (using adaptive {chain_used} chain with {num_sources} sources):**\n\n{answer}"
        
        # Add source information
        if result.get("source_documents"):
            formatted_response += "\n\n**Sources:**\n"
            for i, doc in enumerate(result["source_documents"][:3]):
                metadata = getattr(doc, 'metadata', {})
                formatted_response += f"{i+1}. {metadata.get('title', 'Unknown')} ({metadata.get('document_type', 'Unknown')})\n"
        
        return formatted_response
        
    except Exception as e:
        logger.error(f"Error in adaptive QA chain tool: {e}")
        return f"Error in adaptive QA chain: {str(e)}"

@tool
async def dynamic_concept_discovery_tool(query: str, config: RunnableConfig = None) -> str:
    """
    Discover concepts and relationships dynamically from query and related documents.
    
    Args:
        query: The query to analyze for concept discovery
    
    Returns:
        Discovered concepts and relationships
    """
    if not query:
        return "Error: Empty query provided"
    
    try:
        es_manager = config["configurable"]["es_manager"]
        
        # Get relevant documents first
        docs = await es_manager.dynamic_search_chunks(query, k=5)
        
        if not docs:
            return f"No documents found to analyze for concept discovery: {query}"
        
        # Discover concepts from documents
        concepts = await es_manager.concept_engine.discover_document_concepts(docs)
        
        result = f"**Dynamic Concept Discovery for: {query}**\n\n"
        
        if concepts.terms:
            result += f"**Discovered Terms:** {', '.join(concepts.terms[:10])}\n\n"
        
        if concepts.definitions:
            result += "**Key Definitions:**\n"
            for term, definition in list(concepts.definitions.items())[:3]:
                result += f"• {term}: {definition[:200]}...\n"
            result += "\n"
        
        if concepts.relationships:
            result += "**Concept Relationships:**\n"
            for term, related in list(concepts.relationships.items())[:3]:
                result += f"• {term}: related to {', '.join(related[:3])}\n"
            result += "\n"
        
        if concepts.importance_scores:
            top_concepts = sorted(concepts.importance_scores.items(), key=lambda x: x[1], reverse=True)[:5]
            result += "**Top Important Concepts:**\n"
            for term, score in top_concepts:
                result += f"• {term} (importance: {score:.3f})\n"
        
        return result
        
    except Exception as e:
        logger.error(f"Error in dynamic concept discovery tool: {e}")
        return f"Error in dynamic concept discovery: {str(e)}"

@tool
async def adaptive_comparison_tool(topic: str, config: RunnableConfig = None) -> str:
    """
    Perform adaptive comparison that discovers differences dynamically.
    
    Args:
        topic: The topic to compare across different sources/regulations
    
    Returns:
        Dynamic comparative analysis
    """
    if not topic:
        return "Error: Empty topic provided"
    
    try:
        es_manager = config["configurable"]["es_manager"]
        
        # Dynamically discover comparison aspects
        docs = await es_manager.dynamic_search_articles(topic, k=6)
        
        if not docs:
            return f"No documents found for comparative analysis of: {topic}"
        
        # Group documents by type for comparison
        doc_groups = defaultdict(list)
        for doc in docs:
            doc_type = getattr(doc, 'metadata', {}).get('document_type', 'Unknown')
            doc_groups[doc_type].append(doc)
        
        comparison = f"=== DYNAMIC COMPARISON: {topic.upper()} ===\n\n"
        
        for doc_type, type_docs in doc_groups.items():
            comparison += f"--- {doc_type} ---\n"
            if type_docs:
                for doc in type_docs[:2]:
                    metadata = getattr(doc, 'metadata', {})
                    comparison += f"• {metadata.get('title', 'N/A')}\n  {doc.page_content[:200]}...\n\n"
            else:
                comparison += f"No relevant {doc_type} content found.\n\n"
        
        # Add dynamic insights
        if len(doc_groups) > 1:
            comparison += "--- DYNAMIC INSIGHTS ---\n"
            comparison += "This comparison was generated by dynamically discovering differences "
            comparison += "across the available document types and their specific approaches to this topic.\n"
        
        return comparison
        
    except Exception as e:
        logger.error(f"Error in adaptive comparison tool: {e}")
        return f"Error in adaptive comparison: {str(e)}"

# Main Dynamic GDPR Chatbot
class DynamicGDPRChatbot:
    """Main GDPR Q&A Chatbot with fully dynamic, adaptive architecture"""
    
    def __init__(self):
        try:
            logger.info("Initializing Dynamic GDPR Chatbot components...")
            
            # Initialize core managers
            self.openai_manager = AdvancedOpenAIManager()
            logger.info("✓ OpenAI manager initialized")
            
            self.es_manager = DynamicElasticsearchManager(self.openai_manager)
            logger.info("✓ Elasticsearch manager initialized")
            
            # Initialize specialized agents
            self.search_agent = DynamicSearchAgent(self.es_manager)
            logger.info("✓ Dynamic search agent initialized")
            
            self.analysis_agent = DynamicAnalysisAgent(self.openai_manager)
            logger.info("✓ Dynamic analysis agent initialized")
            
            self.qa_manager = DynamicQAChainManager(self.es_manager)
            logger.info("✓ Dynamic QA manager initialized")
            
            self.memory_store = InMemoryStore()
            logger.info("✓ Memory store initialized")
            
            # Create ReAct agent
            self.react_agent = None
            self._create_dynamic_react_agent()
            logger.info("✓ Dynamic ReAct agent initialized")
            
        except Exception as e:
            logger.error(f"Error initializing Dynamic GDPR Chatbot: {e}")
            raise
    
    def _create_dynamic_react_agent(self):
        """Create ReAct agent with dynamic, adaptive tools"""
        try:
            # Create dynamic tools
            tools = [
                dynamic_search_tool,
                adaptive_qa_chain_tool,
                dynamic_concept_discovery_tool,
                adaptive_comparison_tool
            ]
            
            # Create chat model without constraints
            chat_model = ChatOpenAI(
                model=config.REASONING_MODEL,
                api_key=config.OPENAI_API_KEY,
                base_url=config.OPENAI_BASE_URL
            )
            
            # Dynamic system prompt
            system_prompt = """
            You are an expert consultant specializing in GDPR and data privacy compliance.
            You ONLY answer questions related to data privacy, GDPR, data protection regulations, and related topics.
            
            Your Dynamic Capabilities:
            1. **Adaptive Search**: Dynamically discover and use the most relevant search strategies
            2. **Intelligent QA**: Select optimal response approaches based on query analysis
            3. **Concept Discovery**: Dynamically identify and explore key concepts from content
            4. **Adaptive Comparison**: Compare topics by discovering differences dynamically
            
            Your Approach:
            1. **First check** if the query is related to data privacy, GDPR, or data protection
            2. **If not related to privacy**, politely redirect the user to ask privacy-related questions
            3. **If related to privacy**, analyze the query to understand its unique characteristics
            4. **Adapt** your strategy based on the analysis - no two queries are the same
            5. **Discover** relevant concepts, terms, and relationships dynamically
            6. **Synthesize** comprehensive answers using the most appropriate tools
            7. **Respond** with insights tailored to the specific query and context
            
            Key Principles:
            - Only answer questions about data privacy, GDPR, and related regulations
            - Never assume what terms or concepts are important - discover them dynamically
            - Adapt your search and analysis strategy for each unique query
            - Use AI reasoning to make intelligent decisions about tool selection
            - Provide responses that are specifically tailored to the query characteristics
            - Focus on discovering and leveraging the actual content rather than assumptions
            
            You have access to powerful dynamic tools that adapt to data privacy queries.
            Use them intelligently to provide the most relevant and comprehensive responses.
            """
            
            # Create ReAct agent
            self.react_agent = create_react_agent(
                model=chat_model,
                tools=tools,
                state_modifier=system_prompt
            )
            
            logger.info("Dynamic ReAct GDPR chatbot created successfully")
            
        except Exception as e:
            logger.error(f"Error creating dynamic ReAct agent: {e}")
            raise
    
    async def chat(self, user_query: str, thread_id: str = None) -> Dict[str, Any]:
        """Main chat interface with fully dynamic processing"""
        try:
            if not user_query or len(user_query.strip()) < 3:
                return {
                    "answer": "Please provide a more detailed question about data privacy or GDPR.",
                    "confidence": "low",
                    "thread_id": thread_id or "unknown"
                }
            
            # Check if query is privacy-related
            if not DataPrivacyFilter.is_privacy_related(user_query):
                return {
                    "answer": DataPrivacyFilter.get_rejection_message(),
                    "confidence": "high",
                    "thread_id": thread_id or str(uuid.uuid4()),
                    "intent": "non_privacy",
                    "complexity": "simple",
                    "approach": "rejection"
                }
            
            if not thread_id:
                thread_id = f"dynamic_chat_{uuid.uuid4().hex[:8]}"
            
            # Create conversation context
            context = ConversationContext(
                thread_id=thread_id,
                query=user_query,
                intent="",
                entities=[],
                previous_searches=[],
                conversation_history=[],
                current_analysis={}
            )
            
            # Dynamic query analysis
            try:
                intent_analysis = await self.analysis_agent.analyze_query_dynamically(user_query, context)
                context.current_analysis = intent_analysis
                logger.info(f"Dynamic analysis - Intent: {intent_analysis.get('intent')}, Approach: {intent_analysis.get('optimal_approach')}")
            except Exception as e:
                logger.warning(f"Dynamic analysis failed: {e}")
                intent_analysis = {}
            
            # Configure ReAct agent
            config_dict = RunnableConfig(
                configurable={
                    "thread_id": thread_id,
                    "es_manager": self.es_manager,
                    "qa_manager": self.qa_manager,
                    "context": context
                }
            )
            
            # Run dynamic ReAct agent
            logger.info(f"Processing with dynamic ReAct agent: {user_query[:100]}...")
            
            messages = [HumanMessage(content=user_query)]
            
            try:
                response = await self.react_agent.ainvoke(
                    {"messages": messages},
                    config=config_dict
                )
            except Exception as e:
                logger.error(f"ReAct agent failed: {e}")
                # Fallback to direct QA chain
                try:
                    qa_result = await self.qa_manager.answer_with_dynamic_chain(user_query, context)
                    return {
                        "answer": qa_result["answer"],
                        "confidence": "medium",
                        "thread_id": thread_id,
                        "intent": intent_analysis.get('intent', 'unknown'),
                        "complexity": intent_analysis.get('complexity', 'unknown'),
                        "approach": "fallback_qa"
                    }
                except Exception as e2:
                    logger.error(f"Fallback QA also failed: {e2}")
                    return {
                        "answer": "I apologize, but I encountered an error processing your data privacy question. Please try rephrasing it.",
                        "confidence": "low",
                        "thread_id": thread_id,
                        "intent": "error",
                        "complexity": "unknown",
                        "approach": "error"
                    }
            
            # Extract final answer
            final_answer = ""
            if response and "messages" in response:
                for message in reversed(response["messages"]):
                    if hasattr(message, 'content') and message.content:
                        content = str(message.content).strip()
                        if (content and 
                            not content.startswith('{"') and 
                            not content.startswith('Error:') and
                            len(content) > 50):
                            final_answer = content
                            break
            
            if not final_answer:
                # Fallback to dynamic QA chain
                logger.info("ReAct didn't provide answer, using dynamic QA chain fallback")
                try:
                    qa_result = await self.qa_manager.answer_with_dynamic_chain(user_query, context)
                    final_answer = qa_result["answer"]
                except Exception as e:
                    final_answer = "I apologize, but I couldn't generate a comprehensive answer about this data privacy topic. Please try rephrasing your question."
            
            # Dynamic answer quality assessment
            confidence = await self._assess_answer_quality_dynamically(final_answer, intent_analysis)
            
            # Store conversation in memory
            try:
                await self._store_conversation_memory(user_query, final_answer, thread_id, confidence)
            except Exception as e:
                logger.warning(f"Failed to store conversation memory: {e}")
            
            return {
                "answer": final_answer,
                "confidence": confidence,
                "thread_id": thread_id,
                "intent": intent_analysis.get('intent', 'unknown'),
                "complexity": intent_analysis.get('complexity', 'unknown'),
                "approach": intent_analysis.get('optimal_approach', 'adaptive')
            }
            
        except Exception as e:
            logger.error(f"Error in dynamic chat processing: {e}")
            return {
                "answer": f"I apologize, but I encountered an error processing your data privacy question: {str(e)}",
                "confidence": "low",
                "thread_id": thread_id or "error"
            }
    
    async def _assess_answer_quality_dynamically(self, answer: str, intent_analysis: Dict) -> str:
        """Dynamically assess answer quality based on multiple factors"""
        if not answer or len(answer) < 50:
            return "low"
        
        try:
            # Dynamic quality indicators based on intent
            intent = intent_analysis.get('intent', 'unknown')
            complexity = intent_analysis.get('complexity', 'moderate')
            
            base_score = 0
            
            # Length-based scoring
            if len(answer) > 200:
                base_score += 1
            if len(answer) > 500:
                base_score += 1
            
            # Structure-based scoring
            if "**" in answer or "###" in answer:  # Has formatting
                base_score += 1
            
            # Content relevance scoring
            query_terms = intent_analysis.get('entities', [])
            if any(term.lower() in answer.lower() for term in query_terms):
                base_score += 1
            
            # Intent-specific scoring
            if intent == "definition" and any(word in answer.lower() for word in ['means', 'refers to', 'defined as']):
                base_score += 1
            elif intent == "compliance" and any(word in answer.lower() for word in ['requirement', 'must', 'obligation']):
                base_score += 1
            
            # Dynamic thresholds based on complexity
            if complexity == "simple":
                return "high" if base_score >= 3 else "medium" if base_score >= 2 else "low"
            elif complexity == "complex":
                return "high" if base_score >= 4 else "medium" if base_score >= 3 else "low"
            else:  # moderate
                return "high" if base_score >= 4 else "medium" if base_score >= 2 else "low"
                
        except Exception as e:
            logger.error(f"Error in quality assessment: {e}")
            return "medium"  # Default fallback
    
    async def _store_conversation_memory(self, query: str, answer: str, thread_id: str, confidence: str):
        """Store conversation in memory for context"""
        try:
            memory_data = {
                "query": query,
                "answer_length": len(answer),
                "confidence": confidence,
                "timestamp": datetime.now().isoformat(),
                "thread_id": thread_id,
                "processing_type": "dynamic"
            }
            
            await self.memory_store.aput(
                namespace=("conversations", "dynamic_gdpr_chatbot"),
                key=f"conversation_{uuid.uuid4()}",
                value=memory_data
            )
        except Exception as e:
            logger.error(f"Error storing conversation memory: {e}")

# Interface classes
class DynamicGDPRChatbotInterface:
    """Dynamic interface for GDPR chatbot with fully adaptive capabilities"""
    
    def __init__(self):
        self.chatbot = None
    
    async def initialize(self):
        """Initialize the dynamic chatbot"""
        try:
            logger.info("Initializing Dynamic GDPR Chatbot...")
            
            # Check if already initialized
            if self.chatbot is not None:
                logger.info("Chatbot already initialized")
                return True
            
            # Initialize the chatbot
            self.chatbot = DynamicGDPRChatbot()
            
            # Validate initialization
            if (hasattr(self.chatbot, 'openai_manager') and 
                hasattr(self.chatbot, 'es_manager') and 
                hasattr(self.chatbot, 'react_agent') and
                self.chatbot.react_agent is not None):
                logger.info("Dynamic GDPR Chatbot initialized successfully!")
                return True
            else:
                logger.error("Chatbot initialization incomplete - missing components")
                return False
                
        except Exception as e:
            logger.error(f"Failed to initialize dynamic chatbot: {e}")
            self.chatbot = None
            return False
    
    async def ask_question(self, question: str, thread_id: str = None) -> Dict[str, Any]:
        """Ask a question to the dynamic chatbot"""
        if not self.chatbot:
            if not await self.initialize():
                return {
                    "answer": "Chatbot failed to initialize. Please check your configuration.",
                    "confidence": "low",
                    "thread_id": thread_id or "error"
                }
        
        return await self.chatbot.chat(question, thread_id)
    
    def run_interactive_session(self):
        """Run an interactive session with dynamic capabilities"""
        print("="*80)
        print("Dynamic GDPR Q&A Chatbot - Data Privacy Expert")
        print("="*80)
        print("Features: Dynamic Term Discovery, Adaptive Search, AI-Powered Analysis")
        print("Specializes in: GDPR, Data Privacy, Data Protection Regulations")
        print("Ask any questions about data privacy - the system adapts to your specific query.")
        print("Type 'exit' to quit, 'help' for examples")
        print("="*80)
        
        async def interactive_loop():
            if not await self.initialize():
                print("❌ Failed to initialize dynamic chatbot.")
                return
            
            thread_id = f"dynamic_{uuid.uuid4().hex[:8]}"
            print(f"✅ Dynamic GDPR Chatbot ready! (Thread ID: {thread_id})")
            
            while True:
                try:
                    question = input("\n💬 Your question: ").strip()
                    
                    if question.lower() in ['exit', 'quit', 'bye']:
                        print("👋 Goodbye!")
                        break
                    
                    if question.lower() == 'help':
                        print("\n🧠 Dynamic Analysis Examples:")
                        print("• What is the definition of data controller under GDPR?")
                        print("• How should we implement privacy by design?")
                        print("• What are the requirements for international data transfers?")
                        print("• Compare GDPR and CCPA approaches to data subject rights")
                        print("• What are the penalties for non-compliance with GDPR?")
                        print("• How do we conduct a Data Protection Impact Assessment?")
                        print("• What constitutes valid consent under GDPR?")
                        continue
                    
                    if not question:
                        print("Please enter a question.")
                        continue
                    
                    print("\n🔍 Analyzing query and adapting approach dynamically...")
                    
                    response = await self.ask_question(question, thread_id)
                    
                    print(f"\n📋 **Dynamic Answer** (Confidence: {response.get('confidence', 'unknown')})")
                    print(f"Intent: {response.get('intent', 'unknown')} | Approach: {response.get('approach', 'unknown')}")
                    print("="*70)
                    print(response['answer'])
                    print("="*70)
                    
                except KeyboardInterrupt:
                    print("\n👋 Goodbye!")
                    break
                except Exception as e:
                    print(f"\n❌ Error: {e}")
        
        # Run the async interactive loop with proper error handling
        try:
            loop = get_event_loop()
            if loop.is_running():
                print("Running in existing event loop...")
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, interactive_loop())
                    future.result()
            else:
                asyncio.run(interactive_loop())
        except Exception as e:
            logger.error(f"Error in interactive session: {e}")
            print(f"❌ Interactive session error: {e}")

# Main execution and demo functions
async def main():
    """Main function to run the dynamic chatbot"""
    print("Dynamic GDPR Q&A Chatbot - Data Privacy Expert")
    print("=" * 80)
    
    # Validate configuration
    print("🔍 Validating configuration...")
    
    try:
        # Test OpenAI connection
        test_client = openai.OpenAI(api_key=config.OPENAI_API_KEY, base_url=config.OPENAI_BASE_URL)
        # Test with a simple completion instead of listing models
        test_response = test_client.chat.completions.create(
            model=config.REASONING_MODEL,
            messages=[{"role": "user", "content": "test"}],
            reasoning_effort=config.REASONING_EFFORT
        )
        print("✓ OpenAI API connection validated")
    except Exception as e:
        print(f"❌ Error: Cannot connect to OpenAI API: {e}")
        return
    
    # Test Elasticsearch connection using same SSL config as original
    try:
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        if os.path.exists(config.ES_CACERT_PATH):
            ssl_context.load_verify_locations(config.ES_CACERT_PATH)
        
        test_es = Elasticsearch(
            [{"host": config.ES_HOST, "port": config.ES_PORT, "scheme": "https"}],
            basic_auth=(config.ES_USERNAME, config.ES_PASSWORD),
            ssl_context=ssl_context,
            verify_certs=True,
            request_timeout=30,
            max_retries=3,
            retry_on_timeout=True
        )
        es_info = test_es.info()
        print(f"✓ Elasticsearch connection validated: {es_info.get('version', {}).get('number', 'unknown')}")
        test_es.close()
    except Exception as e:
        print(f"❌ Error: Cannot connect to Elasticsearch: {e}")
        return
    
    print("✓ All connections validated successfully")
    print()
    
    print("🧠 Dynamic Features:")
    print("• AI-powered term and concept discovery")
    print("• Adaptive search strategies based on query analysis")
    print("• Dynamic QA chain selection")
    print("• Data privacy focused responses only")
    print("• Self-learning from document content")
    print("• Fully adaptive to data privacy queries")
    print()
    
    # Choose mode
    mode = input("Choose mode:\n1. Interactive Session\n2. Demo\n3. Single Question\nEnter choice (1-3): ").strip()
    
    interface = DynamicGDPRChatbotInterface()
    
    if mode == "1":
        interface.run_interactive_session()
    
    elif mode == "2":
        await demo_dynamic_chatbot()
    
    elif mode == "3":
        if not await interface.initialize():
            print("❌ Failed to initialize dynamic chatbot")
            return
        
        question = input("Enter your data privacy question: ").strip()
        if question:
            print("\n🧠 Processing with dynamic analysis and adaptation...")
            response = await interface.ask_question(question)
            print(f"\n📋 Dynamic Answer (Confidence: {response.get('confidence', 'unknown')}):")
            print(f"Intent: {response.get('intent')} | Approach: {response.get('approach')}")
            print("=" * 70)
            print(response['answer'])
            print("=" * 70)
        else:
            print("No question provided.")
    
    else:
        print("Invalid choice. Please run again and select 1, 2, or 3.")

# Demo function
async def demo_dynamic_chatbot():
    """Demonstrate the dynamic chatbot capabilities"""
    interface = DynamicGDPRChatbotInterface()
    
    if not await interface.initialize():
        print("❌ Failed to initialize dynamic chatbot for demo")
        return
    
    print("\n" + "="*80)
    print("DYNAMIC GDPR CHATBOT DEMONSTRATION")
    print("="*80)
    
    demo_questions = [
        "What is the definition of personal data under GDPR?",
        "How should organizations implement data protection by design?",
        "What are the key differences between data controller and data processor?",
        "Explain the requirements for obtaining valid consent under GDPR.",
        "What are the penalties for GDPR non-compliance?",
        "How long can personal data be retained under GDPR?"
    ]
    
    # Test non-privacy question rejection
    print(f"\n📌 Testing Non-Privacy Query Rejection:")
    print("Question: What is the weather today?")
    print("-" * 70)
    
    try:
        response = await interface.ask_question("What is the weather today?")
        print(f"🎯 Confidence: {response.get('confidence', 'unknown')}")
        print(f"📝 Intent: {response.get('intent', 'unknown')}")
        print("\n📋 Answer:")
        print(response['answer'])
    except Exception as e:
        print(f"❌ Error: {e}")
    
    print("\n" + "="*80)
    
    # Test privacy questions
    for i, question in enumerate(demo_questions, 1):
        print(f"\n📌 Dynamic Demo Question {i}: {question}")
        print("-" * 70)
        
        try:
            response = await interface.ask_question(question)
            print(f"🎯 Confidence: {response.get('confidence', 'unknown')}")
            print(f"📝 Intent: {response.get('intent', 'unknown')}")
            print(f"🧠 Approach: {response.get('approach', 'unknown')}")
            print("\n📋 Answer:")
            print(response['answer'][:600] + "..." if len(response['answer']) > 600 else response['answer'])
            
        except Exception as e:
            print(f"❌ Error: {e}")
        
        print("\n" + "="*80)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n👋 Goodbye!")
