import os
import glob
import pickle
from typing import List, Dict, Any
import asyncio
from pathlib import Path

# Core libraries
import PyPDF2
from langdetect import detect
import chromadb
from chromadb.config import Settings

# LangChain imports
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from langchain.schema import Document
from langchain.memory.chat_message_histories import FileChatMessageHistory

# OpenAI for translation
import openai
from openai import OpenAI

# Global Configuration
class Config:
    """Global configuration for OpenAI API and other settings"""
    OPENAI_API_KEY = "your-openai-api-key-here"  # Replace with your actual API key
    OPENAI_BASE_URL = "https://api.openai.com/v1"  # OpenAI base URL
    EMBEDDING_MODEL = "text-embedding-3-large"
    CHAT_MODEL = "gpt-4"
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200
    PDF_DIRECTORY = "./pdfs"  # Directory containing PDF files
    CHROMADB_PATH = "./chromadb"
    MEMORY_PATH = "./memory"
    
    @classmethod
    def setup_openai(cls):
        """Setup OpenAI client with global configuration"""
        openai.api_key = cls.OPENAI_API_KEY
        openai.base_url = cls.OPENAI_BASE_URL
        return OpenAI(api_key=cls.OPENAI_API_KEY, base_url=cls.OPENAI_BASE_URL)

# Initialize OpenAI client globally
openai_client = Config.setup_openai()

class PDFProcessor:
    """Handles PDF reading and text extraction"""
    
    def __init__(self):
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=Config.CHUNK_SIZE,
            chunk_overlap=Config.CHUNK_OVERLAP,
            length_function=len,
        )
    
    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """Extract text from a PDF file"""
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() + "\n"
                return text.strip()
        except Exception as e:
            print(f"Error extracting text from {pdf_path}: {str(e)}")
            return ""
    
    def detect_language(self, text: str) -> str:
        """Detect the language of the text"""
        try:
            # Take a sample of the text for language detection
            sample = text[:1000] if len(text) > 1000 else text
            return detect(sample)
        except:
            return "unknown"
    
    def translate_to_english(self, text: str) -> str:
        """Translate German text to English using OpenAI"""
        try:
            response = openai_client.chat.completions.create(
                model=Config.CHAT_MODEL,
                messages=[
                    {"role": "system", "content": "You are a professional translator. Translate the following German text to English. Maintain the original meaning and structure as much as possible. If the text is already in English, return it unchanged."},
                    {"role": "user", "content": text}
                ],
                max_tokens=4000,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error translating text: {str(e)}")
            return text  # Return original text if translation fails
    
    def process_pdfs(self, directory: str) -> List[Document]:
        """Process all PDFs in the directory"""
        documents = []
        pdf_files = glob.glob(os.path.join(directory, "*.pdf"))
        
        if not pdf_files:
            print(f"No PDF files found in {directory}")
            return documents
        
        print(f"Found {len(pdf_files)} PDF files to process...")
        
        for pdf_path in pdf_files:
            print(f"Processing: {os.path.basename(pdf_path)}")
            
            # Extract text
            text = self.extract_text_from_pdf(pdf_path)
            if not text:
                continue
            
            # Detect language
            language = self.detect_language(text)
            print(f"Detected language: {language}")
            
            # Translate if German
            if language == 'de':
                print("Translating German text to English...")
                text = self.translate_to_english(text)
            
            # Create document with metadata
            doc = Document(
                page_content=text,
                metadata={
                    "source": pdf_path,
                    "filename": os.path.basename(pdf_path),
                    "original_language": language
                }
            )
            
            # Split into chunks
            chunks = self.text_splitter.split_documents([doc])
            documents.extend(chunks)
            print(f"Created {len(chunks)} chunks from {os.path.basename(pdf_path)}")
        
        return documents

class ChromaDBManager:
    """Manages ChromaDB operations"""
    
    def __init__(self, persist_directory: str = Config.CHROMADB_PATH):
        self.persist_directory = persist_directory
        self.embeddings = OpenAIEmbeddings(
            model=Config.EMBEDDING_MODEL,
            openai_api_key=Config.OPENAI_API_KEY,
            openai_api_base=Config.OPENAI_BASE_URL
        )
        
        # Ensure directory exists
        os.makedirs(persist_directory, exist_ok=True)
        
        # Initialize ChromaDB client
        self.client = chromadb.PersistentClient(path=persist_directory)
    
    def create_vectorstore(self, documents: List[Document]) -> Chroma:
        """Create and populate ChromaDB vector store"""
        print(f"Creating embeddings for {len(documents)} document chunks...")
        
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            persist_directory=self.persist_directory,
            collection_name="pdf_documents"
        )
        
        print("Vector store created and persisted successfully!")
        return vectorstore
    
    def load_vectorstore(self) -> Chroma:
        """Load existing vector store"""
        return Chroma(
            persist_directory=self.persist_directory,
            embedding_function=self.embeddings,
            collection_name="pdf_documents"
        )

class RAGChatbot:
    """RAG Chatbot with memory checkpoints"""
    
    def __init__(self, vectorstore: Chroma):
        self.vectorstore = vectorstore
        self.llm = ChatOpenAI(
            model=Config.CHAT_MODEL,
            openai_api_key=Config.OPENAI_API_KEY,
            openai_api_base=Config.OPENAI_BASE_URL,
            temperature=0.7
        )
        
        # Setup memory with file persistence
        os.makedirs(Config.MEMORY_PATH, exist_ok=True)
        self.memory_file = os.path.join(Config.MEMORY_PATH, "chat_history.json")
        
        # Initialize memory with file-based chat history
        self.memory = ConversationBufferMemory(
            memory_key="chat_history",
            chat_memory=FileChatMessageHistory(self.memory_file),
            output_key="answer",
            return_messages=True
        )
        
        # Create conversational retrieval chain
        self.qa_chain = ConversationalRetrievalChain.from_llm(
            llm=self.llm,
            retriever=self.vectorstore.as_retriever(
                search_type="similarity",
                search_kwargs={"k": 4}
            ),
            memory=self.memory,
            return_source_documents=True,
            verbose=True
        )
    
    def chat(self, question: str) -> Dict[str, Any]:
        """Process a chat question and return response with sources"""
        try:
            # Add instruction to ensure English output
            enhanced_question = f"""Please answer the following question in English only, even if the source documents contain German text: {question}"""
            
            result = self.qa_chain({"question": enhanced_question})
            
            return {
                "answer": result["answer"],
                "source_documents": result.get("source_documents", []),
                "sources": list(set([doc.metadata.get("filename", "Unknown") 
                                   for doc in result.get("source_documents", [])]))
            }
        except Exception as e:
            return {
                "answer": f"I encountered an error while processing your question: {str(e)}",
                "source_documents": [],
                "sources": []
            }
    
    def save_memory_checkpoint(self, checkpoint_name: str = "default"):
        """Save current memory state to a checkpoint"""
        checkpoint_path = os.path.join(Config.MEMORY_PATH, f"checkpoint_{checkpoint_name}.pkl")
        try:
            with open(checkpoint_path, 'wb') as f:
                pickle.dump(self.memory.chat_memory.messages, f)
            print(f"Memory checkpoint saved: {checkpoint_name}")
        except Exception as e:
            print(f"Error saving checkpoint: {str(e)}")
    
    def load_memory_checkpoint(self, checkpoint_name: str = "default"):
        """Load memory state from a checkpoint"""
        checkpoint_path = os.path.join(Config.MEMORY_PATH, f"checkpoint_{checkpoint_name}.pkl")
        try:
            if os.path.exists(checkpoint_path):
                with open(checkpoint_path, 'rb') as f:
                    messages = pickle.load(f)
                self.memory.chat_memory.messages = messages
                print(f"Memory checkpoint loaded: {checkpoint_name}")
            else:
                print(f"Checkpoint not found: {checkpoint_name}")
        except Exception as e:
            print(f"Error loading checkpoint: {str(e)}")
    
    def clear_memory(self):
        """Clear conversation memory"""
        self.memory.clear()
        print("Memory cleared!")

def main():
    """Main function to run the RAG system"""
    print("=== RAG Chatbot with German Translation ===")
    print(f"PDF Directory: {Config.PDF_DIRECTORY}")
    print(f"ChromaDB Path: {Config.CHROMADB_PATH}")
    
    # Ensure PDF directory exists
    os.makedirs(Config.PDF_DIRECTORY, exist_ok=True)
    
    # Initialize components
    pdf_processor = PDFProcessor()
    chroma_manager = ChromaDBManager()
    
    # Check if we need to process PDFs
    vectorstore_exists = os.path.exists(os.path.join(Config.CHROMADB_PATH, "chroma.sqlite3"))
    
    if not vectorstore_exists:
        print("\nProcessing PDFs and creating vector store...")
        documents = pdf_processor.process_pdfs(Config.PDF_DIRECTORY)
        
        if not documents:
            print("No documents found to process. Please add PDF files to the directory.")
            return
        
        vectorstore = chroma_manager.create_vectorstore(documents)
    else:
        print("\nLoading existing vector store...")
        vectorstore = chroma_manager.load_vectorstore()
    
    # Initialize chatbot
    chatbot = RAGChatbot(vectorstore)
    
    print("\n=== Chatbot Ready! ===")
    print("Commands:")
    print("- Type your questions normally")
    print("- 'save_checkpoint <name>' - Save memory checkpoint")
    print("- 'load_checkpoint <name>' - Load memory checkpoint")
    print("- 'clear_memory' - Clear conversation history")
    print("- 'quit' - Exit the chatbot")
    print("-" * 50)
    
    while True:
        try:
            user_input = input("\nYou: ").strip()
            
            if user_input.lower() == 'quit':
                print("Goodbye!")
                break
            
            elif user_input.lower() == 'clear_memory':
                chatbot.clear_memory()
                continue
            
            elif user_input.startswith('save_checkpoint'):
                parts = user_input.split(' ', 1)
                checkpoint_name = parts[1] if len(parts) > 1 else "default"
                chatbot.save_memory_checkpoint(checkpoint_name)
                continue
            
            elif user_input.startswith('load_checkpoint'):
                parts = user_input.split(' ', 1)
                checkpoint_name = parts[1] if len(parts) > 1 else "default"
                chatbot.load_memory_checkpoint(checkpoint_name)
                continue
            
            elif not user_input:
                continue
            
            # Process question
            print("Assistant: Processing your question...")
            response = chatbot.chat(user_input)
            
            print(f"\nAssistant: {response['answer']}")
            
            if response['sources']:
                print(f"\nSources: {', '.join(response['sources'])}")
        
        except KeyboardInterrupt:
            print("\nGoodbye!")
            break
        except Exception as e:
            print(f"Error: {str(e)}")

if __name__ == "__main__":
    # Check if required packages are installed
    required_packages = [
        "PyPDF2", "langdetect", "chromadb", "langchain", "langchain-openai", 
        "langchain-community", "openai"
    ]
    
    print("Required packages:", ", ".join(required_packages))
    print("Install with: pip install " + " ".join(required_packages))
    print()
    
    main()
