"""
ISO 11179 Data Enrichment with Semantic Knowledge Graph & Advanced Reasoning
===========================================================================
FIXED ISSUES:
- Context pollution prevention (no "Customer" bleeding from application)
- Proper modelling when PBT matches are weak
- Complete output with all rationales and reasoning
- Semantic validation for correct mappings
"""

import json
import os
import pandas as pd
from typing import TypedDict, Annotated, List, Dict, Any, Literal, Sequence, Tuple
import numpy as np
from openai import OpenAI
import time
from datetime import datetime
from collections import defaultdict
import networkx as nx
from difflib import SequenceMatcher
import pickle

# LangChain and LangGraph imports
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.embeddings import Embeddings
from langchain_community.vectorstores import InMemoryVectorStore
from langchain_core.documents import Document
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-api-key-here")
OPENAI_BASE_URL = "https://api.openai.com/v1"
OPENAI_REASONING_MODEL = "o3-mini"
OPENAI_EMBEDDING_MODEL = "text-embedding-3-large"

openai_client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_BASE_URL)

INPUT_JSON_PATH = "cib_long_json.json"
EXCEL_PATH = "pbt.xlsx"
ACRONYM_CSV_PATH = "acronyms.csv"
OUTPUT_CSV_PATH = "enriched_mapped_output.csv"
CACHE_JSON_PATH = "mapping_cache.json"
PROCEDURAL_MEMORY_PATH = "procedural_memory.json"
EPISODIC_MEMORY_PATH = "episodic_memory.json"
KNOWLEDGE_GRAPH_PATH = "semantic_knowledge_graph.gpickle"
GRAPH_STATS_PATH = "graph_statistics.json"

# Global stores
MAPPING_CACHE = {}
PROCEDURAL_MEMORY = {}
EPISODIC_MEMORY = []
SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()


# ============================================================================
# KNOWLEDGE GRAPH MANAGEMENT
# ============================================================================

def initialize_knowledge_graph():
    """Initialize or load semantic knowledge graph."""
    global SEMANTIC_KNOWLEDGE_GRAPH
    
    if os.path.exists(KNOWLEDGE_GRAPH_PATH):
        try:
            with open(KNOWLEDGE_GRAPH_PATH, 'rb') as f:
                SEMANTIC_KNOWLEDGE_GRAPH = pickle.load(f)
            print(f"   ‚Üí Loaded knowledge graph: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
        except Exception as e:
            print(f"   ‚Üí Could not load knowledge graph: {e}")
            SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()
    else:
        print(f"   ‚Üí Creating new knowledge graph")
        SEMANTIC_KNOWLEDGE_GRAPH = nx.MultiDiGraph()


def save_knowledge_graph():
    """Save knowledge graph to disk."""
    try:
        with open(KNOWLEDGE_GRAPH_PATH, 'wb') as f:
            pickle.dump(SEMANTIC_KNOWLEDGE_GRAPH, f, protocol=pickle.HIGHEST_PROTOCOL)
        print(f"   ‚Üí Saved knowledge graph: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
    except Exception as e:
        print(f"   ‚ö† Warning: Could not save knowledge graph: {e}")


def add_field_to_graph(field_name, enriched_name, object_name, property_name, confidence, pii_category, application, eim_id):
    """Add a processed field and its relationships to the knowledge graph."""
    field_node = f"field:{field_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(field_node, type='field', original_name=field_name, enriched_name=enriched_name, application=application, eim_id=eim_id, timestamp=datetime.now().isoformat())
    
    enriched_node = f"concept:{enriched_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(enriched_node, type='concept', name=enriched_name)
    
    object_node = f"object:{object_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(object_node, type='object', name=object_name)
    
    property_node = f"property:{property_name.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(property_node, type='property', name=property_name)
    
    pii_node = f"pii:{pii_category.lower()}"
    SEMANTIC_KNOWLEDGE_GRAPH.add_node(pii_node, type='pii_category', category=pii_category)
    
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(field_node, enriched_node, relationship='enriched_to', confidence=confidence)
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(enriched_node, object_node, relationship='mapped_to_object', confidence=confidence)
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(enriched_node, property_node, relationship='mapped_to_property', confidence=confidence)
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(enriched_node, pii_node, relationship='classified_as', confidence=confidence)
    SEMANTIC_KNOWLEDGE_GRAPH.add_edge(object_node, property_node, relationship='has_property')


def query_graph_patterns(field_name: str) -> Dict[str, Any]:
    """Query knowledge graph for relevant patterns."""
    patterns = {'similar_fields': [], 'common_objects': [], 'common_properties': []}
    
    field_lower = field_name.lower()
    for node, data in SEMANTIC_KNOWLEDGE_GRAPH.nodes(data=True):
        if data.get('type') == 'field':
            original = data.get('original_name', '').lower()
            similarity = calculate_lexical_similarity(field_lower, original)
            if similarity > 0.6 and node != f"field:{field_lower}":
                neighbors = list(SEMANTIC_KNOWLEDGE_GRAPH.successors(node))
                for neighbor in neighbors:
                    neighbor_data = SEMANTIC_KNOWLEDGE_GRAPH.nodes[neighbor]
                    if neighbor_data.get('type') == 'concept':
                        concept_neighbors = list(SEMANTIC_KNOWLEDGE_GRAPH.successors(neighbor))
                        obj = None
                        prop = None
                        for cn in concept_neighbors:
                            cn_data = SEMANTIC_KNOWLEDGE_GRAPH.nodes[cn]
                            if cn_data.get('type') == 'object':
                                obj = cn_data.get('name')
                            elif cn_data.get('type') == 'property':
                                prop = cn_data.get('name')
                        
                        if obj and prop:
                            patterns['similar_fields'].append({
                                'field': data.get('original_name'),
                                'enriched': neighbor_data.get('name'),
                                'object': obj,
                                'property': prop,
                                'similarity': similarity
                            })
    
    patterns['similar_fields'] = sorted(patterns['similar_fields'], key=lambda x: x['similarity'], reverse=True)[:5]
    return patterns


def discover_graph_relationships_with_llm(patterns: Dict[str, Any], enriched_name: str) -> str:
    """Use LLM to reason about graph patterns."""
    if not patterns['similar_fields']:
        return "No significant graph patterns found."
    
    prompt = f"""Analyze semantic knowledge graph patterns for: {enriched_name}

Similar Fields: {json.dumps(patterns['similar_fields'], indent=2)}

Provide concise insights (max 200 words):
1. Consistent mapping patterns?
2. Strong object-property co-occurrences?
3. Recommendations for current field?"""

    try:
        messages = [{"role": "user", "content": prompt}]
        response = openai_client.chat.completions.create(model=OPENAI_REASONING_MODEL, messages=messages)
        return response.choices[0].message.content.strip()
    except:
        return "Graph reasoning failed"


# ============================================================================
# LEXICAL + SEMANTIC MATCHING
# ============================================================================

def calculate_lexical_similarity(str1: str, str2: str) -> float:
    """Calculate lexical similarity using multiple metrics."""
    str1 = str1.lower()
    str2 = str2.lower()
    
    seq_similarity = SequenceMatcher(None, str1, str2).ratio()
    
    words1 = set(str1.split('_') + str1.split())
    words2 = set(str2.split('_') + str2.split())
    jaccard = len(words1 & words2) / len(words1 | words2) if words1 or words2 else 0
    
    def get_trigrams(s):
        return set([s[i:i+3] for i in range(len(s)-2)])
    
    trigrams1 = get_trigrams(str1)
    trigrams2 = get_trigrams(str2)
    trigram_sim = len(trigrams1 & trigrams2) / len(trigrams1 | trigrams2) if trigrams1 or trigrams2 else 0
    
    return (0.4 * seq_similarity + 0.4 * jaccard + 0.2 * trigram_sim)


def hybrid_similarity_search(query: str, vector_store: Any, all_items: List[str], top_k: int = 5) -> List[Tuple[str, float, Dict[str, float]]]:
    """Perform hybrid lexical + semantic similarity search."""
    semantic_results = vector_store.similarity_search_with_score(query, k=top_k * 2)
    semantic_dict = {}
    for doc, score in semantic_results:
        item = doc.metadata.get('object') or doc.metadata.get('property') or doc.page_content
        semantic_dict[item] = float(score)
    
    lexical_scores = {}
    for item in all_items:
        lexical_scores[item] = calculate_lexical_similarity(query, item)
    
    all_items_set = set(semantic_dict.keys()) | set(lexical_scores.keys())
    combined_results = []
    
    for item in all_items_set:
        semantic_score = semantic_dict.get(item, 0)
        lexical_score = lexical_scores.get(item, 0)
        semantic_score_norm = 1 / (1 + semantic_score) if semantic_score > 0 else 0
        combined_score = (0.3 * lexical_score) + (0.7 * semantic_score_norm)
        
        combined_results.append((item, combined_score, {'lexical': lexical_score, 'semantic': semantic_score_norm, 'combined': combined_score}))
    
    combined_results.sort(key=lambda x: x[1], reverse=True)
    return combined_results[:top_k]


# ============================================================================
# MEMORY FUNCTIONS
# ============================================================================

def load_all_memory():
    """Load all memory systems."""
    global MAPPING_CACHE, PROCEDURAL_MEMORY, EPISODIC_MEMORY
    
    if os.path.exists(CACHE_JSON_PATH):
        with open(CACHE_JSON_PATH, 'r') as f:
            MAPPING_CACHE = json.load(f)
        print(f"   ‚Üí Cache: {len(MAPPING_CACHE)} entries")
    
    if os.path.exists(PROCEDURAL_MEMORY_PATH):
        with open(PROCEDURAL_MEMORY_PATH, 'r') as f:
            PROCEDURAL_MEMORY = json.load(f)
        print(f"   ‚Üí Procedural memory loaded")
    else:
        PROCEDURAL_MEMORY = {"prefix_patterns": {}, "suffix_patterns": {}}
    
    if os.path.exists(EPISODIC_MEMORY_PATH):
        with open(EPISODIC_MEMORY_PATH, 'r') as f:
            EPISODIC_MEMORY = json.load(f)
        print(f"   ‚Üí Episodic: {len(EPISODIC_MEMORY)} episodes")
    
    initialize_knowledge_graph()


def save_all_memory():
    """Save all memory systems."""
    with open(CACHE_JSON_PATH, 'w') as f:
        json.dump(MAPPING_CACHE, f, indent=2)
    with open(PROCEDURAL_MEMORY_PATH, 'w') as f:
        json.dump(PROCEDURAL_MEMORY, f, indent=2)
    with open(EPISODIC_MEMORY_PATH, 'w') as f:
        json.dump(EPISODIC_MEMORY, f, indent=2)
    save_knowledge_graph()


def update_all_memory(field_name, enriched_name, obj, prop, strategy, confidence, pii, obj_mod, prop_mod, application, eim_id):
    """Update all memory systems."""
    cache_key = f"{enriched_name.lower()}|{field_name.lower()[:100]}"
    MAPPING_CACHE[cache_key] = {'object': obj, 'property': prop, 'confidence': confidence, 'object_was_modelled': obj_mod, 'property_was_modelled': prop_mod}
    
    EPISODIC_MEMORY.append({"timestamp": datetime.now().isoformat(), "field": field_name, "enriched": enriched_name, "mapping": {"object": obj, "property": prop}, "confidence": confidence, "pii": pii})
    if len(EPISODIC_MEMORY) > 1000:
        EPISODIC_MEMORY[:] = EPISODIC_MEMORY[-1000:]
    
    add_field_to_graph(field_name, enriched_name, obj, prop, confidence, pii, application, eim_id)


# ============================================================================
# EMBEDDINGS
# ============================================================================

class OpenAIEmbeddings(Embeddings):
    def __init__(self, model: str = OPENAI_EMBEDDING_MODEL):
        self.model = model
        self.client = openai_client
    
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        embeddings = []
        for idx, text in enumerate(texts, 1):
            print(f"      üìä Embedding {idx}/{len(texts)}")
            embeddings.append(self.embed_query(text))
            time.sleep(0.1)
        return embeddings
    
    def embed_query(self, text: str) -> List[float]:
        response = self.client.embeddings.create(model=self.model, input=[text[:8000]])
        return response.data[0].embedding


def call_openai_with_retry(messages: List[Dict], max_retries: int = 10) -> str:
    for attempt in range(max_retries):
        try:
            response = openai_client.chat.completions.create(model=OPENAI_REASONING_MODEL, messages=messages)
            return response.choices[0].message.content
        except Exception as e:
            print(f"      ‚ö† Attempt {attempt + 1} failed: {e}")
            time.sleep(2 ** attempt)
    raise Exception(f"Failed after {max_retries} attempts")


# ============================================================================
# AGENT STATE
# ============================================================================

class EnrichmentState(TypedDict):
    messages: Annotated[Sequence[BaseMessage], add_messages]
    current_field: Dict[str, Any]
    enriched_name: str
    enriched_description: str
    object_name: str
    property_name: str
    object_was_modelled: bool
    property_was_modelled: bool
    pii_classification: Dict[str, Any]
    enrichment_rationale: str
    mapping_rationale: str
    enrichment_confidence: Dict[str, Any]
    mapping_confidence: Dict[str, Any]
    pii_confidence: Dict[str, Any]
    intersection_vector_store: Any
    object_vector_store: Any
    property_vector_store: Any
    all_objects: List[str]
    all_properties: List[str]
    objects_dict: Dict[str, List[str]]
    acronym_dict: Dict[str, str]
    graph_patterns: Dict[str, Any]
    graph_reasoning: str
    mapping_strategy: str


# ============================================================================
# ENRICHMENT COORDINATOR
# ============================================================================

def enrichment_coordinator_node(state: EnrichmentState) -> EnrichmentState:
    """Coordinator with context pollution prevention and proper modelling."""
    
    field_name = state['current_field'].get('Field Name', '')
    app_name = state['current_field'].get('Application Name', '')
    app_desc = state['current_field'].get('Application Description', '')
    
    print(f"\n{'='*80}")
    print(f"PROCESSING: {field_name}")
    print(f"APPLICATION: {app_name}")
    print(f"{'='*80}")
    
    # STEP 1: ENRICHMENT WITH CONTEXT POLLUTION PREVENTION
    print("\n[STEP 1] ISO 11179 Name Enrichment (Context-Aware)...")
    
    enrichment_prompt = f"""You are an ISO 11179 metadata naming expert.

CRITICAL INSTRUCTION - PREVENT CONTEXT POLLUTION:
The field is from a "{app_name}" application/system. DO NOT assume the field is about "{app_name.split()[0]}" just because that word appears in the application name.

ANALYZE THE FIELD NAME ITSELF, NOT THE APPLICATION CONTEXT.

FIELD NAME TO ENRICH: {field_name}

RULES FOR DERIVING OBJECT CLASS:
1. Look at the FIELD NAME ONLY - ignore application name/description
2. Identify prefixes in the field name:
   - "cust_", "customer_" ‚Üí Customer
   - "txn_", "trans_" ‚Üí Transaction
   - "acc_", "acct_", "account_" ‚Üí Account
   - "emp_", "employee_" ‚Üí Employee
   - "prod_", "product_" ‚Üí Product
   - "pay_", "payment_" ‚Üí Payment
   - "usr_", "user_" ‚Üí User
   - "sys_", "system_" ‚Üí System
   - "addr_", "address_" ‚Üí Address
   - "inv_", "invoice_" ‚Üí Invoice
   - "ord_", "order_" ‚Üí Order

3. If field has NO clear object prefix, use GENERIC object classes:
   - "balance" ‚Üí Account Balance (not Customer Balance)
   - "amount" ‚Üí Transaction Amount (not Customer Amount)
   - "status" ‚Üí Status (not Customer Status)
   - "code" ‚Üí Code (not Customer Code)
   - "date" ‚Üí Date (not Customer Date)
   - "number" ‚Üí Number (not Customer Number)

WRONG EXAMPLES (DO NOT DO THIS):
- Field: "balance" in Customer app ‚Üí "Customer Balance" ‚ùå WRONG
- Field: "status_cd" in Customer app ‚Üí "Customer Status Code" ‚ùå WRONG
- Field: "trans_amt" in Customer app ‚Üí "Customer Transaction Amount" ‚ùå WRONG

CORRECT EXAMPLES (DO THIS):
- Field: "balance" in Customer app ‚Üí "Account Balance" ‚úì CORRECT
- Field: "status_cd" in Customer app ‚Üí "Status Code" ‚úì CORRECT
- Field: "trans_amt" in Customer app ‚Üí "Transaction Amount" ‚úì CORRECT
- Field: "cust_name" in Customer app ‚Üí "Customer Name" ‚úì CORRECT (has "cust_" prefix)

ISO 11179 FORMAT: [Object Class] [Qualifier] [Property]
- Use Title Case with proper spacing
- Be semantically accurate to the FIELD NAME
- Generic and reusable across systems

THINK STEP BY STEP:
1. Does the field name have a clear object prefix?
2. If YES: Use that object (e.g., "cust_id" ‚Üí Customer)
3. If NO: Use the most logical GENERIC object (e.g., "balance" ‚Üí Account Balance, not Customer Balance)
4. Remember: Just because the app is about customers doesn't mean every field is a "Customer" field

Provide ONLY the enriched field name, nothing else."""

    try:
        enriched_name = call_openai_with_retry([{"role": "user", "content": enrichment_prompt}]).strip()
        if '\n' in enriched_name:
            enriched_name = enriched_name.split('\n')[0].strip()
        # Remove any quotes or extra text
        enriched_name = enriched_name.strip('"').strip("'").strip()
        state['enriched_name'] = enriched_name
        print(f"   ‚úì Enriched: {enriched_name}")
    except Exception as e:
        print(f"   ‚ùå Enrichment failed: {e}")
        state['enriched_name'] = field_name
    
    # STEP 2: DEFINITION
    print("\n[STEP 2] Definition Generation...")
    try:
        definition_prompt = f"""Create a precise ISO 11179 definition for: {state['enriched_name']}

The definition should:
- State what the concept IS
- Include essential characteristics
- Be semantically accurate
- Be 2-3 sentences

Provide ONLY the definition text."""
        
        definition = call_openai_with_retry([{"role": "user", "content": definition_prompt}]).strip()
        state['enriched_description'] = definition
        print(f"   ‚úì Definition: {definition[:80]}...")
    except:
        state['enriched_description'] = f"A data element representing {state['enriched_name'].lower()}."
    
    # STEP 3: QUERY KNOWLEDGE GRAPH
    print("\n[STEP 3] Querying Knowledge Graph...")
    graph_patterns = query_graph_patterns(field_name)
    state['graph_patterns'] = graph_patterns
    
    if graph_patterns['similar_fields']:
        print(f"   üìä Found {len(graph_patterns['similar_fields'])} similar fields")
        for sf in graph_patterns['similar_fields'][:2]:
            print(f"      ‚Ä¢ {sf['field']} ‚Üí {sf['object']}.{sf['property']}")
    
    # STEP 4: GRAPH REASONING
    print("\n[STEP 4] LLM Graph Reasoning...")
    graph_reasoning = discover_graph_relationships_with_llm(graph_patterns, state['enriched_name'])
    state['graph_reasoning'] = graph_reasoning
    print(f"   üß† Insights: {graph_reasoning[:100]}...")
    
    # STEP 5: HYBRID MATCHING
    print("\n[STEP 5] Hybrid Lexical + Semantic Matching...")
    
    query = f"{state['enriched_name']} {state['enriched_description']}"
    
    object_results = hybrid_similarity_search(query, state['object_vector_store'], state['all_objects'], top_k=5)
    property_results = hybrid_similarity_search(query, state['property_vector_store'], state['all_properties'], top_k=5)
    intersection_results = hybrid_similarity_search(query, state['intersection_vector_store'], [], top_k=5)
    
    print(f"   ‚Üí Top object: {object_results[0][0]} (score: {object_results[0][1]:.3f})")
    print(f"   ‚Üí Top property: {property_results[0][0]} (score: {property_results[0][1]:.3f})")
    
    # STEP 6: SEMANTIC MAPPING WITH MODELLING LOGIC
    print("\n[STEP 6] Semantic Mapping with Modelling Decision...")
    
    mapping_prompt = f"""You are a semantic mapping expert with ISO 11179, BIAN, and FIBO expertise.

TASK: Map this enriched field to object.property OR model new terms if no good match exists.

ENRICHED FIELD: {state['enriched_name']}
DEFINITION: {state['enriched_description']}

HYBRID MATCHING RESULTS:
Top Objects: {json.dumps([(r[0], round(r[1], 3)) for r in object_results[:3]], indent=2)}
Top Properties: {json.dumps([(r[0], round(r[1], 3)) for r in property_results[:3]], indent=2)}

GRAPH INSIGHTS:
{graph_reasoning}

DECISION PROCESS:

STEP 1 - EVALUATE OBJECT MATCH:
- Does the top object semantically match the enriched name?
- Is the match score >0.70?
- Does it make logical sense?
- Example: "Transaction Amount" should map to Transaction (not Customer)
- Example: "Account Balance" should map to Account (not Customer)

STEP 2 - EVALUATE PROPERTY MATCH:
- Does the top property semantically match?
- Is the match score >0.70?
- Does object.property combination make sense?

STEP 3 - DECIDE: MATCH OR MODEL?
- If object score >0.70 AND property score >0.70 AND semantic fit is good: USE PBT MATCH
- If object score >0.70 but property <0.70: USE object, SEARCH all properties for better fit
- If property score >0.70 but object <0.70: USE property, SEARCH all objects for better fit
- If BOTH scores <0.70 OR semantic fit is poor: MODEL NEW TERMS using ISO 11179/BIAN/FIBO

MODELLING GUIDELINES:
When modelling is necessary:
- Follow ISO 11179: Clear, unambiguous, Title Case
- Use BIAN patterns for banking: Party, Account, Product, Agreement, Transaction
- Use FIBO patterns for finance: Financial Instrument, Legal Entity
- Ensure modelled terms are semantically SUPERIOR to available PBT terms

CRITICAL: Be willing to model! If PBT matches are weak or semantically incorrect, model new terms.

OUTPUT FORMAT (JSON only):
{{
    "best_object": "<object name>",
    "best_property": "<property name>",
    "object_was_modelled": <true/false>,
    "property_was_modelled": <true/false>,
    "confidence": <0-100>,
    "strategy": "<pbt_match|object_fixed|property_fixed|modelled>",
    "mapping_rationale": "<DETAILED explanation: Why this mapping? Why this confidence? If modelled, why was it necessary? What PBT alternatives were considered and why rejected? Be specific and thorough.>"
}}

Provide ONLY valid JSON."""

    try:
        mapping_response = call_openai_with_retry([{"role": "user", "content": mapping_prompt}])
        if '```json' in mapping_response:
            mapping_response = mapping_response.split('```json')[1].split('```')[0]
        elif '```' in mapping_response:
            mapping_response = mapping_response.split('```')[1].split('```')[0]
        
        mapping_data = json.loads(mapping_response.strip())
        
        state['object_name'] = mapping_data['best_object']
        state['property_name'] = mapping_data['best_property']
        state['object_was_modelled'] = mapping_data.get('object_was_modelled', False)
        state['property_was_modelled'] = mapping_data.get('property_was_modelled', False)
        state['mapping_strategy'] = mapping_data.get('strategy', 'unknown')
        state['mapping_rationale'] = mapping_data.get('mapping_rationale', 'No rationale provided')
        
        print(f"   ‚úì Mapped: {state['object_name']}.{state['property_name']}")
        print(f"      Strategy: {state['mapping_strategy']}")
        print(f"      Modelled: Obj={state['object_was_modelled']}, Prop={state['property_was_modelled']}")
        print(f"      Rationale: {state['mapping_rationale'][:150]}...")
        
    except Exception as e:
        print(f"   ‚ùå Mapping failed: {e}")
        state['object_name'] = object_results[0][0] if object_results else 'Unknown'
        state['property_name'] = property_results[0][0] if property_results else 'Unknown'
        state['object_was_modelled'] = False
        state['property_was_modelled'] = False
        state['mapping_strategy'] = 'fallback'
        state['mapping_rationale'] = f"Mapping failed with error: {str(e)}"
    
    # STEP 7: PII CLASSIFICATION
    print("\n[STEP 7] PII Classification...")
    try:
        pii_prompt = f"""Classify this data element for PII.

FIELD: {state['enriched_name']}
DESCRIPTION: {state['enriched_description']}
MAPPING: {state['object_name']}.{state['property_name']}

CATEGORIES:
- NON PERSONAL DATA: Cannot identify individuals
- PERSONAL DATA: Can identify individuals (name, email, address, phone, DOB, etc.)
- SENSITIVE PERSONAL DATA: Highly sensitive (SSN, financial accounts, medical, biometric, etc.)

OUTPUT (JSON only):
{{
    "pii_category": "<category>",
    "is_pii": <boolean>,
    "regulatory_considerations": ["<regulations>"],
    "detailed_rationale": "<why this classification?>"
}}"""
        
        pii_response = call_openai_with_retry([{"role": "user", "content": pii_prompt}])
        if '```json' in pii_response:
            pii_response = pii_response.split('```json')[1].split('```')[0]
        elif '```' in pii_response:
            pii_response = pii_response.split('```')[1].split('```')[0]
        
        pii_data = json.loads(pii_response.strip())
        state['pii_classification'] = pii_data
        print(f"   ‚úì PII: {pii_data.get('pii_category', 'UNKNOWN')}")
    except Exception as e:
        print(f"   ‚ùå PII classification failed: {e}")
        state['pii_classification'] = {"pii_category": "NON PERSONAL DATA", "is_pii": False, "regulatory_considerations": [], "detailed_rationale": "Classification failed"}
    
    # STEP 8: SUPERVISOR VALIDATION WITH CONFIDENCE SCORING
    print("\n[STEP 8] Supervisor Validation with Confidence Scoring...")
    
    supervisor_prompt = f"""You are a SUPERVISOR AGENT validating enrichment, mapping, and PII classification.

ORIGINAL FIELD: {field_name}
APPLICATION: {app_name}

RESULTS TO VALIDATE:
- Enriched Name: {state['enriched_name']}
- Description: {state['enriched_description']}
- Mapping: {state['object_name']}.{state['property_name']}
- Strategy: {state['mapping_strategy']}
- Object Modelled: {state['object_was_modelled']}
- Property Modelled: {state['property_was_modelled']}
- PII: {state['pii_classification'].get('pii_category', 'UNKNOWN')}

MAPPING RATIONALE PROVIDED:
{state['mapping_rationale']}

GRAPH INSIGHTS:
{graph_reasoning}

VALIDATION TASKS:

1. ENRICHMENT VALIDATION:
   - Does enriched name follow ISO 11179 standards?
   - Is it semantically accurate to the FIELD NAME (not application)?
   - Did we avoid context pollution (not adding "Customer" inappropriately)?
   - Is the description clear and precise?

2. MAPPING VALIDATION:
   - Is object.property semantically correct?
   - Does the combination make logical sense?
   - If modelled: Was it truly necessary? Could PBT terms work?
   - If using PBT: Is the match semantically strong?

3. PII VALIDATION:
   - Is the PII category appropriate?
   - Are regulatory considerations complete?

4. CONSISTENCY CHECK:
   - Do all components align coherently?
   - Any contradictions?

CONFIDENCE SCORING (CRITICAL):
For EACH of three aspects (enrichment, mapping, PII), you MUST provide:

A. THREE SUPPORTING REASONS:
   Each with weight 0.0-1.0 (0.0=weak, 1.0=very strong)
   Be specific and evidence-based

B. THREE CONTRADICTORY REASONS:
   Each with weight 0.0-1.0 (0.0=minor concern, 1.0=major concern)
   Include doubts, inconsistencies, weaknesses

C. CONFIDENCE SCORE CALCULATION:
   Formula: ((sum_supporting - sum_contradictory) / (sum_supporting + sum_contradictory)) * 100
   Range: 0-100

D. CONFIDENCE RATIONALE:
   Explain why you assigned these weights
   What would increase/decrease confidence?

MODELLING SCRUTINY:
If object or property was modelled:
- Was modelling truly necessary?
- Are there existing PBT terms that could work?
- Is the modelled term semantically superior?
- Only give high confidence (>80) if modelling was genuinely needed

OUTPUT (JSON only):
{{
    "validation_passed": <boolean>,
    "quality_score": <1-10>,
    "enrichment_rationale": "<comprehensive validation of enrichment quality, including context pollution check>",
    "mapping_rationale": "<comprehensive validation of mapping correctness, modelling necessity, semantic fit>",
    "concerns": ["<specific concerns>"],
    "recommendations": ["<specific recommendations>"],
    "final_approval": <boolean>,
    "enrichment_confidence": {{
        "supporting_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "contradictory_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "confidence_score": <0-100>,
        "confidence_rationale": "<detailed explanation of confidence calculation>"
    }},
    "mapping_confidence": {{
        "supporting_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "contradictory_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "confidence_score": <0-100>,
        "confidence_rationale": "<detailed explanation including modelling validation if applicable>"
    }},
    "pii_confidence": {{
        "supporting_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "contradictory_reasons": [
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}},
            {{"reason": "<specific reason>", "weight": <0.0-1.0>}}
        ],
        "confidence_score": <0-100>,
        "confidence_rationale": "<detailed explanation of PII confidence>"
    }}
}}

Provide ONLY valid JSON."""

    try:
        supervisor_response = call_openai_with_retry([{"role": "user", "content": supervisor_prompt}])
        if '```json' in supervisor_response:
            supervisor_response = supervisor_response.split('```json')[1].split('```')[0]
        elif '```' in supervisor_response:
            supervisor_response = supervisor_response.split('```')[1].split('```')[0]
        
        supervisor_data = json.loads(supervisor_response.strip())
        
        state['enrichment_rationale'] = supervisor_data.get('enrichment_rationale', 'No enrichment rationale provided')
        # Note: mapping_rationale is already set from mapping step, but supervisor adds validation
        supervisor_mapping_rationale = supervisor_data.get('mapping_rationale', '')
        if supervisor_mapping_rationale:
            state['mapping_rationale'] = f"{state['mapping_rationale']}\n\nSupervisor Validation: {supervisor_mapping_rationale}"
        
        state['enrichment_confidence'] = supervisor_data.get('enrichment_confidence', {})
        state['mapping_confidence'] = supervisor_data.get('mapping_confidence', {})
        state['pii_confidence'] = supervisor_data.get('pii_confidence', {})
        
        print(f"   ‚úì Validation: Quality {supervisor_data.get('quality_score', 0)}/10")
        print(f"      Enrichment Confidence: {state['enrichment_confidence'].get('confidence_score', 0)}")
        print(f"      Mapping Confidence: {state['mapping_confidence'].get('confidence_score', 0)}")
        print(f"      PII Confidence: {state['pii_confidence'].get('confidence_score', 0)}")
        
    except Exception as e:
        print(f"   ‚ö† Supervisor validation failed: {e}")
        state['enrichment_rationale'] = 'Supervisor validation failed'
        state['enrichment_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Validation failed'}
        state['mapping_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Validation failed'}
        state['pii_confidence'] = {'confidence_score': 0, 'supporting_reasons': [], 'contradictory_reasons': [], 'confidence_rationale': 'Validation failed'}
    
    # STEP 9: UPDATE MEMORY & GRAPH
    print("\n[STEP 9] Updating Memory & Knowledge Graph...")
    try:
        update_all_memory(
            field_name,
            state['enriched_name'],
            state['object_name'],
            state['property_name'],
            state['mapping_strategy'],
            state['mapping_confidence'].get('confidence_score', 0),
            state['pii_classification'].get('pii_category', 'NON PERSONAL DATA'),
            state['object_was_modelled'],
            state['property_was_modelled'],
            app_name,
            state['current_field'].get('EIM ID', '')
        )
        print(f"   ‚úì Memory & graph updated")
    except Exception as e:
        print(f"   ‚ö† Memory update failed: {e}")
    
    print(f"{'='*80}\n")
    return state


def should_continue(state: EnrichmentState) -> Literal["end"]:
    return "end"


def create_enrichment_graph():
    workflow = StateGraph(EnrichmentState)
    workflow.add_node("enrichment_coordinator", enrichment_coordinator_node)
    workflow.set_entry_point("enrichment_coordinator")
    workflow.add_conditional_edges("enrichment_coordinator", should_continue, {"end": END})
    return workflow.compile()


# ============================================================================
# MAIN PROCESSING
# ============================================================================

def process_data_enrichment_and_mapping():
    print("="*80)
    print("ISO 11179 WITH KNOWLEDGE GRAPH & ADVANCED REASONING")
    print("FIXED: Context pollution, Modelling, Complete output")
    print("="*80)
    
    print("\n[1] Loading Memory & Knowledge Graph...")
    load_all_memory()
    
    print("\n[2] Loading Input...")
    with open(INPUT_JSON_PATH, 'r') as f:
        input_data = json.load(f)
    print(f"   ‚Üí {len(input_data)} records")
    
    acronym_dict = {}
    if os.path.exists(ACRONYM_CSV_PATH):
        df = pd.read_csv(ACRONYM_CSV_PATH)
        for _, row in df.iterrows():
            acronym_dict[str(row['acronym']).strip().upper()] = str(row['expansion']).strip()
        print(f"   ‚Üí {len(acronym_dict)} acronyms")
    
    print("\n[3] Creating Vector Stores...")
    excel_df = pd.read_excel(EXCEL_PATH)
    
    objects_dict = {}
    all_objects = []
    all_properties = []
    
    for _, row in excel_df.iterrows():
        obj = str(row['Object name']).strip()
        prop = str(row['Property name']).strip()
        
        if obj not in objects_dict:
            objects_dict[obj] = []
            all_objects.append(obj)
        if prop not in objects_dict[obj]:
            objects_dict[obj].append(prop)
        if prop not in all_properties:
            all_properties.append(prop)
    
    print(f"   ‚Üí {len(all_objects)} objects, {len(all_properties)} properties")
    
    embeddings = OpenAIEmbeddings()
    
    intersection_docs = [Document(page_content=f"{obj} {prop}", metadata={"object": obj, "property": prop}) for obj in all_objects for prop in objects_dict[obj]]
    intersection_store = InMemoryVectorStore.from_documents(intersection_docs, embeddings)
    
    object_docs = [Document(page_content=obj, metadata={"object": obj}) for obj in all_objects]
    object_store = InMemoryVectorStore.from_documents(object_docs, embeddings)
    
    property_docs = [Document(page_content=prop, metadata={"property": prop}) for prop in all_properties]
    property_store = InMemoryVectorStore.from_documents(property_docs, embeddings)
    
    print(f"   ‚úì Created 3 vector stores")
    
    print("\n[4] Initializing Workflow...")
    app = create_enrichment_graph()
    
    print(f"\n[5] Processing Records...")
    
    successful = 0
    failed = 0
    modelled_obj = 0
    modelled_prop = 0
    
    for idx, record in enumerate(input_data):
        eim_id = record.get("EIM ID", "")
        print(f"\n{'='*80}")
        print(f"Record {idx + 1}/{len(input_data)} (EIM ID: {eim_id})")
        print(f"{'='*80}")
        
        try:
            initial_state = {
                "messages": [], "current_field": record, "enriched_name": "", "enriched_description": "",
                "object_name": "", "property_name": "", "object_was_modelled": False, "property_was_modelled": False,
                "pii_classification": {}, "enrichment_rationale": "", "mapping_rationale": "",
                "enrichment_confidence": {}, "mapping_confidence": {}, "pii_confidence": {},
                "intersection_vector_store": intersection_store, "object_vector_store": object_store,
                "property_vector_store": property_store, "all_objects": all_objects, "all_properties": all_properties,
                "objects_dict": objects_dict, "acronym_dict": acronym_dict,
                "graph_patterns": {}, "graph_reasoning": "", "mapping_strategy": "unknown"
            }
            
            final_state = app.invoke(initial_state)
            
            def fmt_reasons(reasons):
                if not reasons:
                    return ""
                return " | ".join([f"{i+1}. {r.get('reason', 'N/A')} (weight: {r.get('weight', 0.0):.2f})" for i, r in enumerate(reasons)])
            
            pii = final_state['pii_classification']
            ec = final_state.get('enrichment_confidence', {})
            mc = final_state.get('mapping_confidence', {})
            pc = final_state.get('pii_confidence', {})
            
            result = {
                "EIM ID": eim_id,
                "Application Name": record.get("Application Name", ""),
                "Application Description": record.get("Application Description", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": final_state['enriched_name'],
                "Enriched Description": final_state['enriched_description'],
                "Mapped Object": final_state['object_name'],
                "Mapped Property": final_state['property_name'],
                "Mapping Strategy": final_state.get('mapping_strategy', 'unknown'),
                "Object Was Modelled": final_state.get('object_was_modelled', False),
                "Property Was Modelled": final_state.get('property_was_modelled', False),
                "PII Category": pii.get('pii_category', ''),
                "Is PII": pii.get('is_pii', False),
                "Regulatory Considerations": ", ".join(pii.get('regulatory_considerations', [])),
                "PII Rationale": pii.get('detailed_rationale', ''),
                "Enrichment Rationale": final_state.get('enrichment_rationale', ''),
                "Mapping Rationale": final_state.get('mapping_rationale', ''),
                "Enrichment Confidence Score": ec.get('confidence_score', 0),
                "Enrichment Supporting Reasons": fmt_reasons(ec.get('supporting_reasons', [])),
                "Enrichment Contradictory Reasons": fmt_reasons(ec.get('contradictory_reasons', [])),
                "Enrichment Confidence Rationale": ec.get('confidence_rationale', ''),
                "Mapping Confidence Score": mc.get('confidence_score', 0),
                "Mapping Supporting Reasons": fmt_reasons(mc.get('supporting_reasons', [])),
                "Mapping Contradictory Reasons": fmt_reasons(mc.get('contradictory_reasons', [])),
                "Mapping Confidence Rationale": mc.get('confidence_rationale', ''),
                "PII Confidence Score": pc.get('confidence_score', 0),
                "PII Supporting Reasons": fmt_reasons(pc.get('supporting_reasons', [])),
                "PII Contradictory Reasons": fmt_reasons(pc.get('contradictory_reasons', [])),
                "PII Confidence Rationale": pc.get('confidence_rationale', ''),
                "Graph Reasoning": final_state.get('graph_reasoning', '')[:500],
                "Original ISR Classification": record.get("ISR Classification", ""),
                "Status": "SUCCESS"
            }
            
            successful += 1
            if result["Object Was Modelled"]:
                modelled_obj += 1
            if result["Property Was Modelled"]:
                modelled_prop += 1
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
            
            result = {
                "EIM ID": eim_id, "Application Name": record.get("Application Name", ""),
                "Application Description": record.get("Application Description", ""),
                "Original Field Name": record.get("Field Name", ""),
                "Enriched Field Name": record.get("Field Name", ""),
                "Enriched Description": f"Error: {str(e)[:200]}",
                "Mapped Object": "Unknown", "Mapped Property": "Unknown",
                "Mapping Strategy": "error", "Object Was Modelled": False, "Property Was Modelled": False,
                "PII Category": "NON PERSONAL DATA", "Is PII": False,
                "Regulatory Considerations": "", "PII Rationale": "",
                "Enrichment Rationale": "Error", "Mapping Rationale": "Error",
                "Enrichment Confidence Score": 0, "Enrichment Supporting Reasons": "",
                "Enrichment Contradictory Reasons": "", "Enrichment Confidence Rationale": "",
                "Mapping Confidence Score": 0, "Mapping Supporting Reasons": "",
                "Mapping Contradictory Reasons": "", "Mapping Confidence Rationale": "",
                "PII Confidence Score": 0, "PII Supporting Reasons": "",
                "PII Contradictory Reasons": "", "PII Confidence Rationale": "",
                "Graph Reasoning": "", "Original ISR Classification": record.get("ISR Classification", ""),
                "Status": "FAILED"
            }
            failed += 1
        
        # Write incrementally
        pd.DataFrame([result]).to_csv(OUTPUT_CSV_PATH, mode='a', header=(successful+failed==1), index=False)
        print(f"\n   ‚Üí Written to CSV")
    
    print("\n[6] Saving Memory & Knowledge Graph...")
    save_all_memory()
    
    print(f"\n{'='*80}")
    print("COMPLETE!")
    print(f"{'='*80}")
    print(f"Success: {successful}, Failed: {failed}")
    print(f"Modelled: Objects={modelled_obj}, Properties={modelled_prop}")
    print(f"\nGraph: {SEMANTIC_KNOWLEDGE_GRAPH.number_of_nodes()} nodes, {SEMANTIC_KNOWLEDGE_GRAPH.number_of_edges()} edges")
    print(f"Output: {OUTPUT_CSV_PATH}")


if __name__ == "__main__":
    process_data_enrichment_and_mapping()
