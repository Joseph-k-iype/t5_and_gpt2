"""
Advanced ELDM Field Mapping System with Graph RAG
Uses FalkorDB native vector indexes, full-text search, hybrid search, and Graph RAG
Leverages cosine similarity, relationship traversal, and multi-modal retrieval
"""

import os
import json
import numpy as np
import pandas as pd
from typing import List, Dict, Any, Optional, TypedDict, Annotated, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import logging
from scipy.stats import zscore
import operator

# OpenAI and LangChain imports
import openai
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# FalkorDB
from falkordb import FalkorDB

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


# ============================================================================
# GLOBAL CONFIGURATION
# ============================================================================

# OpenAI API Configuration
BASE_URL = "https://your-openai-gateway.company.com/v1"
API_KEY = "your-api-key-here"
REASONING_MODEL = "o3-mini"
EMBEDDING_MODEL = "text-embedding-3-large"
EMBEDDING_DIMENSIONS = 3072

# FalkorDB Configuration
FALKORDB_HOST = "localhost"
FALKORDB_PORT = 6379
GRAPH_NAME = "ELDM_MAPPING"

# File Paths
TRANSACTION_FILE = "transaction_fields.xlsx"
ELDM_FILE = "eldm_attributes.xlsx"
OUTPUT_FILE = "eldm_mapping_results.xlsx"

# Search Configuration
VECTOR_INDEX_NAME = "eldm_vector_idx"
FULLTEXT_INDEX_NAME = "eldm_fulltext_idx"
HYBRID_SEARCH_ALPHA = 0.6  # Weight for vector vs full-text (0.6 = 60% vector, 40% text)

# Confidence Thresholds
HIGH_CONFIDENCE_THRESHOLD = 0.85
MEDIUM_CONFIDENCE_THRESHOLD = 0.70
LOW_CONFIDENCE_THRESHOLD = 0.50

# Processing Configuration
BATCH_SIZE = 50
TOP_K_CANDIDATES = 5


# ============================================================================
# DATA MODELS
# ============================================================================

@dataclass
class TransactionField:
    """Represents a field from the transaction file"""
    tt_file_name: str
    tt_column_name: str
    standardised_name: str
    is_primary_key: bool
    comment: str
    data_type: str
    creation_sql: str
    transformation_sql: str
    
    def get_context(self) -> str:
        """Get rich context for this field"""
        context = f"""
Field: {self.tt_column_name}
Standardised Name: {self.standardised_name}
File: {self.tt_file_name}
Data Type: {self.data_type}
Primary Key: {self.is_primary_key}
Description: {self.comment}

SQL Context:
Creation: {self.creation_sql}
Transformation: {self.transformation_sql}
"""
        return context.strip()
    
    def get_searchable_text(self) -> str:
        """Get text for embedding and full-text search"""
        parts = [
            self.tt_column_name,
            self.standardised_name,
            self.comment,
            self.data_type,
            f"primary_key_{self.is_primary_key}"
        ]
        return " ".join([p for p in parts if p and str(p).strip()])


@dataclass
class ELDMAttribute:
    """Represents an attribute from ELDM"""
    name: str
    description: str
    entity_attribute_path: str
    embedding: Optional[np.ndarray] = None
    
    def get_searchable_text(self) -> str:
        """Get text representation for embedding and indexing"""
        return f"{self.name} {self.description} {self.entity_attribute_path}"


@dataclass
class MappingResult:
    """Represents a mapping result with confidence scores"""
    transaction_field: str
    eldm_attribute: str
    confidence_score: float
    vector_similarity: float
    fulltext_score: float
    hybrid_score: float
    graph_rag_score: float
    reasoning_confidence: float
    validation_score: float
    reasoning_explanation: str
    validation_notes: str
    statistical_metrics: Dict[str, float]
    confidence_level: str
    retrieval_method: str  # VECTOR, FULLTEXT, HYBRID, GRAPH_RAG
    timestamp: str


class GraphState(TypedDict):
    """State for the LangGraph workflow"""
    transaction_field: TransactionField
    vector_candidates: List[Dict[str, Any]]
    fulltext_candidates: List[Dict[str, Any]]
    hybrid_candidates: List[Dict[str, Any]]
    graph_rag_candidates: List[Dict[str, Any]]
    final_candidates: List[Dict[str, Any]]
    mapping_proposals: List[Dict[str, Any]]
    validation_results: List[Dict[str, Any]]
    final_mapping: Optional[MappingResult]
    messages: Annotated[List, operator.add]
    iteration_count: int
    memory_context: Dict[str, Any]


# ============================================================================
# EMBEDDING SERVICE
# ============================================================================

class EmbeddingService:
    """Direct OpenAI API embedding service"""
    
    def __init__(self):
        self.client = openai.OpenAI(
            base_url=BASE_URL,
            api_key=API_KEY
        )
        logger.info(f"Initialized EmbeddingService with model: {EMBEDDING_MODEL}")
    
    def create_embedding(self, text: str) -> np.ndarray:
        """Create embedding for a single text"""
        try:
            response = self.client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text,
                dimensions=EMBEDDING_DIMENSIONS
            )
            embedding = np.array(response.data[0].embedding)
            return embedding
        except Exception as e:
            logger.error(f"Error creating embedding: {e}")
            raise
    
    def create_embeddings_batch(self, texts: List[str]) -> List[np.ndarray]:
        """Create embeddings for multiple texts"""
        try:
            response = self.client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=texts,
                dimensions=EMBEDDING_DIMENSIONS
            )
            embeddings = [np.array(item.embedding) for item in response.data]
            logger.info(f"Created {len(embeddings)} embeddings in batch")
            return embeddings
        except Exception as e:
            logger.error(f"Error creating batch embeddings: {e}")
            raise


# ============================================================================
# FALKORDB GRAPH RAG KNOWLEDGE GRAPH
# ============================================================================

class ELDMGraphRAG:
    """FalkorDB-based Graph RAG system with vector and full-text indexes"""
    
    def __init__(self):
        self.db = FalkorDB(
            host=FALKORDB_HOST,
            port=FALKORDB_PORT
        )
        self.graph = self.db.select_graph(GRAPH_NAME)
        logger.info(f"Connected to FalkorDB graph: {GRAPH_NAME}")
    
    def clear_graph(self):
        """Clear all data from the graph"""
        self.graph.query("MATCH (n) DETACH DELETE n")
        logger.info("Cleared FalkorDB graph")
    
    def create_indexes(self):
        """Create vector and full-text indexes using FalkorDB native functions"""
        try:
            # Create vector index for ELDM attributes with cosine similarity
            vector_index_query = f"""
            CREATE VECTOR INDEX FOR (e:ELDMAttribute) ON (e.embedding) 
            OPTIONS {{
                dimension: {EMBEDDING_DIMENSIONS}, 
                similarityFunction: 'cosine',
                M: 32,
                efConstruction: 200,
                efRuntime: 10
            }}
            """
            self.graph.query(vector_index_query)
            logger.info(f"Created vector index with cosine similarity (dimension: {EMBEDDING_DIMENSIONS})")
            
            # Create full-text index for ELDM attributes
            fulltext_index_query = """
            CALL db.idx.fulltext.createNodeIndex('ELDMAttribute', 
                {field: 'searchable_text', phonetic: 'dm:en'}, 
                {field: 'name'}, 
                {field: 'description'},
                {field: 'entity_attribute_path'}
            )
            """
            self.graph.query(fulltext_index_query)
            logger.info("Created full-text index with phonetic matching")
            
            # Create indexes for relationships
            self.graph.query("CREATE INDEX FOR (t:TransactionField) ON (t.name)")
            self.graph.query("CREATE INDEX FOR (t:TransactionField) ON (t.file_name)")
            
            logger.info("All indexes created successfully")
            
        except Exception as e:
            logger.warning(f"Index creation note: {e}")
    
    def store_eldm_attribute(self, attribute: ELDMAttribute):
        """Store an ELDM attribute with embedding using vecf32"""
        # Convert embedding to list for vecf32
        embedding_list = attribute.embedding.tolist()
        
        query = """
        CREATE (e:ELDMAttribute {
            name: $name,
            description: $description,
            entity_attribute_path: $entity_attribute_path,
            searchable_text: $searchable_text,
            embedding: vecf32($embedding),
            created_at: $created_at
        })
        """
        params = {
            'name': attribute.name,
            'description': attribute.description,
            'entity_attribute_path': attribute.entity_attribute_path,
            'searchable_text': attribute.get_searchable_text(),
            'embedding': embedding_list,
            'created_at': datetime.now().isoformat()
        }
        self.graph.query(query, params)
    
    def store_eldm_attributes_batch(self, attributes: List[ELDMAttribute]):
        """Store multiple ELDM attributes"""
        for attr in attributes:
            self.store_eldm_attribute(attr)
        logger.info(f"Stored {len(attributes)} ELDM attributes in FalkorDB")
    
    def vector_search(self, query_embedding: np.ndarray, top_k: int = 5) -> List[Dict[str, Any]]:
        """Perform native vector similarity search using FalkorDB's vector index"""
        embedding_list = query_embedding.tolist()
        
        # Use FalkorDB's native vector search with cosine similarity
        query = f"""
        CALL db.idx.vector.queryNodes('ELDMAttribute', 'embedding', {top_k}, vecf32($embedding))
        YIELD node, score
        RETURN node.name as name,
               node.description as description,
               node.entity_attribute_path as entity_attribute_path,
               score
        ORDER BY score DESC
        """
        
        result = self.graph.query(query, {'embedding': embedding_list})
        
        candidates = []
        for record in result.result_set:
            candidates.append({
                'name': record[0],
                'description': record[1],
                'entity_attribute_path': record[2],
                'similarity': record[3],
                'method': 'VECTOR'
            })
        
        logger.info(f"Vector search returned {len(candidates)} candidates")
        return candidates
    
    def fulltext_search(self, query_text: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """Perform full-text search using FalkorDB's full-text index"""
        # Use FalkorDB's native full-text search
        query = f"""
        CALL db.idx.fulltext.queryNodes('ELDMAttribute', $query_text)
        YIELD node, score
        RETURN node.name as name,
               node.description as description,
               node.entity_attribute_path as entity_attribute_path,
               score
        ORDER BY score DESC
        LIMIT {top_k}
        """
        
        result = self.graph.query(query, {'query_text': query_text})
        
        candidates = []
        for record in result.result_set:
            candidates.append({
                'name': record[0],
                'description': record[1],
                'entity_attribute_path': record[2],
                'similarity': record[3],
                'method': 'FULLTEXT'
            })
        
        logger.info(f"Full-text search returned {len(candidates)} candidates")
        return candidates
    
    def hybrid_search(self, query_embedding: np.ndarray, query_text: str, 
                     top_k: int = 5, alpha: float = HYBRID_SEARCH_ALPHA) -> List[Dict[str, Any]]:
        """
        Perform hybrid search combining vector and full-text search
        alpha: weight for vector search (1-alpha for full-text)
        """
        # Get results from both search methods
        vector_results = self.vector_search(query_embedding, top_k * 2)
        fulltext_results = self.fulltext_search(query_text, top_k * 2)
        
        # Combine and normalize scores
        combined_scores = {}
        
        # Normalize vector scores
        vector_scores = {r['name']: r['similarity'] for r in vector_results}
        max_vector = max(vector_scores.values()) if vector_scores else 1.0
        
        # Normalize full-text scores
        fulltext_scores = {r['name']: r['similarity'] for r in fulltext_results}
        max_fulltext = max(fulltext_scores.values()) if fulltext_scores else 1.0
        
        # Collect all unique names
        all_names = set(vector_scores.keys()) | set(fulltext_scores.keys())
        
        # Calculate hybrid scores
        for name in all_names:
            v_score = vector_scores.get(name, 0.0) / max_vector if max_vector > 0 else 0.0
            f_score = fulltext_scores.get(name, 0.0) / max_fulltext if max_fulltext > 0 else 0.0
            combined_scores[name] = alpha * v_score + (1 - alpha) * f_score
        
        # Get full details for top results
        sorted_names = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
        
        candidates = []
        for name, hybrid_score in sorted_names:
            # Find the full record
            record = next((r for r in vector_results + fulltext_results if r['name'] == name), None)
            if record:
                candidates.append({
                    'name': record['name'],
                    'description': record['description'],
                    'entity_attribute_path': record['entity_attribute_path'],
                    'similarity': hybrid_score,
                    'vector_score': vector_scores.get(name, 0.0),
                    'fulltext_score': fulltext_scores.get(name, 0.0),
                    'method': 'HYBRID'
                })
        
        logger.info(f"Hybrid search returned {len(candidates)} candidates")
        return candidates
    
    def graph_rag_search(self, query_embedding: np.ndarray, query_text: str, 
                        transaction_field: TransactionField, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        Perform Graph RAG search: combine vector similarity with graph relationships
        This leverages graph structure for context-aware retrieval
        """
        # First, do hybrid search to get initial candidates
        candidates = self.hybrid_search(query_embedding, query_text, top_k * 2)
        
        # Check if similar fields have been mapped (graph traversal)
        similar_mappings_query = """
        MATCH (t:TransactionField)-[r:MAPPED_TO]->(e:ELDMAttribute)
        WHERE t.data_type = $data_type 
           OR t.file_name = $file_name
           OR t.standardised_name CONTAINS $partial_name
        WITH e, COUNT(r) as mapping_frequency, AVG(r.confidence_score) as avg_confidence
        RETURN e.name as name,
               e.description as description,
               e.entity_attribute_path as entity_attribute_path,
               mapping_frequency,
               avg_confidence
        ORDER BY mapping_frequency DESC, avg_confidence DESC
        LIMIT $top_k
        """
        
        params = {
            'data_type': transaction_field.data_type,
            'file_name': transaction_field.tt_file_name,
            'partial_name': transaction_field.standardised_name[:10] if transaction_field.standardised_name else "",
            'top_k': top_k
        }
        
        result = self.graph.query(similar_mappings_query, params)
        
        # Add graph context to candidates
        graph_boosted = {}
        for record in result.result_set:
            name = record[0]
            mapping_freq = record[3]
            avg_conf = record[4]
            # Boost score based on historical mappings
            graph_boosted[name] = {
                'name': record[0],
                'description': record[1],
                'entity_attribute_path': record[2],
                'graph_boost': mapping_freq * avg_conf * 0.2,  # 20% boost factor
                'mapping_frequency': mapping_freq,
                'avg_confidence': avg_conf
            }
        
        # Combine with hybrid search results
        enhanced_candidates = []
        for candidate in candidates:
            name = candidate['name']
            base_score = candidate['similarity']
            
            # Add graph boost if available
            if name in graph_boosted:
                boost = graph_boosted[name]['graph_boost']
                enhanced_score = min(base_score + boost, 1.0)  # Cap at 1.0
                candidate['similarity'] = enhanced_score
                candidate['graph_rag_score'] = boost
                candidate['mapping_frequency'] = graph_boosted[name]['mapping_frequency']
                candidate['method'] = 'GRAPH_RAG'
            else:
                candidate['graph_rag_score'] = 0.0
                candidate['mapping_frequency'] = 0
            
            enhanced_candidates.append(candidate)
        
        # Re-sort by enhanced score
        enhanced_candidates.sort(key=lambda x: x['similarity'], reverse=True)
        
        logger.info(f"Graph RAG search returned {len(enhanced_candidates[:top_k])} candidates with relationship context")
        return enhanced_candidates[:top_k]
    
    def store_mapping_result(self, result: MappingResult, transaction_field: TransactionField):
        """Store a mapping result with rich relationships in the graph"""
        query = """
        MERGE (e:ELDMAttribute {name: $eldm_name})
        MERGE (t:TransactionField {
            name: $transaction_field,
            file_name: $file_name,
            data_type: $data_type,
            standardised_name: $standardised_name
        })
        MERGE (t)-[r:MAPPED_TO]->(e)
        SET r.confidence_score = $confidence_score,
            r.vector_similarity = $vector_similarity,
            r.hybrid_score = $hybrid_score,
            r.reasoning_confidence = $reasoning_confidence,
            r.validation_score = $validation_score,
            r.confidence_level = $confidence_level,
            r.retrieval_method = $retrieval_method,
            r.reasoning_explanation = $reasoning_explanation,
            r.timestamp = $timestamp
        """
        params = {
            'eldm_name': result.eldm_attribute,
            'transaction_field': result.transaction_field,
            'file_name': transaction_field.tt_file_name,
            'data_type': transaction_field.data_type,
            'standardised_name': transaction_field.standardised_name,
            'confidence_score': result.confidence_score,
            'vector_similarity': result.vector_similarity,
            'hybrid_score': result.hybrid_score,
            'reasoning_confidence': result.reasoning_confidence,
            'validation_score': result.validation_score,
            'confidence_level': result.confidence_level,
            'retrieval_method': result.retrieval_method,
            'reasoning_explanation': result.reasoning_explanation,
            'timestamp': result.timestamp
        }
        self.graph.query(query, params)
        logger.info(f"Stored mapping result with Graph RAG relationships")


# ============================================================================
# AGENT PROMPTS
# ============================================================================

MAPPING_AGENT_SYSTEM_PROMPT = """You are an expert data architect and semantic mapping specialist with deep knowledge of enterprise data modeling, database schemas, and logical data models.

Your task is to analyze transaction fields and map them to Enterprise Logical Data Model (ELDM) attributes with high precision and confidence.

You will receive:
1. A transaction field with rich context including:
   - Field name and standardized name
   - Data type and constraints
   - SQL creation and transformation queries
   - Comments and descriptions
2. Candidates from multiple retrieval methods:
   - Vector similarity search (semantic meaning)
   - Full-text search (keyword matching)
   - Hybrid search (combined approach)
   - Graph RAG (relationship-aware with historical context)

Your responsibilities:
1. Analyze the semantic meaning and purpose of the transaction field
2. Consider the SQL context to understand data lineage and transformations
3. Evaluate each candidate ELDM attribute for conceptual alignment
4. Consider historical mapping patterns from Graph RAG (if available)
5. Propose the best mapping with detailed reasoning
6. Provide a confidence score (0.0 to 1.0) based on:
   - Semantic alignment
   - Data type compatibility
   - Business context match
   - SQL context relevance
   - Historical mapping patterns

Use chain-of-thought reasoning. Break down your analysis step by step:
- What does this transaction field represent?
- What are the key semantic concepts?
- How do the SQL queries inform the field's purpose?
- Which retrieval method provides the most relevant candidates?
- Do historical mappings suggest a pattern?
- Which ELDM attribute best captures this meaning?
- What is your confidence level and why?

Be precise, thorough, and justify your reasoning with specific evidence from all contexts provided."""

VALIDATION_AGENT_SYSTEM_PROMPT = """You are a senior data governance specialist and quality assurance expert responsible for validating data mappings in enterprise systems.

Your task is to critically evaluate proposed field-to-attribute mappings to ensure they meet enterprise standards for accuracy, consistency, and semantic correctness.

You will receive:
1. A transaction field with full context
2. A proposed ELDM attribute mapping
3. The mapping agent's reasoning and confidence score
4. Retrieval method used (vector, full-text, hybrid, or Graph RAG)
5. Historical mapping patterns (if available from Graph RAG)

Your responsibilities:
1. Validate the semantic correctness of the mapping
2. Check for logical inconsistencies or misalignments
3. Evaluate whether the data types are compatible
4. Assess if the SQL context supports the mapping
5. Consider if historical patterns support or contradict this mapping
6. Identify potential issues, edge cases, or concerns
7. Provide a validation score (0.0 to 1.0) indicating:
   - APPROVE (0.8-1.0): High confidence, mapping is correct
   - NEEDS_REVIEW (0.5-0.79): Uncertain, requires human review
   - REJECT (0.0-0.49): Incorrect mapping, significant issues

Use systematic validation:
- Does the mapping preserve semantic meaning?
- Are there any conceptual mismatches?
- Could this mapping cause data quality issues?
- Do historical mappings support this choice?
- What alternative mappings might be better?
- What evidence supports or contradicts this mapping?

Be critical, objective, and thorough. Your validation protects data integrity."""

SUPERVISOR_AGENT_SYSTEM_PROMPT = """You are the chief data architect overseeing the enterprise data mapping initiative. You have final authority over all mapping decisions.

Your task is to review mapping proposals and validation results, then make final decisions that balance accuracy, confidence, and business needs.

You will receive:
1. Transaction field context
2. Mapping proposal with agent reasoning
3. Validation results and concerns
4. Statistical confidence metrics
5. Retrieval method effectiveness scores
6. Historical mapping patterns from Graph RAG

Your responsibilities:
1. Synthesize all available evidence and reasoning
2. Resolve any conflicts between mapping and validation agents
3. Consider the effectiveness of different retrieval methods
4. Weight historical patterns appropriately
5. Make final mapping decisions based on:
   - Overall confidence score
   - Semantic alignment quality
   - Validation assessment
   - Statistical metrics
   - Historical consistency
6. Classify mappings into confidence levels:
   - HIGH: Confidence ≥ 0.85 - Auto-approve
   - MEDIUM: 0.70 ≤ Confidence < 0.85 - Flag for review
   - LOW: 0.50 ≤ Confidence < 0.70 - Require human validation
   - REJECTED: Confidence < 0.50 - Reject mapping

Decision-making principles:
- Prioritize semantic correctness over statistical similarity
- Consider historical patterns but don't blindly follow them
- Weight Graph RAG insights when available
- Consider both agents' reasoning carefully
- Be conservative with high-confidence approvals
- Document reasoning for all decisions
- Flag ambiguous cases for human review

You ensure mapping quality, consistency, and trustworthiness across the enterprise."""


# ============================================================================
# MULTI-AGENT SYSTEM
# ============================================================================

class MappingAgent:
    """Agent responsible for proposing field-to-attribute mappings"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=REASONING_MODEL,
            base_url=BASE_URL,
            api_key=API_KEY
        )
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", MAPPING_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])
        logger.info("Initialized MappingAgent")
    
    def propose_mapping(self, state: GraphState) -> GraphState:
        """Propose a mapping for the transaction field"""
        field = state['transaction_field']
        
        # Use the best candidates (prioritize Graph RAG if available)
        candidates = state.get('graph_rag_candidates') or state.get('hybrid_candidates') or state.get('vector_candidates', [])
        
        # Prepare input for the agent
        input_text = f"""
Transaction Field Analysis Required:

{field.get_context()}

Candidate ELDM Attributes from Multi-Modal Retrieval:
"""
        for i, candidate in enumerate(candidates, 1):
            method = candidate.get('method', 'UNKNOWN')
            input_text += f"""
{i}. Name: {candidate['name']}
   Description: {candidate['description']}
   Entity Path: {candidate['entity_attribute_path']}
   Similarity Score: {candidate['similarity']:.4f}
   Retrieval Method: {method}
"""
            if method == 'GRAPH_RAG':
                input_text += f"   Historical Mappings: {candidate.get('mapping_frequency', 0)} similar fields mapped\n"
                input_text += f"   Average Confidence: {candidate.get('avg_confidence', 0.0):.3f}\n"
            elif method == 'HYBRID':
                input_text += f"   Vector Score: {candidate.get('vector_score', 0.0):.4f}\n"
                input_text += f"   Full-Text Score: {candidate.get('fulltext_score', 0.0):.4f}\n"
        
        input_text += """
Based on the above context, propose the best mapping. Your response must be a JSON object with this exact structure:
{
    "selected_eldm_attribute": "exact name of the ELDM attribute",
    "confidence_score": 0.0-1.0,
    "reasoning": "detailed step-by-step reasoning",
    "key_factors": ["factor1", "factor2", "factor3"],
    "concerns": ["any concerns or caveats"],
    "retrieval_method_used": "which retrieval method was most helpful"
}
"""
        
        try:
            messages = state.get('messages', [])
            chain = self.prompt | self.llm
            response = chain.invoke({
                "messages": messages,
                "input": input_text
            })
            
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            proposal = json.loads(content)
            
            state['mapping_proposals'].append(proposal)
            state['messages'].append(HumanMessage(content=input_text))
            state['messages'].append(AIMessage(content=response.content))
            
            logger.info(f"Mapping proposed: {proposal['selected_eldm_attribute']} "
                       f"(confidence: {proposal['confidence_score']:.3f})")
            
        except Exception as e:
            logger.error(f"Error in propose_mapping: {e}")
            proposal = {
                'selected_eldm_attribute': candidates[0]['name'],
                'confidence_score': candidates[0]['similarity'],
                'reasoning': f"Fallback to top candidate due to error: {str(e)}",
                'key_factors': ['semantic_similarity'],
                'concerns': ['Error in reasoning agent'],
                'retrieval_method_used': candidates[0].get('method', 'UNKNOWN')
            }
            state['mapping_proposals'].append(proposal)
        
        return state


class ValidationAgent:
    """Agent responsible for validating proposed mappings"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=REASONING_MODEL,
            base_url=BASE_URL,
            api_key=API_KEY
        )
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", VALIDATION_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])
        logger.info("Initialized ValidationAgent")
    
    def validate_mapping(self, state: GraphState) -> GraphState:
        """Validate the proposed mapping"""
        field = state['transaction_field']
        proposals = state['mapping_proposals']
        
        if not proposals:
            logger.warning("No proposals to validate")
            return state
        
        latest_proposal = proposals[-1]
        
        # Find the candidate details from all search results
        all_candidates = (state.get('graph_rag_candidates', []) + 
                         state.get('hybrid_candidates', []) + 
                         state.get('vector_candidates', []))
        
        selected_candidate = next(
            (c for c in all_candidates if c['name'] == latest_proposal['selected_eldm_attribute']),
            all_candidates[0] if all_candidates else {'name': 'Unknown', 'description': '', 'entity_attribute_path': ''}
        )
        
        input_text = f"""
Validation Request:

Transaction Field:
{field.get_context()}

Proposed ELDM Mapping:
- Attribute Name: {latest_proposal['selected_eldm_attribute']}
- Description: {selected_candidate['description']}
- Entity Path: {selected_candidate['entity_attribute_path']}
- Retrieval Method: {selected_candidate.get('method', 'UNKNOWN')}
"""
        
        if selected_candidate.get('method') == 'GRAPH_RAG':
            input_text += f"""
- Historical Context: {selected_candidate.get('mapping_frequency', 0)} similar fields previously mapped
- Average Historical Confidence: {selected_candidate.get('avg_confidence', 0.0):.3f}
"""
        
        input_text += f"""
Mapping Agent's Reasoning:
{latest_proposal['reasoning']}

Mapping Agent's Confidence: {latest_proposal['confidence_score']:.3f}
Key Factors: {', '.join(latest_proposal['key_factors'])}
Stated Concerns: {', '.join(latest_proposal['concerns'])}

Please validate this mapping. Your response must be a JSON object with this exact structure:
{{
    "validation_decision": "APPROVE|NEEDS_REVIEW|REJECT",
    "validation_score": 0.0-1.0,
    "validation_reasoning": "detailed validation analysis",
    "identified_issues": ["issue1", "issue2"],
    "strengths": ["strength1", "strength2"],
    "recommendations": "any recommendations for improvement"
}}
"""
        
        try:
            messages = state.get('messages', [])
            chain = self.prompt | self.llm
            response = chain.invoke({
                "messages": messages,
                "input": input_text
            })
            
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            validation = json.loads(content)
            
            state['validation_results'].append(validation)
            state['messages'].append(HumanMessage(content=input_text))
            state['messages'].append(AIMessage(content=response.content))
            
            logger.info(f"Validation complete: {validation['validation_decision']} "
                       f"(score: {validation['validation_score']:.3f})")
            
        except Exception as e:
            logger.error(f"Error in validate_mapping: {e}")
            validation = {
                'validation_decision': 'NEEDS_REVIEW',
                'validation_score': 0.6,
                'validation_reasoning': f"Unable to complete validation due to error: {str(e)}",
                'identified_issues': ['Validation error'],
                'strengths': [],
                'recommendations': 'Manual review required'
            }
            state['validation_results'].append(validation)
        
        return state


class SupervisorAgent:
    """Agent responsible for final mapping decisions"""
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=REASONING_MODEL,
            base_url=BASE_URL,
            api_key=API_KEY
        )
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", SUPERVISOR_AGENT_SYSTEM_PROMPT),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])
        logger.info("Initialized SupervisorAgent")
    
    def make_final_decision(self, state: GraphState) -> GraphState:
        """Make the final mapping decision"""
        field = state['transaction_field']
        proposals = state['mapping_proposals']
        validations = state['validation_results']
        
        if not proposals or not validations:
            logger.error("Missing proposals or validations for final decision")
            return state
        
        latest_proposal = proposals[-1]
        latest_validation = validations[-1]
        
        # Get all candidates to find the selected one
        all_candidates = (state.get('graph_rag_candidates', []) + 
                         state.get('hybrid_candidates', []) + 
                         state.get('vector_candidates', []))
        
        selected_candidate = next(
            (c for c in all_candidates if c['name'] == latest_proposal['selected_eldm_attribute']),
            all_candidates[0] if all_candidates else None
        )
        
        if not selected_candidate:
            logger.error("Could not find selected candidate")
            return state
        
        # Calculate statistical metrics
        all_similarities = [c['similarity'] for c in all_candidates]
        z_scores = zscore(all_similarities) if len(all_similarities) > 1 else [0.0]
        top_similarity = selected_candidate['similarity']
        top_z_score = float(z_scores[0]) if all_similarities and all_similarities[0] == top_similarity else 0.0
        
        gap_to_second = top_similarity - all_similarities[1] if len(all_similarities) > 1 else top_similarity
        
        statistical_metrics = {
            'semantic_similarity': top_similarity,
            'z_score': top_z_score,
            'gap_to_second_best': gap_to_second,
            'rank_position': 1,
            'percentile': 100.0
        }
        
        input_text = f"""
Final Decision Required:

Transaction Field: {field.tt_column_name}

Mapping Proposal:
- ELDM Attribute: {latest_proposal['selected_eldm_attribute']}
- Agent Confidence: {latest_proposal['confidence_score']:.3f}
- Retrieval Method: {selected_candidate.get('method', 'UNKNOWN')}
- Reasoning: {latest_proposal['reasoning']}

Validation Results:
- Decision: {latest_validation['validation_decision']}
- Validation Score: {latest_validation['validation_score']:.3f}
- Reasoning: {latest_validation['validation_reasoning']}
- Issues: {', '.join(latest_validation['identified_issues'])}

Statistical Metrics:
- Similarity Score: {statistical_metrics['semantic_similarity']:.4f}
- Z-Score: {statistical_metrics['z_score']:.4f}
- Gap to 2nd Best: {statistical_metrics['gap_to_second_best']:.4f}
"""
        
        if selected_candidate.get('method') == 'GRAPH_RAG':
            input_text += f"""
Graph RAG Context:
- Historical Mappings: {selected_candidate.get('mapping_frequency', 0)}
- Graph Boost Score: {selected_candidate.get('graph_rag_score', 0.0):.4f}
"""
        
        input_text += """
Make your final decision. Response must be a JSON object with this structure:
{
    "final_decision": "APPROVE|REJECT",
    "confidence_level": "HIGH|MEDIUM|LOW|REJECTED",
    "overall_confidence_score": 0.0-1.0,
    "reasoning": "comprehensive decision reasoning",
    "action_required": "description of any required action"
}
"""
        
        try:
            messages = state.get('messages', [])
            chain = self.prompt | self.llm
            response = chain.invoke({
                "messages": messages,
                "input": input_text
            })
            
            content = response.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()
            
            decision = json.loads(content)
            
            if decision['final_decision'] == 'APPROVE':
                result = MappingResult(
                    transaction_field=field.tt_column_name,
                    eldm_attribute=latest_proposal['selected_eldm_attribute'],
                    confidence_score=decision['overall_confidence_score'],
                    vector_similarity=selected_candidate.get('vector_score', selected_candidate['similarity']),
                    fulltext_score=selected_candidate.get('fulltext_score', 0.0),
                    hybrid_score=selected_candidate.get('similarity', 0.0),
                    graph_rag_score=selected_candidate.get('graph_rag_score', 0.0),
                    reasoning_confidence=latest_proposal['confidence_score'],
                    validation_score=latest_validation['validation_score'],
                    reasoning_explanation=latest_proposal['reasoning'],
                    validation_notes=latest_validation['validation_reasoning'],
                    statistical_metrics=statistical_metrics,
                    confidence_level=decision['confidence_level'],
                    retrieval_method=selected_candidate.get('method', 'UNKNOWN'),
                    timestamp=datetime.now().isoformat()
                )
                state['final_mapping'] = result
                logger.info(f"Final decision: APPROVED - {result.eldm_attribute} "
                           f"({result.confidence_level} confidence: {result.confidence_score:.3f}) "
                           f"via {result.retrieval_method}")
            else:
                logger.info(f"Final decision: REJECTED - {latest_proposal['selected_eldm_attribute']}")
            
            state['messages'].append(HumanMessage(content=input_text))
            state['messages'].append(AIMessage(content=response.content))
            
        except Exception as e:
            logger.error(f"Error in make_final_decision: {e}")
            result = MappingResult(
                transaction_field=field.tt_column_name,
                eldm_attribute=latest_proposal['selected_eldm_attribute'],
                confidence_score=0.5,
                vector_similarity=selected_candidate.get('vector_score', selected_candidate['similarity']),
                fulltext_score=selected_candidate.get('fulltext_score', 0.0),
                hybrid_score=selected_candidate.get('similarity', 0.0),
                graph_rag_score=selected_candidate.get('graph_rag_score', 0.0),
                reasoning_confidence=latest_proposal['confidence_score'],
                validation_score=latest_validation['validation_score'],
                reasoning_explanation=latest_proposal['reasoning'],
                validation_notes=latest_validation['validation_reasoning'],
                statistical_metrics=statistical_metrics,
                confidence_level='MEDIUM',
                retrieval_method=selected_candidate.get('method', 'UNKNOWN'),
                timestamp=datetime.now().isoformat()
            )
            state['final_mapping'] = result
        
        return state


# ============================================================================
# LANGGRAPH WORKFLOW
# ============================================================================

def create_mapping_workflow() -> StateGraph:
    """Create the LangGraph workflow for field mapping"""
    
    mapping_agent = MappingAgent()
    validation_agent = ValidationAgent()
    supervisor_agent = SupervisorAgent()
    
    workflow = StateGraph(GraphState)
    
    workflow.add_node("propose_mapping", mapping_agent.propose_mapping)
    workflow.add_node("validate_mapping", validation_agent.validate_mapping)
    workflow.add_node("final_decision", supervisor_agent.make_final_decision)
    
    workflow.set_entry_point("propose_mapping")
    workflow.add_edge("propose_mapping", "validate_mapping")
    workflow.add_edge("validate_mapping", "final_decision")
    workflow.add_edge("final_decision", END)
    
    memory = MemorySaver()
    app = workflow.compile(checkpointer=memory)
    
    logger.info("Created LangGraph workflow with memory management")
    return app


# ============================================================================
# MAIN MAPPING SYSTEM
# ============================================================================

class ELDMMappingSystem:
    """Complete ELDM field mapping system with Graph RAG"""
    
    def __init__(self):
        self.embedding_service = EmbeddingService()
        self.graph_rag = ELDMGraphRAG()
        self.workflow = create_mapping_workflow()
        logger.info("Initialized Advanced ELDM Mapping System with Graph RAG")
    
    def load_transaction_data(self) -> List[TransactionField]:
        """Load transaction data from Excel"""
        logger.info(f"Loading transaction data from {TRANSACTION_FILE}")
        df = pd.read_excel(TRANSACTION_FILE)
        
        fields = []
        for _, row in df.iterrows():
            field = TransactionField(
                tt_file_name=str(row['TT File name']),
                tt_column_name=str(row['TT COLUMN/FIELD Name']),
                standardised_name=str(row.get('Standardised Name', '')),
                is_primary_key=bool(row.get('PK', False)),
                comment=str(row.get('Comment', '')),
                data_type=str(row.get('DataType', '')),
                creation_sql=str(row.get('Creation', '')),
                transformation_sql=str(row.get('Transformation', ''))
            )
            fields.append(field)
        
        logger.info(f"Loaded {len(fields)} transaction fields")
        return fields
    
    def load_eldm_data(self) -> List[ELDMAttribute]:
        """Load ELDM data from Excel and create embeddings"""
        logger.info(f"Loading ELDM data from {ELDM_FILE}")
        df = pd.read_excel(ELDM_FILE)
        
        attributes = []
        for _, row in df.iterrows():
            attr = ELDMAttribute(
                name=str(row['Name']),
                description=str(row.get('Description', '')),
                entity_attribute_path=str(row.get('ELDM Entity owns ELDM Attribute > Name', ''))
            )
            attributes.append(attr)
        
        logger.info("Creating embeddings for ELDM attributes...")
        texts = [attr.get_searchable_text() for attr in attributes]
        
        for i in range(0, len(texts), BATCH_SIZE):
            batch_texts = texts[i:i+BATCH_SIZE]
            batch_embeddings = self.embedding_service.create_embeddings_batch(batch_texts)
            
            for j, embedding in enumerate(batch_embeddings):
                attributes[i+j].embedding = embedding
            
            logger.info(f"Created embeddings for batch {i//BATCH_SIZE + 1}")
        
        logger.info(f"Loaded {len(attributes)} ELDM attributes with embeddings")
        return attributes
    
    def initialize_knowledge_graph(self):
        """Initialize FalkorDB with ELDM attributes and indexes"""
        logger.info("Initializing Graph RAG knowledge graph...")
        
        self.graph_rag.clear_graph()
        
        eldm_attributes = self.load_eldm_data()
        self.graph_rag.store_eldm_attributes_batch(eldm_attributes)
        
        # Create vector and full-text indexes
        self.graph_rag.create_indexes()
        
        logger.info("Graph RAG knowledge graph initialized with vector and full-text indexes")
    
    def map_single_field(self, field: TransactionField) -> Optional[MappingResult]:
        """Map a single transaction field using multi-modal retrieval"""
        logger.info(f"Mapping field: {field.tt_column_name}")
        
        # Create embedding for the transaction field
        field_text = field.get_searchable_text()
        field_embedding = self.embedding_service.create_embedding(field_text)
        
        # Perform multi-modal search
        logger.info("Performing multi-modal retrieval...")
        
        # 1. Vector search
        vector_candidates = self.graph_rag.vector_search(field_embedding, TOP_K_CANDIDATES)
        
        # 2. Full-text search
        fulltext_candidates = self.graph_rag.fulltext_search(field_text, TOP_K_CANDIDATES)
        
        # 3. Hybrid search
        hybrid_candidates = self.graph_rag.hybrid_search(
            field_embedding, field_text, TOP_K_CANDIDATES, HYBRID_SEARCH_ALPHA
        )
        
        # 4. Graph RAG search (relationship-aware)
        graph_rag_candidates = self.graph_rag.graph_rag_search(
            field_embedding, field_text, field, TOP_K_CANDIDATES
        )
        
        # Initialize state for the workflow
        initial_state = {
            'transaction_field': field,
            'vector_candidates': vector_candidates,
            'fulltext_candidates': fulltext_candidates,
            'hybrid_candidates': hybrid_candidates,
            'graph_rag_candidates': graph_rag_candidates,
            'final_candidates': graph_rag_candidates,  # Prioritize Graph RAG
            'mapping_proposals': [],
            'validation_results': [],
            'final_mapping': None,
            'messages': [],
            'iteration_count': 0,
            'memory_context': {
                'sql_context': {
                    'creation': field.creation_sql,
                    'transformation': field.transformation_sql
                },
                'lineage': {
                    'file': field.tt_file_name,
                    'standardised_name': field.standardised_name
                }
            }
        }
        
        # Execute workflow
        try:
            config = {"configurable": {"thread_id": field.tt_column_name}}
            result = self.workflow.invoke(initial_state, config)
            
            final_mapping = result.get('final_mapping')
            
            if final_mapping:
                # Store in knowledge graph with relationships
                self.graph_rag.store_mapping_result(final_mapping, field)
                logger.info(f"Successfully mapped: {field.tt_column_name} -> {final_mapping.eldm_attribute} "
                           f"(method: {final_mapping.retrieval_method})")
                return final_mapping
            else:
                logger.warning(f"No mapping approved for: {field.tt_column_name}")
                return None
                
        except Exception as e:
            logger.error(f"Error mapping field {field.tt_column_name}: {e}")
            return None
    
    def map_all_fields(self) -> List[MappingResult]:
        """Map all transaction fields"""
        logger.info("Starting batch mapping process with Graph RAG...")
        
        fields = self.load_transaction_data()
        
        results = []
        for i, field in enumerate(fields, 1):
            logger.info(f"Processing field {i}/{len(fields)}: {field.tt_column_name}")
            
            result = self.map_single_field(field)
            if result:
                results.append(result)
            
            if i % 10 == 0:
                logger.info(f"Progress: {i}/{len(fields)} fields processed, "
                           f"{len(results)} successful mappings")
        
        logger.info(f"Mapping complete. {len(results)} successful mappings out of {len(fields)} fields")
        return results
    
    def export_results(self, results: List[MappingResult]):
        """Export mapping results to Excel"""
        logger.info(f"Exporting results to {OUTPUT_FILE}")
        
        data = []
        for result in results:
            row = {
                'Transaction Field': result.transaction_field,
                'ELDM Attribute': result.eldm_attribute,
                'Confidence Score': result.confidence_score,
                'Confidence Level': result.confidence_level,
                'Retrieval Method': result.retrieval_method,
                'Vector Similarity': result.vector_similarity,
                'Full-Text Score': result.fulltext_score,
                'Hybrid Score': result.hybrid_score,
                'Graph RAG Score': result.graph_rag_score,
                'Reasoning Confidence': result.reasoning_confidence,
                'Validation Score': result.validation_score,
                'Z-Score': result.statistical_metrics['z_score'],
                'Gap to 2nd Best': result.statistical_metrics['gap_to_second_best'],
                'Reasoning Explanation': result.reasoning_explanation,
                'Validation Notes': result.validation_notes,
                'Timestamp': result.timestamp
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        
        with pd.ExcelWriter(OUTPUT_FILE, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Mapping Results', index=False)
            
            # Summary statistics by retrieval method
            summary = {
                'Total Mappings': len(results),
                'HIGH Confidence': len([r for r in results if r.confidence_level == 'HIGH']),
                'MEDIUM Confidence': len([r for r in results if r.confidence_level == 'MEDIUM']),
                'LOW Confidence': len([r for r in results if r.confidence_level == 'LOW']),
                'Vector Method': len([r for r in results if r.retrieval_method == 'VECTOR']),
                'Full-Text Method': len([r for r in results if r.retrieval_method == 'FULLTEXT']),
                'Hybrid Method': len([r for r in results if r.retrieval_method == 'HYBRID']),
                'Graph RAG Method': len([r for r in results if r.retrieval_method == 'GRAPH_RAG']),
                'Avg Confidence Score': np.mean([r.confidence_score for r in results]),
                'Avg Vector Similarity': np.mean([r.vector_similarity for r in results]),
                'Avg Graph RAG Score': np.mean([r.graph_rag_score for r in results if r.graph_rag_score > 0])
            }
            summary_df = pd.DataFrame([summary])
            summary_df.to_excel(writer, sheet_name='Summary', index=False)
            
            logger.info(f"Results exported successfully to {OUTPUT_FILE}")
    
    def run(self):
        """Run the complete mapping pipeline"""
        logger.info("=" * 80)
        logger.info("Advanced ELDM Field Mapping System with Graph RAG - Starting")
        logger.info("=" * 80)
        
        try:
            self.initialize_knowledge_graph()
            results = self.map_all_fields()
            
            if results:
                self.export_results(results)
            
            logger.info("=" * 80)
            logger.info("Graph RAG Mapping System - Completed Successfully")
            logger.info("=" * 80)
            
            return results
            
        except Exception as e:
            logger.error(f"Error in mapping pipeline: {e}")
            raise


# ============================================================================
# USAGE EXAMPLE
# ============================================================================

if __name__ == "__main__":
    # You can override global variables from environment
    # BASE_URL = os.getenv("OPENAI_BASE_URL", BASE_URL)
    # API_KEY = os.getenv("OPENAI_API_KEY", API_KEY)
    
    system = ELDMMappingSystem()
    results = system.run()
    
    print(f"\n✅ Graph RAG Mapping completed!")
    print(f"📊 {len(results)} fields mapped successfully")
    print(f"📈 Results exported to: {OUTPUT_FILE}")
    
    # Print retrieval method distribution
    methods = {}
    for r in results:
        methods[r.retrieval_method] = methods.get(r.retrieval_method, 0) + 1
    
    print("\n🔍 Retrieval Method Distribution:")
    for method, count in methods.items():
        print(f"   {method}: {count} mappings ({count/len(results)*100:.1f}%)")
