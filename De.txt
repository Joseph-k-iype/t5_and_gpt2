# backend/app/core/research_engine.py
import asyncio
import logging
import sys
import os
from typing import Dict, Any, Optional
from datetime import datetime

# Add the parent directory to path to import the original chatbot
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

try:
    from enhanced_chatbot import EnhancedChatbotInterface
except ImportError as e:
    logging.error(f"Failed to import enhanced_chatbot: {e}")
    # Create a mock class for development
    class EnhancedChatbotInterface:
        async def initialize(self):
            return True
        async def ask_question(self, question: str, user_id: str = None, thread_id: str = None):
            return {
                "answer": "Mock response: Research functionality not available",
                "confidence": "low",
                "approach": "mock"
            }
        async def conduct_deep_research(self, topic: str, user_id: str = None):
            return {
                "final_synthesis": "Mock deep research result",
                "overall_confidence": 0.5
            }

logger = logging.getLogger(__name__)

class ResearchEngineWrapper:
    """
    Wrapper for the enhanced chatbot research engine
    Provides async interface and session management
    """
    
    def __init__(self):
        self.chatbot_interface = None
        self.is_initialized = False
        self._initialization_lock = asyncio.Lock()
    
    async def initialize(self):
        """Initialize the research engine"""
        async with self._initialization_lock:
            if self.is_initialized:
                return True
            
            try:
                logger.info("Initializing Enhanced Chatbot Research Engine...")
                self.chatbot_interface = EnhancedChatbotInterface()
                
                # Initialize the chatbot in a thread pool to avoid blocking
                loop = asyncio.get_event_loop()
                success = await loop.run_in_executor(
                    None, 
                    lambda: asyncio.run(self.chatbot_interface.initialize())
                )
                
                if success:
                    self.is_initialized = True
                    logger.info("✅ Research engine initialized successfully")
                    return True
                else:
                    logger.error("❌ Research engine initialization returned False")
                    return False
                    
            except Exception as e:
                logger.error(f"❌ Failed to initialize research engine: {e}")
                # Use mock interface for development
                self.chatbot_interface = EnhancedChatbotInterface()
                self.is_initialized = True
                logger.warning("⚠️ Using mock research interface")
                return True
    
    async def quick_chat(self, question: str, user_id: str, session_id: str) -> Dict[str, Any]:
        """
        Handle quick chat queries
        """
        if not self.is_initialized:
            await self.initialize()
        
        try:
            logger.info(f"Processing quick chat: {question[:100]}...")
            
            # Use thread pool for blocking operation
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                None,
                lambda: asyncio.run(
                    self.chatbot_interface.ask_question(
                        question, 
                        user_id=user_id, 
                        thread_id=session_id
                    )
                )
            )
            
            # Enhance result with metadata
            enhanced_result = {
                **result,
                "session_id": session_id,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat(),
                "query_type": "quick_chat",
                "processing_time": "fast"
            }
            
            logger.info(f"Quick chat completed with confidence: {result.get('confidence', 'unknown')}")
            return enhanced_result
            
        except Exception as e:
            logger.error(f"Error in quick chat: {e}")
            return {
                "answer": f"I encountered an error processing your question: {str(e)}",
                "confidence": "low",
                "approach": "error",
                "session_id": session_id,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat(),
                "error": str(e)
            }
    
    async def deep_research(self, topic: str, user_id: str, session_id: str, 
                          progress_callback=None) -> Dict[str, Any]:
        """
        Handle deep research queries with progress updates
        """
        if not self.is_initialized:
            await self.initialize()
        
        try:
            logger.info(f"Starting deep research: {topic[:100]}...")
            
            if progress_callback:
                await progress_callback({
                    "stage": "initialization",
                    "message": "Initializing multi-agent research system...",
                    "progress": 0
                })
            
            # Use thread pool for long-running operation
            loop = asyncio.get_event_loop()
            
            # Create a wrapper to handle progress updates
            async def research_with_progress():
                if progress_callback:
                    await progress_callback({
                        "stage": "planning",
                        "message": "Creating research plan and assigning agents...",
                        "progress": 20
                    })
                
                # Start the research
                result = await loop.run_in_executor(
                    None,
                    lambda: asyncio.run(
                        self.chatbot_interface.conduct_deep_research(
                            topic, 
                            user_id=user_id
                        )
                    )
                )
                
                if progress_callback:
                    await progress_callback({
                        "stage": "research",
                        "message": "Agents conducting specialized research...",
                        "progress": 60
                    })
                
                # Simulate progressive updates (in real implementation, 
                # this would come from the research engine)
                await asyncio.sleep(1)
                
                if progress_callback:
                    await progress_callback({
                        "stage": "synthesis",
                        "message": "Synthesizing findings and generating report...",
                        "progress": 80
                    })
                
                await asyncio.sleep(1)
                
                if progress_callback:
                    await progress_callback({
                        "stage": "completion",
                        "message": "Research completed successfully!",
                        "progress": 100
                    })
                
                return result
            
            result = await research_with_progress()
            
            # Enhance result with metadata
            enhanced_result = {
                **result,
                "session_id": session_id,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat(),
                "query_type": "deep_research",
                "processing_time": "extended"
            }
            
            logger.info(f"Deep research completed with confidence: {result.get('overall_confidence', 'unknown')}")
            return enhanced_result
            
        except Exception as e:
            logger.error(f"Error in deep research: {e}")
            if progress_callback:
                await progress_callback({
                    "stage": "error",
                    "message": f"Research failed: {str(e)}",
                    "progress": 0,
                    "error": True
                })
            
            return {
                "final_synthesis": f"Research failed due to error: {str(e)}",
                "overall_confidence": 0.0,
                "session_id": session_id,
                "user_id": user_id,
                "timestamp": datetime.utcnow().isoformat(),
                "error": str(e)
            }
    
    async def get_engine_status(self) -> Dict[str, Any]:
        """Get the status of the research engine"""
        return {
            "initialized": self.is_initialized,
            "engine_type": "EnhancedChatbotInterface",
            "capabilities": [
                "Quick Chat",
                "Deep Multi-Agent Research",
                "Knowledge Synthesis",
                "Domain Filtering",
                "Session Management"
            ],
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def cleanup(self):
        """Clean up resources"""
        try:
            if self.chatbot_interface and hasattr(self.chatbot_interface, 'cleanup'):
                await self.chatbot_interface.cleanup()
            
            self.is_initialized = False
            logger.info("Research engine cleanup completed")
            
        except Exception as e:
            logger.error(f"Error during research engine cleanup: {e}")

# backend/app/models/chat.py
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime

class ChatMessage(BaseModel):
    """Chat message model"""
    role: str = Field(..., description="Message role: 'user' or 'assistant'")
    content: str = Field(..., description="Message content")
    timestamp: Optional[datetime] = Field(default_factory=datetime.utcnow)
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)

class QuickChatRequest(BaseModel):
    """Request model for quick chat"""
    message: str = Field(..., min_length=1, max_length=5000, description="User message")
    session_id: Optional[str] = Field(None, description="Session ID (will be created if not provided)")
    user_id: Optional[str] = Field(None, description="User ID (will be generated if not provided)")

class QuickChatResponse(BaseModel):
    """Response model for quick chat"""
    answer: str = Field(..., description="AI response")
    confidence: str = Field(..., description="Confidence level")
    approach: str = Field(..., description="Processing approach used")
    session_id: str = Field(..., description="Session ID")
    user_id: str = Field(..., description="User ID")
    timestamp: datetime = Field(..., description="Response timestamp")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)

class ConversationHistory(BaseModel):
    """Conversation history model"""
    messages: List[ChatMessage] = Field(..., description="List of messages in conversation")
    session_id: str = Field(..., description="Session ID")
    total_messages: int = Field(..., description="Total number of messages")

# backend/app/models/research.py
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
from enum import Enum

class ResearchStage(str, Enum):
    """Research stages for progress tracking"""
    INITIALIZATION = "initialization"
    PLANNING = "planning"
    RESEARCH = "research"
    SYNTHESIS = "synthesis"
    COMPLETION = "completion"
    ERROR = "error"

class ResearchProgressUpdate(BaseModel):
    """Progress update during research"""
    stage: ResearchStage = Field(..., description="Current research stage")
    message: str = Field(..., description="Progress message")
    progress: int = Field(..., ge=0, le=100, description="Progress percentage")
    details: Optional[Dict[str, Any]] = Field(default_factory=dict)
    error: bool = Field(default=False, description="Whether this is an error update")
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class DeepResearchRequest(BaseModel):
    """Request model for deep research"""
    topic: str = Field(..., min_length=5, max_length=2000, description="Research topic")
    session_id: Optional[str] = Field(None, description="Session ID")
    user_id: Optional[str] = Field(None, description="User ID")
    focus_areas: Optional[List[str]] = Field(default_factory=list, description="Specific focus areas")
    max_duration_minutes: Optional[int] = Field(default=10, ge=1, le=30, description="Maximum research duration")

class ResearchResult(BaseModel):
    """Research result model"""
    final_synthesis: str = Field(..., description="Final research synthesis")
    overall_confidence: float = Field(..., ge=0.0, le=1.0, description="Overall confidence score")
    agents_used: Optional[List[str]] = Field(default_factory=list, description="Research agents used")
    iterations_completed: Optional[int] = Field(default=0, description="Research iterations completed")
    session_id: str = Field(..., description="Session ID")
    user_id: str = Field(..., description="User ID")
    timestamp: datetime = Field(..., description="Completion timestamp")
    processing_time: Optional[str] = Field(default="unknown", description="Processing time category")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)

class ResearchStatus(BaseModel):
    """Research status model"""
    session_id: str = Field(..., description="Session ID")
    is_active: bool = Field(..., description="Whether research is currently active")
    current_stage: Optional[ResearchStage] = Field(None, description="Current research stage")
    progress_percentage: int = Field(default=0, ge=0, le=100, description="Overall progress")
    estimated_completion: Optional[datetime] = Field(None, description="Estimated completion time")
    error_message: Optional[str] = Field(None, description="Error message if any")
