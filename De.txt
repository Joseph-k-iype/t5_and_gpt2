from langchain.chains import LLMChain
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor

def _setup_agent(self) -> None:
    try:
        # 1) Define Tools
        def _graph_qa(query: str) -> str:
            return self.graph_qa_chain.run(query)

        def _vectorstore_search(query: str) -> str:
            results = self.vs.similarity_search_with_score(query, k=3)
            if not results:
                return "No relevant matches found."
            lines = []
            for idx, (doc, score) in enumerate(results, start=1):
                confidence = max(0.0, min(1.0, 1.0 - score))
                rating = "Green" if confidence >= 0.8 else ("Amber" if confidence >= 0.5 else "Red")
                reason = (
                    f"Confidence={confidence:.2f}, rating={rating}. "
                    f"Matched: {doc.page_content}"
                )
                line = (
                    f"Match #{idx}\n"
                    f"Name: {doc.metadata.get('name', 'Unknown')}\n"
                    f"ID: {doc.metadata.get('id', 'No ID')}\n"
                    f"Confidence: {confidence:.2f}\n"
                    f"Rating: {rating}\n"
                    f"Reason: {reason}\n"
                )
                lines.append(line)
            return "\n".join(lines)

        graph_tool = Tool(
            name="GraphQATool",
            func=_graph_qa,
            description="Query the knowledge graph for relationships or definitions."
        )
        vs_tool = Tool(
            name="VectorStoreSearch",
            func=_vectorstore_search,
            description="Semantic search with confidence, rating, reason."
        )
        self.tools = [graph_tool, vs_tool]

        # 2) Create a prompt using ZeroShotAgent's helper
        prefix = "You are an AI assistant with these tools available:"
        suffix = "Begin!"
        prompt = ZeroShotAgent.create_prompt(
            tools=self.tools,
            prefix=prefix,
            suffix=suffix,
            input_variables=["input"]
        )

        # 3) Build an LLMChain from your LLM + prompt
        llm_chain = LLMChain(llm=self.llm, prompt=prompt)

        # 4) Construct ZeroShotAgent with llm_chain (keyword argument),
        #    not passing your LLM or Tools positionally.
        agent = ZeroShotAgent(
            llm_chain=llm_chain,     # <--- correct
            tools=self.tools,
            verbose=True
        )

        # 5) Create an AgentExecutor
        self.agent_executor = AgentExecutor.from_agent_and_tools(
            agent=agent,
            tools=self.tools,
            verbose=True
        )

        logger.info("Multi-tool RAG agent created successfully")

    except Exception as e:
        logger.error(f"Failed to set up RAG agent: {str(e)}")
        raise
